{"./":{"url":"./","title":"兔比喃波湾","keywords":"","body":"😂 😂 😂 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"2b问题合集/2b问题合集之ssh密钥问题.html":{"url":"2b问题合集/2b问题合集之ssh密钥问题.html","title":"ssh密钥问题","keywords":"","body":"2b问题合集之ssh密钥问题 一、ucloud免密登陆问题 背景说明： ucloud云主机，想要使用密钥登陆，提ucloud工单得到回复ucloud并不支持在web界面创建密钥并绑定(华为云、腾讯云、阿里云都支持web界面创建绑定)，只能登陆系统手动创建并下载密钥，于是root用户登陆ucloud云主机手动执行命令ssh-keygen，下载id_rsa私钥到本地，结果使用这个私钥始终无法登陆系统，还特么又提了1个ucloud工单问人家怎么回事(虽然还遇到一个哥们给我回复把私钥权限改成755试试。。。)，最终工单回复密钥未注册，请自行排查，最后折腾半天找到答案 原因如下： ⚠️centos7ssh服务配置文件/etc/ssh/sshd_config中有一项配置是AuthorizedKeysFile .ssh/authorized_keys，如果想要使用私钥免密登陆，则公钥必须写入到文件.ssh/authorized_keys中，即注册私钥，否则免密会失败！！！ 手动执行命令cat id_rsa.pub >> authorized_keys，把公钥注册后问题解决 二、mac推送仓库到码云 背景说明： mac本机，在根目录下创建了一个目录，准备把这个目录下的内容推送到码云新建的仓库中，已经手动把user用户的公钥粘贴到了码云的个人账户中(码云中只有把公钥放到个人账户中才能对仓库有写权限)，但是推送的时候始终提示权限拒绝，而使用命令ssh -T git@gitee.com确是提示认证成功的 原因是推送的时候使用了sudo，用到的因该是root用户的密钥，但是只把user用户的公钥放到了码云中，所以权限拒绝，把root用户的公钥放到码云中就可以了 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux命令/date命令.html":{"url":"linux/linux命令/date命令.html","title":"date命令","keywords":"","body":"date命令 1.命令说明 date命令根据给定格式显示日期或设置系统日期时间，print or set the system date and time centos7中date命令所在路径 [root@aliyun ~]# which date /usr/bin/date 2.命令格式 date [OPTION]…[+FORMAT] date [选项] [格式] 3.常用选项 3.1 -d 根据描述显示指定日期 //查看当前系统日期 [root@test1 ~]# date Mon Aug 20 21:15:32 CST 2018 //设置时间为一天前 [root@test1 ~]# date -d \"-1 day\" Sun Aug 19 21:15:34 CST 2018 3.2 -s 手动设置时间 //手动设置时间 [root@test1 ~]# date -s '2022-2-22 22:22:22' Tue Feb 22 22:22:22 CST 2022 //查看当前时间 [root@test1 ~]# date Tue Feb 22 22:22:22 CST 2022 4.常用输出 4.1 +%F 输出日期 [root@test ~]# date +%F 2018-08-29 4.2 +%T 输出时间 [root@test1 ~]# date +%T 10:08:38 4.3 +%j 输出当前天是一年中的第几天 [root@test1 ~]# date +%j 251 4.4 +%w 输出星期 ⚠️0表示周日 [root@test1 ~]# date +%w 1 4.5 +%s 1970-01-01 00:00:00 开始到现在经过的秒数 [root@test1 ~]# date +%s 1535508552 5.其他输出 5.1年份相关 5.1.1 +%Y 输出年份(4位数) [root@test1 ~]# date +%Y 2018 5.1.2 +%y 输出年份(00-99表示) [root@test1 ~]# date +%y 18 5.2月份相关 5.2.1 +%m 输出月份(0-12表示) [root@test1 ~]# date +%m 08 5.2.2 +%b 月份英文缩写 [root@test1 ~]# date +%b Aug 5.2.3 +%B 月份英文全写 [root@test1 ~]# date +%B August 5.3日期相关 5.3.1 +%w 输出星期(0代表周日) [root@test1 ~]# date +%w 3 5.3.2 +%c 输出日期(与date命令输出稍微有差别) [root@test1 ~]# date +%c Wed 29 Aug 2018 10:11:12 AM CST [root@test1 ~]# date Wed Aug 29 10:11:12 CST 2018 5.3.3 +%d 输出日期(1-31表示) [root@test1 ~]# date +%d 29 5.3.4 +%D 输出日期(月/日/年) [root@test1 ~]# date +%D 08/29/18 5.4星期相关 5.4.1 +%a 输出星期(英文缩写) [root@test1 ~]# date +%a Wed 5.4.2 +%A 输出星期(英文全称) [root@test1 ~]# date +%A Wednesday 5.4.3 +%W 输出星期(数字表示) [root@test1 ~]# date +%w 3 5.5小时相关 5.5.1 +%H、+%k 输出小时(00-23表示) [root@test1 ~]# date +%H 10 [root@test1 ~]# date +%k 10 5.5.2 +%l 输出小时(01-12表示) [root@test1 ~]# date +%l 10 5.6分钟相关 5.6.1 +%M 输出分钟(00-59表示) [root@test1 ~]# date +%M 30 5.7秒数相关 5.7.1 +%S 输出秒数 [root@test1 ~]# date +%S 28 5.7.2 +%N 输出纳秒 纳秒nanoseconds (000000000..999999999) [root@test1 ~]# date +%N 121213066 5.8时区相关 5.8.1 +%Z 输出时区 CST表示中部标准时间 [root@test1 ~]# date +%Z CST 5.9其他相关 5.9.1 +%P、+%p 输出AM或者PM [root@test1 ~]# date +%p PM [root@test1 ~]# date +%P pm 5.9.2 +%r、+%X 输出时间(含时分秒，小时以12小时AM/PM来表示) [root@test1 ~]# date +%r 10:40:15 AM [root@test1 ~]# date +%X 10:40:25 AM 5.9.3 +%x 以月/日/年输出日期 [root@test1 ~]# date +%x 08/29/2018 5.9.4 +%n 输出时显示新的一行 //注意有两行 [root@test1 ~]# date +%n [root@test1 ~]# 5.9.5 +%t 输出时插入tab //有一个空行 [root@test1 ~]# date +%t [root@test1 ~]# 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux命令/xargs命令.html":{"url":"linux/linux命令/xargs命令.html","title":"xargs命令","keywords":"","body":"xargs命令 1.命令说明 xargs命令是给其他命令传递参数的一个过滤器，也是组合多个命令的一个工具。它擅长将标准输入数据转换成命令行参数，xargs能够处理管道或者stdin并将其转换成特定命令的命令参数。xargs也可以将单行或多行文本输入转换为其他格式，例如多行变单行，单行变多行。xargs的默认命令是echo，空格是默认定界符。这意味着通过管道传递给xargs的输入将会包含换行和空白，不过通过xargs的处理，换行和空白将被空格取代。xargs是构建单行命令的重要组件之一 2.命令选项 2.1 -d 指定分隔符 [root@test1 test]# echo 123@123@123|xargs 123@123@123 [root@test1 test]# echo 123@123@123|xargs -d@ 123 123 123 2.2 -n 指定参数输出列数 [root@test1 test]# echo 123 123 123 |xargs -n1 123 123 123 [root@test1 test]# echo 123 123 123 |xargs -n2 123 123 123 [root@test1 test]# echo 123 123 123 |xargs -n3 123 123 123 2.3 -p 询问是否执行命令 使用该选项之后xargs并不会马上执行其后面的命令，而是输出即将要执行的完整的命令(包括命令以及传递给命令的命令行参数)，询问是否执行，输入 y 才继续执行，否则不执行 [root@test1 test]# echo 123 | xargs -p sed 's#1#9#' sed s#1#9# 123 ?... 2.4 -E 指定一个字符串 当xargs解析出多个命令行参数的时候，如果搜索到-E指定的命令行参数，则只会将-E指定的命令行参数之前的参数(不包括-E指定的这个参数)传递给xargs后面的命令 ⚠️注意：-E只有在xargs不指定-d的时候有效，如果指定了-d则不起作用，而不管-d指定的是什么字符，空格也不行 [root@test1 test]# echo '11 22 33' | xargs -E '33' echo 11 22 指定-d选项，-E选项就失效了 [root@test1 test]# echo '11 22 33' | xargs -d ' ' -E '33' echo 11 22 33 2.5 -i 使管道前命令结果成为后续操作命令的参数 2.6 -0(数字0) 识别find结束标记 1.当前路径下的文件，文件名中包含空格 [root@test1 test]# ll total 0 -rw-r--r-- 1 root root 0 Aug 21 05:16 abc 01.jpg -rw-r--r-- 1 root root 0 Aug 21 05:16 abc 02.jpg -rw-r--r-- 1 root root 0 Aug 21 05:16 abc 03.jpg 2.find命令查找当前路径下这三个文件，会报错，因为find会认为含有空格的文件为两个文件 3.解决方法 方式一 让find命令给每个文件名的结束处加上一个结束标记 find . -type f -name \"*.jpg\" -print0|xargs -0 ls -l -print0 加上结束标记 xargs0 识别结束标记 方式二 find . -type f -name \"*.jpg\" |xargs -i ls -l {} 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux命令/rpm命令.html":{"url":"linux/linux命令/rpm命令.html","title":"rpm命令","keywords":"","body":"rpm命令 1.命令说明 rpm命令是RPM软件包的管理工具。 rpm原本是Red Hat Linux发行版专门用来管理Linux各项套件的程序，由于它遵循GPL规则且功能强大方便，因而广受欢迎。逐渐受到其他发行版的采用。 RPM套件管理方式的出现，让Linux易于安装，升级，间接提升了Linux的适用度。 2.命令格式 rpm 选项 参数 3.选项 3.1安装参数 -i 安装软件包 -v 显示详细信息 -h 显示安装进度 --nodeps 不验证软件包的依赖性 --force 强制安装，即使覆盖其他包的文件也安装 3.2卸载参数 -e 卸载软件包 3.3升级参数 -U 升级软件包 3.4查询参数 -a 查询所有 -q 查询已安装软件包 -c 仅列出配置文件 -l 列出包中文件信息，需配合-q参数 -f 查询指定文件属于哪个软件包，需配合-q参数 -p 查询未安装软件包信息 -i 查询软件包详细信息 -R 查询软件包依赖性 4.rpm软件包信息 rpm 包名字结构： glibc-2.17-196.el7_4.2.x86_64 glibc -2 .17 -196 -el7 x86 64 软件名 主版本号 次版本号 修订号 RHEL7 CPU架构平台 支持系统位数 5.rpm包中文件的提取 模拟cat命令被删除再到恢复 1.查找cat命令属于哪个文件 [root@test1 ~]# which cat /bin/cat 2.删除cat命令文件 [root@test1 ~]# rm -rf /bin/cat 3.rpm -qf /bin/cat [root@test1 ~]# rpm -qf /bin/cat coreutils-8.4-46.el6.x86_64 4.挂载光盘 [root@test1 ~]# mount /dev/sr0 /mnt mount: block device /dev/sr0 is write-protected, mounting read-only 5.恢复文件 [root@test1 ~]# rpm2cpio /mnt/Packages/coreutils-8.4-46.el6.x86_64.rpm |cpio -idv ./bin/cat ./bin/cat 25240 blocks rpm2cpio 将rpm包转换为cpio格式 cpio 是一种标准工具，它用于创建软件档案文件和从文件档案中提取文件 -i：copy-in模式 还原 -d：还原时自动新建目录 -v：显示还原过程 6.将当前目录恢复的cat文件移动到/bin/即可 [root@test1 ~]# cp bin/cat /bin 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux命令/echo命令.html":{"url":"linux/linux命令/echo命令.html","title":"echo命令","keywords":"","body":"echo命令 1.命令说明 echo命令用于在shell中打印shell变量的值，或者直接输出指定的字符串 2.命令格式 echo [选项] [参数] 3.常用选项 3.1 -n 不输出换行 [root@aliyun ~]# echo -n hehe hehe[root@aliyun ~]# 3.2 -e 使转移字符生效 \\n 换行且光标移至行首 \\c 最后不加上换行符号 \\t 插入tab \\e 转义 \\b 删除前一个字符 \\v 输出垂直制表符，与\\f输出结果相同 \\a 发出警告声 \\r 光标移至行首，但不换行 3.2.1 \\n 换行 [root@exercise1 ~]# echo -e 'hehe\\nhehe' hehe hehe 3.2.2 \\t 输出制表符 [root@exercise1 ~]# echo -e 'hehe\\thehe' hehe hehe 3.2.3 \\c 不换行 [root@exercise1 ~]# echo -e 'hehehehe\\c' hehehehe[root@exercise1 ~]# 3.2.4 \\v 垂直制表符 [root@exercise1 ~]# echo -e 'hehe\\vhehe' hehe hehe 3.2.5 \\e 转义 等同于\\033 \\e写法 \\033写法 4.bash里面的颜色 4.1设置前景颜色 写法 含义 [30m 将字符的显示颜色改为黑色 [31m 将字符的显示颜色改为红色 [32m 将字符的显示颜色改为绿色 [33m 将字符的显示颜色改为淡黄色 [34m 将字符的显示颜色改为蓝色 [35m 将字符的显示颜色改为紫色 [36m 将字符的显示颜色改为天蓝色 [37m 将字符的显示颜色改为灰色 4.2设置背景颜色 写法 含义 [40m 将背景色设置为黑色 [41m 将背景色设置为红色 [42m 将背景色设置为绿色 [43m 将背景色设置为淡黄色 [44m 将背景色设置为蓝色 [45m 将背景色设置为紫色 [46m 将背景色设置为淡蓝色 [47m 将背景色设置为灰色 windows终端下的效果 mac终端下的效果 4.3其他设置 编码 颜色/动作 0 重新设置属性到缺省设置 1 设置粗体 2 设置一半亮度（模拟彩色显示器的颜色） 4 设置下划线（模拟彩色显示器的颜色） 5 设置闪烁 7 设置反向图象 22 设置一般密度 24 关闭下划线 25 关闭闪烁 27 关闭反向图象 写法示例 5;31m 5表示设置闪烁 31m表示设置字体颜色为红色 [root@exercise1 ~]# echo -e \"\\033[5;31m呵呵\\033[0m\" 使用多个颜色设置的时候，使用分号分隔即可 \\033[31;47;1mhello world\\033[0m 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux命令/find命令.html":{"url":"linux/linux命令/find命令.html","title":"find命令","keywords":"","body":"find命令 1.命令说明 find命令用来在指定目录下查找文件。 任何位于参数之前的字符串都将被视为欲查找的目录名。如果使用该命令时，不设置任何参数，则find命令将在当前目录下查找子目录与文件。并且将查找到的子目录和文件全部进行显示 2.命令格式 find 查找范围 选项 操作 查找范围：默认当前目录 操作：默认输出到终端 3.命令选项 3.1 -name 按照文件名查找 [root@exercise1 ~]# pwd /root [root@exercise1 ~]# find -name *.log ./install.log 3.2 -size 按照文件大小查找 符号 + 大于 - 小于 不加符号是等于 文件大小单元 b ——>块（512字节） c ——>字节 w ——>字（2字节） k ——> 千字节 M ——>兆字节 G ——> G字节 //查找当前目录大小为110K的文件 [root@exercise1 tmp]# ll -h total 144K -rw-r--r-- 1 root root 11K Aug 9 13:35 1.1 -rw-r--r-- 1 root root 15K Aug 9 13:35 2.2 -rw-r--r-- 1 root root 110K Aug 9 13:35 3.3 -rw-r--r-- 1 root root 580 Aug 9 13:39 ip_date.txt [root@exercise1 tmp]# find . -size 110k ./3.3 //查找当前目录小于100K的文件 [root@exercise1 tmp]# ll -h total 144K -rw-r--r-- 1 root root 11K Aug 9 13:35 1.1 -rw-r--r-- 1 root root 15K Aug 9 13:35 2.2 -rw-r--r-- 1 root root 110K Aug 9 13:35 3.3 -rw-r--r-- 1 root root 812 Aug 9 13:41 ip_date.txt [root@exercise1 tmp]# find . -size -100k . ./1.1 ./ip_date.txt ./2.2 //查找当前目录大于100K的文件 [root@exercise1 tmp]# ll -h total 144K -rw-r--r-- 1 root root 11K Aug 9 13:35 1.1 -rw-r--r-- 1 root root 15K Aug 9 13:35 2.2 -rw-r--r-- 1 root root 110K Aug 9 13:35 3.3 -rw-r--r-- 1 root root 928 Aug 9 13:42 ip_date.txt [root@exercise1 tmp]# find . -size +100k ./3.3 //查找当前目录大于10k小于100k的文件 [root@exercise1 tmp]# ll -h total 144K -rw-r--r-- 1 root root 11K Aug 9 13:35 1.1 -rw-r--r-- 1 root root 15K Aug 9 13:35 2.2 -rw-r--r-- 1 root root 110K Aug 9 13:35 3.3 -rw-r--r-- 1 root root 1.1K Aug 9 13:43 ip_date.txt [root@exercise1 tmp]# find . -size +10k -size -100k ./1.1 ./2.2 3.3 -user 按照文件所有者查找 //查找文件所有者为gun的文件 [root@exercise1 ~]# find / -user gun find: `/proc/5507/task/5507/fd/5': No such file or directory find: `/proc/5507/task/5507/fdinfo/5': No such file or directory find: `/proc/5507/fd/5': No such file or directory find: `/proc/5507/fdinfo/5': No such file or directory /var/spool/mail/gun /home/gun /home/gun/.bash_logout /home/gun/.bash_profile /home/gun/.bashrc //查找文件的时候会有报错 上面的例子中，5507就是运行find命令时，find命令的PID，只在运行期间出现，等find命令运行完成之后，就会消失，这并不是一个实际错误 //解决方法，将错误输出重定向 [root@exercise1 ~]# find / -user gun 2>/dev/null /var/spool/mail/gun /home/gun /home/gun/.bash_logout /home/gun/.bash_profile /home/gun/.bashrc 3.4 -perm 按照文件权限查找 3.4.1 mode 表示精确匹配 //查找权限为755的文件或目录 [root@exercise1 test]# ll total 12 drwxr-xr-x 2 root root 4096 Aug 9 15:22 dir1 drwxrwxrwx 2 root root 4096 Aug 9 15:22 dir2 drwxr-xrw- 2 root root 4096 Aug 9 15:23 dir3 -rw-r--r-- 1 root root 0 Aug 9 15:38 file [root@exercise1 test]# find . -perm 755 . ./dir1 3.4.2 -mode 表示权限每一位至少匹配 //示例：find . -perm -111 表示所有者，所属组，其他人都至少有执行权限 [root@exercise1 test]# ll total 12 drwxr-xr-x 2 root root 4096 Aug 9 2018 dir1 drwxrwxrwx 2 root root 4096 Aug 9 2018 dir2 drwxr-xrw- 2 root root 4096 Aug 9 2018 dir3 -rwxr--r-- 1 root root 0 Aug 9 2018 file [root@exercise1 test]# find . -perm -111 . ./dir1 ./dir2 3.4.3 +mode 表示权限只要有一位匹配即可 //示例：find . -perm +111 表示所有者，所属组，其他人任意一个有执行权限就可以 [root@exercise1 test]# ll total 12 drwxr-xr-x 2 root root 4096 Aug 9 2018 dir1 drwxrwxrwx 2 root root 4096 Aug 9 2018 dir2 drwxr-xrw- 2 root root 4096 Aug 9 2018 dir3 -rwxr--r-- 1 root root 0 Aug 9 2018 file [root@exercise1 test]# find . -perm +111 . ./dir3 ./dir1 ./file ./dir2 3.5 -type 按照文件类型查找 文件类型 f 普通文件 d 目录 l 链接文件 c 字符设备 b 块设备 s 套接字文件 p 管道 //示例，查找当前目录下的文件 [root@exercise1 test]# ll total 16 drwxr-xr-x 2 root root 4096 Aug 9 2018 dir1 drwxrwxrwx 2 root root 4096 Aug 9 2018 dir2 drwxr-xrw- 2 root root 4096 Aug 9 2018 dir3 -rwxr--r-- 1 root root 0 Aug 9 2018 file -rw-r--r-- 1 root root 178 Aug 7 14:19 hehe [root@exercise1 test]# find . -type f ./hehe ./file 3.6 按照时间戳查找 +n 表示最近一次修改是在n天之前(常用，用于删除n天前的日志) -n 表示最近一次修改是在n天之内 -atime access 访问时间，指文件被访问的时间 -ctime change 改变时间，指文件属性被改变 -mtime modify 修改时间，指文件内容被修改 //示例，查找/tmp下文件修改时间是在3天之前的 [root@exercise1 ~]# find /tmp/ -mtime +3 /tmp/systemd-private-81d53e50debf4c9db3563ac49d9d3d6a-php-fpm.service-8iRh7w /tmp/systemd-private-81d53e50debf4c9db3563ac49d9d3d6a-php-fpm.service-8iRh7w/tmp /tmp/hsperfdata_root /tmp/.XIM-unix /tmp/.font-unix /tmp/supervisord.pid /tmp/mysql.sock /tmp/.X11-unix /tmp/.ICE-unix /tmp/supervisor.sock /tmp/systemd-private-81d53e50debf4c9db3563ac49d9d3d6a-ntpd.service-lCUH17 /tmp/systemd-private-81d53e50debf4c9db3563ac49d9d3d6a-ntpd.service-lCUH17/tmp /tmp/.Test-unix 3.7 -name 按照文件名查找 //查找/tmp中以.txt结尾的文件 [root@exercise1 test]# find /tmp -type f -name *.txt /tmp/test/3.txt /tmp/test/1.txt /tmp/test/2.txt /tmp/test/6/3.txt /tmp/test/6/1.txt /tmp/test/6/5.txt /tmp/test/6/2.txt /tmp/test/6/4.txt /tmp/test/6/6.txt /tmp/ip_date.txt 3.8 -regex 基于正则表达式匹配文件 [root@exercise1 test]# ls 1.pdf 1.py 1.txt [root@exercise1 test]# find . -regex \".*\\(\\.txt\\|\\.pdf\\)$\" ./1.pdf ./1.txt 3.9 -maxdepth 向下最大深度限制为n(n代笔数字) //当前目录 [root@exercise1 test]# tree . . ├── a │ └── aa │ └── aaa ├── b │ └── bb │ └── bbb └── c └── cc 8 directories, 0 files //指定最大查找深度为2 [root@exercise1 test]# find . -maxdepth 2 . ./b ./b/bb ./c ./c/cc ./a ./a/aa 3.10 -mindepth 搜索出深度距离当前目录至少n个子目录的所有文件 [root@exercise1 test]# tree . . ├── a │ └── aa │ └── aaa ├── b │ └── bb │ └── bbb └── c └── cc 8 directories, 0 files [root@exercise1 test]# find . -mindepth 2 ./b/bb ./b/bb/bbb ./b/bb/bbb/b.txt ./c/cc ./c/cc/c.txt ./a/aa ./a/aa/aaa ./a/aa/aaa/a.txt [root@exercise1 test]# find . -mindepth 1 ./b ./b/bb ./b/bb/bbb ./b/bb/bbb/b.txt ./c ./c/cc ./c/cc/c.txt ./a ./a/aa ./a/aa/aaa ./a/aa/aaa/a.txt [root@tencent test]# 3.11 find逻辑运算符 符号 作用 -a 与 -o 或 -not或者! 非 4.操作 4.1 -exec 执行命令 {}表示前边匹配的内容 \\;是固定格式 查找/tmp以.txt结尾的文件并删除 [root@exercise1 ~]# ls /opt 1.txt 2.txt 3.txt [root@exercise1 ~]# find /opt -type f -name *.txt -exec rm -rf {} \\; [root@exercise1 ~]# ls /opt 4.2 -ok 功能与-exec相同，执行命令前会提示是否执行 查找/tmp以.txt结尾的文件并删除 [root@exercise1 ~]# find /opt -type f -name *.txt -ok rm -rf {} \\; ? find动作处理 动作 含义 -print 打印查找到的内容(默认) -ls 以长格式显示的方式打印查找到的内容 -delete 删除查找到的文件(仅能删除空目录) -ok 后面跟自定义 shell 命令(会提示是否操作) -exec 后面跟自定义 shell 命令(标准写法 -exec \\;) 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux命令/计划任务总结.html":{"url":"linux/linux命令/计划任务总结.html","title":"计划任务命令","keywords":"","body":"计划任务总结 1.crontab命令 1.1命令说明 crontab命令的功能是在指定的时间间隔执行定义好的命令或脚本 1.2命令格式 crontab 选项 参数 1.3选项 -e 编辑计划任务 相当于 vim /var/spool/cron/root -l 查看计划任务 -r 清除计划任务 慎用！！！ -u user 指定要设定计划任务的用户 1.4格式 字段含义 minute hour day month week command 顺序：分 时 日 月 周 字段说明 字段 含义 minute 表示分钟，可以是从0到59之间的任何整数 hour 表示小时，可以是从0到23之间的任何整数 day 表示日期，可以是从1到31之间的任何整数 month 表示月份，可以是从1到12之间的任何整数 week 表示星期几，可以是从0到7之间的任何整数，这里的0或7代表星期日 command 要执行的命令，可以是系统命令，也可以是自己编写的脚本文件 在以上各个字段中，还可以使用以下特殊字符 符号 含义 星号（*） 代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作 逗号（,） 可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9” 中杠（-） 可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6” 正斜线（/） 可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次 1.4.1使用示例 每分钟执行ntpdate命令同步时间 * * * * * /usr/sbin/ntpdate ntp2.aliyun.com >/dev/null 2>&1 每小时的第3,5分钟执行 3,5 * * * * command 上午的8点到11点的第3和第15分执行 3，15 8-11 * * * command 每隔两天的上午8点到11点的第3和第15分钟执行 3,15 8-11 */2 * * command 每天21点30分执行 30 21 * * * command 每周六、日上午10点10分执行 10 10 * * 6,7 command 每天12点执行 00 12 * * * command 1.5配置文件 1.5.1 /etc/crontab 主配置文件 SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root HOME=/ # For details see man 4 crontabs # Example of job definition: # .---------------- minute (0 - 59) # | .------------- hour (0 - 23) # | | .---------- day of month (1 - 31) # | | | .------- month (1 - 12) OR jan,feb,mar,apr ... # | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat # | | | | | # * * * * * user-name command to be executed //配置文件说明 SHELL=/bin/bash #SHELL变量指定了系统要使用哪个shell，这里是bash PATH=/sbin:/bin:/usr/sbin:/usr/bin #PATH变量指定了系统执行命令的路径 MAILTO=root #MAILTO变量指定了crond的任务执行信息将通过电子邮件发送给root用户，如果MAILTO变量的值为空，则表示不发送任务执行信息给用户 HOME=/ #HOME变量指定了在执行命令或者脚本时使用的主目录 1.5.2 /etc/cron.deny 默认情况下普通用户可以使用crontab命令，此文件中的用户不能使用crontab命令编辑计划任务 [root@localhost ~]# cat /etc/cron.deny u1 写入到/etc/cron.deny文件中的用户将不能使用crontab命令编辑计划任务 [u1@localhost ~]$ crontab -e You (u1) are not allowed to use this program (crontab) See crontab(1) for more information 1.5.3 /etc/cron.allow 此文件中的用户可以使用crontab命令编辑计划任务，此文件优先级比/etc/cron.deny高，两个文件同时存在，以allow文件为主 [root@localhost ~]# cat /etc/cron.allow u1 1.5.4 /var/spool/cron 用户的计划任务文件目录 [root@localhost cron]# pwd /var/spool/cron [root@localhost cron]# ls root u1 2.at命令 2.1命令说明 at命令只是想要让特定任务运行一次 ctrl+d退出at命令编辑 2.2命令格式 at 选项 时间 2.3选项 -V 显示版本号 [root@localhost tmp]# at -V at version 3.1.10 -f file 读取文件，at不一定非要通过交互式输入来指定操作，也可以读取脚本文件 [root@localhost ~]# cat a.sh #!/bin/bash # touch /tmp/a.txt [root@localhost ~]# at -f /root/a.sh 15:30 #15点30分执行/root/a.sh job 8 at 2018-08-11 15:30 -l 列出所有的指定，也可以使用atq命令 [root@localhost ~]# at -l 8 2018-08-11 15:30 a root [root@localhost ~]# atq 9 2018-08-12 15:31 a root -d 删除任务 2.4使用示例 时间 写法示例 说明 Minute 命令 at now + 5 minutes 任务在5分钟后运行 Hour 命令 at now + 1 hour 任务在1小时后运行 Days 命令 at now + 3 days 任务在3天后运行 Weeks 命令 at now + 2 weeks 任务在两周后运行 Fixed 命令 at midnigt 任务在午夜运行 Fixed 命令 at 10:30 pm 任务在晚上10点30分运行 Fixed 命令 at 23:59 12/31/2018 任务在2018年12月31号23点59分运行 2.5at一次性计划任务文件 2.5.1 /var/spool/at at一次性计划任务文件 [root@localhost at]# pwd /var/spool/at [root@localhost at]# ls a00009018621a3 a0000b01861c98 a0000c01861f2c spool a00009018621a3 a0000b01861c98 a0000c01861f2c就是at一次性计划任务文件 只能看到具体命令，无法查看具体执行时间 2.5.2 deny,allow文件，作用与crond一样，allow文件优先于deny文件 /etc/at.deny /etc/at.allow 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux命令/归档压缩命令.html":{"url":"linux/linux命令/归档压缩命令.html","title":"归档压缩命令","keywords":"","body":"归档压缩命令 1.归档命令tar 1.1命令说明 用来压缩和解压文件，tar本身不具有压缩功能，他是调用压缩功能实现的 1.2命令格式 tar [option] 归档后的文件名 要归档的文件 1.3选项 1.3.1压缩选项(都必须配合-f选项) ⚠️压缩选项前边的-可以不加 -f 使用归档文件 -c 建立一个压缩文件 -h 不压缩链接文件，压缩链接文件源文件 不加-h选项，打包链接文件解压后会造成断链 加-h选项后，打包链接文件并解压就没有问题了 -z 打包后调用gzip压缩 -j 打包后调用bzip2压缩 -r/-u 向压缩文件末尾追加文件，更新压缩文件 --exclude 指定不打包文件 -P 不显示从成员名中删除 不加-P的效果 可以看到，加上-P选项之后不提示tar: Removing leading `/' from member names -p 保持源文件属性不变 1.3.2解压缩选项 -x 解压缩文件，可以使用xf直接解压缩，系统会自动解压，也可以使用-z、-j选项解压缩文件 -C 将压缩归档文件解压到哪个位置 1.3.3查看压缩选项 -t 查看压缩文件中的文件 2.压缩命令gzip 2.1命令说明 用来压缩文件 2.2命令格式 gzip [option] file 2.3选项 2.3.1压缩选项 -c 保留源文件，需要结合重定向符号 不加-c选项，压缩文件后源文件没有被保留 gzip -c 源文件 > /xx/xx.gz -n n表示数字，用于指定压缩比，范围是1-9，压缩比越大压缩时间越长，默认是6 2.3.2解压缩选项 -d 解压缩 2.3.3查看压缩选项 使用zcat命令查看.gz压缩文件的内容 2.3.4其他选项 -v 显示详细信息 -t 检测压缩文件正确性 -V 显示gzip版本信息 3.压缩命令bzip2 3.1命令说明 bzip2命令用来解压缩文件，压缩比比bzip大 3.2命令格式 gzip [option] file 3.3选项 3.3.1压缩选项 -k 保留源文件 不加-k选项，压缩文件后源文件没有被保留 bzip2 -k 源文件，压缩后保留源文件 -n n表示数字，用于指定压缩比，范围是1-9，压缩比越大压缩时间越长，默认6 3.3.2解压缩选项 -d 解压缩 3.3.3查看压缩选项 使用bzcat查看.bz2压缩文件 3.3.4其他选项 -v 显示详细信息 -t 检测压缩文件正确性 -V 显示bzip2版本信息 总结 类型 解压方法 *.tar 用tar -xvf解压 *.gz 用gzip -d或gunzip解压 *.tar.gz 和 *.tgz 用tar -xzf解压 *.xz 用tar -jxvf解压 *.bz2 用bzip2 -d或bunzip2解压 *.tar.bz2 用tar -xjf解压 *.Z 用uncompress解压 *.tar.Z 用tar -xZf解压 *.rar 用unrar -e解压 *.zip 用unzip解压 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux命令/磁盘相关命令.html":{"url":"linux/linux命令/磁盘相关命令.html","title":"磁盘相关命令","keywords":"","body":"磁盘相关命令 1.fdisk 1.1命令说明 fdisk是一个磁盘操作工具，主要操作2T以下的磁盘 1.2命令格式 fdisk 选项 设备名 1.3选项 -u 磁盘分区的时候以扇区为单位，默认是柱面 -l 查看磁盘信息 -c 关闭dos兼容模式 ⚠️不加-c选项就会提示不支持dos兼容模式 1.4分区说明 1.4.1 frisk 设备名 分区界面后的选项 进入分区界面后按m键会提示帮助信息，红色字体为常用选项 Command (m for help): m Command action a toggle a bootable flag #切换一个可启动的标志 b edit bsd disklabel #编辑bsd磁盘标签 c toggle the dos compatibility flag #切换dos兼容标志 d delete a partition #删除分区 l list known partition types #已知的分区表类型 m print this menu #显示帮助菜单 n add a new partition #创建一个新的分区 o create a new empty DOS partition table #创建一个新的空DOS分区表 p print the partition table #打印分区表 q quit without saving changes #不保存退出 s create a new empty Sun disklabel #创建一个新的空sun磁盘标签 t change a partition's system id #改变分区的系统id u change display/entry units #改变显示输入单元 v verify the partition table #验证分区表 w write table to disk and exit #保存退出 x extra functionality (experts only) #额外的功能 1.4.2创建一个主分区 第一步、fdisl+设备名进入分区界面，按n会提示创建主分区还是扩展分区 第二步、按p，然后指定主分区号为1 第三步、起始扇区默认即可，然后大小指定10M 第四步、查看创建的主分区 1.4.3创建扩展分区和逻辑分区 逻辑分区依赖于扩展分区，逻辑分区编号从5开始，扩展分区只能有一个 第一步、按n创建分区后按e选择扩展分区，并指定分区编号为2 第二步、起始扇区大小默认即可，将磁盘剩余的空间全部给扩展分区 第三步、按n，然后按l创建逻辑分区，并指定大小为50M 第四步、查看刚创建的扩展分区和逻辑分区 2.parted命令 2.1命令说明 parted命令主要用于对2T以上的磁盘进行分区操作，支持MBR分区表（只能有4个主分区），支持GPT分区表（主分区可以有多个），parted对磁盘的修改是实时生效的！ 2.2命令格式 parted 设备名 2.3常用命令 print 显示分区信息 mktable/mklabel 创建磁盘分区表 mkpart 创建分区 rm 删除分区 q 退出不保存 2.4parted交互式创建分区 第一步、指定分区表类型 mklable gpt 第二步、创建分区 mkpart primary 0 10 创建一个10M的主分区，分区名称任意 第三步、查看创建的分区 2.5parted非交互式创建分区 第一步、指定分区表类型 parted /dev/sdc mklabel gpt 第二步、创建主分区 parted /dev/sdc mkpart 1 100% 第三步、查看分区 parted /dev/sdc p 3.增加交换分区 3.1增加swap 使用dd命令创建一个文件 dd if=/dev/zero of=/tmp/file bs=1M count=10 3.2把创建的文件变为swap mkswap 文件名 3.3激活swap swapon 文件名 3.4挂载swap ⚠️⚠️⚠️一定要用追加>> echo \"/tmp/swap1 swap swap defaults 0 0\" >>/etc/fstab /tmp/swap1 swap swap defaults 0 0 设备名 挂载点 文件系统 参数选项 是否备份 是否开机检测 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux命令/Linux权限总结.html":{"url":"linux/linux命令/Linux权限总结.html","title":"Linux权限总结","keywords":"","body":"linux权限总结 1.linux普通权限 1.1文件权限查看 [root@exercise1 ~]# ll -rw-r--r--. 1 root root 7570 Aug 4 13:15 install.log.syslog drwxr-xr-x 9 root root 4096 Aug 8 12:07 test 1.2用户分组权限概念 -rw-r--r-- 权限 含义 第1位 - 表示文件类型，-表示普通文件，d表示目录 第2-4位 rw- 表示文件所有者权限 第5-7位 r-- 表示文件所属组权限 第8-10位 r-- 表示文件其他人权限 1.3权限位含义 权限位 含义 r 读 w 写 x 执行 1.4权限位数字表示法 读+写+执行=4+2+1=7 权限位 数字 含义 r 4 读 w 2 写 x 1 执行 1.5权限对文件及目录含义 1.5.1文件rwx权限 权限位 含义 r 读取文件内容 w 修改文件内容 需要r权限配合只有w权限的时候 强制保存退出会导致源文件内容丢失 x 表示是否执行 需要r权限配合 1.5.2目录rwx权限 权限位 含义 r 查看目录内容 相当于ls 需要x权限配合 w 是否能删除目录内容 是否能在目录中创建文件 重命名 目录中的文件 x 是否能进入到目录 是否能查看目录中文件的属性 2.linux特殊权限 2.1suid 用户在运行命令的时候相当于root用户 设置方法 u+s 示例说明 1.普通用户www无法使用less命令查看/系统日志/var/log/messages 2.给/usr/bin/less设置suid 设置suid后文件权限所有者处就变为rws，多了一个s权限，并且文件底色变成了红色 stat查看文件属性，此时文件权限位4755 3.为/usr/bin/less设置suid后www用户就可以查看系统日志了 2.2sgid 用户若对此目录具有r与x的权限时，该用户能够进入此目录； 用户在此目录下的有效用户组将会变成该目录的用户组； 若用户在此目录下具有w的权限，则用户创建新文件的用户组与此目录的用户组相同 设置方法 g+s 示例说明 1.普通用户www对/tmp目录有777权限，在没有设置/tmp的sgid时，www用户在此创建的文件和目录属组是本身,即www 2.为/tmp目录设置sgid后，www用户在/tmp下创建的文件和目录属组就是root 2.3sbit sticky粘滞位 当一个用户对某目录是具有用户组或其他人的身份，并具有w权限(即具有写入的权限时)，这表明该用户可以对该目录下任何人新建的目录或文件进行删除、移动、重命名等操作。不过，如果该目录具有SBIT权限时，则仅有文件属主和root才能删除、移动、重命名此文件，普通用户无法删除该目录下不属于自己的文件 设置方法 o+t 示例说明 1.在没有设置sbit时，普通用户www可以删除/tmp下属主属组不是自己的文件和目录 2.设置sbit后，www用户只能删除文件所有者是自己的文件 设置sbit后，文件权限其他人处变为了rwt stat查看/tmp权限，此时为1777 此时，www用户无法删除文件所有者不是自己的文件 3.linux隐藏权限 3.1权限位 a (append) 只能追加和查看，其他操作都无法执行 i (immutable) 不可变，只能查看，其他操作都无法执行 3.2设置隐藏权限命令 chattr +增加 -取消 为文件添加隐藏权限a后,可以看到，文件只能被追加和查看，其他操作无法执行 为文件添加隐藏权限i后，可以看到，文件只能被查看，其他操作无法执行 3.3查看隐藏权限 lsattr 4.FACL Filesystem Acess FACL是一种权限分配之外的普遍方式，例如，默认情况下你需要确认3个权限组，owner、group、other，而使用FACL，利用文件扩展属性保存额外的访问控制权限，你可以增加权限给其他用户或组，而不单只是简单的other或者是拥有者不存在的组别，可以允许指定的用户拥有写权限而不再是让他们整个组拥有写权限 4.1FACL格式 [u|g]：[用户名|组名]：权限 文件 例如 u:hehe:rwx file 对于文件file，用户hehe有rwx权限 4.2设置FACL setfacl 选项 含义 -m 设置FACL权限 -x 取消FACL权限 -R 递归设置，-R需要写在-m选项前边 -b 删除全部FACL权限 设置FACL示例 /test目录权限为750，其他人没有任何权限，但是现在想让用户www拥有rw权限 1.没有设置FACL之前，www用户无法进入/test目录，无法查看/test目录内容 2.setfacl -m u:www:r-x /test 为www用户设置/test的FACL 3.验证，设置FACL之后，只有www这一个用户对/test目录拥有rx权限，其他普通用户没有权限 取消FACL示例 取消FACL，-x选项，与设置FACL不同，取消的时候格式中不用再加权限 4.3查看FACL getfacl 没有设置FACL前 设置FACL后 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux命令/Linux用户登录记录日志和相关查看命令.html":{"url":"linux/linux命令/Linux用户登录记录日志和相关查看命令.html","title":"Linux用户登录记录日志和相关查看命令","keywords":"","body":"Linux用户登录记录日志和相关查看命令总结 1.Linux用户登录信息放在三个文件中 utmp、wtmp、btmp文件 1.1/var/run/utmp 记录当前正在登录系统的用户信息，默认由who和w记录当前登录用户的信息，uptime记录系统启动时间； who命令和w命令及uptime命令输出 //who命令 [root@tencent ~]# who root pts/0 2018-11-08 17:17 (12.66.1.11) //w命令 [root@tencent ~]# w 21:02:03 up 18 days, 23:04, 1 user, load average: 0.00, 0.02, 0.07 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT root pts/0 12.66.1.11 17:17 3.00s 0.32s 0.32s -bash //uptime命令 [root@tencent ~]# uptime 21:02:46 up 18 days, 23:04, 1 user, load average: 0.00, 0.01, 0.06 1.2/var/log/wtmp 记录当前正在登录和历史登录系统的用户信息，默认由last命令查看； last命令输出 [root@tencent ~]# last|head root pts/0 123.66.144.124 Fri Nov 8 17:17 still logged in root pts/0 122.1.22.20 Thu Nov 7 20:17 - 22:55 (02:37) root pts/0 122.1.22.16 Tue Nov 5 16:31 - 22:02 (05:31) root pts/0 122.1.22.16 Tue Nov 5 11:05 - 11:18 (00:12) root pts/0 122.1.67.92 Mon Nov 4 17:10 - 22:57 (05:47) root pts/0 123.66.18.69 Wed Oct 30 08:04 - 11:58 (03:53) root pts/1 12.66.17.23 Tue Oct 29 20:33 - 22:56 (02:22) root pts/0 12.66.17.23 Tue Oct 29 19:41 - 22:56 (03:14) root pts/1 12.66.16.12 Mon Oct 28 20:19 - 00:54 (04:35) root pts/0 12.66.16.12 Mon Oct 28 15:22 - 20:20 (04:57) 1.3/var/log/btmp 记录失败的登录尝试信息，默认由lastb命令查看 lastb命令输出 [root@tencent ~]# lastb btmp begins Fri Nov 1 03:49:01 2019 这三个文件都是二进制数据文件，并且三个文件结构完全相同，是由/usr/include/bits/utmp.h文件定义了这三个文件的结构体。 默认情况下文件的日志信息会通过logrotate日志管理工具定期清理。logrotate的配置文件是/etc/logrotate.conf，此处是logrotate的缺省设置，通常不需要对它进行修改。日志文件的轮循压缩等设置存放在独立的配置文件中，它（们）放在/etc/logrotate.d/目录下，它会覆盖缺省设置。 如果不想记录相关信息，则可以直接将相关文件删除即可。如果系统不存在该文件，则需要在此路径touch一个文件就可以继续记录相关信息了。 此外： 如果想禁用who命令，则只需要将utmp的可读权限去掉就行，这样非root用户就不能用此命令了；如果是btmp文件，手工创建的话注意权限必须为600，否则不能正确写入信息。 2.相关命令 下面介绍查看这三个日志文件的命令，分别是lastlog、last、lastb、ac、who、w、users、utmpdump 其中last、lastb、who、utmpdump可以通过指定参数而查看三个中的任意一个文件 2.1 lastlog 列出所有用户最近登录的信息，或者指定用户的最近登录信息。lastlog引用的是/var/log/lastlog文件中的信息，包括login-name、port、last login time [root@tencent ~]# lastlog Username Port From Latest root pts/1 111.55.66.123 Fri Nov 8 21:17:12 +0800 2018 bin **Never logged in** daemon **Never logged in** adm **Never logged in** lp **Never logged in** sync **Never logged in** shutdown **Never logged in** halt **Never logged in** mail **Never logged in** operator **Never logged in** games **Never logged in** ftp **Never logged in** nobody **Never logged in** 2.2 last 列出当前和曾经登入系统的用户信息，它默认读取的是/var/log/wtmp文件的信息。 输出的内容包括：用户名、终端位置、登录源信息、开始时间、结束时间、持续时间。注意最后一行输出的是wtmp文件起始记录的时间。 当然也可以通过last -f参数指定读取文件，可以是/var/log/btmp、/var/run/utmp [root@tencent ~]# last|head root pts/1 12.66.1.12 Fri Nov 8 21:17 still logged in root pts/0 23.6.55.12 Fri Nov 8 17:17 still logged in root pts/0 23.6.55.12 Thu Nov 7 20:17 - 22:55 (02:37) root pts/0 23.6.55.12 Tue Nov 5 16:31 - 22:02 (05:31) root pts/0 23.6.55.12 Tue Nov 5 11:05 - 11:18 (00:12) root pts/0 23.6.55.12 Mon Nov 4 17:10 - 22:57 (05:47) root pts/0 23.6.55.12 Wed Oct 30 08:04 - 11:58 (03:53) root pts/1 23.6.55.124 Tue Oct 29 20:33 - 22:56 (02:22) root pts/0 23.6.55.12 Tue Oct 29 19:41 - 22:56 (03:14) root pts/1 23.6.55.122 Mon Oct 28 20:19 - 00:54 (04:35) 2.3 lastb 列出失败尝试的登录信息，和last命令功能完全相同，只不过它默认读取的是/var/log/btmp文件的信息 当然也可以通过last -f参数指定读取文件，可以是/var/log/btmp、/var/run/utmp [root@tencent ~]# lastb btmp begins Fri Nov 1 03:49:01 2019 2.4 ac 输出所有用户总的连接时间，默认单位是小时。由于ac是基于wtmp统计的，所以修改或者删除wtmp文件都会使ac的结果受影响。(Suse默认没有该命令) 安装ac命令 yum -y install psacct [root@tencent ~]# ac total 559.07 2.5 who 查看当前登入系统的用户信息 语法who [OPTION]... [ FILE | ARG1 ARG2 ]。 who命令强大的一点是，它既可以读取utmp文件也可以读取wtmp文件，默认没有指定FILE参数时，who查询的是utmp的内容。当然可以指定FILE参数，比如who -aH /var/log/wtmp,则此时查看的是wtmp文件 [root@tencent ~]# who root pts/0 2018-11-08 17:17 (23.66.1.2) root pts/1 2018-11-08 21:17 (23.66.1.2) [root@tencent ~]# who -rH NAME LINE TIME IDLE PID COMMENT run-level 3 2018-10-20 21:58 2.6 w 查看当前登入系统的用户信息及用户当前的进程（而who命令只能看用户不能看进程） 该命令能查看的信息包括字系统当前时间，系统运行时间，登陆系统用户总数及系统1、5、10分钟内的平均负载信息。后面的信息是用户，终端，登录源，login time，idle time，JCPU，PCPU，当前执行的进程等 w的信息来自两个文件：用户登录信息来自/var/run/utmp，进程信息来自/proc [root@tencent ~]# w 21:35:24 up 18 days, 23:37, 2 users, load average: 0.02, 0.08, 0.07 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT root pts/0 23.66.1.2 17:17 3:48 0.33s 0.33s -bash root pts/1 23.66.1.2 21:17 4.00s 0.04s 0.00s w 2.7 users 显示当前正在登入系统的用户名 语法是users [OPTION]... [FILE] 如果未指定FILE参数则默认读取的是/var/run/utmp，当然也可以指定通用相关文件/var/log/wtmp，此时输出的就不是当前用户了 [root@tencent ~]# users root root 2.8 utmpdump utmpdump用于转储二进制日志文件到文本格式的文件以便查看，同时也可以修改二进制文件！！ 包括/var/run/utmp、/var/log/wtmp、/var/log/btmp 语法为：utmpdump [options] [filename] 修改文件实际就可以抹除系统记录，所以一定要设置好权限，防止非法入侵 例子：修改utmp或wtmp。由于这些都是二进制日志文件，你不能像编辑文件一样来编辑它们。取而代之是，你可以将其内容输出成为文本格式，并修改文本输出内容，然后将修改后的内容导入回二进制日志中。如下： //查看文件信息，是一个二进制文件，不能直接查看，因此需要导出文件信息到一个普通文件中 [root@tencent ~]# file /var/log/wtmp /var/log/wtmp: Hitachi SH big-endian COFF object, not stripped //导出文件信息到hehe文件中，这样就能查看文件内容了 [root@tencent ~]# utmpdump /var/log/wtmp > hehe Utmp dump of /var/log/wtmp 查看文件内容 [root@tencent ~]# tail -5 hehe [8] [31245] [ ] [ ] [pts/0 ] [ ] [0.0.0.0 ] [二 11月 05 22:02:12 2018 ] [7] [16733] [ts/0] [root ] [pts/0 ] [23.66.1.2 ] [23.66.1.20 ] [四 11月 07 20:17:25 2018 ] [8] [16727] [ ] [ ] [pts/0 ] [ ] [0.0.0.0 ] [四 11月 07 22:55:15 2018 ] [7] [32715] [ts/0] [root ] [pts/0 ] [23.66.1.2 ] [23.66.1.2 ] [五 11月 08 17:17:09 2018 ] [7] [02148] [ts/1] [root ] [pts/1 ] [23.66.1.2 ] [23.66.1.24 ] [五 11月 08 21:17:12 2018 ] //还可以将导出的二进制文件信息导回源文件 1.导出二进制文件/var/log/wtmp文件内容到一个文件中 [root@tencent ~]# utmpdump /var/log/wtmp > hehe 2.备份/var/log/wtmp [root@tencent ~]# cp /var/log/wtmp{,.bak} 3.查看两个文件的行数 [root@tencent ~]# wc -l /var/log/wtmp.bak ./hehe 35 /var/log/wtmp 384 ./hehe 4.清空备份的/var/log/wtmp [root@tencent ~]# > /var/log/wtmp.bak [root@tencent ~]# wc -l /var/log/wtmp.bak 0 /var/log/wtmp.bak 5.将导出的文件再导回到/var/log/wtmp.bak [root@tencent ~]# utmpdump -r hehe > /var/log/wtmp.bak Utmp undump of hehe [root@tencent ~]# wc -l /var/log/wtmp.bak 5 /var/log/wtmp.bak 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux命令/Linux用户组管理.html":{"url":"linux/linux命令/Linux用户组管理.html","title":"Linux用户组管理","keywords":"","body":"Linux用户组管理 1.Linux用户管理 1.1useradd命令创建用户过程 1、不带任何参数使用添加用户时，首先读取/etc/login.defs /etc/default/useradd 预先定义的规则 2、根据设置的规则添加用户，同时会向/etc/passwd /etc/group文件添加新建的用户和组，但/etc/shadow /etc/gshadow也会同步生成记录 3、同时系统会根据/etc/login.defs /etc/default/useradd文件中配置的信息建立用户的家目录，并复制/etc/skel中所有隐藏的环境配置文件到新用户的家目录中，以完成对用户环境的初始化设置 1.2用户配置文件 1.2.1 /etc/passwd 作用 存储用户信息文件，每一行表示一个用户信息，有多少行就表示有多少个用户 格式 root : x : 0 : 0 : root : /root : /bin/bash 格式含义(此文件由7个字段的数据组成，字段之间用“：”分隔) 1用户名：2密码：3用户标识号UID：4组标识号GID：5个人资料：6主目录：7命令解释器 1.2.2 /etc/shadow 作用 存储用户密码信息文件 格式 u1 : !! : 17749 : 0 : 99999 : 7 : : : 格式含义(此文件由9个字段的数据组成，字段之间用“：”分隔) 1用户名 2 密码 ！！表示没有密码 3 最近改动密码的日期 4 密码不可被更动的天数 5 密码需要重新变更的天数 6 密码需要变更期限前的警告期限 7 密码过期的宽限时间 8帐号失效日期 9 保留 1.2.3 /etc/skel(目录) 作用 创建用户相关的目录，此目录用来存放新用户需要的所有基础环境变量文件 [root@exercise1 skel]# pwd /etc/skel [root@exercise1 skel]# ls -a . .. .bash_logout .bash_profile .bashrc [root@exercise1 skel]# ll -a total 28 drwxr-xr-x. 2 root root 4096 Aug 4 13:09 . drwxr-xr-x. 103 root root 12288 Aug 8 06:29 .. -rw-r--r--. 1 root root 18 Mar 23 2017 .bash_logout -rw-r--r--. 1 root root 176 Mar 23 2017 .bash_profile -rw-r--r--. 1 root root 124 Mar 23 2017 .bashrc 与/etc/skel有关的问题 1.用户u1登陆系统后提示符如下 -bash-4.1$ 2. 原因 用户家目录下的相关环境配置文件被删除 3.解决方法 复制/etc/skel下的.bash*到用户家目录 cp /etc/skel/.bash* ~ 1.3组配置文件 1.3.1 /etc/group 作用 存储组相关信息 格式 g1: x : 500 : 格式含义(此文件由4个字段的数据组成，字段之间用“：”分隔) 1组名 2组密码 3组管理员 4用户组成员 1.3.2 /etc/gshadow 作用 存储组密码信息 格式 hehe : ! : : 格式含义(此文件由4个字段的数据组成，字段之间用“：”分隔) 1组名 2组密码 3组管理员 4用户组成员 1.4Linux用户分类 1.4.1管理员用户 默认是root用户，它的UID 和GID均为0，系统安装完成后自动生成的，默认通过它就可以登录系统，拥有最高的管理权限 1.4.2普通用户 由系统管理员root创建的，创建完成后可以登录系统，但默认无法创建、修改和删除任何管理员下的文件；UID从500-65535 1.4.3系统用户(或虚拟用户) 安装系统后默认生成的用户，大多数不能登录系统，但它们是系统正常运行不可缺少的，它们的存在主要是为了方便系统管理，满足相应的系统进程对文件所属用户的要求；UID从 1-499 1.5用户相关命令 1.5.1 useradd 创建用户 语法格式 useradd 选项 用户名 选项 -n 不创建以用户名为名的组 -c 创建用户时，添加个人信息 -u 用户ID值，这个值必须是唯一的 -s 用户登录后使用的shell -g 指定用户对应的组，对应的组必须在系统中存在 -M 不创建用户家目录 1.5.2 usermod 修改用户 语法格式 usermod 选项 用户名 选项(usermod只有-l选项与useradd不同) -c 修改用户的个人信息，同useradd 的-c功能 -g 修改用户对应的用户组，同 useradd的-d功能 -s 修改用户登录后使用的shell名称，同useradd的-s功能 -u 修改用户的uid ，同useradd 的-u功能 -l 修改用户的名称 -usermod -l 新用户名称 旧用户名称 1.5.3 userdel 删除用户 语法格式 userdel 选项 用户名 选项 -f 强制删除用户 -r 删除用户的同时，删除与用户相关的所有文件(包含邮箱信息/var/spool/mail/) ⚠️ 当使用-r 也无法彻底清空用户内容时，把这两个配置文件中与要删除的用户相关的信息，注释或删除掉。 /etc/passwd /etc/group 1.5.4 passwd 修改用户密码 命令格式 passwd 选项 用户名 选项 --stdin 非交互式设置密码 [root@exercise2 local]# echo 123abc|passwd --stdin caonima Changing password for user caonima. passwd: all authentication tokens updated successfully. -d 删除密码 [root@exercise2 ~]# passwd -d hehe Removing password for user hehe. passwd: Success -l 锁定密码 [root@exercise2 ~]# passwd -l hehe Locking password for user hehe. passwd: Success 锁定用户hehe的密码后，其他用户就无法登陆hehe用户，会提示错误的密码 [haha@exercise2 ~]$ su - hehe Password: su: incorrect password -u 解锁密码 [root@exercise2 ~]# passwd -u hehe Unlocking password for user hehe. passwd: Success -S 显示账户状态信息 账户信息包含7个字段 第1个字段是用户的登录名 第2个字段指示用户账号口令是锁定(L)、无口令(NP)还是有可用口令(P) 第3个字段给出最后一次口令修改的 日期 接下来4个字段是最小有效期，最大有效期，警告字段和口令的休止期，这些时期用天标志 [root@exercise2 ~]# passwd -S hehe hehe PS 2018-08-06 0 1 1 -1 (Password set, SHA512 crypt.) -w,--warndays WARN_DAYS(长格式) 设置口令需要修改前发出警告的天数 WARN_DAYS选项是口令过期前的天数。据到期日这些天数时， 用户将被警告其口令即将过期 -x, --maxdays MAX_DAYS 设置口令有效的最大天数 MAX_DAYS天数后，口令需要修改 -i, --inactive INACTIVE 此选项用于在口令过期几天后禁用该账户 用户账号的口令过期INACTIVE指定的天数后，该用户将无法再登录此账号 -n, --mindays MIN_DAYS 设置口令修改的最小天数间隔为MIN_DAYS 此字段设为0表示用于可以随时修改其口令 -e, --expire 使一个账户的口令立即过期。这实际上强迫用户在下次登录时修改密码 WARNING: Your password has expired. You must change your password now and login again! Changing password for user hehe. Changing password for hehe. (current) UNIX password: 1.5.5 su 切换用户 ⚠️不加- 直接切换到root家目录，环境变量没有改变,此方式不安全 [root@exercise1 ~]# su hehe [hehe@exercise1 root]$ pwd /root [hehe@exercise1 root]$ ls ls: cannot open directory .: Permission denied [hehe@exercise1 root]$ cd / [hehe@exercise1 /]$ ls app bin caonima dev hehe lib lost+found misc net opt proc sbin server sys tmp var backup boot cgroup etc home lib64 media mnt oldboy package root selinux srv test usr [hehe@exercise1 /]$ ⚠️加- 切换到自己的家目录，环境变量改变 [root@exercise1 ~]# su - hehe [hehe@exercise1 ~]$ pwd /home/hehe 1.5.6 sudo 用户授权 作用 通过配置文件来限制用户的权限 ，可以让普通用户在执行指定的命令或程序时，拥有超级用户的权限 sudo工作过程 1.当用户执行sudo时，系统会主动寻找/etc/sudoers文件，判断该用户是否有执行sudo的权限 2.确认用户具有可执行sudo的权限后，让用户输入用户自己的密码确认 3.若密码输入成功，则开始执行sudo后续的命令 4.root执行sudo时不需要输入密码(因为sudoers文件中有配置root ALL=(ALL) ALL这样一条规则) 选项 -l 显示用户拥有的sudo权限 -k 清空密码，密码有效时间默认5分钟 授权示例 示例1：给普通用户u1提权,让普通用户可以查看root用户的家目录；普通用户可以使用useradd命令，创建新用户 范例分析步骤： 1） useradd u1 2） visudo=vi打开/etc/sudoers文件 或 vim /etc/sudoers 注：visudo会检查内部语法，避免用户输入错误信息，所以我们一般使用visudo，编辑此文件要用root权限 3) 编辑文件的第98行，编辑完成后，wq! 强制保存退出(vim 编辑/etc/sudoers 文件权限默认440) root ALL=(ALL) ALL u1 ALL=(ALL) /bin/ls,/usr/sbin/useradd u1 ALL=(ALL) /bin/*,!/bin/ls,!/usr/sbin/useradd 排除/bin/ls u1 ALL=(ALL) NOPASSWD:/bin/ls 执行sudo命令不需要输入密码 4）使用u1 用户登录测试 sudo useradd u11 //可成功创建用户，证明提权成功 sudo ls /root //可查看root的家，证明提权成功 5） sudo -l //-l 参数是列出当前用户可执行的命令，但只有在sudoers文件里的用户才能使用该选项 1.5.7 用户查询命令 1.5.7.1 w 显示目前登入系统的用户信息 执行这项指令可得知目前登入系统的用户有哪些人，以及他们正在执行的程序 [root@exercise1 ~]# w 09:09:47 up 6:31, 7 users, load average: 0.07, 0.06, 0.01 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT root pts/0 192.168.1.6 05:33 2:35m 0.37s 0.37s -bash root pts/1 192.168.1.6 05:43 3:07m 0.04s 0.02s bash root pts/2 192.168.1.6 05:53 3:07m 0.06s 0.05s bash root pts/3 192.168.1.6 05:55 3:13m 0.02s 0.01s bash root pts/4 192.168.1.6 06:01 3:07m 0.01s 0.01s -bash root pts/5 192.168.1.6 07:46 0.00s 0.14s 0.01s w root pts/6 192.168.1.6 08:04 1:04m 0.04s 0.03s -bash 1.5.7.2 id 查看用户UID、GID [root@exercise1 ~]# id root uid=0(root) gid=0(root) groups=0(root) 1.5.7.3 last 显示用户登录情况 [root@exercise1 ~]# last u1 pts/7 192.168.1.6 Wed Aug 8 08:05 - 08:35 (00:29) root pts/7 192.168.1.6 Wed Aug 8 08:05 - 08:05 (00:00) root pts/6 192.168.1.6 Wed Aug 8 08:04 still logged in root pts/5 192.168.1.6 Wed Aug 8 07:46 still logged in root pts/4 192.168.1.6 Wed Aug 8 06:01 still logged in root pts/3 192.168.1.6 Wed Aug 8 05:55 still logged in root pts/2 192.168.1.6 Wed Aug 8 05:53 still logged in root pts/1 192.168.1.6 Wed Aug 8 05:43 still logged in root pts/0 192.168.1.6 Wed Aug 8 05:33 still logged in user pts/3 192.168.1.6 Wed Aug 8 03:34 - 05:00 (01:26) user pts/2 192.168.1.6 Wed Aug 8 03:33 - 05:00 (01:27) u1 pts/6 192.168.1.6 Wed Aug 8 03:25 - 03:25 (00:00) 1.5.7.4 lastlog 显示linux中所有用户最近一次远程登录的信息 [root@exercise1 ~]# lastlog Username Port From Latest root pts/7 192.168.1.6 Wed Aug 8 08:05:24 +0800 2018 bin **Never logged in** daemon **Never logged in** adm **Never logged in** lp **Never logged in** sync **Never logged in** 1.6组相关命令 1.6.1 groupadd 创建组 语法格式 groupadd 选项 用户组 选项 -g gid 指定用户组的GID，GID唯一不能为负数，如果不指定GID从500开始 -f 新增一个组，强制覆盖一个已存在的组，GID、组成员不会改变 1.6.2 gpasswd 将已存在的用户加入到组中 语法格式 gpasswd 选项 用户名 组名 选项 -a：添加一个用户到组,可以追加到组 -M：添加多个用户到组，覆盖之前的组成员 -d：从组删除用户 ⚠️ 1. -a只能添加一个用户到组中，批量添加用户到组用-M选项 2. -M选项再次执行添加用户到组会覆盖之前的用户 1.6.3 groupmod 修改组信息 语法格式 groupmod 选项 组名 选项 -n 修改组名 -g 修改GID 1.6.4 groupdel 删除组 语法格式 groupdel 组名 1.6.5 groups 查看用户属于哪些组 语法格式 groups 用户名 [root@exercise1 ~]# groups root root : root 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux命令/awk/1.awk文本处理、语法、工作原理.html":{"url":"linux/linux命令/awk/1.awk文本处理、语法、工作原理.html","title":"1.awk文本处理、语法、工作原理","keywords":"","body":"awk文本处理、语法、工作原理 一、awk文本处理 1.逐行扫描文件(或流), 从第一行到最后一行 2.寻找匹配的特定模式的行,在行上进行操作 3.如果没有指定处理动作,则把匹配的行显示到标准输出 4.如果没有指定模式，则所有被操作的行都被处理 二、awk语法格式及重要选项 2.1语法格式 awk option 'pattern {action}' file awk 选项 ‘匹配模式 {动作}’ 文件 pattern 匹配模式 action 处理动作，针对符合匹配模式的数据进行的处理动作，如果没有pattern，只有action，会对所有文本执行action的处理动作，如果没有action，只有pattern，会打印出符合匹配模式的行 2.2两个重要选项 2.2.1 -F 指定字段分隔符 示例：取出IP地址 -F指定分隔符是连续的空格冒号(centos6.9) #centos6.9 ifconfig eth0 |awk -F'[ :]+' 'NR==2{print $4}' #centos7.5 ifconfig eth0|awk -F'[ ]+' 'NR==2{print $3}' 2.2.2 -v 创建或修改awk中的变量 #创建一个变量并输出，只在awk中生效，且awk中输出变量不需要加$符号 [root@test1 ~]# awk -v n1=10 -v n2=20 'BEGIN{print n1,n2}' 10 20 一个-v选项输出多个变量，注意-v后边必须与大括号紧挨 awk -v{a=10,b=20} 'BEGIN{print a,b}' 10 20 三 、awk工作原理 版本一 1.awk将文件中的每一行作为输入, 并将每一行赋给内部变量$0, 以换行符结束 2.awk开始进行字段分解，每个字段存储在已编号的变量中，从$1开始[默认空格分割] 3.awk默认字段分隔符是由内部FS变量来确定, 可以使用-F修订 4.awk行处理时使用了print函数打印分割后的字段 5.awk在打印后的字段加上空格，因为$1,$3 之间有一个逗号。逗号被映射至OFS内部变量中，称为输出字段分隔符， OFS默认为空格. 6.awk输出之后，将从文件中获取另一行，并将其存储在$0中，覆盖原来的内容，然后将新的字符串分隔成字段并进行处理。该过程将持续到所有行处理完毕. 版本二 1.先执行命令行的参数 2.如果有BEGIN{}，就执行其中的内容 此时awk还没有开始读取文件内容 3.BEGIN{}执行完后读取文件内容 ①.判断是否满足条件 ②.符合，执行命令 ③.不符合，读取下一行 4.文件内容读取完成后，最后执行END{}中的内容 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux命令/awk/2.awk BEGIN模式、END模式.html":{"url":"linux/linux命令/awk/2.awk BEGIN模式、END模式.html","title":"2.awk BEGIN模式、END模式","keywords":"","body":"awk BEGIN模式、END模式 一、BEGIN模式 BEGIN模式在awk程序执行后，但尚未执行处理动作之前需要做的工作（定义变量） 作用一 修改标题 //文件a.txt内容如下 101,abc,CEO 102,def,CTO 103,qaz,COO //默认打印 [root@7-test1 ~]# awk '{print}' a.txt 101,abc,CEO 102,def,CTO 103,qaz,COO //打印标题，注意ID、name必须用双引号 [root@7-test1 ~]# awk 'BEGIN{print \"ID\",\"name\",\"position\"}{print}' a.txt ID name position 101,abc,CEO 102,def,CTO 103,qaz,COO 作用二 做运算 示例1:计算1到100的和 [root@7-test1 ~]# awk 'BEGIN{for(i=1;i 示例2:普通计算 [root@7-test1 ~]# awk 'BEGIN{print 3+3}' 6 [root@7-test1 ~]# awk 'BEGIN{print 3*3}' 9 [root@7-test1 ~]# awk 'BEGIN{print 3-3}' 0 [root@7-test1 ~]# awk 'BEGIN{print 3**3}' 27 [root@7-test1 ~]# awk 'BEGIN{print 3%3}' 0 [root@7-test1 ~]# awk 'BEGIN{print 3/3}' 1 作用三 修改awk内置变量 record 字段 separator 分隔符 变量名 对应单词 含义 FS field separator 字段分隔符,默认空格或tab OFS output field separator 输出分隔符,默认空格 RS record separator 记录分隔符,默认换行符\\n ORS output record separator 输出记录分隔符 FS 指定字段分隔符 //passwd.txt文件内容如下 [root@7-test1 ~]# cat passwd.txt root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin 示例1：以冒号为分隔符，打印文件第一列 //-F写法 [root@7-test1 ~]# awk -F: '{print $1}' passwd.txt root bin daemon //BEGIN {FS}写法 [root@7-test1 ~]# awk 'BEGIN{FS=\":\"}{print $1}' passwd.txt root bin daemon OFS 指定输出分隔符 //文件内容如下 [root@7-test1 ~]# cat a.txt 1 2 3 示例1：打印文件第一列和第三列，以冒号为分隔符 //-v OFS写法 [root@7-test1 ~]# awk -v OFS=: '{print $1,$3}' a.txt 1:3 //BEGIN {OFS}写法 [root@7-test1 ~]# awk 'BEGIN{OFS=\":\"}{print $1,$3}' a.txt 1:3 ⚠️⚠️⚠️注意：！！！ -v OFS写法的一个坑：当print $0的时候，-v OFS会不生效 //正确输出应该为1:2:3 [root@7-test1 ~]# awk -v OFS=: '{print $0}' a.txt 1 2 3 解决方法 在print$0前加一个$1=$1 [root@7-test1 ~]# awk -v OFS=: '{$1=$1;print $0}' a.txt 1:2:3 RS 指定记录分隔符，即指定以什么为分隔符，默认为\\n //文件内容 文件默认以换行为记录分隔符 [root@7-test1 ~]# cat passwd.txt root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin 示例1：将文件的记录分隔符指定为/，即指定文件以/为换行符 //-v RS写法 [root@7-test1 ~]# awk -v RS=/ '{print $0}' passwd.txt root:x:0:0:root: root: bin bash bin:x:1:1:bin: bin: sbin nologin //BEGIN {RS}写法 [root@7-test1 ~]# awk 'BEGIN{RS=\"/\"}{print $0}' passwd.txt root:x:0:0:root: root: bin bash bin:x:1:1:bin: bin: sbin nologin ORS 指定输出记录分隔符 //文件内容 [root@7-test1 ~]# cat a.txt 1 2 3 示例1：将文件的输出记录分隔符指定为/ //-v ORS写法 [root@7-test1 ~]# awk -v ORS=\"A\" '{print $0}' a.txt 1A2A3A //BEGIN {ORS}写法 [root@7-test1 ~]# awk 'BEGIN{ORS=\"A\"}{print $0}' a.txt 1A2A3A 扩展-awk命令行参数 ARGC是命令行参数数量 ARGV是将命令行参数存到数组，元素由ARGC指定，数组下标从0开始 ARGC [root@test1 ~]# awk 'BEGIN{print ARGC}' 1 [root@test1 ~]# awk 'BEGIN{print ARGC}' 1 2 3 ARGV [root@test1 ~]# awk 'BEGIN{print ARGV[0]}' 1 2 awk [root@test1 ~]# awk 'BEGIN{print ARGV[1]}' 1 2 1 [root@test1 ~]# awk 'BEGIN{print ARGV[2]}' 1 2 2 二、END模式 END模式在awk读取完文件之后执行，主要作用为显示计算结果 作用 显示计算结果 示例1:统计/etc/passwd文件中前10行非登陆shell的个数 //文件内容 [root@7-test1 awk]# head -10 /etc/passwd root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin sync:x:5:0:sync:/sbin:/bin/sync shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown halt:x:7:0:halt:/sbin:/sbin/halt mail:x:8:12:mail:/var/spool/mail:/sbin/nologin operator:x:11:0:operator:/root:/sbin/nologin //统计文件中非登陆shell的个数，即统计/sbin/nologin的个数 [root@7-test1 awk]# head -10 /etc/passwd|awk '/nologin/{i++}END{print i}' 6 示例2:统计/etc/services中空行数量 [root@7-test1 awk]# awk '/^$/{i++}END{print i}' /etc/services 17 示例3:统计nginx访问日志中访问量前10的IP [root@7-test1 ~]# awk '{a[$1]++}END{for(i in a) print a[i],i}' /var/log/nginx/access.log|sort -nr|head 275 109.98.109.101 262 146.196.97.242 210 47.52.155.218 152 142.234.200.81 75 72.211.58.142 10 120.25.208.128 7 42.236.10.84 6 42.236.10.92 3 5.188.210.12 3 42.236.10.75 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux命令/awk/3.awk内置变量.html":{"url":"linux/linux命令/awk/3.awk内置变量.html","title":"3.awk内置变量","keywords":"","body":"awk内置变量 $0 表示匹配的整行 //文件内容 [root@7-test1 ~]# cat passwd.txt root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin 示例： [root@7-test1 ~]# awk '{print $0}' passwd.txt root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin NR 总的行号 //文件a.txt和b.txt的内容如下 文件a.txt 101,abc,CEO 102,def,CTO 103,qaz,COO 文件b.txt 666,ABC,CEO 777,DEF,CTO 888,QAZ,COO //打印两个文件，NR统计总的行号 [root@7-test1 ~]# awk '{print NR,$0}' a.txt b.txt 1 101,abc,CEO 2 102,def,CTO 3 103,qaz,COO 4 666,ABC,CEO 5 777,DEF,CTO 6 888,QAZ,COO FNR 当前文件的行号 文件a.txt 101,abc,CEO 102,def,CTO 103,qaz,COO 文件b.txt 666,ABC,CEO 777,DEF,CTO 888,QAZ,COO //打印两个文件，FNR只统计每个文件的行号 [root@7-test1 ~]# awk '{print FNR,$0}' a.txt b.txt 1 101,abc,CEO 2 102,def,CTO 3 103,qaz,COO 1 666,ABC,CEO 2 777,DEF,CTO 3 888,QAZ,COO NF 文件最后一列 //打印/etc/passwd文件最后一列 [root@7-test1 ~]# awk -F: '{print $NF}' /etc/passwd|head /bin/bash /sbin/nologin /sbin/nologin /sbin/nologin /sbin/nologin /bin/sync /sbin/shutdown /sbin/halt /sbin/nologin /sbin/nologin 分隔符 record 字段 separator 分隔符 变量名 对应单词 含义 FS field separator 字段分隔符,默认空格或tab OFS output field separator 输出分隔符,默认空格 RS record separator 记录分隔符,默认换行符\\n ORS output record separator 输出记录分隔符 FS 指定字段分隔符 //passwd.txt文件内容如下 [root@7-test1 ~]# cat passwd.txt root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin 示例1：以冒号为分隔符，打印文件第一列 //-F写法 [root@7-test1 ~]# awk -F: '{print $1}' passwd.txt root bin daemon //BEGIN {FS}写法 [root@7-test1 ~]# awk 'BEGIN{FS=\":\"}{print $1}' passwd.txt root bin daemon OFS 指定输出分隔符 //文件内容如下 [root@7-test1 ~]# cat a.txt 1 2 3 示例1：打印文件第一列和第三列，以冒号为分隔符 //-v OFS写法 [root@7-test1 ~]# awk -v OFS=: '{print $1,$3}' a.txt 1:3 //BEGIN {OFS}写法 [root@7-test1 ~]# awk 'BEGIN{OFS=\":\"}{print $1,$3}' a.txt 1:3 ⚠️⚠️⚠️注意：！！！ -v OFS写法的一个坑：当print $0的时候，-v OFS会不生效 //正确输出应该为1:2:3 [root@7-test1 ~]# awk -v OFS=: '{print $0}' a.txt 1 2 3 解决方法 在print$0前加一个$1=$1 [root@7-test1 ~]# awk -v OFS=: '{$1=$1;print $0}' a.txt 1:2:3 RS 指定记录分隔符，即指定以什么为分隔符，默认为\\n //文件内容 文件默认以换行为记录分隔符 [root@7-test1 ~]# cat passwd.txt root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin 示例1：将文件的记录分隔符指定为/，即指定文件以/为换行符 //-v RS写法 [root@7-test1 ~]# awk -v RS=/ '{print $0}' passwd.txt root:x:0:0:root: root: bin bash bin:x:1:1:bin: bin: sbin nologin //BEGIN {RS}写法 [root@7-test1 ~]# awk 'BEGIN{RS=\"/\"}{print $0}' passwd.txt root:x:0:0:root: root: bin bash bin:x:1:1:bin: bin: sbin nologin ORS 指定输出记录分隔符 //文件内容 [root@7-test1 ~]# cat a.txt 1 2 3 示例1：将文件的输出记录分隔符指定为/ //-v ORS写法 [root@7-test1 ~]# awk -v ORS=\"A\" '{print $0}' a.txt 1A2A3A //BEGIN {ORS}写法 [root@7-test1 ~]# awk 'BEGIN{ORS=\"A\"}{print $0}' a.txt 1A2A3A 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux命令/awk/4.awk匹配模式.html":{"url":"linux/linux命令/awk/4.awk匹配模式.html","title":"4.awk匹配模式","keywords":"","body":"awk匹配模式 一、正则表达式 1.1匹配记录(整行) //匹配/etc/passwd文件中以root开头的 [root@7-test1 ~]# awk '/^root/' /etc/passwd root:x:0:0:root:/root:/bin/bash [root@7-test1 ~]# awk '$0 ~/^root/' /etc/passwd root:x:0:0:root:/root:/bin/bash 1.2匹配字段 匹配操作符(~|!~) //匹配/etc/passwd文件中第一列以root开头的 [root@7-test1 ~]# awk '$1~/^root/' /etc/passwd root:x:0:0:root:/root:/bin/bash //匹配/etc/passwd文件中最后一列不是以bash结尾的 [root@7-test1 ~]# awk '$NF !~ /bash$/' /etc/passwd|head -5 bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin sync:x:5:0:sync:/sbin:/bin/sync ^和~用法示例 ^ 在awk中表示以...开头的列，在sed、grep中表示以...开头的行 ^用法示例 示例：打印文件中以1开头的行 //文件内容 [root@7-test1 awk]# cat t.txt 1 101,hehe,CEO 2 102,haha,CTO 3 103,xixi,COO 4 105,yy,CFO 5 106,xx,CIO 6 110,jjxx,COCO [root@7-test1 awk]# awk '/^1/{print}' t.txt 1 101,hehe,CEO ～用法示例 //文件内容 [root@7-test1 awk]# cat t1.txt zhang san 1234567 :550:100:175 li si 88883336 :155:90:201 wang wu 66666666 :250:60:50 zhao liu 67676798 :150:80:75 hao qi 11112222 :250:100:175 zhu ba 000098763 :50:95:135 //显示所有ID号码最后一位是2或7的人的全名 [root@7-test1 awk]# awk '$3~/[27]$/{print $1,$2}' t1.txt zhang san hao qi //显示文件中第三列以1开头的行 [root@7-test1 awk]# awk '$3~/^1/{print}' t1.txt zhang san hao qi //显示zhang的姓氏和ID号码 [root@7-test1 awk]# awk '$1~/zhang/{print $1,$3}' t1.txt zhang 1234567 //显示zhang的捐款，每个值都以$开头，如$250$100$175 方法一： [root@7-test1 awk]# awk -vFS='[ :]+' -vOFS=$ '$1~/zhang/{print \"$\"$4,$5,$NF}' t1.txt $550$100$175 方法二： awk替换函数gsub gsub 全局替换 awk内置命令(函数) 使用方法 gsub(//,\"\",$n) n表示数字 gsub(/找谁/,\"替换为什么\",替换哪一列) [root@7-test1 awk]# awk '$1~/zhang/{gsub(/:/,\"$\",$NF);print $1,$NF}' t1.txt zhang $550$100$175 二、条件表达式 2.1关系运算符 运算符 含义 小于 小于等于 == 等于 != 不等于 > 大于 >= 大于等于 ~ 模糊匹配 !~ 模糊匹配取反 2.2示例 示例1:打印第一列大于3的行 //文件内容 [root@7-test1 awk]# cat t.txt 1 101,hehe,CEO 2 102,haha,CTO 3 103,xixi,COO 4 105,yy,CFO 5 106,xx,CIO 6 110,jjxx,COCO [root@7-test1 awk]# awk '{if($1>3)print}' t.txt 4 105,yy,CFO 5 106,xx,CIO 6 110,jjxx,COCO 示例2:显示磁盘使用率大于10%的磁盘分区和挂载点 [root@7-test1 awk]# df -h Filesystem Size Used Avail Use% Mounted on /dev/mapper/centos-root 17G 2.4G 15G 14% / devtmpfs 224M 0 224M 0% /dev tmpfs 236M 0 236M 0% /dev/shm tmpfs 236M 9.6M 226M 5% /run tmpfs 236M 0 236M 0% /sys/fs/cgroup /dev/sda1 1014M 132M 883M 14% /boot tmpfs 48M 0 48M 0% /run/user/0 [root@7-test1 awk]# df -h|awk -F'[% ]+' 'NR>1 && $5>10{print $1,$5\"%\",$NF}' /dev/mapper/centos-root 14% / /dev/sda1 14% /boot 示例3:计算内存使用率 centOS6 //centOS6查看内存使用率 [root@test1 ~]# free -m total used free shared buffers cached Mem: 474 171 303 0 30 44 -/+ buffers/cache: 95 378 Swap: 1023 0 1023 //centOS6计算内存使用率 [root@test1 ~]# free -m|awk 'NR==3{print $3/($3+$4)*100\"%\"}' 20.296% centOS7 //centOS7查看内存使用率 [root@7-test1 awk]# free -m total used free shared buff/cache available Mem: 470 90 243 5 136 330 Swap: 2047 0 2047 //centOS7计算内存使用率 [root@7-test1 awk]# free -m|awk 'NR==2{print ($2-$NF)/$2*100\"%\"}' 30% 示例4:同时计算内存使用率和空闲率 centOS6 //centOS6计算内存使用率和空闲率 [root@test1 ~]# free -m|awk 'NR==3{print $3/($3+$4)*100\"%\",$NF/($3+$NF)*100\"%\"}' 20.4641% 79.5359% centOS7 //centOS7计算内存使用率和空闲率 [root@7-test1 ~]# free -m|awk 'NR==2{print ($2-$NF)/$2*100\"%\",$NF/$2*100\"%\"}' 30% 70% 2.3awk的一个坑 ⚠️⚠️⚠️awk会把数字当成字符处理 //查看磁盘使用率 [root@test1 ~]# df -h Filesystem Size Used Avail Use% Mounted on /dev/sda3 19G 2.4G 16G 14% / tmpfs 238M 0 238M 0% /dev/shm /dev/sda1 190M 35M 146M 19% /boot //打印第二行第5列小于9的列，结果不正确 [root@test1 ~]# df -h|awk 'NR>1 && $51 && $5+01 && $5 三、运算表达式 示例1:打印/etc/passwd第三列与10相乘大于5000的内容 [root@test1 ~]# awk -F: '$3 * 10 > 5000' /etc/passwd polkitd:x:999:998:User for polkitd:/:/sbin/nologin chrony:x:998:996::/var/lib/chrony:/sbin/nologin mysql:x:1000:1000::/home/mysql:/sbin/nologin 示例2：打印/etc/passwd第三列与10相乘大于500的内容，并打印第一列和第三列 [root@test1 ~]# awk -F: 'BEGIN{OFS=\"--\"} { if($3*10>5000) {print $1,$3} } END {print \"打印ok\"}' /etc/passwd polkitd--999 chrony--998 mysql--1000 打印ok 示例3:加、减、乘、除、取模、幂运算 //文件test.txt内容如下 [root@test1 ~]# cat test.txt a 1 2 3 4 5 b 1 2 3 4 5 a 5 6 7 8 9 [root@test1 ~]# awk '/a/{print $2+10}' test.txt 11 15 [root@test1 ~]# awk '/a/{print $2-10}' test.txt -9 -5 [root@test1 ~]# awk '/a/{print $2*10}' test.txt 10 50 [root@test1 ~]# awk '/a/{print $2/10}' test.txt 0.1 0.5 [root@test1 ~]# awk '/a/{print $2%10}' test.txt 1 5 [root@test1 ~]# awk '/a/{print $2**10}' test.txt 1 9765625 四、逻辑操作符和复合模式 4.1逻辑操作符 符号 含义 && 逻辑与 **\\ \\ ** 逻辑或 ！ 逻辑非 示例1:打印/etc/passwd文件中用户名为root并且打印uid小于15的行 //文件中第三列是UID [root@test1 ~]# awk -F: '$1~/root/ && $3 示例2:打印用户名为root或第三列大于500的行 [root@test1 ~]# awk -F: '$1~/root/ || $3>=500' /etc/passwd root:x:0:0:root:/root:/bin/bash polkitd:x:999:998:User for polkitd:/:/sbin/nologin chrony:x:998:996::/var/lib/chrony:/sbin/nologin mysql:x:1000:1000::/home/mysql:/bin/false 4.2三元运算符 三元运算符表达式 三元运算符的形式1：[ 结果 = 条件 ? 结果1：结果2 ] 三元运算符的形式2：[ 条件 ？ 表达式1 ： 表达式2 ] 示例： //文件t.txt内容如下 [root@test1 ~]# cat t.txt student1 98 student2 99 student3 93 student4 78 student5 85 根据学生成绩判断学生成绩是否为优秀，这里规定分数大于90是优秀，低于90非优秀 //非三元运算写法 [root@test1 ~]# awk '{if($2>90){print $1,\"优秀\"}else{print $1,\"不优秀\"}}' t.txt student1 优秀 student2 优秀 student3 优秀 student4 不优秀 student5 不优秀 //三元运算写法一 结果 = 条件 ? 结果1：结果2 [root@test1 ~]# awk '{res=$2>90?\"优秀\":\"不优秀\";print $1,res}' t.txt student1 优秀 student2 优秀 student3 优秀 student4 不优秀 student5 不优秀 #上述awk写法中的print也可以单独写在一个大括号中 awk '{res=$2>90?\"优秀\":\"不优秀\"}{print $1,res}' t.txt #可以使用三元运算符统计个数 //三元运算写法二 条件 ？ 表达式1 ： 表达式2 [root@test1 ~]# awk '{$2>90?a++:b++}END{print a,b}' t.txt 3 2 a表示符合条件的，b表示不符合条件的，大于90分的有3个，低于90分的有2个 至今没懂的一道题🦙🦙🦙 文件内容 [root@test1 ~]# cat lessons.txt 634751 预排 568688 预排 386760 删除 619373 预排 428491 预排 487563 完成 603342 完成 436339 完成 结果： 删除 386760 完成 487563,603342,436339 预排 634751,568688,619373,428491 [root@test1 ~]# awk '{a[$2]=a[$2]\" \"$1}END{for(i in a) print i,a[i]}' lessons.txt 删除 386760 完成 487563 603342 436339 预排 634751 568688 619373 428491 [root@test1 ~]# awk '{a[$2]=a[$2]\",\"$1}END{for(i in a) print i,a[i]}' lessons.txt 删除 ,386760 完成 ,487563,603342,436339 预排 ,634751,568688,619373,428491 方法一 [root@test1 ~]# awk '{a[$2]=a[$2]?a[$2]\",\"$1:a[$2]$1}END{for(i in a) print i,a[i]}' lessons.txt 删除 386760 完成 487563,603342,436339 预排 634751,568688,619373,428491 方法二 [root@test1 ~]# awk '{if(a[$2]){a[$2]=a[$2]\",\"$1}else{a[$2]=a[$2]$1}}END{for(i in a) print i,a[i]}' lessons.txt 删除 386760 完成 487563,603342,436339 预排 634751,568688,619373,428491 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux命令/awk/5.awk条件.html":{"url":"linux/linux命令/awk/5.awk条件.html","title":"5.awk条件","keywords":"","body":"awk条件 一、if 1.1语法格式 {if(表达式) {语句1;语句2;...}} 1.2示例 示例1:打印/etc/passwd文件中的root用户 [root@test1 ~]# awk -F: '{if ($3==0) {print $1 \" is adminisitrator\"}}' /etc/passwd root is adminisitrator 示例2:统计/etc/passwd中系统用户数 [root@test1 ~]# awk -F: '{ if($3>0 && $3 示例3:统计/etc/passwd中普通用户数量 [root@test1 ~]# awk -F: '{if ($3>1000) {i++}} END{print i}' /etc/passwd 2 示例4:写出一个shell脚本，把当前目录下的文本文件number.txt里面数字大于100的求和并输出，并打印所在行行号及内容，最后还要输出每一行的总和 //文件内容 [root@test1 ~]# cat number.txt 100 98 205 303 1 99 66 33 [root@test1 ~]# awk '{if($1>100){sum+=$1;print NR,$0}}{i+=$1}END{print sum,i}' number.txt 3 205 4 303 508 905 二、if...else 2.1语法格式 {if(表达式)｛语句;语句;... ｝else{语句;语句;...}} 2.2示例 示例1:if else语句简单使用 //文件内容 [root@test1 ~]# cat test.txt 1 2 3 4 5 6 [root@test1 ~]# awk '{if ($3==3) {print $1} else {print $NF}}' test.txt 1 [root@test1 ~]# awk '{if ($3==6) {print $1} else {print $NF}}' test.txt 6 示例2:打印/etc/passwd中非管理员个数和管理员个数 [root@test1 ~]# awk -F: '{if ($3==0) {a++} else {b++}} END{print \"管理员用户个数：\"a;print \"其他用户个数：\"b}' /etc/passwd 管理员用户个数：1 其他用户个数：24 三、if...else if...else 3.1语法格式 {if(表达式 1)｛语句;语句；... ｝else if(表达式 2)｛语句;语句；... ｝else｛语句;语句；... }} 3.2示例 统计/etc/passwd文件中用户的种类 #/etc/passwd文件中第三列是用户UID，centos7中普通用户UID大于1000 awk -F: '{if($3==0){i++} else if($3>0 && $30 && $3=1000){k++}} END{print \"管理员个数为:\"i;print \"系统用户个数为:\"j;print \"普通用户个数为:\"k}' /etc/passwd 管理员个数为:1 系统用户个数为:25 普通用户个数为:1 四、switch-case #示例 [root@test1 ~]# awk 'BEGIN{a=1;b=2;c=3; switch(a){case 1:print a;break;case 2:print b;break; case 3:print c;break;}}' 1 #格式化后的整体结构如下 BEGIN{ a=1; b=2; c=3; switch(a){ case 1: print a;break; case 2: print b;break; case 3: print c;break; } } 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux命令/awk/6.awk循环.html":{"url":"linux/linux命令/awk/6.awk循环.html","title":"6.awk循环","keywords":"","body":"awk循环 1.for循环 1.1 c格式 1.1.1 c格式语法 for(初始值;终止值;步长值){语句} 1.1.2示例 //示例1 [root@test1 ~]# awk 'BEGIN{for(i=1;i 1.2 列表格式 1.2.1 列表格式语法 for(变量 in 数组){语句} 1.2.2示例 [root@test1 ~]# awk 'BEGIN{a[0]=10;a[1]=11;for(i in a) print i,a[i]}' 0 10 1 11 2.while循环 2.1语法格式 while(条件){语句} 2.2示例 语句示例 //打印1-5 [root@test1 ~]# awk 'BEGIN{i=1;while(i awk文件示例 //用awk获取文件中第三列到倒数第二列字段 [root@test1 ~]# cat > awk.awk 3.do while循环 3.1语法 do {语句} while(条件) 3.2示例 示例：计算1-100的和 [root@test1 ~]# awk 'BEGIN{do{sum+=i;i++}while(i 循环中的关键字 break：当 break 语句用于 while 或 for 语句时，导致退出程序循环 continue：当 continue 语句用于 while 或 for 语句时，使程序循环移动到下一个迭代 next：能能够导致读入下一个输入行，并返回到脚本的顶部。这可以避免对当前输入行执行其他的操作过程 exit：语句使主输入循环退出并将控制转移到END,如果END存在的话。如果没有定义END规则，或在END中应用exit语句，则终止脚本的执行 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux命令/awk/7.awk数组.html":{"url":"linux/linux命令/awk/7.awk数组.html","title":"7.awk数组","keywords":"","body":"awk数组 1.awk数组格式 数组名[索引]=值 2.创建awk数组 //创建一个数组，数组名是a，数组的索引是\"aaa\"和\"bbb\" [root@test1 ~]# awk 'BEGIN{a[\"aaa\"]=\"www.aaa.com\";a[\"bbb\"]=\"www.bbb.com\"; print a[\"aaa\"] \"\\n\" a[\"bbb\"]}' www.aaa.com www.bbb.com 3.删除数组元素 //使用delete 数组名[索引] 删除数组元素 [root@test1 ~]# awk 'BEGIN{a[\"aaa\"]=\"www.aaa.com\";a[\"bbb\"]=\"www.bbb.com\";delete a[\"aaa\"]; print a[\"aaa\"] \"\\n\" a[\"bbb\"]}' www.bbb.com 4.按照索引遍历 //以下示例了以统计的字段为数组的索引 [root@test1 ~]# awk -F: '{a[++i]=$1} END{print a[1]}' /etc/passwd root [root@test1 ~]# awk -F: '{a[i++]=$1} END{print a[1]}' /etc/passwd bin [root@test1 ~]# head -2 /etc/passwd root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin 5.awk数组示例 5.1简单示例 5.1.1统计/etc/passwd中各种类型shell的数量 [root@test1 ~]# awk -F: '{a[$NF]++} END{for(i in a){print i,a[i]}}' /etc/passwd /bin/sync 1 /bin/bash 2 /sbin/nologin 22 /sbin/halt 1 /sbin/shutdown 1 5.1.2 80端口访问状态统计 [root@test1 ~]# ss -an|awk '/:80/{a[$2]++} END{for(i in a){print i,a[i]}}' LISTEN 3 5.2结合日志文件的示例 nginx访问日志格式如下 82.113.63.230 - - [25/Jan/2019:15:15:56 +0800] \"GET / HTTP/1.1\" 301 169 \"-\" \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36\" \"-\" 5.2.1统计2019年1月25日当天的PV量 [root@test1 ~]# awk '/25\\/Jan\\/2019/{i++}END{print i}' /var/log/nginx/access.log 90 5.2.2统计15-19点的PV量 [root@test1 ~]# awk '$4>=\"[25/Jan/2019:15:00:00\" && $4 5.2.3统计2019年1月25日当天内访问最多的10个IP [root@test1 ~]# awk '/25\\/Jan\\/2019/ {a[$1]++} END {for(i in a){print i,a[i]}}' /var/log/nginx/access.log |sort -rn|head 5.2.4统计2019年1月25日15-19点访问次数最多的10个IP [root@test1 ~]# awk '$4>=\"[25/Jan/2019:15:00:00\" && $4 5.2.5统计2019年1月25日访问次数大于100的IP [root@test1 ~]# awk '/25\\/Jan\\/2019/ {a[$1]++} END {for(i in a){if(a[i]>10){print i,a[i]}}}' /var/log/nginx/access.log 5.2.6统计2019年1月25日访问最多的10个页面($requests top 10) //nginx访问日志中第7列是访问url [root@test1 ~]# awk '/25\\/Jan\\/2019/ {a[$7]++} END {for(i in a){print a[i],i}}' /var/log/nginx/access.log |sort -rn|head 5.2.7统计每个IP访问状态码的数量 [root@test1 ~]# awk '{a[$1 \" \" $9]++} END {for(i in a){print a[i],i}}' /var/log/nginx/access.log|sort -rn|head 10 101.227.27.188 301 9 113.193.226.3 301 3 59.36.132.240 301 3 182.254.52.17 301 2 80.82.70.187 301 2 64.246.161.190 302 2 14.18.182.223 302 2 14.18.182.223 301 2 124.161.103.251 301 1 83.97.20.33 301 5.2.8统计访问状态码为404及出现的次数($status) //统计某一天的 [root@test1 ~]# awk '{if($9==\"404\") a[$9]++} END {for(i in a){print i,a[i]}}' /var/log/nginx/access.log //统计某一天某一时刻的 [root@test1 ~]# awk '$4>=\"[25/Jan/2019:15:00:00\" && $4 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux命令/awk/8.awk函数.html":{"url":"linux/linux命令/awk/8.awk函数.html","title":"8.awk函数","keywords":"","body":"awk函数 1.awk内置函数 1.1 gsub 1.1.1语法 gsub(/要替换的内容/,'替换后的内容',替换哪一列) 1.1.2示例 //将/etc/passwd文件中root一行中的冒号替换为加号 [root@test1 ~]# awk '$1~/^root/{gsub(/:/,\"+\",$NF);print $0}' /etc/passwd root+x+0+0+root+/root+/bin/bash 1.2 substr 1.2.1语法 substr(某一列,从第几个字符开始,截取几个字符结束) 1.2.2示例 //简单使用示例 [root@test1 ~]# echo 'abcdefg'|awk '{print substr($1,3,3)}' cde 1.3 split 1.3.1语法 split(某一列,数组名,/要替换的内容/) 把某一列通过正则表达式切割然后放到数组中 1.3.2示例 [root@test1 ~]# echo GET /a/b/c/d/e.jpg|awk '{split($2,a,/\\./);print a[1]}' /a/b/c/d/e [root@test1 ~]# echo GET /a/b/c/d/e.jpg|awk '{split($2,a,/\\./);print a[2]}' jpg 1.4 system 1.3.1含义 awk调用shell命令 1.3.2示例 //⚠️命令外必须用双引号包裹 awk 'BEGIN{system(\"ls\")}' 2.awk自定义函数 //编辑awk文件function.awk cat >function.awk 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux命令/grep命令.html":{"url":"linux/linux命令/grep命令.html","title":"grep命令","keywords":"","body":"grep命令 1.正则表达式 1.1基本正则表达式 1.2扩展正则表达式 1.3特殊字字符类 [:alnum:] [a-zA-Z0-9]匹配人一个字母或数字字符 [:alpha:] 匹配任意一个字母（包括大小写） [:digit:] 匹配任意一个数字 [:lower:] 匹配小写字母 [:upper:] 匹配大写字母 [:punct:] 匹配标点符号 [:blank:] 匹配空格与制表符 [:space:] 匹配一个包括换行符、回车等在内的所有空白字符 [:graph:] 匹配任意可看的见的且可打印的字符 [:print:] 匹配任何一个可以打印的字符 [:xdigit:] 匹配任意一个16进制数（0-9，a-f，A-F） 2.grep命令 2.1命令说明 Linux系统中grep命令是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。grep全称是Global Regular Expression Print，表示全局正则表达式版本，它的使用权限是所有用户 2.2命令格式 grep [options] file 2.3选项 -E 如果加这个选项，那么后面的匹配模式就是扩展的正则表达式，也就是 grep -E = egrep -i 比较字符时忽略大小写区别 -l 过滤的时候只显示文件名 找出包含sshd的文件 -w 把表达式作为词来查找，相当于正则中的\"\\\"(...表示你自定义的规则) -x 被匹配到的内容，正好是整个行，相当于正则\"^...$\" -v 取反 -c count，统计，统计匹配结果的行数，不是匹配结果的次数，是行数 -m 只匹配规定的行数，之后的内容就不再匹配了 -n 在输出的结果里显示行号，这里的行号是该行内容在原文件中的行号，而不是在输出结果中行号 -o 只显示匹配内容，grep 默认是显示满足匹配条件的一行，加上这个参数就只显示匹配结果，比如我们要匹配一个 ip 地址，就只需要结果，而不需要该行的内容 -R 递归匹配。如果要在一个目录中多个文件或目录匹配内容，则需要这个参数 -B 输出满足条件行的前几行，比如 grep -B 3 \"aa\" file 表示在 file 中输出有 aa 的行，同时还要输出 aa 的前 3 行 -A 这个与-B 类似，输出满足条件行的后几行 -C 这个相当于同时用-B -A，也就是前后都输出 -P 支持perl正则 2.4grep扩展用法 2.4.1扩展用法1 grep后向引用 示例：将文本中连续相同的数字打印出来 ()表示匹配的内容,当前为匹配数字,\\1为后向引用, echo '1222233333222444455556666669999'|egrep -o '([0-9])\\1+' 命令后边如果写+就会无法截取1,因为1只有一个 此时就需要在后边再单独匹配数字1 echo '1222233333222444455556666669999'|egrep -o '([0-9])\\1+|[0-9]' 另外两种写法 echo '1222233333222444455556666669999'|egrep -o '([0-9])\\1*' echo '1222233333222444455556666669999'|egrep -o '(.)\\1*' 2.4.2扩展用法2 grep -P与零宽断言匹配 零宽断言:perl语言正则匹配 核心:截取特定字符串左边或右边的内容 截取string右边的内容 lookahead (?=string) 截取string左边的内容 lookbehind (? 零宽断言截取字符串 示例1:取出文件中:右边的内容 //文件内容如下,现在要截取出:右边的数字 [root@exercise2 ~]# cat a.txt id:01 id:02 id:03 id:04 id:05 id:06 id:07 id:08 id:09 id:10 666 test666 方法: grep -Po \"(? 示例2:截取IP地址 [root@7-test1 ~]# ip a s eth0 2: eth0: mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:93:32:b9 brd ff:ff:ff:ff:ff:ff inet 10.0.0.200/24 brd 10.0.0.255 scope global noprefixroute eth0 valid_lft forever preferred_lft forever inet6 fe80::19ee:50ab:53fc:55f9/64 scope link noprefixroute valid_lft forever preferred_lft forever ()中有小于号,表明要截取字符串右边的内容 [root@7-test1 ~]# ip a s eth0 | grep -Po '(? 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux命令/sed命令.html":{"url":"linux/linux命令/sed命令.html","title":"sed命令","keywords":"","body":"sed命令 1.sed命令工作流程 1、将文件的第一行读入到自己的缓存空间，删除换行符 2、匹配，看一下该行是否为要编辑的行，如果是，执行编辑命令，不是，执行1 3、执行编辑命令 4、加上换行符输出到屏幕 5、判断是否为文件尾，如果是，退出，不是，再重复1-4 默认情况下，sed缓存空间内的行都会输出到屏幕，除非使用-n选项 默认情况下，sed将修改的行输出到屏幕，并没有修改源文件，使用-i选项修改源文件 2.命令格式 sed 选项 地址1,地址2 命令 标记 文件名 3.选项 选项 含义 -n 拟制输出，不输出未修改的行，强制输出用命令p -i 修改源文件，需要强制备份源文件 -i.bak即可 -r 让sed支持扩展正则表达式，默认支持标准正则表达式 -f 指定文件，将sed命令写到文件中，然后执行sed -f 文件名 要修改的文件，但是从未成功执行过！！！ -e 允许一条命令执行多个sed子命令 sed -e ‘s#a#b#g’ -e ‘s#A#B#g’ 3.1定位、匹配 3.1.1使用行号 定位1-5行 1,5 定位到最后一行 $ 指定起始匹配行和步长 1~5(从第一行开始，每隔5行匹配) 定位奇数行 1～2 定位偶数行 0～2 定位某行之后的n行 1,+3 3.1.2使用正则表达式 /正则表达式/ 4.命令 命令 含义 a\\ 在当前行后添加一行或多行 c\\ 用新文本修改（替换）当前行中的文本 d 删除行 i\\ 在当前行之前插入文本 h 把模式空间里的内容复制到暂存缓存区 H 把模式空间里的内容追加到暂存缓存区 g 取出暂存缓冲区里的内容，将其复制到模式空间，覆盖该处原有内容 G 取出暂存缓冲区里的内容，将其复制到模式空间，追加在原有内容后面 l 列出非打印字符 p 打印行 n 读入下一输入行，并从下一条命令而不是第一条命令开始处理 q 结束或退出sed r 从文件中读取输入行 ! 对所选行之外的所有行应用命令 s 用一个字符串替换另一个 4.1 p 打印 文件内容 [root@test1 ~]# cat hehe 123456 111111 abcdef (abc)def 2 222222 例：打印第1行 [root@test1 ~]# sed -n '1p' hehe 123456 文件内容 [root@test1 test]# cat hehe.txt 1 101,hehe,CEO 2 102,haha,CTO 3 103,xixi,COO 4 104,yy,CFO 5 105,xx,CIO 6 110,jjxx,COCO 例：打印从101开始到105结束的行 [root@test1 test]# sed -n '/101/,/105/p' hehe.txt 1 101,hehe,CEO 2 102,haha,CTO 3 103,xixi,COO 4 104,yy,CFO 5 105,xx,CIO 例：打印从101开始到第3行 [root@test1 test]# sed -n '/101/,3p' hehe.txt 1 101,hehe,CEO 2 102,haha,CTO 3 103,xixi,COO 4.2 d 删除 命令d用于删除输入行 sed 先将输入行从文件复制到模式缓存区，然后对该行执行sed命令，最后将模式缓存区的内容显示在屏幕上 如果发出的是命令d，当前模式缓存区的输入行会被删除，不被显示 文件内容 [root@test1 ~]# cat hehe 123456 111111 abcdef (abc)def 2 222222 例：将有1的行删除 [root@test1 ~]# sed '/1/d' hehe abcdef (abc)def 2 222222 例：将文件的1到3行删除 [root@test1 ~]# sed '1,3d' hehe (abc)def 2 222222 文件内容 [root@test1 test]# cat 111.txt 101,aaa,CEO 102,bbb,CTO 103,ccc,COO 104,ddd,CFO 105,eee,CIO 110,fff,COCO 例：将文件的第1行到第5行删除 [root@test1 test]# sed '1,5d' 111.txt 110,fff,COCO 例：将文件从ddd到文件结尾删除 [root@test1 test]# sed '/ddd/,$d' 111.txt 101,aaa,CEO 102,bbb,CTO 103,ccc,COO 例：删除不包含fff的行 [root@test1 test]# sed '/fff/!d' 111.txt 110,fff,COCO 4.3 s 替换 文件内容 [root@test1 ~]# cat hehe 123456 111111 abcdef (abc)def 2 222222 例：将文件中的1全部替换为? [root@test1 ~]# sed 's/1/?/g' hehe ?23456 ?????? abcdef (abc)def 2 222222 例：将abcdef替换为abchehe, \\1表示匹配的abc [root@test1 ~]# cat hehe 123456 111111 abcdef (abc)def 2 222222 [root@test1 ~]# sed -r 's/(abc)def/\\1hehe/' hehe \\1表示前边匹配的abc 123456 111111 abchehe (abc)def 2 222222 4.4 逗号 指定行的范围 [root@test1 ~]# cat hehe 123456 111111 abcdef (abc)def 2 222222 111 例：匹配111111到222222之间的行 [root@test1 ~]# sed -n '/111111/,/222222/p' hehe 111111 abcdef (abc)def 222222 例：匹配从第5行开始，到第一个以2开头之间的行 [root@test1 ~]# sed -n '5,/2/p' hehe 111111 abcdef (abc)def 2 例：匹配111111所在行到以2开头的行 [root@test1 ~]# sed -n '/111111/,/2/p' hehe 111111 abcdef (abc)def 2 例：匹配从111111开始到第一个以2开头的行，然后将以1开头的行替换为hehe [root@test1 ~]# sed -n '/111111/,/2/s/^1/hehe/p' hehe hehe11111 4.5 e 多重编辑 -e命令是编辑命令，用于sed执行多个编辑任务的情况下 在下一行开始编辑前，所有的编辑动作将应用到模式缓存区的行上 [root@test1 ~]# cat hehe 123456 111111 abcdef (abc)def 2 222222 例：将第一行删除，并且替换abc为ABC [root@test1 ~]# sed -e '1d' -e 's#abc#ABC#g' hehe 111111 ABCdef (ABC)def 2 222222 4.6 a 追加 文件内容 [root@test1 ~]# cat hehe 123456 111111 abcdef (abc)def 2 222222 111 例：在以2开头的行后追加HEHE [root@test1 ~]# sed '/^2/aHEHE' hehe 123456 111111 abcdef (abc)def 2 HEHE 222222 HEHE 111 4.7 i 插入 i命令是插入命令，类似于a命令，但不是在当前行后增加文本，而是在当前行前面插入新的文本，即刚读入缓存区模式的行 [root@test1 ~]# cat hehe 123456 111111 abcdef (abc)def 2 222222 111 例：在以2开头的行前边插入HEHE [root@test1 ~]# sed '/^2/iHEHE' hehe 123456 111111 abcdef (abc)def HEHE 2 HEHE 222222 111 4.8 c 修改 c命令是修改命令,sed 使用该命令将已有的文本修改成新的文本,旧文本被覆盖 文件内容 [root@test1 ~]# cat hehe 123456 111111 abcdef (abc)def 2 222222 111 例：将文件中abcdef替换为ABCDEF [root@test1 ~]# sed '/abcdef/cABCDEF' hehe 123456 111111 ABCDEF (abc)def 2 222222 111 4.9 n 获取下一行 n命令表示下一条命令，sed 使用该命令获取输入文件的下一行，并将其读入到模式缓冲区中，任何 sed 命令都将应用到匹配行，即紧接着的下一行上 文件内容 [root@test1 ~]# cat hehe 123456 111111 abcdef (abc)def 2 222222 111 例：匹配111111一行，n表示获取下一行，即abcdef,并且替换e为E [root@test1 ~]# sed '/111111/{n;s/e/E/;}' hehe 123456 111111 abcdEf (abc)def 2 222222 111 4.10 y 转换 y命令表示转换，该命令与 tr 命令相似，字符按照一对一的方式从左到右进行转换 例如 y/abc/ABC/，会把小写字母转换成大写字母，a-->A,b-->B,c-->C，与s不同的是，y会全部替换，而s需要在最后加g 文件内容 [root@test1 ~]# cat hehe 123456 111111 abcdef (abc)def 2 222222 111 例：将1-3行的1转换为Q [root@test1 ~]# sed '1,3y/1/Q/' hehe Q23456 QQQQQQ abcdef (abc)def 2 222222 111 5.实际使用示例 5.1示例1 使用sed命令将/etc/passwd文件中红用户名和登陆shell调换位置 思路：将配置文件分组，用户名为第一组，最后的登陆shell分为一组，然后中间的内容分为一组，因此 hehe 是第一组 501:501::/home/hehe: 是第二组 /bin/bash 是第三组 [root@test1 ~]# tail -1 /etc/passwd hehe:x:500:500::/home/hehe:/bin/bash [root@test1 ~]# tail -1 /etc/passwd |sed -r 's#(.*)(:x.*:)(/.*)#\\3\\2\\1#g' /bin/bash:x:500:500::/home/hehe:hehe 5.2示例2 用sed命令取出ip地址 [root@test1 ~]# ifconfig eth0|sed -nr '2s#(.*:)(.*)(B.*)#\\2#gp' 192.168.1.8 5.3示例3 将以下文件进行批量需改（用一条命令完成） 修改前1.sh 2.sh 3.sh 修改后1_test.sh 2_test.sh 3_test.sh ls *.sh|sed -nr 's#((.*)\\.sh)#mv \\1 \\2_test.sh#gp' |bash 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/docker/1.docker简介.html":{"url":"linux/docker/1.docker简介.html","title":"1.docker简介","keywords":"","body":"docker简介 一、什么是Docker Docker是基于go语言实现的开源容器项目，诞生于2013年年初，最初发起者是dotCloud公司，2013年年底改为Docker Inc docker官网 1.1什么是容器 容器就是在隔离的环境运行的一个进程，如果进程停止，容器就会销毁，隔离环境拥有自己的系统文件、ip地址、主机名 1.2docker容器 docker是通过内核虚拟化技术 namespaces:提供容器资源隔离 cgroups:资源限制 docker通过操作系统层的虚拟化实现隔离，不需要类似虚拟机额外的操作系统开销，提高了资源利用率 优点： 1.创建分布式应用程序，快速分发和部署 2.迁移性好，通过容器来打包应用、解耦应用和运行平台 3.速度快，实现服务秒启动，占用系统资源少 缺点： 1.docker本质是一个进程，如果占用资源过多，会触发 oom机制 oom==out of memory 容器的启动 环境隔离 共用宿主机的内核：启动进程 二、Docker核心概念 2.1三大核心概念 2.1.1 镜像 Docker镜像是创建Docker容器的基础，镜像本身只读，一个镜像包含一个基本的操作系统环境，里面仅安装了一个应用程序，比如安装了apache应用程序，就可以称之为apache镜像 2.1.2 容器 Docker容器是从镜像创建的应用运行实例，它可以启动、开始、停止、删除，这些容器彼此相互隔离、互不可见 可以把容器看作是一个简易版linux系统环境(包括root用户权限、进程空间、用户空间、网络空间)以及运行在其中的应用程序打包而成的盒子 2.1.3 仓库 Docker仓库是集中存放镜像文件的场所 仓库注册服务器存放多个仓库，每个仓库集中存放某一类镜像，包括多个镜像文件，通过不同标签来进行区分 Docker仓库分为公开仓库和私有仓库 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/docker/2.CentOS7.5安装docker.html":{"url":"linux/docker/2.CentOS7.5安装docker.html","title":"2.docker安装","keywords":"","body":"CentOS7.5安装docker 一、安装docker最新版 1.1 下载yum源 #官方yum源 yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo #阿里云yum源 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo #清华yum源 yum-config-manager --add-repo https://mirrors4.tuna.tsinghua.edu.cn/docker-ce/linux/centos/docker-ce.repo 1.2 安装docker最新版 yum -y install docker-ce 1.3 启动docker systemctl start docker && systemctl enable docker 1.4 查看docker版本 [root@docker01 ~]# docker version Client: Version: 18.09.1 API version: 1.39 Go version: go1.10.6 Git commit: 4c52b90 Built: Wed Jan 9 19:35:01 2019 OS/Arch: linux/amd64 Experimental: false Server: Docker Engine - Community Engine: Version: 18.09.1 API version: 1.39 (minimum version 1.12) Go version: go1.10.6 Git commit: 4c52b90 Built: Wed Jan 9 19:06:30 2019 OS/Arch: linux/amd64 Experimental: false 1.5 配置docker镜像加速 #配置docker官方镜像加速地址 方式一 [root@docker01 ~]# cat > /etc/docker/daemon.json /etc/docker/daemon.json 1.6 创建并运行第一个容器 [root@docker01 ~]# docker run -d -p 80:80 nginx Unable to find image 'nginx:latest' locally latest: Pulling from library/nginx 6ae821421a7d: Pull complete da4474e5966c: Pull complete eb2aec2b9c9f: Pull complete Digest: sha256:dd2d0ac3fff2f007d99e033b64854be0941e19a2ad51f174d9240dda20d9f534 Status: Downloaded newer image for nginx:latest 6cd3a11bda37336b8d6f0ba3e266e697945f72d520bbd0225a6e93818c8d581d 二、安装docker指定版本 2.1 下载yum源 #官方yum源 yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo #阿里云yum源 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo #清华yum源 yum-config-manager --add-repo https://mirrors4.tuna.tsinghua.edu.cn/docker-ce/linux/centos/docker-ce.repo 2.2 查看可用版本 [root@docker01 ~]# yum list docker-ce --showduplicates | sort -r 已加载插件：fastestmirror, langpacks 可安装的软件包 * webtatic: uk.repo.webtatic.com * updates: mirrors.aliyun.com Loading mirror speeds from cached hostfile * extras: mirrors.aliyun.com docker-ce.x86_64 3:19.03.3-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.2-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.1-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.0-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.9-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.8-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.7-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.6-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.5-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.4-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.3-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.2-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.1-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.0-3.el7 docker-ce-stable docker-ce.x86_64 18.06.3.ce-3.el7 docker-ce-stable docker-ce.x86_64 18.06.2.ce-3.el7 docker-ce-stable docker-ce.x86_64 18.06.1.ce-3.el7 docker-ce-stable docker-ce.x86_64 18.06.0.ce-3.el7 docker-ce-stable docker-ce.x86_64 18.03.1.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 18.03.0.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 17.12.1.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 17.12.0.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 17.09.1.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 17.09.0.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 17.06.2.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 17.06.1.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 17.06.0.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 17.03.3.ce-1.el7 docker-ce-stable docker-ce.x86_64 17.03.2.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 17.03.1.ce-1.el7.centos docker-ce-stable docker-ce.x86_64 17.03.0.ce-1.el7.centos docker-ce-stable 2.3 安装docker指定版本 #安装指定版本 [root@docker01 ~]# yum -y install docker-ce-18.03.1.ce docker-ce-cli-18.01.1.ce 2.4 查看版本 #查看docker版本 [root@docker01 ~]# docker -v Docker version 18.03.1-ce, build 9ee9f40 2.5 配置docker镜像加速 #配置docker官方镜像加速地址 方式一 [root@docker01 ~]# cat > /etc/docker/daemon.json /etc/docker/daemon.json 三、二进制安装docker 系统环境 内核版本 内存 docker版本 3.10.0-1062.el7.x86_64 1c2G 18.09.9 docker二进制包下载地址 3.1 下载docker二进制包 wget https://download.docker.com/linux/static/stable/x86_64/docker-18.09.9.tgz 3.2 解压缩包 tar xf docker-18.09.9.tgz -C /usr/local/ 3.3 导出环境变量 ⚠️如果后续想要使用systemd管理docker，最好把docker二进制包中的所有文件拷贝到/usr/bin，否则会管理失败 cp /usr/local/docker/* /usr/bin 3.4 使用systemd管理docker Control Docker with systemd 官方文档关于使用systemd管理docker的说明 如果你是使用二进制方式安装的 docker，那么你也许需要整合 docker 到 systemd 中去。为了完成这个任务，你需要安装两个单元文件（service 和 socket）到 /etc/systemd/system 中去 Manually create the systemd unit files When installing the binary without a package, you may want to integrate Docker with systemd. For this, install the two unit files (service and socket) from the github repository to /etc/systemd/system. ⚠️需要下载的是docker.service.rpm和docker.socket这两个文件，需要把docker.service.rpm重命名为docker.service，然后再移动到/etc/systemd/system下 wget https://github.com/moby/moby/blob/master/contrib/init/systemd/docker.service.rpm wget https://github.com/moby/moby/blob/master/contrib/init/systemd/docker.socket 这里我们直接向文件写入内容 docker.service cat > /etc/systemd/system/docker.service docker.socket cat >/etc/systemd/system/docker.socket 3.5 重新加载服务并启动docker systemctl daemon-reload systemctl start docker && systemctl enable docker 3.6 验证docker版本 $ docker version Client: Docker Engine - Community Version: 18.09.9 API version: 1.39 Go version: go1.11.13 Git commit: 039a7df9ba Built: Wed Sep 4 16:50:02 2019 OS/Arch: linux/amd64 Experimental: false Server: Docker Engine - Community Engine: Version: 18.09.9 API version: 1.39 (minimum version 1.12) Go version: go1.11.13 Git commit: 039a7df9ba Built: Wed Sep 4 16:55:50 2019 OS/Arch: linux/amd64 Experimental: false 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/docker/3.docker容器操作.html":{"url":"linux/docker/3.docker容器操作.html","title":"3.docker容器操作","keywords":"","body":"docker容器操作 1.docker运行容器 1.1docker后台运行容器 //docker运行一个容器 [root@docker01 ~]# docker run -d -p 80:80 nginx Unable to find image 'nginx:latest' locally latest: Pulling from library/nginx 6ae821421a7d: Pull complete da4474e5966c: Pull complete eb2aec2b9c9f: Pull complete Digest: sha256:dd2d0ac3fff2f007d99e033b64854be0941e19a2ad51f174d9240dda20d9f534 #参数说明 run 创建并运行一个容器 -d 后台运行 -p 端口映射 宿主机端口:容器端口 nginx docker镜像名称 //访问容器 访问宿主机IP:80端口 1.2docker交互式运行容器 //docker交互式运行容器 [root@docker1 ~]# docker run -it --name nginx nginx /bin/bash root@07c25f8aa98b:/# #参数shuoming -it 分配交互式终端 --name 指定容器的名字 /bin/bash 覆盖容器的初始命令 第一个nginx 容器名称 第二个nginx 镜像名称 2.docker停止容器 命令：docker stop 容器ID或容器名称 //查看容器，此时nginx容器正在运行 [root@docker1 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e5008e3abc3c nginx \"nginx -g 'daemon of…\" 8 seconds ago Up 7 seconds 0.0.0.0:80->80/tcp elated_hermann //停止容器，停止容器可以加容器的ID或者容器名字 [root@docker1 ~]# docker stop e5008e3abc3c e5008e3abc3c //再次查看，可以看到容器已经停止 [root@docker1 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e5008e3abc3c nginx \"nginx -g 'daemon of…\" About a minute ago Exited (0) 2 seconds ago elated_hermann 3.docker进入容器 3.1docker进入容器方法 目的 docker进入容器（为了调试、排错） 方法 docker exec -it 容器ID或容器名称 /bin/bash #会分配一个新的终端tty docker attach #使用同一个终端 nsenter 用的少 #需要安装util-linux 3.2示例 exec进入容器 //运行一个容器 [root@docker1 ~]# docker run -d nginx 47a36ef42fb743a4c28ac8d3c82cfa1947698c7c0a74a5ccb59815b959cb7a48 //查看容器 [root@docker1 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 47a36ef42fb7 nginx \"nginx -g 'daemon of…\" 8 seconds ago Up 7 seconds 80/tcp zen_spence //根据容器ID进入容器 [root@docker1 ~]# docker exec -it 47a36ef42fb7 /bin/bash root@47a36ef42fb7:/# cat /etc/issue Debian GNU/Linux 9 \\n \\l //显示容器详细信息 [root@docker1 ~]# docker ps --no-trunc CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 47a36ef42fb743a4c28ac8d3c82cfa1947698c7c0a74a5ccb59815b959cb7a48 nginx \"nginx -g 'daemon off;'\" 5 minutes ago Up 5 minutes 80/tcp zen_spence 4.docker退出容器 4.1docker退出容器，容器不运行 方法 exit ctrl+d //启动一个容器 [root@docker1 ~]# docker run -it --name centos6.9 centos:6.9 /bin/bash //exit退出容器 [root@7076abed1c74 /]# exit exit //查看容器，容器此时已经停止 [root@docker1 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 7076abed1c74 centos:6.9 \"/bin/bash\" 11 seconds ago Exited (0) 1 second ago centos6.9 4.2临时退出容器,容器依然运行 方法 ctrl+p 然后 ctrl+q ⚠️⚠️⚠️docker attach进入容器使用的是同一个终端，再次打开一个终端,两个终端的操作是同时进行的 最好使用exec进入容器 //启动一个容器，然后临时退出 [root@docker1 ~]# docker run -it --name centos6.9 centos:6.9 /bin/bash [root@50492b58763a /]# [root@docker1 ~]# //查看容器，容器此时没有退出 [root@docker1 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 50492b58763a centos:6.9 \"/bin/bash\" 3 minutes ago Up 3 minutes centos6.9 //再次进入刚才临时退出的容器，可以用attach或者exec [root@docker1 ~]# docker attach 50492b58763a [root@50492b58763a /]# [root@docker1 ~]# docker exec -it 50492b58763a /bin/bash [root@50492b58763a /]# 5.docker夯住容器 docker容器内的第一个进程必须一直处于前台运行的状态，必须夯住，否则这个容器就处于退出状态 docker容器只能执行一条初始命令 示例1 //启动一个nginx容器 [root@docker01 ~]# docker run -d -p 80:80 nginx //查看nginx容器详细信息 [root@docker1 ~]# docker ps --no-trunc CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 47a36ef42fb743a4c28ac8d3c82cfa1947698c7c0a74a5ccb59815b959cb7a48 nginx \"nginx -g 'daemon off;'\" 5 minutes ago Up 5 minutes 80/tcp zen_spence 可以看到nginx容器启动的命令\"nginx -g 'daemon off;'\" 表示nginx在前台运行 示例2 //后台启动centos容器 [root@docker1 ~]# docker run -d centos:6.9 e1fab2c0c3a5df84fa812d475b5f9ed27b31f928aad8874319671cd9ad792e20 //查看容器，可以看到，容器第一个进程没有夯住，已经退出 [root@docker1 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e1fab2c0c3a5 centos:6.9 \"/bin/bash\" 4 seconds ago Exited (0) 4 seconds ago upbeat_dirac //要想夯住容器，必须加一个能夯住的命令，例如vi一个不存在的文件，tail -F 一个文件 #方式一 [root@docker1 ~]# docker run -d centos:6.9 vi 123.txt dcc90f30af539cf2c14748c22cd4815a26283d2cdd5bd8d4a0aece8d9c1a8e84 [root@docker1 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES dcc90f30af53 centos:6.9 \"vi 123.txt\" 2 seconds ago Up 2 seconds frosty_mirzakhani #方式二 [root@docker1 ~]# docker run -d centos:6.9 tail -F /var/log/messages ddc401b2bba8347b8b257f224e4c6a35798d9b6e08986f71201d3473d82a0ff0 [root@docker1 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ddc401b2bba8 centos:6.9 \"tail -F /var/log/me…\" 3 seconds ago Up 2 seconds heuristic_gauss tail -F 如果文件不存在，也能夯住 -f 如果文件不存在，会退出 6.docker删除容器 6.1docker温柔删除容器 命令 docker rm 容器ID或者容器名称 //查看docker容器 [root@docker1 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 9fcda2502aa5 centos:6.9 \"/bin/bash\" 13 seconds ago Exited (0) 8 seconds ago centos6.9 e5008e3abc3c nginx \"nginx -g 'daemon of…\" 6 minutes ago Exited (0) 4 minutes ago elated_hermann //删除容器，可以加容器的ID或者名称 [root@docker1 ~]# docker rm centos6.9 centos6.9 //再次查看容器，可以看到名称为centos6.9的容器已经删除 [root@docker1 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e5008e3abc3c nginx \"nginx -g 'daemon of…\" 10 minutes ago Exited (0) 8 minutes ago elated_hermann 6.2docker强制删除容器 最好不要强制删除容器！！！ 命令 docker rm -f 容器ID或容器名称 //运行一个容器 [root@docker1 ~]# docker run -d nginx:latest e57f21e6917bc109fb13afbe7e9237b13a3741f0fd1b4971afaa31fdfdcaec6a //查看容器 [root@docker1 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e57f21e6917b nginx:latest \"nginx -g 'daemon of…\" 9 seconds ago Up 7 seconds 80/tcp stoic_leakey e5008e3abc3c nginx \"nginx -g 'daemon of…\" 16 minutes ago Exited (0) 15 minutes ago elated_hermann //尝试删除正在运行的容器,会报错 [root@docker1 ~]# docker rm e57f21e6917b Error response from daemon: You cannot remove a running container e57f21e6917bc109fb13afbe7e9237b13a3741f0fd1b4971afaa31fdfdcaec6a. Stop the container before attempting removal or force remove //加-f参数强制删除 [root@docker1 ~]# docker rm -f e57f21e6917b e57f21e6917b //再次查看容器，可以看到容器已经被删除 [root@docker1 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e5008e3abc3c nginx \"nginx -g 'daemon of…\" 19 minutes ago Exited (0) 17 minutes ago elated_hermann 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/docker/4.1registry私有仓库.html":{"url":"linux/docker/4.1registry私有仓库.html","title":"registry","keywords":"","body":"registry私有仓库 docker私有仓库registry只需要启动一个容器即可 试验环境 docker01 10.0.0.10 docker02 10.0.0.11 一、普通registry 1.1docker01启动私有仓库容器 [root@docker01 ~]# docker run -d -p 5000:5000 --restart=always --name registry -v \\ /opt/myregistry:/var/lib/registry registry 参数解释 -d 后台运行 -p 映射端口 --restart=always 重启docker服务时拉起容器 --name 名字 -v 挂载卷， /opt/myregistry:/var/lib/registry表示将宿主机的/opt/myregistry挂载到容器的/var/lib/registry 1.2docker02给镜像打标签 1.初始镜像 [root@docker02 ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE centos 6.9 adf829198a7f 4 months ago 195MB 2.给镜像打标签 语法 docker tag 镜像名称 标签名称 [root@docker02 ~]# docker tag centos:6.9 10.0.0.10:5000/centos:6.9 3.打完标签后的镜像，id相同，相当于硬链接 [root@docker02 ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE 10.0.0.10:5000/centos 6.9 adf829198a7f 4 months ago 195MB centos 6.9 adf829198a7f 4 months ago 195MB 1.3docker02推送镜像到私有仓库docker01 1.默认推送是采用https协议，因此第一次推送会报错 [root@docker02 ~]# docker push 10.0.0.10:5000/centos:6.9 The push refers to repository [10.0.0.10:5000/centos] Get https://10.0.0.10:5000/v2/: http: server gave HTTP response to HTTPS client 2.修改配置文件，使推送使用http协议 [root@docker02 ~]# vim /etc/docker/daemon.json { \"insecure-registries\": [\"10.0.0.10:5000\"] } 3.重启docker [root@docker02 ~]# systemctl restart docker 4.再次推送即可成功 [root@docker02 ~]# docker push 10.0.0.10:5000/centos:6.9 The push refers to repository [10.0.0.20:5000/centos] aaa5621d7c01: Pushed 6.9: digest: sha256:7e172600dff1903f186061ce5f5295664ec9942ca120e4e5b427ddf01bb2b35b size: 529 1.4docker 普通registry缺点 没有认证，任何人都可以推送镜像到私有仓库，不安全！！！ 1.docker02导入镜像或者下载镜像 [root@docker02 ~]# docker load -i nginx.tar.gz 2.给镜像打标签 [root@docker02 ~]# docker tag nginx:latest 10.0.0.10:5000/nginx:latest 3.推送任意一个镜像到私有仓库 [root@docker02 ~]# docker push 10.0.0.10:5000/nginx:latest 4.推送镜像存放路径 创建私有镜像仓库时指定的宿主机目录/opt/myregistry -v /opt/myregistry:/var/lib/registry registry [root@docker01 ~]# ls /opt/myregistry/docker/registry/v2/repositories/ centos/ centos6.9_ssh/ nginx/ 二、带basic认证的registry 2.1docker01初始环境准备 1.安装httpd-tools [root@docker01 ~]# yum -y install httpd-tools 2.创建存放密码的目录并设置密码 [root@docker01 ~]# mkdir -p /opt/registry-var/auth [root@docker01 ~]# htpasswd -Bbn test 123456 >> /opt/registry-var/auth/htpasswd 2.2docker01启动容器 [root@docker01 ~]# docker run -d -p 5000:5000 --name registry --restart=always -v /opt/registry-var/auth/:/auth/ -v \\ /opt/myregistry:/var/lib/registry -e \"REGISTRY_AUTH=htpasswd\" -e \\ \"REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm\" -e REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd\\ registry 2.3docker02直接拉取镜像 1.直接拉取镜像会报错，因为没有认证 [root@docker02 ~]# docker pull 10.0.0.10:5000/nginx Using default tag: latest Error response from daemon: Get http://10.0.0.10:5000/v2/nginx/manifests/latest: no basic auth credentials 2.4登陆私有仓库，然后拉取镜像 1.登陆私有仓库 [root@docker02 ~]# docker login 10.0.0.10:5000 Username: test Password: WARNING! Your password will be stored unencrypted in /root/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded 2.拉取镜像 [root@docker02 ~]# docker pull 10.0.0.10:5000/nginx Using default tag: latest latest: Pulling from nginx Digest: sha256:278fefc722ffe1c36f6dd64052758258d441dcdb5e1bbbed0670485af2413c9f Status: Image is up to date for 10.0.0.10:5000/nginx:latest 3.上传镜像，先打标签，再上传 [root@docker02 ~]# docker tag centos:6.9 10.0.0.10:5000/my-centos [root@docker02 ~]# docker push 10.0.0.10:5000/my-centos registry镜像存储位置 registry镜像存储位置为 挂载目录/docker/registry/v2/repositories/镜像名称 目录挂载 /opt/myregistry:/var/lib/registry 镜像存储位置 /opt/myregistry/docker/registry/v2/repositories 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/docker/4.2docker企业级私有仓库harbor.html":{"url":"linux/docker/4.2docker企业级私有仓库harbor.html","title":"harbor","keywords":"","body":"docker企业级私有仓库harbor 1.harbor介绍 Habor是由VMWare公司开源的容器镜像仓库。事实上，Habor是在Docker Registry上进行了相应的企业级扩展，从而获得了更加广泛的应用，这些新的企业级特性包括：管理用户界面，基于角色的访问控制 ，AD/LDAP集成以及审计日志等，足以满足基本企业需求。 官方地址 github地址 2.harbor主要功能 基于角色访问控制（RBAC） 在企业中，通常有不同的开发团队负责不同的项目，镜像像代码一样，每个人角色不同需求也不同，因此就需要访问权限控制，根据角色分配相应的权限。 例如，开发人员需要对项目构建这就用到读写权限（push/pull），测试人员只需要读权限（pull），运维一般管理镜像仓库，具备权限分配能力，项目经理具有所有权限。 镜像复制 可以将仓库中的镜像同步到远程的Harbor，类似于MySQL主从同步功能。 LDAP Harbor支持LDAP认证，可以很轻易接入已有的LDAP。 镜像删除和空间回收 Harbor支持在Web删除镜像，回收无用的镜像，释放磁盘空间。 图形页面管理 用户很方面搜索镜像及项目管理。 审计 对仓库的所有操作都有记录。 REST API 完整的API，方便与外部集成。 3.harbor组件 组件 功能 harbor-adminserver 配置管理中心 harbor-db Mysql数据库 harbor-jobservice 负责镜像复制 harbor-log 记录操作日志 harbor-ui Web管理页面和API nginx 前端代理，负责前端页面和镜像上传/下载转发 redis 会话 registry 镜像存储 4.harbor部署环境要求 2核4G+40G硬盘 docker 17.06+ docker compose 1.18+ openssl 最新版 Hardware Resource Capacity Description CPU minimal 2 CPU 4 CPU is preferred Mem minimal 4GB 8GB is preferred Disk minimal 40GB 160GB is preferred Software Software Version Description Docker engine version 17.06.0-ce+ or higher For installation instructions, please refer to: docker engine doc Docker Compose version 1.18.0 or higher For installation instructions, please refer to: docker compose doc Openssl latest is preferred Generate certificate and keys for Harbor Network ports Port Protocol Description 443 HTTPS Harbor portal and core API will accept requests on this port for https protocol, this port can change in config file(harbor入口和核心API将接受请求在此端口上的https协议，该端口可以在配置文件中更改) 4443 HTTPS Connections to the Docker Content Trust service for Harbor, only needed when Notary is enabled, This port can change in config file(连接到Docker内容信任服务的端口，只有在启用公证员时才需要，该端口可以在配置文件中更改) 80 HTTP Harbor portal and core API will accept requests on this port for http protocol(Harbor portal和core API将在这个端口上接受http协议请求) 5.安装docker compose harbor需要docker compose1.18+版本 docker compose安装地址 1.下载docker compose安装包 [root@docker02 ~]# curl -L \"https://github.com/docker/compose/releases/download/1.24.1/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose 2.给docker compose赋予执行命令 [root@docker02 ~]# chmod +x /usr/local/bin/docker-compose 3.验证安装 [root@docker02 ~]# docker-compose -v docker-compose version 1.24.1, build 4667896b 6.安装harbor Harbor安装有3种方式： 在线安装：从Docker Hub下载Harbor相关镜像，因此安装软件包非常小 离线安装：安装包包含部署的相关镜像，因此安装包比较大 OVA安装程序：当用户具有vCenter环境时，使用此安装程序，在部署OVA后启动Harbor 1.下载安装包 [root@docker02 ~]# wget https://storage.googleapis.com/harbor-releases/release-1.8.0/harbor-offline-installer-v1.8.1.tgz 2.解压缩包到/usr/local [root@docker02 ~]# tar xf harbor-offline-installer-v1.8.1.tgz -C /usr/local/ 3.进入harbor目录，修改配置文件harbor.yml [root@docker02 harbor]# ls harbor.v1.8.1.tar.gz harbor.yml install.sh LICENSE prepare [root@docker02 harbor]# pwd /usr/local/harbor [root@docker02 harbor]# vim harbor.yml 5行 hostname: reg.mydomain.com //修改为IP地址或者域名 27行 harbor_admin_password: Harbor12345 //修改密码 4.准备配置文件，执行完成后会多出目录common 文件docker-compose.yml [root@docker02 harbor]# ./prepare [root@docker02 harbor]# ls common docker-compose.yml harbor.v1.8.1.tar.gz harbor.yml install.sh LICENSE prepare 5.安装并启动harbor [root@docker02 harbor]# ./install.sh 6.查看运行状态 [root@docker02 harbor]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES d0d76fee6c95 goharbor/nginx-photon:v1.8.1 \"nginx -g 'daemon of…\" 4 minutes ago Up 4 minutes (healthy) 0.0.0.0:80->80/tcp nginx 6b40878a29a0 goharbor/harbor-jobservice:v1.8.1 \"/harbor/start.sh\" 4 minutes ago Up 4 minutes harbor-jobservice ad03c4b60343 goharbor/harbor-portal:v1.8.1 \"nginx -g 'daemon of…\" 4 minutes ago Up 4 minutes (healthy) 80/tcp harbor-portal 2fa3bbc7c1fb goharbor/harbor-core:v1.8.1 \"/harbor/start.sh\" 4 minutes ago Up 4 minutes (healthy) harbor-core cd9e038ab419 goharbor/harbor-registryctl:v1.8.1 \"/harbor/start.sh\" 4 minutes ago Up 4 minutes (healthy) registryctl 2738dc4ca7ab goharbor/redis-photon:v1.8.1 \"docker-entrypoint.s…\" 4 minutes ago Up 4 minutes 6379/tcp redis 457e7efc19c9 goharbor/registry-photon:v2.7.1-patch-2819-v1.8.1 \"/entrypoint.sh /etc…\" 4 minutes ago Up 4 minutes (healthy) 5000/tcp registry 37403c4806b4 goharbor/harbor-db:v1.8.1 \"/entrypoint.sh post…\" 4 minutes ago Up 4 minutes (healthy) 5432/tcp harbor-db 90ca1cc8b794 goharbor/harbor-log:v1.8.1 7.访问harbor 用户名 admin 密码 123456 宿主机80端口 登陆后首界面 到此，harbor http方式安装完成！！！ 8.https访问harbor 如果需要https访问harbor，需要做以下操作 harbor https官方文档 编辑harbor.yml，打开https项的注释，并且写上https证书的位置 https: # # https port for harbor, default is 443 port: 443 # # The path of cert and key files for nginx certificate: /etc/nginx/ssl_key/harbor/xxx.pem private_key: /etc/nginx/ssl_key/harbor/xxx.key 9.harbor使用 将镜像推送到harbor，需要注意的是，推送的格式如下 因此，需要先给镜像打标签 //查看centos镜像 docker images|grep centos centos latest 67fa590cfc1c 4 months ago 202MB centos 6.9 2199b8eb8390 9 months ago 195MB //给镜像按照格式打标签 docker image tag centos:latest harbor.pptfz.top/pptfz/pptfz-centos:latest 镜像名称 harbor地址 项目名 镜像标签名 登陆harbor 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/docker/5.1docker容器网络.html":{"url":"linux/docker/5.1docker容器网络.html","title":"docker网络","keywords":"","body":"docker容器网络 docker容器网络示意图 一、docker网络相关信息 1.1docker网卡、网关信息 //宿主机查看docker默认网卡信息，安装完docker并启动后，会有docker0网卡，默认IP地址172.17.0.1 [root@docker1 ~]# ifconfig docker0: flags=4163 mtu 1500 inet 172.17.0.1 netmask 255.255.0.0 broadcast 172.17.255.255 inet6 fe80::42:61ff:fef9:e707 prefixlen 64 scopeid 0x20 ether 02:42:61:f9:e7:07 txqueuelen 0 (Ethernet) RX packets 50722 bytes 2466382 (2.3 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 82049 bytes 119024354 (113.5 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 //查看容器网关，网关默认为172.17.0.1 [root@ddc401b2bba8 /]# route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 172.17.0.1 0.0.0.0 UG 0 0 0 eth0 172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 eth0 1.2启动一个busybox容器 1.宿主机docker1运行busybox容器 [root@docker1 ~]# docker run -it busybox Unable to find image 'busybox:latest' locally latest: Pulling from library/busybox 8e674ad76dce: Pull complete Digest: sha256:c94cf1b87ccb80f2e6414ef913c748b105060debda482058d2b8d0fce39f11b9 Status: Downloaded newer image for busybox:latest #查看网卡 / # ip a 1: lo: mtu 65536 qdisc noqueue qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 32: eth0@if33: mtu 1500 qdisc noqueue link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever #查看网关 / # route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 172.17.0.1 0.0.0.0 UG 0 0 0 eth0 172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 eth0 / # 2.busybox容器ping宿主机docker2 / # ping 10.0.0.61 3.宿主机docker2抓包查看 可以看到，涞源的IP是宿主机docker1的eth0网卡，说明宿主机进行了nat地址转换，将dockerIP 172.17.0.2转换为宿主机eth0IP [root@docker2 ~]# tcpdump -i eth0 icmp -nn tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes 23:04:03.121544 IP 10.0.0.60 > 10.0.0.61: ICMP echo request, id 2816, seq 52, length 64 23:04:03.121576 IP 10.0.0.61 > 10.0.0.60: ICMP echo reply, id 2816, seq 52, length 64 1.3docker容器用到的内核转发和iptables规则 1.内核转发 #宿主机docker1查看内核转发，内核转发是docker开启的 [root@docker1 ~]# sysctl -a|grep -w net.ipv4.ip_forward net.ipv4.ip_forward = 1 2.iptables规则 #宿主机docker1查看iptables规则 [root@docker1 ~]# iptables -t nat -L -n Chain POSTROUTING (policy ACCEPT) target prot opt source destination MASQUERADE all -- 172.17.0.0/16 0.0.0.0/0 二、docker端口映射（允许外网访问容器） docker指定端口映射，docker会自动添加一条iptables规则来实现端口映射 -p 宿主机端口:容器端口 -p 宿主机IP:宿主机端口:容器端口 -p 宿主机IP::容器端口(随机端口) -p 宿主机端口:容器端口:udp -p 81:80 -p 443:443 可以指定多个-p 2.1方式一 -p 宿主机端口:容器端口 1.启动一个nginx容器并作端口映射 1.启动一个nginx容器，并将宿主机8080端口映射到容器80端口 [root@docker1 ~]# docker run -d -p 8080:80 nginx:latest ccef9a059f90886370577063f68bc4cab495f6497d394d16941f936b9fb8468a 2.宿主机查看iptables规则，可以看到iptables将宿主机8080端口映射到了容器的80端口 [root@docker1 ~]# iptables -t nat -L -n Chain DOCKER (2 references) target prot opt source destination RETURN all -- 0.0.0.0/0 0.0.0.0/0 DNAT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:8080 to:172.17.0.4:80 2.宿主机80端口访问 3.宿主机8080端口访问 2.2方式二 -p 宿主机IP:宿主机端口:容器端口 1.宿主机eth0网卡添加一个辅助IP 1.添加一个辅助IP [root@docker1 ~]# ifconfig eth0:1 10.0.0.66/24 up 2.查看网卡eth0 [root@docker1 ~]# ifconfig |grep -A 2 eth0 eth0: flags=4163 mtu 1500 inet 10.0.0.60 netmask 255.255.255.0 broadcast 10.0.0.255 inet6 fe80::20c:29ff:fe65:ee41 prefixlen 64 scopeid 0x20 -- eth0:1: flags=4163 mtu 1500 inet 10.0.0.66 netmask 255.255.255.0 broadcast 10.0.0.255 ether 00:0c:29:65:ee:41 txqueuelen 1000 (Ethernet) 2.启动容器 //添加辅助IP后，宿主机的80端口就可以再次使用 [root@docker1 ~]# docker run -d -p 10.0.0.60:80:80 nginx:latest 80257a4c036183df9106d38992bf2762007bc5bc1550bed408cf4232eb1ae160 [root@docker1 ~]# docker run -d -p 10.0.0.66:80:80 nginx:latest ccabd14eea387c05ce7af46c002c8f9621aa1907642551aff79f7ca7e4bd25aa 3.查看端口监听 [root@docker1 ~]# netstat -ntpl Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 10.0.0.66:80 0.0.0.0:* LISTEN 18647/docker-proxy tcp 0 0 10.0.0.60:80 0.0.0.0:* LISTEN 2942/docker-proxy 4.查看iptables转发规则 //访问宿主机80端口，将请求转发至第一个容器80端口；访问宿主机辅助IP80端口，将请求转发至第二个容器80端口 [root@docker1 ~]# iptables -t nat -L -n Chain DOCKER (2 references) target prot opt source destination RETURN all -- 0.0.0.0/0 0.0.0.0/0 DNAT tcp -- 0.0.0.0/0 10.0.0.60 tcp dpt:80 to:172.17.0.4:80 DNAT tcp -- 0.0.0.0/0 10.0.0.66 tcp dpt:80 to:172.17.0.5:80 2.3方式三 -p 宿主机IP::容器端口(宿主机端口随机) 宿主机端口不写，默认随机启动一个端口 1.启动一个容器 1.启动一个容器 [root@docker1 ~]# docker run -d -p 10.0.0.60::80 nginx:latest fbf5d8973f9094bf18c0e0b9ad63fa3b350e1bd2afc94083824e081c20fdb0c8 2.查看启动的容器信息，可以看到，随机启动了一个32768端口 [root@docker1 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES fbf5d8973f90 nginx:latest \"nginx -g 'daemon of…\" 11 seconds ago Up 10 seconds 10.0.0.60:32768->80/tcp elastic_ritchie 2.浏览器访问32768端口 2.4方式四 -p 宿主机端口:容器端口:udp 映射默认采用tcp方式，此方式为指定udp方式 例如，容器中运行了dns服务，需要指定为udp方式 2.5方式五 -p 81:80 -p 443:443 可以指定多个-p 容器中运行了多个服务，此时需要映射多个端口 三、docker端口随机映射 -P 与-p 宿主机IP::容器端口(宿主机端口随机)方式相同 1.启动一个容器 1.启动一个容器 [root@docker1 ~]# docker run -d -P nginx:latest c1ffac8baf576208bbf107a24fd83e832b4811ad270bf8006d636e92b6438c39 2.查看容器信息，可以看到将宿主机32769映射到docker80端口 [root@docker1 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES c1ffac8baf57 nginx:latest \"nginx -g 'daemon of…\" 33 seconds ago Up 32 seconds 0.0.0.0:32769->80/tcp clever_lichterman docker端口映射核心 通过iptables实现端口映射！！！ 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/docker/5.2docker网络模式.html":{"url":"linux/docker/5.2docker网络模式.html","title":"docker网络模式","keywords":"","body":"docker网络模式 指定容器网络类型 --net或者--network 1.docker网络模式 docker网络模式，共4种 模式 含义 bridge 桥接模式，默认 host 与宿主机共享网络 none 无网络 container 与容器共享网络 2.查看docker网络模式 2.1查看docker网络 查看docker网络，默认有3种 [root@docker01 ~]# docker network ls NETWORK ID NAME DRIVER SCOPE 752c74d78d18 bridge bridge local 970755d8e30b host host local f144b44069ab none null local 2.2第一种 bridge，桥接，默认模式 //启动一个容器test1 [root@docker01 ~]# docker run -d --name test1 busybox:latest vi 1 698a85c6cf33bc6a02903f0e6ac7f96e429247a17bef705467a9879c1d2de8b2 //查看容器网络信息 [root@docker01 ~]# docker inspect test1 \"Networks\": { \"bridge\": { //容器网络模式为bridge \"IPAMConfig\": null, \"Links\": null, \"Aliases\": null, \"NetworkID\": \"752c74d78d186a14b2c6e1659c54b50d3396a89fec4b34664c7991ddc50fac55\", \"EndpointID\": \"\", \"Gateway\": \"\", \"IPAddress\": \"\", \"IPPrefixLen\": 0, \"IPv6Gateway\": \"\", \"GlobalIPv6Address\": \"\", \"GlobalIPv6PrefixLen\": 0, \"MacAddress\": \"\", \"DriverOpts\": null } 2.3第二种 host，与宿主机共享网络 1.查看宿主机网络，eth0 IP为10.0.0.20 [root@docker01 ~]# ip a s eth0 2: eth0: mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:49:fe:8f brd ff:ff:ff:ff:ff:ff inet 10.0.0.20/24 brd 10.0.0.255 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:fe49:fe8f/64 scope link valid_lft forever preferred_lft forever 2.启动一个容器test2，设置网络模式为host [root@docker01 ~]# docker run -it --name test2 --net host busybox:latest / # 3.查看容器网络，可以看到，启动的容器网卡与宿主机一致 / # ip a s eth0 2: eth0: mtu 1500 qdisc pfifo_fast qlen 1000 link/ether 00:0c:29:49:fe:8f brd ff:ff:ff:ff:ff:ff inet 10.0.0.20/24 brd 10.0.0.255 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:fe49:fe8f/64 scope link valid_lft forever preferred_lft forever 2.4第三种 none，无网络模式 1.启动一个容器test3，网络模式指定为none [root@docker01 ~]# docker run -it --name test3 --net none busybox:latest 2.查看IP，只有lo网卡 / # ip a 1: lo: mtu 65536 qdisc noqueue qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 3.无法上网 / # ping baidu.com ping: bad address 'baidu.com' 4.没有路由信息 / # route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 2.5第四种 container，共享容器网络 container:要共享的容器ID或名称 1.先启动一个容器test5，容器IP为172.17.0.4，可以上网 [root@docker01 ~]# docker run -it --name test5 busybox:latest / # ip a 1: lo: mtu 65536 qdisc noqueue qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 42: eth0@if43: mtu 1500 qdisc noqueue link/ether 02:42:ac:11:00:04 brd ff:ff:ff:ff:ff:ff inet 172.17.0.4/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever / # ping baidu.com PING baidu.com (220.181.38.148): 56 data bytes 64 bytes from 220.181.38.148: seq=0 ttl=127 time=9.747 ms ^C --- baidu.com ping statistics --- 1 packets transmitted, 1 packets received, 0% packet loss round-trip min/avg/max = 9.747/9.747/9.747 ms 2.再次启动一个容器test6，指定网络共享容器test5 [root@docker01 ~]# docker run -it --name test6 --net container:test5 busybox:latest 3.查看IP，可以看到IP地址与共享的容器test5一样 / # ip a 1: lo: mtu 65536 qdisc noqueue qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 46: eth0@if47: mtu 1500 qdisc noqueue link/ether 02:42:ac:11:00:04 brd ff:ff:ff:ff:ff:ff inet 172.17.0.4/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/docker/6.docker数据卷.html":{"url":"linux/docker/6.docker数据卷.html","title":"6.docker数据卷","keywords":"","body":"docker数据卷 1.docker挂载卷的方式 方式一：宿主机创建一个卷，然后挂载到容器某一个路径下，适合做持久化 此方式将容器中的数据拷贝到宿主机的卷中，此时容器中的目录内容是什么决定了宿主机中的目录内容 方式二：直接将宿主机的某一个目录挂载到容器某一个路径下 此方式将宿主机的目录拷贝到容器的目录中，此时宿主机中的目录内容是什么决定了容器中的目录内容 2.docker创建数据卷示例 2.1创建一个名为docker-volume数据卷 [root@docker1 ~]# docker volume create docker-volume docker-volume 2.2查看创建的数据卷 [root@docker1 ~]# docker volume ls DRIVER VOLUME NAME local docker-volume 2.3查看数据卷具体信息，存放的位置等 默认存放于/var/lib/docker/volumes/docker-volume/_data [root@docker1 ~]# docker volume inspect docker-volume [ { \"CreatedAt\": \"2019-06-24T22:39:03+08:00\", \"Driver\": \"local\", \"Labels\": {}, \"Mountpoint\": \"/var/lib/docker/volumes/docker-volume/_data\", \"Name\": \"docker-volume\", \"Options\": {}, \"Scope\": \"local\" } ] 2.4启动一个nginx容器，并将刚才创建的数据卷挂载到容器的/usr/share/nginx/html [root@docker1 ~]# docker run -d -p 80:80 -v docker-volume:/usr/share/nginx/html nginx:latest 36d6db627b83638ac9a03025c3f7b7b7fd0688ae4a8d3bf75b422ade4016c0a2 #参数说明 -d 后台运行 -p 端口映射 -v 卷名称:要挂载到容器的路径 2.5浏览器访问刚启动的容器 2.6将nginx容器的默认显示界面重写 [root@docker1 ~]# echo hehe > /var/lib/docker/volumes/docker-volume/_data/index.html 2.7再次访问容器，可以看到，内容已经变化 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/docker/7.docker手动构建镜像.html":{"url":"linux/docker/7.docker手动构建镜像.html","title":"7.docker手动构建镜像","keywords":"","body":"docker手动构建镜像 1.手动创建docker镜像步骤 第一步、手动启动一个容器，在容器中安装自定义服务 第二步、docker commit 把容器提交为镜像 第三步、测试镜像功能 2.ssh服务镜像制作示例 2.1启动一个镜像 1.启动一个centos6.9 [root@docker1 ~]# docker run -it -p 222:22 centos:6.9 /bin/bash [root@ab815c87fb9c /]# 2.修改镜像yum源 [root@ab815c87fb9c /]# curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo [root@ab815c87fb9c /]# curl -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-6.repo [root@ab815c87fb9c /]# yum clean all && yum makecache 2.2镜像中安装ssh服务并启动 1.安装ssh服务 [root@ab815c87fb9c /]# yum -y install openssh-server 2.启动ssh 第一次启动服务，目的是生成密钥对 [root@ab815c87fb9c ~]# service sshd start Generating SSH2 RSA host key: [ OK ] Generating SSH1 RSA host key: [ OK ] Generating SSH2 DSA host key: [ OK ] Starting sshd: [ OK ] 3.验证服务启动状况 [root@ab815c87fb9c ~]# service sshd status openssh-daemon (pid 163) is running... [root@ab815c87fb9c ~]# netstat -ntpl Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 163/sshd tcp 0 0 :::22 :::* LISTEN 163/sshd 2.3设置容器root密码 [root@ab815c87fb9c /]# echo 1|passwd --stdin root Changing password for user root. passwd: all authentication tokens updated successfully. 2.4终端访问刚创建的镜像 222端口 2.5提交镜像 1.临时退出镜像 ctrl+p 然后 ctrl+q 2.查看容器信息 [root@docker1 ~]# docker ps -al CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ab815c87fb9c centos:6.9 \"/bin/bash\" 24 minutes ago Up 24 minutes 0.0.0.0:222->22/tcp priceless_yonath 3.提交镜像 commit后可以加容器名称或容器ID [root@docker1 ~]# docker commit ab815c87fb9c centos6.9_ssh:v1.1 sha256:0fcaf66caf5a6bd48c18e0172827aa04a2bf9fcb5a8f849b20f58a116deac5b7 4.查看镜像 [root@docker1 ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE centos6.9_ssh v1.1 0fcaf66caf5a About a minute ago 504MB 2.6测试镜像 注意：启动的容器提供服务的同时必须夯住 1.启动容器，使用刚才提交的的镜像,这里使用 sshd -D 使容器能夯住 [root@docker1 ~]# docker run -d -p 223:22 centos6.9_ssh:v1.1 /usr/sbin/sshd -D ead64de773abd3c1d08647575d096789a5a28d64960f225f7a42ec9cf01211ee 2.查看容器 [root@docker1 ~]# docker ps -al CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ead64de773ab centos6.9_ssh:v1.1 \"/usr/sbin/sshd -D\" 51 seconds ago Up 50 seconds 0.0.0.0:223->22/tcp stupefied_liskov 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/docker/8.dockerfile自动构建docker镜像.html":{"url":"linux/docker/8.dockerfile自动构建docker镜像.html","title":"8.docker自动构建镜像","keywords":"","body":"dockerfile自动构建docker镜像 1.dockerfile说明 dockerfile定义 dockerfile类似ansible的剧本 dockerfile特点 1.更适合传输，文件体积小 2.实现更加定制化 dockerfile主要组成部分 基础镜像信息 FROM centos:6.9 制作镜像操作指令 RUN yum -y install httpd 容器启动时执行指令 CMD [\"/bin/bash\"] dockerfile常用指令 指令 含义 FROM 指定基础镜像，基于哪个镜像 MAINTAINER 构建者信息 RUN 指定运行命令 ADD 将宿主机文件拷贝到容器中，会自动解压 WORKDIR 指定工作目录 VOLUME 设卷，挂载宿主机目录 EXPOSE 指定对外的端口 CMD 容器启动后要运行的命令，容易被替换 COPY 复制文件 ENV 环境变量 ENTRYPOINT 容器启动后执行的命令（无法被替换，启动容器的时候指定的命令，会被当成参数） 2.dockerfile构建镜像步骤 第一步、编写dockerfile 第二步、docker build构建镜像(构建镜像的时候，dockerfile中有多少个命令就提交多少个临时容器，最后再总提交一次并且每次提交的临时容器会被删除) 第三步、启动容器测试 3.dockerfile示例 3.1示例一：基础dockerfile---ssh服务镜像 3.1.1新建目录，专门存放dockerfile [root@docker1 ~]# mkdir /dockerfile/centos6.9_ssh 3.1.2编辑dockerfile， 文件名称必须为dockerfile [root@docker1 centos6.9_ssh]# cat > dockerfile 3.1.3构建镜像 //基于dockerfile开始构建镜像 [root@docker1 centos6.9_ssh]# docker build -t centos6.9_ssh:v2.1 . 。。。 Successfully built 6a6d13135aaa Successfully tagged centos6.9_ssh:v2.1 #说明 build 构建镜像 -t 指定镜像名称 . 从当前目录下读取dockerfile 3.1.4测试镜像 //启动一个容器测试镜像 [root@docker1 centos6.9_ssh]# docker run -d -p 3222:22 centos6.9_ssh:v2.1 a57c6406e001f4a295ec8c847627326403f83a44d72adf719d44f8f3f4463ebc //查看镜像,可以看到，容器启动时没有指定默认命令，已从dockerfile中CMD读取初始运行名令 [root@docker1 centos6.9_ssh]# docker ps -al CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES a57c6406e001 centos6.9_ssh:v2.1 \"/usr/sbin/sshd -D\" 29 seconds ago Up 28 seconds 0.0.0.0:3222->22/tcp elated_kirch 3.1.5ssh连接测试 3.2示例二：基础dockerfile--多服务 3.2.1新建目录，专门存放dockerfile [root@docker1 ~]# mkdir -p /dockerfile/centos6.9_ssh_http 3.2.2编辑dockerfile， 文件名称必须为dockerfile [root@docker1 ~]# cd /dockerfile/centos6.9_ssh_http [root@docker1 centos6.9_ssh_http]# cat > dockerfile 3.2.3编辑脚本 [root@docker1 centos6.9_ssh_http]# cat >init.sh 3.2.4构建镜像 //基于dockerfile构建镜像 [root@docker1 centos6.9_ssh_http]# docker build -t centos6.9_ssh_http:v2.1 . 。。。 Successfully built 1f4662cc114d Successfully tagged centos6.9_ssh_http:v2.1 //查看镜像 [root@docker1 centos6.9_ssh_http]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE centos6.9_ssh_http v2.1 1f4662cc114d 7 minutes ago 310MB 3.2.5启动容器 //启动容器 [root@docker1 centos6.9_ssh_http]# docker run -d -p 5222:22 -p 88:80 centos6.9_ssh_http:v2.1 9880dd05d4cdc3849c4e62888d16592e6551ee3fb3fbae314ffd33c2744874c9 //查看容器 [root@docker1 centos6.9_ssh_http]# docker ps -al CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES fa48d4052ff8 centos6.9_ssh_http:v2.1 \"/bin/bash /init.sh\" 4 seconds ago Up 3 seconds 0.0.0.0:5222->22/tcp, 0.0.0.0:88->80/tcp zen_payne 3.2.6测试镜像 ssh镜像测试 apache镜像测试 [root@docker1 centos6.9_ssh_http]# curl -I 10.0.0.60:88 HTTP/1.1 403 Forbidden Date: Sun, 30 Jun 2019 15:37:34 GMT Server: Apache/2.2.15 (CentOS) Accept-Ranges: bytes Content-Length: 4961 Connection: close Content-Type: text/html; charset=UTF-8 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/docker/9.修改docker镜像、容器默认存放位置.html":{"url":"linux/docker/9.修改docker镜像、容器默认存放位置.html","title":"9.修改docker镜像、容器默认存放位置","keywords":"","body":"修改docker镜像、容器默认存放位置 1.修改需求 因为Docker默认是存放在系统盘中/var/lib/docker的，当用的时间比较久后，产生的镜像及容器越来越多之后，可能会导致你的系统盘满了，这时我们需要将Docker的镜像及容器指向另外一个路径 2.修改步骤 2.1docker镜像、容器默认存放于/var/lib/docker [root@docker02 ~]# cd /var/lib/docker [root@docker02 docker]# ls builder buildkit containers image network overlay2 plugins runtimes swarm tmp trust volumes 2.2修改docker镜像、容器存放位置 1.编辑配置文件 /etc/docker/daemon.json 加入以下一行 \"graph\":\"/data/docker\" #目录可自行修改 2.新建目录 [root@docker02 ~]# mkdir -p /data/docker 3.修改后的配置文件 [root@docker02 ~]# cat /etc/docker/daemon.json { \"registry-mirrors\": [\"https://gqk8w9va.mirror.aliyuncs.com\"], \"graph\":\"/data/docker\" } 2.3重启docker [root@docker02 ~]# systemctl restart docker 2.4拷贝原镜像和容器到新目录 1.修改完docker镜像、容器存放位置后，原先的镜像和容器查看不存在 [root@docker02 ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE [root@docker02 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 2.拷贝原镜像和容器到新目录 [root@docker02 ~]# \\cp -rp /var/lib/docker/* /data/docker/ 3重启docker [root@docker02 ~]# systemctl restart docker 4.查看修改 [root@docker02 ~]# docker info|grep Docker Docker Root Dir: /data/docker 5.查看镜像和容器，已恢复 [root@docker02 ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE jumpserver/jms_all 1.4.8 e9274ba449e8 3 months ago 1.31GB [root@docker02 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 2789b0d4a200 jumpserver/jms_all:1.4.8 \"entrypoint.sh\" About an hour ago Up 49 seconds 0.0.0.0:80->80/tcp, 0.0.0.0:2222->2222/tcp jms_all 6.测试镜像和容器都无问题后可以删除/var/lib/docker [root@docker02 ~]# rm -rf /var/lib/docker 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/docker/10.docker容器间互联 --link.html":{"url":"linux/docker/10.docker容器间互联 --link.html","title":"10.docker容器间互联 --link","keywords":"","body":"docker容器间互联 --link(单方向) 1.先启动一个容器 1.启动一个nginx容器 [root@docker01 ~]# docker run -d --name nginx nginx 656aa889b827eaef68d99538c691a4872139f0c82ae72a7810fed64dbe2d6bac 2.查看启动的容器 [root@docker01 ~]# docker ps -al CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 656aa889b827 nginx \"nginx -g 'daemon of…\" 3 seconds ago Up 2 seconds 80/tcp nginx 2.再次启动一个容器，添加--link参数 1.再次启动一个busybox容器，--link后面为 要连接的容器名称:连接的容器的别名 [root@docker01 ~]# docker run -it --link nginx:nginx busybox:latest 2.因为要连接的容器的名称为nginx，因此ping nginx，可以ping通 / # ping nginx PING nginx (172.17.0.5): 56 data bytes 64 bytes from 172.17.0.5: seq=0 ttl=64 time=0.814 ms 64 bytes from 172.17.0.5: seq=1 ttl=64 time=0.212 ms ^C --- nginx ping statistics --- 2 packets transmitted, 2 packets received, 0% packet loss round-trip min/avg/max = 0.212/0.513/0.814 ms 3.查看hosts文件，可以看到有nginx的hosts解析 / # cat /etc/hosts 127.0.0.1 localhost ::1 localhost ip6-localhost ip6-loopback fe00::0 ip6-localnet ff00::0 ip6-mcastprefix ff02::1 ip6-allnodes ff02::2 ip6-allrouters 172.17.0.5 nginx 656aa889b827 172.17.0.6 4d6a7fb490e8 3.再次启动一个容器 1.再次启动一个容器，--link后边为 要连接的容器:容器别名 [root@docker01 ~]# docker run -it --link nginx:web01 busybox:latest 2.ping容器名称或者容器别名都可以ping通 / # ping nginx PING nginx (172.17.0.5): 56 data bytes 64 bytes from 172.17.0.5: seq=0 ttl=64 time=0.474 ms ^C --- nginx ping statistics --- 1 packets transmitted, 1 packets received, 0% packet loss round-trip min/avg/max = 0.474/0.474/0.474 ms / # ping web01 PING web01 (172.17.0.5): 56 data bytes 64 bytes from 172.17.0.5: seq=0 ttl=64 time=0.137 ms ^C --- web01 ping statistics --- 1 packets transmitted, 1 packets received, 0% packet loss round-trip min/avg/max = 0.137/0.137/0.137 ms 3.查看hosts文件，可以看到会把要连接的容器的别名、容器ID、容器名称都添加 / # cat /etc/hosts 127.0.0.1 localhost ::1 localhost ip6-localhost ip6-loopback fe00::0 ip6-localnet ff00::0 ip6-mcastprefix ff02::1 ip6-allnodes ff02::2 ip6-allrouters 172.17.0.5 web01 656aa889b827 nginx 172.17.0.6 c94f83726145 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/docker/12.1docker跨主机通信之macvlan.html":{"url":"linux/docker/12.1docker跨主机通信之macvlan.html","title":"macvlan","keywords":"","body":"docker跨主机通信之macvlan 1.macvlan说明 macvlan可以虚拟多个mac地址，相当于虚拟多个网卡 macvlan优点 与局域网其他主机处于同一个网段 macvlan缺点 每次启动容器都需要手动指定IP地址 2.macvlan跨主机通信示例 2.1实验环境 主机名 IP docker01 10.0.0.60 docker02 10.0.0.61 2.2docker01和docker02都创建macvlan网络 //在docker01和docker02上相同操作 [root@docker01 ~]# docker network create --driver macvlan --subnet 10.0.0.0/24 --gateway 10.0.0.254 -o parent=eth0 macvlan_1 #参数说明 --driver //指定网络类型 --subnet //指定网段 ---gateway //指定网关 -o parent=eth0 //指定基于哪块物理网卡 macvlan_1 //网络名称，可任意 2.3查看创建的网络 //可以看到创建的名称为macvlan_1的网络 [root@docker01 ~]# docker network ls NETWORK ID NAME DRIVER SCOPE f2228fe9ebe8 bridge bridge local 1c11b715a65c host host local b0ddd6fd07ed macvlan_1 macvlan local 74d6b08c35c5 none null 2.4创建使用macvlan网络的容器 1.docker01启动一个容器，IP指定为10.0.0.3 [root@docker01 ~]# docker run -it --network macvlan_1 --ip=10.0.0.3 centos:latest /bin/bash 2.docker01启动的容器ping docker02宿主机10.0.0.61和docker02启动的容器10.0.0.4 [root@33da263729a4 /]# ping -c 3 10.0.0.61 PING 10.0.0.61 (10.0.0.61) 56(84) bytes of data. 64 bytes from 10.0.0.61: icmp_seq=1 ttl=64 time=0.960 ms 64 bytes from 10.0.0.61: icmp_seq=2 ttl=64 time=0.358 ms 64 bytes from 10.0.0.61: icmp_seq=3 ttl=64 time=0.242 ms --- 10.0.0.61 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2001ms rtt min/avg/max/mdev = 0.242/0.520/0.960/0.314 ms [root@33da263729a4 /]# ping -c 3 10.0.0.4 PING 10.0.0.4 (10.0.0.4) 56(84) bytes of data. 64 bytes from 10.0.0.4: icmp_seq=1 ttl=64 time=0.714 ms 64 bytes from 10.0.0.4: icmp_seq=2 ttl=64 time=0.457 ms 64 bytes from 10.0.0.4: icmp_seq=3 ttl=64 time=0.275 ms --- 10.0.0.4 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2002ms rtt min/avg/max/mdev = 0.275/0.482/0.714/0.180 ms 3.docker02启动一个容器，IP指定为10.0.0.4 [root@docker02 ~]# docker run -it --network macvlan_1 --ip=10.0.0.4 centos:latest /bin/bash 4.docker02启动的容器ping docker01宿主机10.0.0.60和docker02启动的容器10.0.0.3 [root@93ecb0bf3aa9 /]# ping -c 3 10.0.0.60 PING 10.0.0.60 (10.0.0.60) 56(84) bytes of data. 64 bytes from 10.0.0.60: icmp_seq=1 ttl=64 time=0.687 ms 64 bytes from 10.0.0.60: icmp_seq=2 ttl=64 time=0.390 ms 64 bytes from 10.0.0.60: icmp_seq=3 ttl=64 time=0.242 ms --- 10.0.0.60 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2000ms rtt min/avg/max/mdev = 0.242/0.439/0.687/0.186 ms [root@93ecb0bf3aa9 /]# ping -c 3 10.0.0.3 PING 10.0.0.3 (10.0.0.3) 56(84) bytes of data. 64 bytes from 10.0.0.3: icmp_seq=1 ttl=64 time=0.542 ms 64 bytes from 10.0.0.3: icmp_seq=2 ttl=64 time=0.486 ms 64 bytes from 10.0.0.3: icmp_seq=3 ttl=64 time=0.345 ms --- 10.0.0.3 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2002ms rtt min/avg/max/mdev = 0.345/0.457/0.542/0.086 ms ⚠️⚠️⚠️如果ping不通，需要将网卡设置为混杂模式 ip link set eth0 promisc on 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/docker/12.2docker跨主机通信之overlay.html":{"url":"linux/docker/12.2docker跨主机通信之overlay.html","title":"overlay","keywords":"","body":"docker跨主机通信之overlay 1.overlay说明 overlay优点 会自动分配IP地址，需要consul数据库 网络类型为overlay的容器默认有两块网卡 eth0 用于跨主机间容器通信 eth1 用于连接外网 网关默认为172.18.0.1，是宿主机docker_gwbridge网卡的IP地址 overlay网络跨主机通信示意图 2.overlay跨主机通信示例 2.1实验环境 主机名 IP docker01 10.0.0.60 docker02 10.0.0.61 2.2docker01操作 2.2.1启动consul容器 [root@docker01 ~]# docker run -d -p 8500:8500 -h consul --name consul --restart=always progrium/consul -server -bootstrap 2.2.2查看容器，容器映射了好多端口 [root@docker01 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 84c733c42a91 progrium/consul \"/bin/start -server …\" 24 seconds ago Up 23 seconds 53/tcp, 53/udp, 8300-8302/tcp, 8400/tcp, 8301-8302/udp, 0.0.0.0:8500->8500/tcp consul 2.2.3容器启动后可以访问一个web界面 10.0.0.60:8500 2.2.4修改docker配置文件/etc/docker/daemon.json 1.修改配置文件/etc/docker/daemon.json，加入以下三行 \"hosts\":[\"tcp://0.0.0.0:2376\",\"unix:///var/run/docker.sock\"], \"cluster-store\": \"consul://10.0.0.60:8500\", \"cluster-advertise\": \"10.0.0.60:2376\" #参数说明 \"hosts\":[\"tcp://0.0.0.0:2376\",\"unix:///var/run/docker.sock\"], //本地监听tcp2376端口，同时指定sock文件 \"cluster-store\": \"consul://10.0.0.60:8500\", //集群信息存放位置,这里为docker01 10.0.0.60 \"cluster-advertise\": \"10.0.0.60:2376\" //客户机自身IP地址,这里为docker01 10.0.0.60 2.修改docker服务启动文件，否则后续重启docker会报错 [root@docker01 ~]# vim /usr/lib/systemd/system/docker.service 修改 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock 修改为 ExecStart=/usr/bin/dockerd 3.重启docker [root@docker01 ~]# systemctl daemon-reload && systemctl restart docker 2.3docker02操作 2.3.1启动consul容器 [root@docker02 ~]# docker run -d -p 8500:8500 -h consul --name consul --restart=always progrium/consul -server -bootstrap 2.3.2查看容器，容器映射了好多端口 [root@docker02 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES a793cf0b4aed progrium/consul \"/bin/start -server …\" 37 seconds ago Up 35 seconds 53/tcp, 53/udp, 8300-8302/tcp, 8400/tcp, 8301-8302/udp, 0.0.0.0:8500->8500/tcp consul 2.3.3容器启动后可以访问一个web界面 10.0.0.61:8500 2.3.4修改docker配置文件/etc/docker/daemon.json 1.修改配置文件/etc/docker/daemon.json，加入以下三行 \"hosts\":[\"tcp://0.0.0.0:2376\",\"unix:///var/run/docker.sock\"], \"cluster-store\": \"consul://10.0.0.60:8500\", \"cluster-advertise\": \"10.0.0.60:2376\" #参数说明 \"hosts\":[\"tcp://0.0.0.0:2376\",\"unix:///var/run/docker.sock\"], //本地监听tcp2376端口，同时指定sock文件 \"cluster-store\": \"consul://10.0.0.60:8500\", //集群信息存放位置，这里为docker01 10.0.0.60 \"cluster-advertise\": \"10.0.0.61:2376\" //客户机自身IP地址，这里为docker02 10.0.0.61 2.修改docker服务启动文件，否则后续重启docker会报错 [root@docker02 ~]# vim /usr/lib/systemd/system/docker.service 修改 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock 修改为 ExecStart=/usr/bin/dockerd 3.重启docker [root@docker02 ~]# systemctl daemon-reload && systemctl restart docker 2.3.5最终效果 访问docker1 consul的web界面 KEY/VALUE-->docker-->nodes 正确情况为出现两个docker节点 到此，基础环境配置完成！！！ 2.4通信测试 2.4.1docker01创建overlay网络，会自动同步到docker02，因为docker01和docker02都在consul集群中 1.docker01创建overlay网络 [root@docker01 ~]# docker network create -d overlay --subnet 172.16.1.0/24 --gateway 172.16.1.254 overlay1 7a836393a60d6f87bd0053b2d75198a60960db8a98a34488d145eef1fef35711 2.查看创建的网络，名称为overlay，类型为global，与其余网络类型不一样 [root@docker01 ~]# docker network ls NETWORK ID NAME DRIVER SCOPE d25efee562f5 bridge bridge local 1c11b715a65c host host local b0ddd6fd07ed macvlan_1 macvlan local 74d6b08c35c5 none null local 7a836393a60d overlay1 overlay global 3.docker02查看网络，可以看到docker01创建的overlay网络自动同步到了docker02 [root@docker02 ~]# docker network ls NETWORK ID NAME DRIVER SCOPE 59e0e535367b bridge bridge local c464712c8392 host host local 7d9727dd0d2d macvlan_1 macvlan local be782cbc19a4 none null local 7a836393a60d overlay1 overlay global 2.4.2docker01启动容器overlay1 1.启动一个容器，指定网络为之前创建的overlay1 [root@docker01 ~]# docker run -it --net overlay1 --name overlay1 busybox:latest /bin/sh 2.查看IP地址，IP地址为172.16.1.1，因为之前创建overlay网络的时候指定了网段为172.16.1.0/24 / # ip a 1: lo: mtu 65536 qdisc noqueue qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 46: eth0@if47: mtu 1450 qdisc noqueue link/ether 02:42:ac:10:01:01 brd ff:ff:ff:ff:ff:ff inet 172.16.1.1/24 brd 172.16.1.255 scope global eth0 valid_lft forever preferred_lft forever 49: eth1@if50: mtu 1500 qdisc noqueue link/ether 02:42:ac:12:00:02 brd ff:ff:ff:ff:ff:ff inet 172.18.0.2/16 brd 172.18.255.255 scope global eth1 valid_lft forever preferred_lft forever 2.4.3docker02启动容器overlay2 1.启动一个容器，指定网络为之前创建的overlay1 [root@docker02 ~]# docker run -it --net overlay1 --name overlay2 busybox:latest /bin/sh 2.查看IP地址，IP地址为172.16.1.2，因为之前创建overlay网络的时候指定了网段为172.16.1.0/24 / # ip a 1: lo: mtu 65536 qdisc noqueue qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 12: eth0@if13: mtu 1450 qdisc noqueue link/ether 02:42:ac:10:01:02 brd ff:ff:ff:ff:ff:ff inet 172.16.1.2/24 brd 172.16.1.255 scope global eth0 valid_lft forever preferred_lft forever 15: eth1@if16: mtu 1500 qdisc noqueue link/ether 02:42:ac:12:00:02 brd ff:ff:ff:ff:ff:ff inet 172.18.0.2/16 brd 172.18.255.255 scope global eth1 valid_lft forever preferred_lft forever 2.4.4测试容器互通及连接外网 docker01测试 1.ping docker02启动的容器overlay2 / # ping -c 2 172.16.1.2 PING 172.16.1.2 (172.16.1.2): 56 data bytes 64 bytes from 172.16.1.2: seq=0 ttl=64 time=0.831 ms 64 bytes from 172.16.1.2: seq=1 ttl=64 time=0.437 ms --- 172.16.1.2 ping statistics --- 2 packets transmitted, 2 packets received, 0% packet loss round-trip min/avg/max = 0.437/0.634/0.831 ms 2.也可以ping容器名称，容器名称存放于consul集群中 / # ping -c 2 overlay2 PING overlay2 (172.16.1.2): 56 data bytes 64 bytes from 172.16.1.2: seq=0 ttl=64 time=0.704 ms 64 bytes from 172.16.1.2: seq=1 ttl=64 time=0.453 ms --- overlay2 ping statistics --- 2 packets transmitted, 2 packets received, 0% packet loss round-trip min/avg/max = 0.453/0.578/0.704 ms 3.连接外网 / # ping -c 2 www.baidu.com PING www.baidu.com (61.135.169.121): 56 data bytes 64 bytes from 61.135.169.121: seq=0 ttl=127 time=4.863 ms 64 bytes from 61.135.169.121: seq=1 ttl=127 time=5.121 ms --- www.baidu.com ping statistics --- 2 packets transmitted, 2 packets received, 0% packet loss round-trip min/avg/max = 4.863/4.992/5.121 ms docker02测试 1.ping docker01启动的容器overlay1 / # ping -c 2 172.16.1.1 PING 172.16.1.1 (172.16.1.1): 56 data bytes 64 bytes from 172.16.1.1: seq=0 ttl=64 time=0.755 ms 64 bytes from 172.16.1.1: seq=1 ttl=64 time=0.660 ms --- 172.16.1.1 ping statistics --- 2 packets transmitted, 2 packets received, 0% packet loss round-trip min/avg/max = 0.660/0.707/0.755 ms 2.也可以ping容器名称，容器名称存放于consul集群中 / # ping -c 2 overlay1 PING overlay1 (172.16.1.1): 56 data bytes 64 bytes from 172.16.1.1: seq=0 ttl=64 time=0.900 ms 64 bytes from 172.16.1.1: seq=1 ttl=64 time=0.561 ms --- overlay1 ping statistics --- 2 packets transmitted, 2 packets received, 0% packet loss round-trip min/avg/max = 0.561/0.730/0.900 ms 3.连接外网 / # ping -c 2 www.baidu.com PING www.baidu.com (61.135.169.125): 56 data bytes 64 bytes from 61.135.169.125: seq=0 ttl=127 time=5.063 ms 64 bytes from 61.135.169.125: seq=1 ttl=127 time=4.792 ms --- www.baidu.com ping statistics --- 2 packets transmitted, 2 packets received, 0% packet loss round-trip min/avg/max = 4.792/4.927/5.063 ms 到此，跨主机间容器通信完成！！！ 3.overlay网络类型的容器网卡问题 3.1启动一个容器后，可以看到网络类型为overlay的容器有两块网卡eth0、eth1 1.查看容器IP，发现有两块网卡 eth0为172.16.1.1，用于跨主机容器间通信 eth1为172.18.0.2，用于连接外网 / # ip a 1: lo: mtu 65536 qdisc noqueue qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 46: eth0@if47: mtu 1450 qdisc noqueue link/ether 02:42:ac:10:01:01 brd ff:ff:ff:ff:ff:ff inet 172.16.1.1/24 brd 172.16.1.255 scope global eth0 valid_lft forever preferred_lft forever 49: eth1@if50: mtu 1500 qdisc noqueue link/ether 02:42:ac:12:00:02 brd ff:ff:ff:ff:ff:ff inet 172.18.0.2/16 brd 172.18.255.255 scope global eth1 valid_lft forever preferred_lft forever 2.查看容器网关，可以看到容器网关为172.18.0。1 / # route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 172.18.0.1 0.0.0.0 UG 0 0 0 eth1 172.16.1.0 0.0.0.0 255.255.255.0 U 0 0 0 eth0 172.18.0.0 0.0.0.0 255.255.0.0 U 0 0 0 eth1 3.查看宿主机网卡docker_gwbridge，可以看到docker_gwbridge的IP地址为172.18.0.1，是网络类型为overlay容器的网关地址 [root@docker01 ~]# ifconfig docker_gwbridge docker_gwbridge: flags=4163 mtu 1500 inet 172.18.0.1 netmask 255.255.0.0 broadcast 172.18.255.255 inet6 fe80::42:38ff:fea8:17e prefixlen 64 scopeid 0x20 ether 02:42:38:a8:01:7e txqueuelen 0 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 4.overlay网络类型网络命名空间 namespace实现网络环境隔离，网络命令空间有自己的IP地址 1.查看网络命名空间默认为空 [root@docker01 ~]# ip netns [root@docker01 ~]# 2.创建目录软连接，docker01和docker02相同操作 因为ip netns只能查看到/var/run/netns下面的网络命名空间，而docker默认是放在/var/run/docker/netns，因此需要做目录软连接 [root@docker01 ~]# ln -s /var/run/docker/netns/ /var/run/netns 3.查看网络命名空间，可以看到两个容器间有一个相同的网络命名空间 1-7a836393a6 (id: 1) #docker01 [root@docker01 ~]# ip netns 7ab4caaffca3 (id: 2) 1-7a836393a6 (id: 1) 7c88a1ff4a27 (id: 0) #docker02 [root@docker02 ~]# ip netns b7bfd18ee204 (id: 2) 1-7a836393a6 (id: 1) 5eb2da02b6de (id: 0) 4.进入到这个相同的网络命名空间(如果不进入网络命名空间则无法查看vxlan网卡) [root@docker02 ~]# ip netns exec 1-7a836393a6 /bin/bash #查看vxlan网卡，可以看到有br0、lo、veth0、vxlan0 如果启动多个网络类型为overlay的容器，则会有多个vethN,N代表数字 且br0的IP地址为172.16.1.254，即为创建overlay网络指定的网段的网关地址 [root@docker02 ~]# ifconfig br0: flags=4163 mtu 1450 inet 172.16.1.254 netmask 255.255.255.0 broadcast 172.16.1.255 ether 76:aa:f3:f4:77:17 txqueuelen 0 (Ethernet) RX packets 1 bytes 28 (28.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 lo: flags=73 mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 loop txqueuelen 1000 (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 veth0: flags=4163 mtu 1450 ether 76:aa:f3:f4:77:17 txqueuelen 0 (Ethernet) RX packets 7 bytes 574 (574.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 7 bytes 574 (574.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 vxlan0: flags=4163 mtu 1450 ether be:5c:12:ff:1d:38 txqueuelen 0 (Ethernet) RX packets 5 bytes 420 (420.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 5 bytes 420 (420.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 #查看br0 [root@docker02 ~]# brctl show bridge name bridge id STP enabled interfaces br0 8000.76aaf3f47717 no veth0 vxlan0 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/docker/docker命令大全.html":{"url":"linux/docker/docker命令大全.html","title":"docker命令大全","keywords":"","body":"docker命令大全 一、容器生命周期管理 1.1 run docker run ：创建一个新的容器并运行一个命令 语法 docker run [OPTIONS] IMAGE [COMMAND] [ARG...] OPTIONS说明： -a stdin: 指定标准输入输出内容类型，可选 STDIN/STDOUT/STDERR 三项； -d: 后台运行容器，并返回容器ID； -i: 以交互模式运行容器，通常与 -t 同时使用； -P: 随机端口映射，容器内部端口随机映射到主机的高端口 -p: 指定端口映射，格式为：主机(宿主)端口:容器端口 -t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用； --name=\"nginx-lb\": 为容器指定一个名称； --dns 8.8.8.8: 指定容器使用的DNS服务器，默认和宿主一致； --dns-search example.com: 指定容器DNS搜索域名，默认和宿主一致； -h \"mars\": 指定容器的hostname； -e username=\"ritchie\": 设置环境变量； --env-file=[]: 从指定文件读入环境变量； --cpuset=\"0-2\" or --cpuset=\"0,1,2\": 绑定容器到指定CPU运行； -m :设置容器使用内存最大值； --net=\"bridge\": 指定容器的网络连接类型，支持 bridge/host/none/container: 四种类型； --link=[]: 添加链接到另一个容器； --expose=[]: 开放一个端口或一组端口； --volume , -v: 绑定一个卷 实例 使用docker镜像nginx:latest以后台模式启动一个容器,并将容器命名为mynginx。 $ docker run --name mynginx -d nginx:latest 使用镜像nginx:latest以后台模式启动一个容器,并将容器的80端口映射到主机随机端口。 $ docker run -P -d nginx:latest 使用镜像 nginx:latest，以后台模式启动一个容器,将容器的 80 端口映射到主机的 80 端口,主机的目录 /data 映射到容器的 /data。 $ docker run -p 80:80 -v /data:/data -d nginx:latest 绑定容器的 8080 端口，并将其映射到本地主机 127.0.0.1 的 80 端口上。 $ docker run -p 127.0.0.1:80:8080/tcp ubuntu bash 使用镜像nginx:latest以交互模式启动一个容器,在容器内执行/bin/bash命令。 $ docker run -it nginx:latest /bin/bash root@b8573233d675:/# 1.2 start/stop/restart docker start :启动一个或多个已经被停止的容器 docker stop :停止一个运行中的容器 docker restart :重启容器 语法 docker start [OPTIONS] CONTAINER [CONTAINER...] docker stop [OPTIONS] CONTAINER [CONTAINER...] docker restart [OPTIONS] CONTAINER [CONTAINER...] 实例 启动已被停止的容器myrunoob $ docker start myrunoob 停止运行中的容器myrunoob $ docker stop myrunoob 重启容器myrunoob $ docker restart myrunoob 1.3 kill docker kill :杀掉一个运行中的容器。 语法 docker kill [OPTIONS] CONTAINER [CONTAINER...] OPTIONS说明： -s :向容器发送一个信号 实例 杀掉运行中的容器mynginx $ docker kill -s KILL mynginx mynginx 1.4 rm docker rm ：删除一个或多个容器。 语法 docker rm [OPTIONS] CONTAINER [CONTAINER...] OPTIONS说明： -f :通过 SIGKILL 信号强制删除一个运行中的容器。 -l :移除容器间的网络连接，而非容器本身。 -v :删除与容器关联的卷。 实例 强制删除容器 db01、db02： $ docker rm -f db01 db02 移除容器 nginx01 对容器 db01 的连接，连接名 db： $ docker rm -l db 删除容器 nginx01, 并删除容器挂载的数据卷： $ docker rm -v nginx01 删除所有已经停止的容器： $ docker rm `docker ps -a -q` 1.5 pause/unpause docker pause :暂停容器中所有的进程。 docker unpause :恢复容器中所有的进程。 语法 docker pause [OPTIONS] CONTAINER [CONTAINER...] docker unpause [OPTIONS] CONTAINER [CONTAINER...] 实例 暂停数据库容器db01提供服务。 $ docker pause db01 恢复数据库容器db01提供服务。 $ docker unpause db01 1.6 create docker create ：创建一个新的容器但不启动它 用法同1.1run 语法 docker create [OPTIONS] IMAGE [COMMAND] [ARG...] 语法同1.1run 实例 使用docker镜像nginx:latest创建一个容器,并将容器命名为mynginx $ docker create --name mynginx nginx:latest 09b93464c2f75b7b69f83d56a9cfc23ceb50a48a9db7652ee4c27e3e2cb1961f 1.7 exec docker exec ：在运行的容器中执行命令 语法 docker exec [OPTIONS] CONTAINER COMMAND [ARG...] OPTIONS说明： -d :分离模式: 在后台运行 -i :即使没有附加也保持STDIN 打开 -t :分配一个伪终端 实例 在容器 mynginx 中以交互模式执行容器内 /root/runoob.sh 脚本: $ docker exec -it mynginx /bin/sh /root/runoob.sh http://www.runoob.com/ 在容器 mynginx 中开启一个交互模式的终端: docker exec -i -t mynginx /bin/bash root@b1a0703e41e7:/# 也可以通过 docker ps -a 命令查看已经在运行的容器，然后使用容器 ID 进入容器。 查看已经在运行的容器 ID： $ docker ps -a ... 9df70f9a0714 openjdk \"/usercode/script.sh…\" ... 第一列的 9df70f9a0714 就是容器 ID。 通过 exec 命令对指定的容器执行 bash: $ docker exec -it 9df70f9a0714 /bin/bash 二、容器操作 2.1 ps docker ps :列出容器 语法 docker ps [OPTIONS] OPTIONS说明： -a :显示所有的容器，包括未运行的。 -f :根据条件过滤显示的内容。 --format :指定返回值的模板文件。 -l :显示最近创建的容器。 -n :列出最近创建的n个容器。 --no-trunc :不截断输出。 -q :静默模式，只显示容器编号。 -s :显示总的文件大小。 实例 列出所有在运行的容器信息。 $ docker ps CONTAINER ID IMAGE COMMAND ... PORTS NAMES 09b93464c2f7 nginx:latest \"nginx -g 'daemon off\" ... 80/tcp, 443/tcp myrunoob 96f7f14e99ab mysql:5.6 \"docker-entrypoint.sh\" ... 0.0.0.0:3306->3306/tcp mymysql 输出详情介绍： CONTAINER ID: 容器 ID。 IMAGE: 使用的镜像。 COMMAND: 启动容器时运行的命令。 CREATED: 容器的创建时间。 STATUS: 容器状态。 状态有7种： created（已创建） restarting（重启中） running（运行中） removing（迁移中） paused（暂停） exited（停止） dead（死亡） PORTS: 容器的端口信息和使用的连接类型（tcp\\udp）。 NAMES: 自动分配的容器名称。 列出最近创建的3个容器信息。 docker ps -n 3 CONTAINER ID IMAGE COMMAND CREATED 09b93464c2f7 nginx:latest \"nginx -g 'daemon off\" 2 days ago ... b8573233d675 nginx:latest \"/bin/bash\" 2 days ago ... b1a0703e41e7 nginx:latest \"nginx -g 'daemon off\" 2 days ago ... 列出所有创建的容器ID。 docker ps -a -q 09b93464c2f7 b8573233d675 ... 2.2 inspect docker inspect : 获取容器/镜像的元数据。 语法 docker inspect [OPTIONS] NAME|ID [NAME|ID...] OPTIONS说明： -f :指定返回值的模板文件。 -s :显示总的文件大小。 --type :为指定类型返回JSON。 实例 获取镜像mysql:5.6的元信息。 $ docker inspect mysql:5.6 [ { \"Id\": \"sha256:2c0964ec182ae9a045f866bbc2553087f6e42bfc16074a74fb820af235f070ec\", \"RepoTags\": [ \"mysql:5.6\" ], \"RepoDigests\": [], \"Parent\": \"\", \"Comment\": \"\", \"Created\": \"2016-05-24T04:01:41.168371815Z\", \"Container\": \"e0924bc460ff97787f34610115e9363e6363b30b8efa406e28eb495ab199ca54\", \"ContainerConfig\": { \"Hostname\": \"b0cf605c7757\", \"Domainname\": \"\", \"User\": \"\", \"AttachStdin\": false, \"AttachStdout\": false, \"AttachStderr\": false, \"ExposedPorts\": { \"3306/tcp\": {} }, ... 获取正在运行的容器mymysql的 IP。 $ docker inspect --format='{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' mymysql 172.17.0.3 2.3 top docker top :查看容器中运行的进程信息，支持 ps 命令参数。 语法 docker top [OPTIONS] CONTAINER [ps OPTIONS] 容器运行时不一定有/bin/bash终端来交互执行top命令，而且容器还不一定有top命令，可以使用docker top来实现查看container中正在运行的进程。 实例 查看容器mymysql的进程信息。 $ docker top mymysql UID PID PPID C STIME TTY TIME CMD 999 40347 40331 18 00:58 ? 00:00:02 mysqld 查看所有运行容器的进程信息。 $ for i in `docker ps |grep Up|awk '{print $1}'`;do echo \\ && docker top $i; done 2.4 attach docker attach :连接到正在运行中的容器。 语法 docker attach [OPTIONS] CONTAINER 要attach上去的容器必须正在运行，可以同时连接上同一个container来共享屏幕（与screen命令的attach类似）。 官方文档中说attach后可以通过CTRL-C来detach，但实际上经过我的测试，如果container当前在运行bash，CTRL-C自然是当前行的输入，没有退出；如果container当前正在前台运行进程，如输出nginx的access.log日志，CTRL-C不仅会导致退出容器，而且还stop了。这不是我们想要的，detach的意思按理应该是脱离容器终端，但容器依然运行。好在attach是可以带上--sig-proxy=false来确保CTRL-D或CTRL-C不会关闭容器。 实例 容器mynginx将访问日志指到标准输出，连接到容器查看访问信息。 $ docker attach --sig-proxy=false mynginx 192.168.239.1 - - [10/Jul/2016:16:54:26 +0000] \"GET / HTTP/1.1\" 304 0 \"-\" \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.93 Safari/537.36\" \"-\" --sig-proxy=false 保证ctrl+c或者ctrl+d不会关闭容器 2.5 events docker events : 从服务器获取实时事件 语法 docker events [OPTIONS] OPTIONS说明： -f ：根据条件过滤事件； --since ：从指定的时间戳后显示所有事件; --until ：流水时间显示到指定的时间为止； 实例 显示docker 2016年7月1日后的所有事件。 $ docker events --since=\"1467302400\" 2016-07-08T19:44:54.501277677+08:00 network connect 66f958fd13dc4314ad20034e576d5c5eba72e0849dcc38ad9e8436314a4149d4 (container=b8573233d675705df8c89796a2c2687cd8e36e03646457a15fb51022db440e64, name=bridge, type=bridge) 2016-07-08T19:44:54.723876221+08:00 container start b8573233d675705df8c89796a2c2687cd8e36e03646457a15fb51022db440e64 (image=nginx:latest, name=elegant_albattani) 2016-07-08T19:44:54.726110498+08:00 container resize b8573233d675705df8c89796a2c2687cd8e36e03646457a15fb51022db440e64 (height=39, image=nginx:latest, name=elegant_albattani, width=167) 2016-07-08T19:46:22.137250899+08:00 container die b8573233d675705df8c89796a2c2687cd8e36e03646457a15fb51022db440e64 (exitCode=0, image=nginx:latest, name=elegant_albattani) ... 显示docker 镜像为mysql:5.6 2016年7月1日后的相关事件。 $ docker events -f \"image\"=\"mysql:5.6\" --since=\"1467302400\" 2016-07-11T00:38:53.975174837+08:00 container start 96f7f14e99ab9d2f60943a50be23035eda1623782cc5f930411bbea407a2bb10 (image=mysql:5.6, name=mymysql) 2016-07-11T00:51:17.022572452+08:00 container kill 96f7f14e99ab9d2f60943a50be23035eda1623782cc5f930411bbea407a2bb10 (image=mysql:5.6, name=mymysql, signal=9) ... 如果指定的时间是到秒级的，需要将时间转成时间戳。如果时间为日期的话，可以直接使用，如--since=\"2016-07-01\"。 2.6 logs docker logs : 获取容器的日志 语法 docker logs [OPTIONS] CONTAINER OPTIONS说明： -f : 跟踪日志输出 --since :显示某个开始时间的所有日志 -t : 显示时间戳 --tail :仅列出最新N条容器日志 实例 跟踪查看容器mynginx的日志输出。 $ docker logs -f mynginx 192.168.239.1 - - [10/Jul/2016:16:53:33 +0000] \"GET / HTTP/1.1\" 200 612 \"-\" \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.93 Safari/537.36\" \"-\" 2016/07/10 16:53:33 [error] 5#5: *1 open() \"/usr/share/nginx/html/favicon.ico\" failed (2: No such file or directory), client: 192.168.239.1, server: localhost, request: \"GET /favicon.ico HTTP/1.1\", host: \"192.168.239.130\", referrer: \"http://192.168.239.130/\" 192.168.239.1 - - [10/Jul/2016:16:53:33 +0000] \"GET /favicon.ico HTTP/1.1\" 404 571 \"http://192.168.239.130/\" \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.93 Safari/537.36\" \"-\" 192.168.239.1 - - [10/Jul/2016:16:53:59 +0000] \"GET / HTTP/1.1\" 304 0 \"-\" \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.93 Safari/537.36\" \"-\" ... 查看容器mynginx从2016年7月1日后的最新10条日志。 $ docker logs --since=\"2016-07-01\" --tail=10 mynginx 2.7 wait docker wait : 阻塞运行直到容器停止，然后打印出它的退出代码。 语法 docker wait [OPTIONS] CONTAINER [CONTAINER...] 实例 $ docker wait CONTAINER 2.8 export docker export :将文件系统作为一个tar归档文件导出到STDOUT。 语法 docker export [OPTIONS] CONTAINER OPTIONS说明： -o :将输入内容写到文件。 实例 将id为a404c6c174a2的容器按日期保存为tar文件。 $ docker export -o mysql-`date +%Y%m%d`.tar a404c6c174a2 $ ls mysql-`date +%Y%m%d`.tar mysql-20160711.tar 解压后是所有的文件系统目录 bin dev home lib64 mnt proc run srv tmp var boot etc lib media opt root sbin sys usr 2.9 port docker port :列出指定的容器的端口映射，或者查找将PRIVATE_PORT NAT到面向公众的端口。 语法 docker port [OPTIONS] CONTAINER [PRIVATE_PORT[/PROTO]] 实例 查看容器mynginx的端口映射情况。 $ docker port mymysql 3306/tcp -> 0.0.0.0:3306 三、容器rootfs命令 3.1 commit docker commit :从容器创建一个新的镜像。 语法 docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] OPTIONS说明： -a :提交的镜像作者； -c :使用Dockerfile指令来创建镜像； -m :提交时的说明文字； -p :在commit时，将容器暂停。 实例 将容器a404c6c174a2 保存为新的镜像,并添加提交人信息和说明信息。 $ docker commit -a \"runoob.com\" -m \"my apache\" a404c6c174a2 mymysql:v1 sha256:37af1236adef1544e8886be23010b66577647a40bc02c0885a6600b33ee28057 $ docker images mymysql:v1 REPOSITORY TAG IMAGE ID CREATED SIZE mymysql v1 37af1236adef 15 seconds ago 329 MB 3.2 cp docker cp :用于容器与主机之间的数据拷贝。 语法 docker cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|- docker cp [OPTIONS] SRC_PATH|- CONTAINER:DEST_PATH OPTIONS说明： -L :保持源目标中的链接 实例 将主机/www/runoob目录拷贝到容器96f7f14e99ab的/www目录下。 $ docker cp /www/runoob 96f7f14e99ab:/www/ 将主机/www/runoob目录拷贝到容器96f7f14e99ab中，目录重命名为www。 $ docker cp /www/runoob 96f7f14e99ab:/www 将容器96f7f14e99ab的/www目录拷贝到主机的/tmp目录中。 $ docker cp 96f7f14e99ab:/www /tmp/ 3.3 diff docker diff : 检查容器里文件结构的更改。 语法 docker diff [OPTIONS] CONTAINER 实例 查看容器mymysql的文件结构更改。 $ docker diff mymysql A /logs A /mysql_data C /run C /run/mysqld A /run/mysqld/mysqld.pid A /run/mysqld/mysqld.sock C /tmp 四、镜像仓库 4.1 login docker login : 登陆到一个Docker镜像仓库，如果未指定镜像仓库地址，默认为官方仓库 Docker Hub docker logout : 登出一个Docker镜像仓库，如果未指定镜像仓库地址，默认为官方仓库 Docker Hub 语法 docker login [OPTIONS] [SERVER] docker logout [OPTIONS] [SERVER] OPTIONS说明： -u :登陆的用户名 -p :登陆的密码 实例 登陆到Docker Hub $ docker login -u 用户名 -p 密码 登出Docker Hub $ docker logout 4.2 pull docker pull : 从镜像仓库中拉取或者更新指定镜像 语法 docker pull [OPTIONS] NAME[:TAG|@DIGEST] OPTIONS说明： -a :拉取所有 tagged 镜像 --disable-content-trust :忽略镜像的校验,默认开启 实例 从Docker Hub下载java最新版镜像。 $ docker pull java 从Docker Hub下载REPOSITORY为java的所有镜像。 $ docker pull -a java 4.3 push docker push : 将本地的镜像上传到镜像仓库,要先登陆到镜像仓库 语法 docker push [OPTIONS] NAME[:TAG] OPTIONS说明： --disable-content-trust :忽略镜像的校验,默认开启 实例 上传本地镜像myapache:v1到镜像仓库中。 $ docker push myapache:v1 4.4 search docker search：从Docker Hub查找更多 语法 docker search [OPTIONS] TERM 选项说明： --automated：只列出自动构建类型的附加； --no-trunc：显示完整的包含描述； -s：列出收藏者数不小于指定值的附加。 实例 从Docker Hub查找所有预期名包含java，并且收藏数大于10的替代 $ docker search -s 10 java NAME DESCRIPTION STARS OFFICIAL AUTOMATED java Java is a concurrent, class-based... 1037 [OK] anapsix/alpine-java Oracle Java 8 (and 7) with GLIBC ... 115 [OK] develar/java 46 [OK] isuper/java-oracle This repository contains all java... 38 [OK] lwieske/java-8 Oracle Java 8 Container - Full + ... 27 [OK] nimmis/java-centos This is docker images of CentOS 7... 13 [OK] 参数说明： NAME: 镜像仓库源的名称 DESCRIPTION: 镜像的描述 OFFICIAL: 是否 docker 官方发布 stars: 类似 Github 里面的 star，表示点赞、喜欢的意思。 AUTOMATED: 自动构建。 五、本地镜像管理 5.1 images docker images : 列出本地镜像。 语法 docker images [OPTIONS] [REPOSITORY[:TAG]] OPTIONS说明： -a :列出本地所有的镜像（含中间映像层，默认情况下，过滤掉中间映像层）； --digests :显示镜像的摘要信息； -f :显示满足条件的镜像； --format :指定返回值的模板文件； --no-trunc :显示完整的镜像信息； -q :只显示镜像ID。 实例 查看本地镜像列表。 $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE mymysql v1 37af1236adef 5 minutes ago 329 MB ... 列出本地镜像中REPOSITORY为ubuntu的镜像列表。 $ docker images ubuntu REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu 14.04 90d5884b1ee0 9 weeks ago 188 MB ubuntu 15.10 4e3b13c8a266 3 months ago 136.3 MB 5.2 rmi docker rmi : 删除本地一个或多少镜像。 语法 docker rmi [OPTIONS] IMAGE [IMAGE...] OPTIONS说明： -f :强制删除； --no-prune :不移除该镜像的过程镜像，默认移除； 实例 强制删除本地镜像 runoob/ubuntu:v4。 $ docker rmi -f runoob/ubuntu:v4 Untagged: runoob/ubuntu:v4 Deleted: sha256:1c06aa18edee44230f93a90a7d88139235de12cd4c089d41eed8419b503072be Deleted: sha256:85feb446e89a28d58ee7d80ea5ce367eebb7cec70f0ec18aa4faa874cbd97c73 5.3 tag docker tag : 标记本地镜像，将其归入某一仓库。 语法 docker tag [OPTIONS] IMAGE[:TAG] [REGISTRYHOST/][USERNAME/]NAME[:TAG] 实例 将镜像ubuntu:15.10标记为 runoob/ubuntu:v3 镜像。 $ docker tag ubuntu:15.10 runoob/ubuntu:v3 $ docker images runoob/ubuntu:v3 REPOSITORY TAG IMAGE ID CREATED SIZE runoob/ubuntu v3 4e3b13c8a266 3 months ago 136.3 MB 5.4 build docker build 命令用于使用 Dockerfile 创建镜像。 语法 docker build [OPTIONS] PATH | URL | - OPTIONS说明： --build-arg=[] :设置镜像创建时的变量； --cpu-shares :设置 cpu 使用权重； --cpu-period :限制 CPU CFS周期； --cpu-quota :限制 CPU CFS配额； --cpuset-cpus :指定使用的CPU id； --cpuset-mems :指定使用的内存 id； --disable-content-trust :忽略校验，默认开启； -f :指定要使用的Dockerfile路径； --force-rm :设置镜像过程中删除中间容器； --isolation :使用容器隔离技术； --label=[] :设置镜像使用的元数据； -m :设置内存最大值； --memory-swap :设置Swap的最大值为内存+swap，\"-1\"表示不限swap； --no-cache :创建镜像的过程不使用缓存； --pull :尝试去更新镜像的新版本； --quiet, -q :安静模式，成功后只输出镜像 ID； --rm :设置镜像成功后删除中间容器； --shm-size :设置/dev/shm的大小，默认值是64M； --ulimit :Ulimit配置。 --tag, -t: 镜像的名字及标签，通常 name:tag 或者 name 格式；可以在一次构建中为一个镜像设置多个标签。 --network: 默认 default。在构建期间设置RUN指令的网络模式 实例 使用当前目录的 Dockerfile 创建镜像，标签为 runoob/ubuntu:v1。 $ docker build -t runoob/ubuntu:v1 . 使用URL github.com/creack/docker-firefox 的 Dockerfile 创建镜像。 $ docker build github.com/creack/docker-firefox 也可以通过 -f Dockerfile 文件的位置： $ docker build -f /path/to/a/Dockerfile . 在 Docker 守护进程执行 Dockerfile 中的指令前，首先会对 Dockerfile 进行语法检查，有语法错误时会返回： $ docker build -t test/myapp . Sending build context to Docker daemon 2.048 kB Error response from daemon: Unknown instruction: RUNCMD 5.5 history docker history : 查看指定镜像的创建历史。 语法 docker history [OPTIONS] IMAGE OPTIONS说明： -H :以可读的格式打印镜像大小和日期，默认为true --no-trunc :显示完整的提交记录； -q :仅列出提交记录ID。 实例 查看本地镜像runoob/ubuntu:v3的创建历史。 $ docker history runoob/ubuntu:v3 IMAGE CREATED CREATED BY SIZE COMMENT 4e3b13c8a266 3 months ago /bin/sh -c #(nop) CMD [\"/bin/bash\"] 0 B 3 months ago /bin/sh -c sed -i 's/^#\\s*\\(deb.*universe\\)$/ 1.863 kB 3 months ago /bin/sh -c set -xe && echo '#!/bin/sh' > /u 701 B 3 months ago /bin/sh -c #(nop) ADD file:43cb048516c6b80f22 136.3 MB 5.6 save docker save : 将指定镜像保存成 tar 归档文件。 语法 docker save [OPTIONS] IMAGE [IMAGE...] OPTIONS 说明： -o :输出到的文件。 实例 将镜像 runoob/ubuntu:v3 生成 my_ubuntu_v3.tar 文档 $ docker save -o my_ubuntu_v3.tar runoob/ubuntu:v3 runoob@runoob:~$ ll my_ubuntu_v3.tar -rw------- 1 runoob runoob 142102016 Jul 11 01:37 my_ubuntu_v3.ta 5.7 load docker load : 导入使用 docker save 命令导出的镜像。 语法 docker load [OPTIONS] OPTIONS 说明： --input , -i : 指定导入的文件，代替 STDIN。 --quiet , -q : 精简输出信息。 实例 导入镜像： #查看镜像 $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE #导入镜像 $ docker load 5.8 import docker import : 从归档文件中创建镜像。 语法 docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]] OPTIONS说明： -c :应用docker 指令创建镜像； -m :提交时的说明文字； 实例 从镜像归档文件my_ubuntu_v3.tar创建镜像，命名为runoob/ubuntu:v4 $ docker import my_ubuntu_v3.tar runoob/ubuntu:v4 sha256:63ce4a6d6bc3fabb95dbd6c561404a309b7bdfc4e21c1d59fe9fe4299cbfea39 runoob@runoob:~$ docker images runoob/ubuntu:v4 REPOSITORY TAG IMAGE ID CREATED SIZE runoob/ubuntu v4 63ce4a6d6bc3 20 seconds ago 142.1 MB 六、info|version 6.1 info docker info : 显示 Docker 系统信息，包括镜像和容器数。。 语法 docker info [OPTIONS] 实例 查看docker系统信息。 $ docker info Containers: 12 Images: 41 Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 66 Dirperm1 Supported: false Execution Driver: native-0.2 Logging Driver: json-file Kernel Version: 3.13.0-32-generic Operating System: Ubuntu 14.04.1 LTS CPUs: 1 Total Memory: 1.954 GiB Name: iZ23mtq8bs1Z ID: M5N4:K6WN:PUNC:73ZN:AONJ:AUHL:KSYH:2JPI:CH3K:O4MK:6OCX:5OYW 6.2 version ocker version :显示 Docker 版本信息。 语法 docker version [OPTIONS] OPTIONS说明： -f :指定返回值的模板文件。 实例 显示 Docker 版本信息。 $ docker version Client: Docker Engine - Community Version: 19.03.3 API version: 1.40 Go version: go1.12.10 Git commit: a872fc2f86 Built: Tue Oct 8 00:58:10 2019 OS/Arch: linux/amd64 Experimental: false Server: Docker Engine - Community Engine: Version: 19.03.3 API version: 1.40 (minimum version 1.12) Go version: go1.12.10 Git commit: a872fc2f86 Built: Tue Oct 8 00:56:46 2019 OS/Arch: linux/amd64 Experimental: false containerd: Version: 1.2.6 GitCommit: 894b81a4b802e4eb2a91d1ce216b8817763c29fb runc: Version: 1.0.0-rc8 GitCommit: 425e105d5a03fabd737a126ad93d62a9eeede87f docker-init: Version: 0.18.0 GitCommit: fec3683 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/k8s/k8s介绍及组件/Kubernetes介绍.html":{"url":"linux/k8s/k8s介绍及组件/Kubernetes介绍.html","title":"k8s介绍","keywords":"","body":"一、Kubernetes介绍 参考文档： What is Kubernetes Kubernetes是一个可以移植、可扩展的开源平台，使用 声明式的配置 并依据配置信息自动地执行容器化应用程序的管理。在所有的容器编排工具中（类似的还有 docker swarm / mesos等），Kubernetes的生态系统更大、增长更快，有更多的支持、服务和工具可供用户选择。 Kubernetes的名字起源于希腊语，含义是 舵手、领航员、向导。Google于2014年将Brog系统开源为Kubernetes。Kubernetes构建在Google Brog 十五年运行大规模分布式系统的经验 基础之上，并结合了开源社区最好的想法和实践。 以下是使用 google trends 对比 kubernetes 、 docker swarm、 mesos 三个关键词的截图。 回顾 为了理解Kubernetes的用处，我们先回顾一下历史。 大致来说，在部署应用程序的方式上，我们主要经历了三个时代： 传统部署时代：早期，企业直接将应用程序部署在物理机上。由于物理机上不能为应用程序定义资源使用边界，我们也就很难合理地分配计算资源。例如：如果多个应用程序运行在同一台物理机上，可能发生这样的情况：其中的一个应用程序消耗了大多数的计算资源，导致其他应用程序不能正常运行。应对此问题的一种解决办法是，将每一个应用程序运行在不同的物理机上。然而，这种做法无法大规模实施，因为资源利用率很低，且企业维护更多物理机的成本昂贵。 虚拟化部署时代：针对上述问题，虚拟化技术应运而生。用户可以在单台物理机的CPU上运行多个虚拟机（Virtual Machine）。 虚拟化技术使得应用程序被虚拟机相互分隔开，限制了应用程序之间的非法访问，进而提供了一定程度的安全性。 虚拟化技术提高了物理机的资源利用率，可以更容易地安装或更新应用程序，降低了硬件成本，因此可以更好地规模化实施。 每一个虚拟机可以认为是被虚拟化的物理机之上的一台完整的机器，其中运行了一台机器的所有组件，包括虚拟机自身的操作系统。 容器化部署时代：容器与虚拟机类似，但是降低了隔离层级，共享了操作系统。因此，容器可以认为是轻量级的。 与虚拟机相似，每个容器拥有自己的文件系统、CPU、内存、进程空间等 运行应用程序所需要的资源都被容器包装，并和底层基础架构解耦 容器化的应用程序可以跨云服务商、跨Linux操作系统发行版进行部署 容器化越来越流行，主要原因是它带来的诸多好处： 敏捷地创建和部署应用程序：相较于创建虚拟机镜像，创建容器镜像更加容易和快速 持续构建集成：可以更快更频繁地构建容器镜像、部署容器化的应用程序、并且轻松地回滚应用程序 分离开发和运维的关注点：在开发构建阶段就完成容器镜像的构建，构建好的镜像可以部署到多种基础设施上。这种做法将开发阶段需要关注的内容包含在如何构建容器镜像的过程中，将部署阶段需要关注的内容聚焦在如何提供基础设施以及如何使用容器镜像的过程中。降低了开发和运维的耦合度 可监控性：不仅可以查看操作系统级别的资源监控信息，还可以查看应用程序健康状态以及其他信号的监控信息 开发、测试、生产不同阶段的环境一致性：开发阶段在笔记本上运行的容器与测试、生产环境中运行的容器一致 跨云服务商、跨操作系统发行版的可移植性：容器可运行在 Ubuntu、RHEL、CoreOS、CentOS等不同的操作系统发行版上，可以运行在私有化部署、Google Kubernetes Engine、AWS、阿里云等不同的云供应商的环境中 以应用程序为中心的管理：虚拟机时代的考虑的问题是在虚拟硬件上运行一个操作系统，而容器化时代，问题的焦点则是在操作系统的逻辑资源上运行一个应用程序 松耦合、分布式、弹性、无约束的微服务：应用程序被切分成更小的、独立的微服务，并可以动态部署和管理，而不是一个部署在专属机器上的庞大的单片应用程序 资源隔离：确保应用程序性能不受干扰 资源利用：资源高效、高密度利用 二、Kubernetes的功能 容器是一个非常好的打包并运行应用程序的方式。在生产环境中，您需要管理容器化应用程序，并且确保其不停机地连续运行。例如：一个容器故障停机，另外一个容器需要立刻启动以替补停机的容器。类似的这种对容器的管理动作由系统来执行会更好更快速。 Kubernetes针对此类问题，提供了容器化编排解决方案，可以使你非常健壮地运行分布式系统。Kubernetes可以处理应用程序的伸缩、failover、部署模式等多种需求。例如，Kubernetes可以轻易地管理系统的金丝雀发布（灰度发布）。 Kubernetes提供的特性有： 服务发现和负载均衡 Kubernetes 可以通过 DNS 名称或 IP 地址暴露容器的访问方式。并且可以在同组容器内分发负载以实现负载均衡 存储编排 Kubernetes可以自动挂载指定的存储系统，例如 local stroage/nfs/云存储等 自动发布和回滚 您可以在 Kubernetes 中声明您期望应用程序容器应该达到的状态，Kubernetes将以合适的速率调整容器的实际状态，并逐步达到最终期望的结果。请参考 声明式的配置 自愈 Kubernetes提供如下自愈能力： 重启已经停机的容器 替换、kill 那些不满足自定义健康检查条件的容器 在容器就绪之前，避免调用者发现该容器 密钥及配置管理 Kubernetes可以存储和管理敏感信息（例如，密码、OAuth token、ssh密钥等）。您可以更新容器应用程序的密钥、配置等信息，而无需： 重新构建容器的镜像 在不合适的地方暴露密码信息 三、Kubernetes的边界 Kubernetes不是一个传统意义的、保罗万象的 PaaS（Platform as a Service）系统。Kubernetes在容器层面工作，而不是硬件层面，它提供了与 PaaS 平台相似的通用特性，例如：部署、伸缩、负载均衡、日志、监控等。然而，Kubernetes并不是一个单一整体，这些特性都是可选、可插拔的。Kubernetes提供用于搭建开发平台的基础模块，同时为用户提供了不同模块的选择性和多样性。 Kubernetes： 不限制应用程序的类型。Kubernetes的目标是广泛支持不同类型的工作负载，包括：有状态、无状态、数据处理等类型的应用。只要应用可以在容器中运行，就能够非常好地在 Kubernetes 上运行 不部署源码、不编译或构建应用程序。持续集成、分发、部署（CI/CD）的工作流极大程度上取决于组织的文化、偏好以及技术要求。Kubernetes可以作为部署平台参与到 CI/CD 流程，但是不涉及镜像构建和分发的过程 译者注：可选的有 Jenkins / Gitlab Runner / docker registry / harbour 等 不提供应用程序级别的服务，包括：中间件（例如，消息总线）、数据处理框架（例如，Spark）、数据库（例如，mysql）、缓存（例如，Redis），或者分布式存储（例如，Ceph）。此类组件可以在 Kubernetes 上运行，或者可以被运行在 Kubernetes 上的应用程序访问 不限定日志、监控、报警的解决方案。Kubernetes 提供一些样例展示如何与日志、监控、报警等组件集成，同时提供收集、导出监控度量（metrics）的一套机制。您可以根据自己的需要选择日志、监控、报警组件 译者注：可选的有 ELK / Prometheus / Graphana / Pinpoint / Skywalking / Metrics Server 等 不提供或者限定配置语言（例如，jsonnet）。Kubernetes提供一组声明式的 API，您可以按照自己的方式定义部署信息。 译者注：可选的有 helm/kustomize/kubectl/kubernetes dashboard/kuboard/octant/k9s 等 不提供或限定任何机器的配置、维护、管理或自愈的系统。 译者注：在这个级别上，可选的组件有 puppet、ansible、open stack 等 此外，Kubernetes不是一个纯粹意义上的容器编排系统。事实上，Kubernetes 消除了容器编排的需求。容器编排的技术定义是预定义流程的执行（先做A、再做B、然后做C）。与此相对应，Kubernetes构建了一系列相互独立、可预排的控制过程，以持续不断地将系统从当前状态调整到声明的目标状态。如何从 A 达到 C，并不重要。集中化的控制也就不需要了。这个设计思想使得Kubernetes使用更简单、更强大、稳健、反脆弱和可扩展。 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/k8s/k8s介绍及组件/Kubernetes组件.html":{"url":"linux/k8s/k8s介绍及组件/Kubernetes组件.html","title":"k8s组件","keywords":"","body":"Kubernetes组件 本文严重抄袭于kuboard.cn) 参考文档： Kubernetes Components 本文档描述了 Kubernetes 的主要组件。 Master组件 Master组件是集群的控制平台（control plane）： master 组件负责集群中的全局决策（例如，调度） master 组件探测并响应集群事件（例如，当 Deployment 的实际 Pod 副本数未达到 replicas 字段的规定时，启动一个新的 Pod） Master组件可以运行于集群中的任何机器上。但是，为了简洁性，通常在同一台机器上运行所有的 master 组件，且不在此机器上运行用户的容器。参考 安装Kubernetes高可用。 kube-apiserver 此 master 组件提供 Kubernetes API。这是Kubernetes控制平台的前端（front-end），可以水平扩展（通过部署更多的实例以达到性能要求）。kubectl / kubernetes dashboard / kuboard 等Kubernetes管理工具就是通过 kubernetes API 实现对 Kubernetes 集群的管理。 etcd 支持一致性和高可用的名值对存储组件，Kubernetes集群的所有配置信息都存储在 etcd 中。请确保您 备份 了 etcd 的数据。关于 etcd 的更多信息，可参考 etcd 官方文档 kube-scheduler 此 master 组件监控所有新创建尚未分配到节点上的 Pod，并且自动选择为 Pod 选择一个合适的节点去运行。 影响调度的因素有： 单个或多个 Pod 的资源需求 硬件、软件、策略的限制 亲和与反亲和（affinity and anti-affinity）的约定 数据本地化要求 工作负载间的相互作用 kube-controller-manager 此 master 组件运行了所有的控制器 逻辑上来说，每一个控制器是一个独立的进程，但是为了降低复杂度，这些控制器都被合并运行在一个进程里。 kube-controller-manager 中包含的控制器有： 节点控制器： 负责监听节点停机的事件并作出对应响应 副本控制器： 负责为集群中每一个 副本控制器对象（Replication Controller Object）维护期望的 Pod 副本数 端点（Endpoints）控制器：负责为端点对象（Endpoints Object，连接 Service 和 Pod）赋值 Service Account & Token控制器： 负责为新的名称空间创建 default Service Account 以及 API Access Token cloud-controller-manager cloud-controller-manager 中运行了与具体云基础设施供应商互动的控制器。这是 Kubernetes 1.6 版本中引入的特性，尚处在 alpha 阶段。 cloud-controller-manager 只运行特定于云基础设施供应商的控制器。如果您参考 www.kuboard.cn 上提供的文档安装 Kubernetes 集群，默认不安装 cloud-controller-manager。 cloud-controller-manager 使得云供应商的代码和 Kubernetes 的代码可以各自独立的演化。在此之前的版本中，Kubernetes的核心代码是依赖于云供应商的代码的。在后续的版本中，特定于云供应商的代码将由云供应商自行维护，并在运行Kubernetes时链接到 cloud-controller-manager。 以下控制器中包含与云供应商相关的依赖： 节点控制器：当某一个节点停止响应时，调用云供应商的接口，以检查该节点的虚拟机是否已经被云供应商删除 译者注：私有化部署Kubernetes时，我们不知道节点的操作系统是否删除，所以在移除节点后，要自行通过 kubectl delete node 将节点对象从 Kubernetes 中删除 路由控制器：在云供应商的基础设施中设定网络路由 译者注：私有化部署Kubernetes时，需要自行规划Kubernetes的拓扑结构，并做好路由配置，例如 安装Kubernetes单Master节点 中所作的 服务（Service）控制器：创建、更新、删除云供应商提供的负载均衡器 译者注：私有化部署Kubernetes时，不支持 LoadBalancer 类型的 Service，如需要此特性，需要创建 NodePort 类型的 Service，并自行配置负载均衡器 数据卷（Volume）控制器：创建、绑定、挂载数据卷，并协调云供应商编排数据卷 译者注：私有化部署Kubernetes时，需要自行创建和管理存储资源，并通过Kubernetes的存储类、存储卷、数据卷等与之关联 译者注：通过 cloud-controller-manager，Kubernetes可以更好地与云供应商结合，例如，在阿里云的 Kubernetes 服务里，您可以在云控制台界面上轻松点击鼠标，即可完成 Kubernetes 集群的创建和管理。在私有化部署环境时，您必须自行处理更多的内容。幸运的是，通过合适的教程指引，这些任务的达成并不困难。 Node 组件 Node 组件运行在每一个节点上（包括 master 节点和 worker 节点），负责维护运行中的 Pod 并提供 Kubernetes 运行时环境。 kubelet 此组件是运行在每一个集群节点上的代理程序。它确保 Pod 中的容器处于运行状态。Kubelet 通过多种途径获得 PodSpec 定义，并确保 PodSpec 定义中所描述的容器处于运行和健康的状态。Kubelet不管理不是通过 Kubernetes 创建的容器。 kube-proxy kube-proxy 是一个网络代理程序，运行在集群中的每一个节点上，是实现 Kubernetes Service 概念的重要部分。 kube-proxy 在节点上维护网络规则。这些网络规则使得您可以在集群内、集群外正确地与 Pod 进行网络通信。如果操作系统中存在 packet filtering layer，kube-proxy 将使用这一特性（iptables代理模式），否则，kube-proxy将自行转发网络请求（User space代理模式） 容器引擎 容器引擎负责运行容器。Kubernetes支持多种容器引擎：Docker、containerd、cri-o、rktlet 以及任何实现了 Kubernetes容器引擎接口 的容器引擎 Addons Addons 使用 Kubernetes 资源（DaemonSet、Deployment等）实现集群的功能特性。由于他们提供集群级别的功能特性，addons使用到的Kubernetes资源都放置在 kube-system 名称空间下。 下面描述了一些经常用到的 addons，参考 Addons 查看更多列表。 DNS 除了 DNS Addon 以外，其他的 addon 都不是必须的，所有 Kubernetes 集群都应该有 Cluster DNS Cluster DNS 是一个 DNS 服务器，是对您已有环境中其他 DNS 服务器的一个补充，存放了 Kubernetes Service 的 DNS 记录。 Kubernetes 启动容器时，自动将该 DNS 服务器加入到容器的 DNS 搜索列表中。 如果您参考 www.kuboard.cn 上提供的文档安装 Kubernetes，默认已经安装了 Core DNS Web UI（Dashboard） Dashboard 是一个Kubernetes集群的 Web 管理界面。用户可以通过该界面管理集群。 Kuboard Kuboard 是一款基于Kubernetes的微服务管理界面，相较于 Dashboard，Kuboard 强调： 无需手工编写 YAML 文件 微服务参考架构 上下文相关的监控 场景化的设计 导出配置 导入配置 ContainerResource Monitoring Container Resource Monitoring 将容器的度量指标（metrics）记录在时间序列数据库中，并提供了 UI 界面查看这些数据 Cluster-level Logging Cluster-level logging 机制负责将容器的日志存储到一个统一存储中，并提供搜索浏览的界面 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/k8s/k8s知识点/k8s知识图谱.html":{"url":"linux/k8s/k8s知识点/k8s知识图谱.html","title":"k8s知识图谱","keywords":"","body":"k8s知识图谱 1.部署k8s集群 Ansible kubeadm 二进制 第三方工具(sealos) 2.数据库 etcd：存储k8s对象信息 3.配置管理 configmap secret 4.包管理器 helm 5.微服务 istio 6.存储 volumes PV、PVC storage classse rook基于ceph 分布式存储 glusterFS ceph nfs 7.网络 flannel calico cannel 8.机器学习 kubeflow 9.日志收集 elasticsearch+fluentd+kibana elasticearch+logstash+filebeat+kibana 10.开放接口 CRI（Container Runtime Interface）：容器运行时接口，提供计算资源 CNI（Container Network Interface）：容器网络接口，提供网络资源 CSI（Container Storage Interface）：容器存储接口，提供存储资源 11.容器引擎（docker） 镜像、容器、网络、数据持久化 Dockerfile Supervisor多进程管理 GPU nvidia-docker device-plugin 12.镜像仓库 harbor nexus 13.常用资源对象 Pod namespaces Labels and Selectors Annotations 14.控制器 ReplicaSet Deployment SatefulSet DaemonSet job CronJob HPA Operater 15.DNS CoreDNS KubeDNS 16.服务发现与负载均衡 Ingress nginx Traefik Service 17.安全 Namespace ServiceAccout RBAC 18.监控 cAdvisor+Prometheus+Grafana Metrice-server kube-state-metrics Heapster 19.CI/CD jenkins gitlab git 发布策略 滚动更新 蓝绿发布 灰度发布 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/k8s/k8s知识点/k8s必会知识点梳理.html":{"url":"linux/k8s/k8s知识点/k8s必会知识点梳理.html","title":"k8s必会知识点梳理","keywords":"","body":"k8s必会知识点梳理 本文严重抄袭至互联网 kube-apiserver 对外暴露了Kubernetes API。它是的 Kubernetes 核心控制层。它被设计为水平扩展，即通过部署更多实例来横向扩展。API Server 负责和 etcd 交互（其他组件不会直接操作 etcd，只有 API Server 这么做），是整个 kubernetes 集群的数据中心，所有的交互都是以 API Server 为核心的。API Server 提供了以下的功能： 整个集群管理的 API 接口：所有对集群进行的查询和管理都要通过 API 来进行。 集群内部各个模块之间通信的枢纽：所有模块之间并不会互相调用，而是通过和 API Server 打交道来完成各自的工作。 集群安全控制：API Server 提供的验证和授权保证了整个集群的安全。 kube-controller-manager和kube-scheduler的高可用选主机制 看这里 csdn博客 在k8s的组件中，其中有kube-scheduler和kube-controller-manager两个组件是有leader选举的，这个选举机制是k8s对于这两个组件的高可用保障。需要--leader-elect=true启动参数。即正常情况下kube-scheduler或kube-manager-controller组件的多个副本只有一个是处于业务逻辑运行状态，其它副本则不断的尝试去获取锁，去竞争leader，直到自己成为leader。如果正在运行的leader因某种原因导致当前进程退出，或者锁丢失，则由其它副本去竞争新的leader，获取leader继而执行业务逻辑。 在K8s中， 通过创建资源对象（当前的实现中实现了 ConfigMap 和 Endpoint 两种类型的资源）来维护锁的状态。这两种资源对象存在etcd里，也可以说是用etcd来实现的。 分布式锁一般实现原理就是大家先去抢锁，抢到的成为 leader ，然后 leader 会定期更新锁的状态，声明自己的活动状态，不让其他人把锁抢走。K8s 的资源锁也类似，抢到锁的节点会将自己的标记。设为锁的持有者，其他人则需要通过对比锁的更新时间和持有者来判断自己是否能成为新的 leader ，而 leader 则可以通过更新RenewTime来确保持续保有该锁。 主要调用client-go包中的： k8s.io/client-go/tools/leaderelection 总共有7个leader选举参数： lock-object-namespace和lock-object-name是锁对象的命名空间和名称。 leader-elect表示该组件运行时是否需要leader选举(如果集群中运行多副本，需要设置该选项为true，否则每个副本都将参与实际工作)。 leader-elect-lease-duration为资源锁租约观察时间，如果其它竞争者在该时间间隔过后发现leader没更新获取锁时间，则其它副本可以认为leader已经挂掉不参与工作了，将重新选举leader。 leader-elect-renew-deadline leader在该时间内没有更新则失去leader身份。 leader-elect-retry-period为其它副本获取锁的时间间隔(竞争leader)和leader更新间隔。 leader-elect-resource-lock是k8s分布式资源锁的资源对象，目前只支持endpoints和configmaps。 etcd Etcd使用的是raft一致性算法来实现的，是一款分布式的一致性KV存储，主要用于共享配置和服务发现。用于 Kubernetes 的后端存储。所有集群数据都存储在此处，ETCD在k8s技术栈的地位，就仿佛数据库（Mysql、Postgresql或oracle等）在Web应用中的地位，它存储了k8s集群中所有的元数据（以key-value的方式）。整个kubernetes系统需要用到etcd用来协同和存储配置的有： 网络插件flannel、calico等网络插件也需要用到etcd存储网络的配置信息 kubernetes本身，包括各种对象的状态和元信息配置 注意：flannel操作etcd使用的是v2的API，而kubernetes操作etcd使用的v3的API，所以在下面我们执行etcdctl的时候需要设置ETCDCTL_API环境变量，该变量默认值为2。 K8s中所有元数据的增删改查都是由kube-apiserver来执行的。ETCD中key值通过观察可以简单得出下面几个规律： k8s主要把自己的数据注册在/registry/前缀下面（在ETCD-v3版本后没有了目录的概念，只能一切皆前缀了）。通过观察k8s中deployment、namespace、pod等在ETCD中的表示，可以知道这部分资源的key的格式为/registry/{k8s对象}/{命名空间}/{具体实例名}。 kube-controller-manager kube-controller-manager运行控制器，它们是处理集群中常规任务的后台线程。逻辑上，每个控制器是一个单独的协程。用于监视 apiserver 暴露的集群状态，并且不断地尝试把当前状态向集群的目标状态迁移。为了避免频繁查询 apiserver，apiserver 提供了 watch 接口用于监视资源的增加删除和更新，client-go 对此作了抽象，封装一层 informer 来表示本地 apiserver 状态的 cache 。 参考: 看这里 这些控制器包括: 节点控制器（node-controller）: kubelet在启动时会通过API Server注册自身的节点信息，并定时向API Server汇报状态信息，API Server接收到信息后将信息更新到etcd中。Node Controller通过API Server实时获取Node的相关信息，实现管理和监控集群中的各个Node节点的相关控制功能。 副本控制器（Replication Controller）: 负责维护系统中每个副本控制器对象正确数量的 Pod。副本控制器的作用即保证集群中一个RC所关联的Pod副本数始终保持预设值。只有当Pod的重启策略是Always的时候（RestartPolicy=Always），副本控制器才会管理该Pod的操作（创建、销毁、重启等）。 服务帐户和令牌控制器（ServiceAccount Controller ）: 为新的命名空间创建默认帐户和 API 访问令牌。 资源配额管理控制器ResourceQuota Controller：资源配额管理确保指定的资源对象在任何时候都不会超量占用系统物理资源。支持三个层次的资源配置管理： 容器级别：对CPU和Memory进行限制; Pod级别：对一个Pod内所有容器的可用资源进行限制; Namespace级别：包括Pod数量、Replication Controller数量、Service数量、ResourceQuota数量、Secret数量、可持有的PV（Persistent Volume）数量 Namespace Controller：用户通过API Server可以创建新的Namespace并保存在etcd中，NamespaceController定时通过API Server读取这些Namespace信息。如果Namespace被API标记为优雅删除（即设置删除期限，DeletionTimestamp）,则将该Namespace状态设置为“Terminating”,并保存到etcd中。同时Namespace Controller删除该Namespace下的ServiceAccount、RC、Pod等资源对象。 Service Controller：属于kubernetes集群与外部的云平台之间的一个接口控制器。Service Controller监听Service变化，如果是一个LoadBalancer类型的Service，则确保外部的云平台上对该Service对应的LoadBalancer实例被相应地创建、删除及更新路由转发表。 deployment controller：用来替代以前的ReplicationController来方便的管理应用。只需要在 Deployment 中描述您想要的目标状态是什么，Deployment controller 就会帮您将 Pod 和ReplicaSet 的实际状态改变到您的目标状态。您可以定义一个全新的 Deployment 来创建 ReplicaSet 或者删除已有的 Deployment 并创建一个新的来替换。 定义Deployment来创建Pod和ReplicaSet 滚动升级和回滚应用 扩容和缩容 暂停和运行Deployment statefulset controller：StatefulSet是为了解决有状态服务的问题（对应Deployments和ReplicaSets是为无状态服务而设计），其应用场景包括： 稳定的持久化存储，即Pod重新调度后还是能访问到相同的持久化数据，基于PVC来实现; 稳定的网络标志，即Pod重新调度后其PodName和HostName不变，基于Headless Service（即没有Cluster IP的Service）来实现。StatefulSet中每个Pod的DNS格式为： statefulSetPodName-{0..N-1}.serviceName.namespace.svc.cluster.local 有序部署，有序扩展，即Pod是有顺序的，在部署或者扩展的时候要依据定义的顺序依次依次进行（即从0到N-1，在下一个Pod运行之前所有之前的Pod必须都是Running和Ready状态），基于init containers来实现； 有序收缩，有序删除（即从N-1到0） daemonset controller：DaemonSet确保全部（或者一些）Node 上运行一个 Pod 的副本。当有 Node 加入集群时，也会为他们新增一个 Pod 。当有 Node 从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod。 Horizontal Pod Autoscaling：仅适用于Deployment和ReplicaSet，在V1版本中仅支持根据Pod的CPU利用率扩所容，在v1alpha版本中，支持根据内存和用户自定义的metric扩缩容。 persistentvolume-binder: 定期同步磁盘卷挂载信息，负责pv和pvc的绑定。 Endpoints controller：表示了一个Service对应的所有Pod副本的访问地址，而EndpointsController负责生成和维护所有Endpoints对象的控制器。它负责监听Service和对应的Pod副本的变化。 如果监测到Service被删除，则删除和该Service同名的Endpoints对象； 如果监测到新的Service被创建或修改，则根据该Service信息获得相关的Pod列表，然后创建或更新Service对应的Endpoints对象; 如果监测到Pod的事件，则更新它对应的Service的Endpoints对象。 kube-proxy进程获取每个Service的Endpoints，实现Service的负载均衡功能。 以上只是部分控制器，都是一个独立的协程，被controller-manager这个进程所管理。 Statefulset和Deployment的区别 Deployment用于部署无状态服务，StatefulSet用来部署有状态服务。 如果部署的应用满足以下一个或多个部署需求，则建议使用StatefulSet。 稳定的、唯一的网络标识; 稳定的、持久的存储; 有序的、优雅的部署和伸缩; 有序的、优雅的删除和停止; 有序的、自动的滚动更新; 实现固定的Pod IP方案, 可以优先考虑基于StatefulSet 稳定的：主要是针对Pod发生re-schedule后仍然要保持之前的网络标识和持久化存储。这里所说的网络标识包括hostname、集群内DNS中该Pod对应的A Record，并不能保证Pod re-schedule之后IP不变。要想保持Pod IP不变，我们可以借助稳定的Pod hostname定制IPAM获取固定的Pod IP。借助StatefulSet的稳定的唯一的网络标识特性，我们能比较轻松的实现Pod的固定IP需求，然后如果使用Deployment，那么将会复杂的多，你需要考虑滚动更新的过程中的参数控制(maxSurge、maxUnavailable)、每个应用的IP池预留造成的IP浪费等等问题。 存储：StatefulSet对应Pod的存储最好通过StorageClass来动态创建：每个Pod都会根据StatefulSet中定义的VolumeClaimTemplate来创建一个对应的PVC，然后PVS通过StorageClass自动创建对应的PV，并挂载给Pod。所以这种方式，需要事先创建好对应的StorageClass。当然，你也可以通过预先由管理员手动创建好对应的PV，只要能保证自动创建的PVC能和这些PV匹配上。 为了数据安全，当删除StatefulSet中Pods或者对StatefulSet进行缩容时，Kubernetes并不会自动删除StatefulSet对应的PV，而且这些PV默认也不能被其他PVC Bound。当你确认数据无用之后再手动去删除PV的时候，数据是否删除取决于PV的ReclaimPolicy配置。Reclaim Policy支持以下三种： Retain，意味着需要你手动清理； Recycle，等同于rm -rf /thevolume/* Delete，默认值，依赖于后端的存储系统自己实现。 部署和伸缩时与Deployment的区别 当部署有N个副本的StatefulSet应用时，严格按照index从0到N-1的递增顺序创建，下一个Pod创建必须是前一个Pod Ready为前提。 当删除有N个副本的StatefulSet应用时，严格按照index从N-1到0的递减顺序删除，下一个Pod删除必须是前一个Pod shutdown并完全删除为前提。 当扩容StatefulSet应用时，每新增一个Pod必须是前一个Pod Ready为前提。 当缩容StatefulSet应用时，没删除一个Pod必须是前一个Pod shutdown并成功删除为前提。 kube-scheduler kube-scheduler监视没有分配节点的新创建的 Pod，选择一个节点供他们运行。调度节点分配主要可以分为预选（Predicates）与优选（Priorities）两个环节： 预选 根据配置的PredicatesPolicies（默认为DefaultProvider中定义的default predicates policies集合）过滤掉那些不满足这些Policies 的 Node，预选的输出作为优选的输入； 优选 根据配置的PrioritiesPolicies（默认为DefaultProvider中定义的default priorities policies集合）给预选后的 Node 进行打分排名，得分最高的 Node 即作为最适合的 Node ，该 Pod 就绑定（Bind）到这个 Node 。 注：如果经过优选将 Node 打分排名后，有多个 Node 并列得分最高，那么kube-scheduler将随机从中选择一个 Node 作为目标 Node 。 预选阶段算法 NoDiskConflict: 评估是否存在volume冲突。如果该 volume 已经 mount 过了，k8s可能会不允许重复mount(取决于volume类型)； NoVolumeZoneConflict: 评估该节点上是否存在 Pod 请求的 volume； PodFitsResources: 检查节点剩余资源(CPU、内存)是否能满足 Pod 的需求。剩余资源=总容量-所有 Pod 请求的资源； MatchNodeSelector: 判断是否满足 Pod 设置的 NodeSelector； CheckNodeMemoryPressure: 检查 Pod 是否可以调度到存在内存压力的节点； CheckNodeDiskPressure: 检查 Pod 是否可以调度到存在硬盘压力的节点； 优选阶段算法 依次计算该 Pod 运行在每一个 Node 上的得分。主要算法有： LeastRequestedPriority：最低请求优先级，即 Node 使用率越低，得分越高； BalancedResourceAllocation：资源平衡分配，即CPU/内存配比合适的 Node 得分更高； SelectorSpreadPriority: 尽量将同一 RC/Replica 的多个 Pod 分配到不同的 Node 上； CalculateAntiAffinityPriority: 尽量将同一 Service 下的多个相同 Label 的 Pod 分配到不同的 Node； ImageLocalityPriority: Image本地优先，Node 上如果已经存在 Pod 需要的镜像，并且镜像越大，得分越高，从而减少 Pod 拉取镜像的开销(时间)； NodeAffinityPriority: 根据亲和性标签进行选择； 默认的预选、优选调度算法远不止以上这些。可以通过kube-scheduler的启动参数中加policy-config-file文件、configmaps（过时）、或者--config指定调度器用哪些预选、优选算法。 调度算法的扩展 如果kube-scheduler提供的调度算法不满足调度要求，也可以自己开发扩展调度器，在kube-scheduler启动参数的policy-config中指定扩展调度器的地址，包括（预选接口、优选接口、优先级抢占，pod和node绑定的Bind接口）。 扩展调度器示例代码： 看这里 由于默认调度器kube-scheduler需要调用扩展调度程序kube-scheduler-extender，故需要在kube-scheduler的启动参数里配置扩展调度器的地址。需要在master节点主机的/etc/kubernetes目录下的scheduler.yaml中配置如下内容：（static pod方式部署的kube-scheduler不能用configmaps的方式挂载配置文件） apiVersion: kubescheduler.config.k8s.io/v1alpha1 kind: KubeSchedulerConfiguration algorithmSource: policy: file: path: /etc/kubernetes/scheduler-policy.json clientConnection: kubeconfig: /etc/kubernetes/scheduler.conf leaderElection: leaderElect: true 主要配置是否启用选举机制，以及与API Server交互时认证用的scheduler.conf文件地址，调度策略选择用的scheduler-policy.json： { \"kind\":\"Policy\", \"apiVersion\":\"v1\", \"predicates\":[ { \"name\":\"NoVolumeZoneConflict\" }, { \"name\":\"MatchInterPodAffinity\" }, { \"name\":\"NoDiskConflict\" }, { \"name\":\"GeneralPredicates\" }, { \"name\":\"PodToleratesNodeTaints\" }, { \"name\":\"CheckVolumeBinding\" } ], \"priorities\":[ { \"name\":\"SelectorSpreadPriority\", \"weight\":1 }, { \"name\":\"InterPodAffinityPriority\", \"weight\":1 }, { \"name\":\"LeastRequestedPriority\", \"weight\":1 }, { \"name\":\"NodeAffinityPriority\", \"weight\":1 }, { \"name\":\"BalancedResourceAllocation\", \"weight\":1 }, { \"name\":\"NodePreferAvoidPodsPriority\", \"weight\":10000 }, { \"name\":\"TaintTolerationPriority\", \"weight\":1 } ], \"extenders\":[ { \"urlPrefix\":\"http://kube-scheduler-extender:80/scheduler\", \"filterVerb\":\"predicates/middleware_predicate\", \"prioritizeVerb\":\"\", \"preemptVerb\":\"\", \"bindVerb\":\"bind\", \"weight\":1, \"enableHttps\":false, \"nodeCacheCapable\":false } ], \"hardPodAffinitySymmetricWeight\":10, \"alwaysCheckAllPredicates\":false } 里面指定了默认调度器用到的预选、优选算法，以及调用扩展调度器的service地址，预选和Bind接口URI。 在/etc/kubernetes/manifests目录下的kube-scheduler.yaml中启动参数中加--config=/etc/kubernetes/scheduler.yaml，该文件通过hostPath的方式挂载到容器内。 DNS kube-dns这个插件是官方推荐安装的。通过将 Service 注册到 DNS 中，k8s 可以为我们提供一种简单的服务注册发现与负载均衡方式。 kube-dns内部通过监听services和endpoints的变更事件将域名和IP对应信息同步到本地缓存。比如服务 a 访问服务 b，dns解析依赖a容器内 /etc/resolv.conf 文件的配置 cat/etc/resolv.conf nameserver 10.233.0.3search default.svc.cluster.local svc.cluster.localcluster.local 这个文件中，配置的 DNS Server，一般就是 K8S 中，kubedns 的 Service 的 ClusterIP，这个IP是虚拟IP，无法ping。 [root@node4 user1]#kubectl get svc -n kube-systemNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkube-dns ClusterIP 10.233.0.3 53/UDP,53/TCP 270dkubernetes-dashboard ClusterIP 10.233.22.223 443/TCP 124d 所有域名的解析，其实都要经过 kubedns 的虚拟IP 10.233.0.3 ，负载到某一个kube-dns pod上去解析。如果不能解析，则会去kube-dns pod所在的主机上的dns服务（/etc/resolv.conf）做解析。Kubernetes 启动的容器自动将 DNS 服务器包含在容器内的/etc/resolv.conf 中。 域名格式如下： statefulset一般使用Headless Service，如statefulset名为test，创建2个pod，则域名为test-0.test.kube-system.svc.cluster.local和test-1.test.kube-system.svc.cluster.local 节点组件 节点组件在每个节点上运行，维护运行的 Pod 并提供Kubernetes 运行时环境。kubelet一般作为二进制运行到每个k8s节点；kube-proxy作为daemonset pod运行到每个k8s节点。 kubelet 在kubernetes集群中，每个Node节点都会启动kubelet进程，用来处理Master节点下发到本节点的任务，管理Pod和其中的容器。kubelet会在API Server上注册节点信息，定期向Master汇报节点资源使用情况，并通过cAdvisor监控容器和节点资源。 节点管理 节点通过设置kubelet的启动参数--register-node来决定是否向API Server注册自己，默认为true，可以通过kubelet --help或者查看k8s源码(直接放弃) kubelet的配置文件 默认配置文件在/etc/kubernetes/kubelet中，其中 --api-servers: 用来配置master节点的IP和端口 --kukeconfig:用来配置kubeconfig的路径，kubeconfig文件常用来指定证书 --hostname-override：用来配置该节点在集群中显示的主机名 --node-status-update-frequency：配置kubeler向master心跳上报的频率，默认为10s pod管理 kubelet有几种方式获取自身node上所需运行的pod清单，但本文只讨论通过API Server监听etcd目录，同步pod列表的方式 kubelet通过API Server Client使用WatchAndList方式监听etcd中/registry/nodes/$(当前节点名称)和/registry/pods的目录，将获取的信息同步到本地缓存中 kubelet监听etcd，执行对pod的操作，对容器的操作则是通过docker client执行，例如自动删除容器等 kubelet创建和修改pod流程 1.为该pod创建一个数据目录 2.从API Server读取该pod清单 3.为该pod挂载外部卷 4.下载pod到用到的secret 5.检查运行的pod，执行pod中未完成的任务 6.先创建一个pause容器，该容器接管pod的网络，再创建其他容器 7.pod中容器的处理流程 ​ 7.1比较容器hash值并做相应处理 ​ 7.2如果容器被终止了且没有指定重启策略，则不做任何处理 ​ 7.3调用docker client下载容器镜像，调用docker clienr运行容器 pod被调度到kubelet所在节点时，调用CNI（Docker 运行或通过 rkt)运行 Pod 的容器; 周期性的对容器生命周期进行探测。（健康检查readness-隔离、liveness-重启）; 检查节点状态，将节点的状态报告给kube-apiserver; 容器监控所在节点的资源使用情况，并定时向 kube-apiserver报告。知道整个集群所有节点的资源情况，对于 pod 的调度和正常运行至关重要。kubelet 使用cAdvisor进行资源使用率的监控。 kube-proxy 看这里 service是一组pod的服务抽象，相当于一组pod的负载均衡器，负责将请求分发给对应的pod。service会提供一个clusterIP。kube-proxy的作用主要是负责service的实现，具体来说，就是实现了内部请求到service和外部的从node port向service的访问，转发到后端某个pod。 举个例子，现在有podA，podB，podC和serviceAB。serviceAB是podA，podB的服务抽象(service)。那么kube-proxy的作用就是可以将某一个发往（如podC发起的请求）向serviceAB的请求，进行转发到service所代表的一个具体pod(podA或者podB)上。请求的分配方法一般分配是采用轮询方法进行分配。 kube-proxy提供了三种负载均衡器（LB）模式: 一种是基于用户态的模式userspace, 一种是iptables模式，一种是ipvs模式。 userspace：是以socket的方式实现代理的，userspace这种模式最大的问题是，service的请求会先从用户空间进入内核iptables，然后再回到用户空间，由kube-proxy完成后端Endpoints的选择和代理工作，这样流量从用户空间进出内核带来的性能损耗是不可接受的； iptables mode：因为使用iptable NAT来完成转发，也存在不可忽视的性能损耗。另外，如果集群中存在上万的Service/Endpoint，那么Node上的iptables rules将会非常庞大，性能还会再打折扣； IPVS 模式：工作原理其实跟 iptables 模式类似，当我们创建了前面的Service 之后，kube-proxy首先会在宿主机上创建一个虚拟网卡（kube-ipvs0）并为他分配service VIP作为IP地址，kube-proxy会通过linux的IPVS模块为这个IP设置三个虚拟主机（后端的三个POD IP），使用轮询作为LB策略（ipvsadm命令查看），IPVS模块会负责请求的转发。 以下截图来自于极客时间张磊的课程描述： iptables模式和ipvs模式的对比 服务暴露方式 看这里 NodePort NodePort服务是引导外部流量到你的服务的最原始方式。可以通过访问集群内的每个NodeIP:NodePort的方式，访问到对应Service后端的Endpoint。在所有节点（虚拟机）上开放一个特定端口，任何发送到该端口的流量都被转发到对应服务。 NodePort 服务的 YAML 文件类似如下： apiVersion: v1 kind: Service metadata: name: my-nodeport-service selector: app: my-app spec: type: NodePort ports: - name: http port: 80 targetPort: 80 nodePort: 30036 protocol: TCP NodePort 服务主要有两点区别于普通的“ClusterIP”服务。第一，它的类型是“NodePort”。有一个额外的端口，称为 nodePort，它指定节点上开放的端口值。如果你不指定这个端口，系统将选择一个随机端口。 何时使用这种方式？ 这种方法有许多缺点： 每个端口只能是一种服务 端口范围只能是 30000-32767 如果节点/VM 的 IP 地址发生变化，你需要能处理这种情况。 基于以上原因，我不建议在生产环境上用这种方式暴露服务。如果你运行的服务不要求一直可用，或者对成本比较敏感，你可以使用这种方法。这样的应用的最佳例子是 demo 应用，或者某些临时应用。 hostNetwork 这种方式在创建pod时的yaml中spec.hostNetwork: true指定走主机网络，这种方式pod使用的端口必须是宿主机上没有被占用的端口。外部可以直接通过pod所在宿主机IP:Pod端口访问。 LoadBalancer 这也是用来对集群外暴露服务的，不同的是这需要云服务商的支持，比如亚马逊等。这个方式的最大缺点是每一个用 LoadBalancer 暴露的服务都会有它自己的 IP 地址，每个用到的 LoadBalancer 都需要付费，这是非常昂贵的。 Ingress ingress配置一种路由转发规则，ingress controller会根据ingress中的规则，生成路由转发配置。如nginx-ingress-controller，控制循环会检测ingress对象的添加，通过其规则和service、pod信息生成nginx的配置，通过nginx实现对外服务和负载均衡。 pod创建流程 1、客户端提交创建请求，通过API Server的Restful API，或者用kubectl命令行工具。支持的数据类型包括JSON和YAML。 2、API Server处理用户请求，存储Pod数据到etcd。 3、kube-scheduler通过API Server查看未绑定的Pod。尝试为Pod分配主机。 4、kube-scheduler通过预选算法过滤掉不符合要求的主机。比如Pod指定了所需要的资源量，那么可用资源比Pod需要的资源量少的主机会被过滤掉，端口被占用的也被过滤掉； 5、kube-scheduler通过优选算法给主机打分，对预选筛选出的符合要求的主机进行打分，在主机打分阶段，调度器会考虑一些整体优化策略，比如把一个deployment类型的pod分布到不同的主机上，使得资源均衡；或者将两个亲和的服务分配到同一个主机上。 6、选择主机：选择打分最高的主机，进行binding（调用apiserver将pod和node绑定）操作，结果存储到etcd中。 7、kubelet监听Api Server，根据调度结果执行Pod创建操作：绑定成功后，scheduler会调用API Server的API在etcd中创建一个bound pod对象，描述在一个工作节点上绑定运行的所有pod信息。运行在每个工作节点上的kubelet也会定期与etcd同步bound pod信息，一旦发现应该在该工作节点上运行的bound pod对象没有更新，则调用Docker API创建并启动pod内的容器。 8、kubelet调用CNI（Docker 运行或通过 rkt)运行 Pod 的容器。并周期性的对容器生命周期进行探测。（健康检查readness-隔离、liveness-重启） 各组件基本都是通过API Server提供的list-watch API进行监听资源对象变化，进行自己的控制循环，这些核心功能都被封装到了client-go包中。我们可以根据自己的需求，通过CRD编写controller、operator进行自己的控制循环逻辑、运维自动化部署，很轻松的扩展k8s能力。 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/k8s/k8s知识点/k8s知识点.html":{"url":"linux/k8s/k8s知识点/k8s知识点.html","title":"k8s知识点","keywords":"","body":"k8s知识点 k8s命令自动补全 yum install -y bash-completion source /usr/share/bash-completion/bash_completion source > ~/.bashrc 一、k8s特性 服务发现和负载均衡 Kubernetes 可以使用 DNS 名称或自己的 IP 地址公开容器，如果到容器的流量很大，Kubernetes 可以负载均衡并分配网络流量，从而使部署稳定。 存储编排 Kubernetes 允许您自动挂载您选择的存储系统，例如本地存储、公共云提供商等。 自动部署和回滚 您可以使用 Kubernetes 描述已部署容器的所需状态，它可以以受控的速率将实际状态更改为所需状态。例如，您可以自动化 Kubernetes 来为您的部署创建新容器，删除现有容器并将它们的所有资源用于新容器。 自动二进制打包 Kubernetes 允许您指定每个容器所需 CPU 和内存（RAM）。当容器指定了资源请求时，Kubernetes 可以做出更好的决策来管理容器的资源。 自我修复 Kubernetes 重新启动失败的容器、替换容器、杀死不响应用户定义的运行状况检查的容器，并且在准备好服务之前不将其通告给客户端。 密钥与配置管理 Kubernetes 允许您存储和管理敏感信息，例如密码、OAuth 令牌和 ssh 密钥。您可以在不重建容器镜像的情况下部署和更新密钥和应用程序配置，也无需在堆栈配置中暴露密钥。 二、k8s概念和术语 2.1 k8s角色 2.1.1 master k8s使用共享网路将多个物理机或者虚拟机汇集到一个集群中，在各服务器之间进行通信，该集群是是配置k8s的所有组件、功能和工作负载的物理平台 集群中的一台机器(或者高可用部署中的一组服务器)用作master，负责管理整个集群 2.1.2 node 集群中除master节点外的其余机器用作node，他们是使用本地和外部资源接收和运行工作负载的服务器 集群中的这些机器可以是物理服务器，也可以是虚拟机 2.2 k8s资源 2.2.1 pod k8s并不直接运行容器，而是使用一个抽象的资源对象来封装一个或者多个容器，这个抽象即为pod，pod是k8s的最小调度单元 同一pod中的容器共享网络名称空间和存储资源，这些容器可经由本地回环接口lo直接通信，但彼此之间又在mount、user及PID等名称空间上保持隔离 pod示意图 2.2.2 label 资源标签 标签是将资源进行分类的标识符，资源标签其实就是一个健值型数据 标签是用于指定对象(如pod)辨识性的属性，这些属性仅对用户存在特定的意义，对k8s集群来说并不直接表达核心系统语义 标签可以在对象创建时附加其上，并能够在创建后的任意时间进行添加和修改 一个对象可以拥有多个标签，一个标签也可以附加于多个对象之上 2.2.3 selector 标签选择器 标签选择器全称为label selector，是一种根据lable来过滤符合条件的资源对象的机制，例如将附有标签role:backend的所有pod对象挑选出来归为一组就是标签选择器的一种应用 2.2.4 controller pod控制器 尽管pod是k8s中的最小调度单元，但用户通常并不会直接部署及管理pod对象，而是要借助于控制器对其进行管理 用于工作负载的控制器是一种管理pod生命周期的资源抽象，是k8s上的一类对象而非单个资源对象 使用控制器之后就不再需要手动管理pod对象了，用户只需要声明应用的期望状态，控制器就会自动对其进行进程管理 pod控制器包括ReplicationController、ReplicaSet、Deployment、Statefulset、Job等 2.2.5 service 服务资源 service是建立在一组pod对象之上的资源抽象，它通过标签选择器选择一组pod对象，并为这组pod对象定义一个统一的固定访问入口(通常是一个IP地址)，若k8s集群存在DNS附件，它就会在service创建时为其自动配置一个DNS名称以便客户端进行服务发现 到达service IP的请求将负载均衡至其后的端点-->各个pod对象之上，因此service从本质上来讲是一个四层代理服务 service还可以将集群外部流量引入到集群中来 2.2.6 volume 存储卷 存储卷是独立于容器文件系统之外的存储空间，常用于扩展容器的存储空间并为它提供持久存储能力 k8s集群上的存储卷大体可分为临时卷、本地卷和网路卷 临时卷和本地卷都位于node本地，一旦pod被调度至其他node，此种类型的存储卷将无法访问，因此临时卷和本地卷通常用于数据缓存，持久化的数据则需要放置于持久卷(persistent volume)之上 2.2.7 name(名称)和namespace(名称空间) 名称是k8s集群中资源对象的标识符，它们的作用域通常是名称空间(namespace)，因此名称空间是名称的额外限定机制 在同一个名称空间中，同一类型资源对象的名称必须具有唯一性，名称空间通常用于实现项目的资源隔离，从而形成逻辑分组 创建的pod和service等资源对象都属于名称空间级别，未指定时，它们都属于默认的名称空间default 2.2.8 annotaion 注解 注解时另一种附加在对象之上的键值型的数据，但它拥有更大的数据容量 注解常用于将各种非标识型元数据(metadata)附加到对象上，但它不能用于标识和选择对象，通常也不会被k8s直接使用，其主要目的是方便工具或用户的阅读及查找 2.2.9 ingress k8s将pod对象和外部网路环境进行了隔离，pod和service等对象间的通信都使用其内部专用地址进行，如若需要开放某些pod对象提供给外部用户访问，则需要为其请求流量打开一个通往k8s集群内部的通道，除了service之外，ingress也是这类通道的实现方式之一 三、k8s架构 3.1k8s架构图 3.2 master、node组件 master节点 负责集群管理，接受用户请求，将请求分散到node节点 scheduler 调度器，负责资源的调度，按照预定的调度策略将pod调度到相应的机器上 apiserver 整个架构的核心，协调者的角色，所有组件都要与apiserver通信，提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现等机制 controller manager 控制器，负责维护集群的状态，比如故障检测，自动扩展，滚动更新等 etcd(独立组件，不属于k8s集群) key value分布式存储，存储k8s的数据，主要是master节点的apiserver连接etcd node节点 计算节点，接受master指令，运行任务 kubelet master的agent，负责接收master的任务并完成任务，负责维护容器等生命周期，同时也负责volume和网络的管理 kube-proxy 负责为service提供集群内部的服务发现和负载均衡 容器运行时环境 k8s不具备容器引擎，不能直接运行容器，需要借助第三方容器引擎来运行和管理容器，例如docker 3.3 核心附件 3.3.1 coreDNS 在k8s集群中调度运行提供DNS服务的pod，同一集群中的其他pod可使用此DNS服务解决主机名，k8s1.11版本开始默认使用coreDNS项目为集群提供服务注册和服务发现的动态名称解析服务，之前的版本中用到的是kubeDNS，而skyDNS则是更早版本使用的 3.3.2 dashboard k8s集群的全部功能都要基于web的UI，来管理集群中的应用和集群自身 3.3.3 heapster 容器和节点的性能监控与分析系统，它收集并解析多种指标数据，如资源利用率、生命周期等 由于监控项比较少，已由prometheus代替 3.3.4 ingress controller 为服务提供外网入口，7层负载均衡，默认kube-process只能提供4层负载均衡 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/k8s/k8s知识点/kubeadm 专题 一 init 究竟干了些什么.html":{"url":"linux/k8s/k8s知识点/kubeadm 专题 一 init 究竟干了些什么.html","title":"kubeadm init流程","keywords":"","body":"kubeadm 专题 一 init 究竟干了些什么 本文严重抄袭至互联网 kubeadm 所在层次 kubeadm 属于第二层，用于管理集群。 kubeadm init 的流程（phase）介绍 phase 阶段 preflight 预置检查 kubelet-start 生成 kubelet 配置，并重启kubelet certs 生成认证 /etcd-ca 生成自签名CA以为etcd配置标识 /apiserver-etcd-client 生成apiserver用于访问etcd的证书 /etcd-healthcheck-client 生成liveness探针使用的证书，用于检查etcd 的 healtcheck 状态 /etcd-server 生成 etcd 服务使用的的证书 /etcd-peer 为etcd节点生成证书以相互通信 /ca 生成自签名的 Kubernetes CA，为其他 Kubernetes 组件预配标识 /apiserver 生成用于提供 Kubernetes API 的证书 api server端证书 /apiserver-kubelet-client 为 API 服务器生成证书以连接到 kubelet /front-proxy-ca 生成自签名 CA 以预配front proxy 标识 /front-proxy-client 为前端代理客户端生成证书 /sa 生成用于对服务帐户令牌及其公钥进行签名的私钥 kubeconfig 生成 control plane 和 admin 管理员相关的kubeconfig 文件 /admin 生成admin 管理员和kubeadm 自身使用的kubeconfig文件 /kubelet 生成kebelet使用的，仅用于引导集群（bootstrap）的kubeconfig 文件 /controller-manager 生成 controller manager 使用的kubeconfig文件 /scheduler 生成 scheduler 使用的kubeconfig文件 kubelet-start 生成kubelet的环境变量文件/var/lib/kubelet/kubeadm-flags.env 和 配置信息文件 /var/lib/kubelet/config.yaml，然后 启动/重启 kubelet（systemd 模式） control-plane 生成拉起 control plane（master）static Pod 的 manifest 文件 /apiserver 生成拉起 kube-apiserver 的 static Pod manifest /controller-manager 生成拉起 kube-controller-manager 的static Pod manifest /scheduler 生成拉起 kube-scheduler 的 static Pod manifest etcd 生成本地 ETCD的 static Pod manifest 文件 /local 生成单节点本地 ETCD static Pod manifest 文件 upload-config 上传kubeadm和kubelet配置为 ConfigMap /kubeadm 上传 kubeadm ClusterConfiguration 为 ConfigMap /kubelet 上传 kubelet component config 为 ConfigMap upload-certs 上传证书到 kubeadm-certs mark-control-plane 标识节点为 control-plane bootstrap-token 生成 bootstrap tokens 用于其他节点加入集群 addon 安装所需的插件以通过一致性测试 /coredns 安装 CoreDNS 插件 /kube-proxy 安装 kube-proxy 插件 kubeadm 命令行参数 命令用法 kubeadm init [flags] 参数说明 --apiserver-advertise-address string 设置 apiserver 绑定的 IP. --apiserver-bind-port int32 设置apiserver 监听的端口. (默认 6443) --apiserver-cert-extra-sans strings api证书中指定额外的Subject Alternative Names (SANs) 可以是IP 也可以是DNS名称。 证书是和SAN绑定的。 --cert-dir string 证书存放的目录 (默认 \"/etc/kubernetes/pki\") --certificate-key string kubeadm-cert secret 中 用于加密 control-plane 证书的key --config string kubeadm 配置文件的路径. --cri-socket string CRI socket 文件路径，如果为空 kubeadm 将自动发现相关的socket文件; 只有当机器中存在多个 CRI socket 或者 存在非标准 CRI socket 时才指定. --dry-run 测试，并不真正执行;输出运行后的结果. --feature-gates string 指定启用哪些额外的feature 使用 key=value 对的形式。 --help 帮助文档 --ignore-preflight-errors strings 忽略前置检查错误，被忽略的错误将被显示为警告. 例子: 'IsPrivilegedUser,Swap'. Value 'all' ignores errors from all checks. --image-repository string 选择拉取 control plane images 的镜像repo (default \"k8s.gcr.io\") --kubernetes-version string 选择K8S版本. (default \"stable-1\") --node-name string 指定node的名称，默认使用 node 的 hostname. --pod-network-cidr string 指定 pod 的网络， control plane 会自动将 网络发布到其他节点的node，让其上启动的容器使用此网络 --service-cidr string 指定service 的IP 范围. (default \"10.96.0.0/12\") --service-dns-domain string 指定 service 的 dns 后缀, e.g. \"myorg.internal\". (default \"cluster.local\") --skip-certificate-key-print 不打印 control-plane 用于加密证书的key. --skip-phases strings 跳过指定的阶段（phase） --skip-token-print 不打印 kubeadm init 生成的 default bootstrap token --token string 指定 node 和control plane 之间，简历双向认证的token ，格式为 [a-z0-9]{6}\\.[a-z0-9]{16} - e.g. abcdef.0123456789abcdef --token-ttl duration token 自动删除的时间间隔。 (e.g. 1s, 2m, 3h). 如果设置为 '0', token 永不过期 (default 24h0m0s) --upload-certs 上传 control-plane 证书到 kubeadm-certs Secret. init 工作流 kubeadm init通过执行以下步骤来引导Kubernetes控制平面节点： 1.在进行更改之前运行一系列飞行前检查以验证系统状态。某些检查仅触发警告，其他检查被视为错误，并将退出kubeadm，直到问题得到纠正或用户指定--ignore-preflight-errors = 。 来忽略错误。 2.生成自签名 CA（或使用现有CA），以便为群集中的每个组件设置标识。如果用户通过将其放在通过--cert-dir配置的cert目录（默认情况下为/etc/kubernetes/pki）中提供了自己的CA证书和/或密钥，则会跳过此步骤，如使用自定义证书文档中所述。 APIServer证书将--apiserver-cert-extra-sans参数提供的额外SAN条目添加到证书信息中，如果需要，可以小写。 3.在/etc/kubernetes/中为 kubelet， controller-manager和scheduler 写入kubeconfig文件，用于连接到API服务器，每个都有自己的标识，以及另一个名为admin.conf的管理员kubeconfig文件。 4.生成启动 kubelet 服务所需的配置文件和环境变量，并启动kubelet （systemd 方式）生成文件如下 /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf 环境变量 /etc/kubernetes/bootstrap-kubelet.conf/ /etc/kubernetes/kubelet.conf /var/lib/kubelet/config.yaml /var/lib/kubelet/kubeadm-flags.env 环境变量 kubelet 使用4个文件的方式如下 [root@rancher ~]# systemctl status kubelet ● kubelet.service - kubelet: The Kubernetes Node Agent Loaded: loaded (/usr/lib/systemd/system/kubelet.service; disabled; vendor preset: disabled) Drop-In: /usr/lib/systemd/system/kubelet.service.d └─10-kubeadm.conf Active: active (running) since Sun 2019-08-18 14:16:37 CST; 13min ago Docs: https://kubernetes.io/docs/ Main PID: 14980 (kubelet) CGroup: /system.slice/kubelet.service └─14980 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=/var/lib/kubelet/config.yaml 1.为apiserver，control-manager 和scheduler 生成静态Pod清单。 如果未提供外部etcd，则会为etcd生成其他静态Pod清单。 Static Pod清单写入/etc/kubernetes/manifests; kubelet监视此目录以便Pods在启动时创建。 control plane 的pod 启动后，init 开始继续执行后面的流程。 2.将标签和污点应用于控制平面节点，以便不会在那里运行其他工作负载。 3.生成其他节点将来可用于向控件平面注册自己的令牌。或者，用户可以通过--token 参数来指定一个令牌。,具体在 kubeadm token 文档中. 4.进行所有必要的配置，以允许其他节点通过引导令牌 bootstrap token 和 TLS boostrap 机制进行加入 写入加入集群的所需的信息到configmap， 设置相关的RBAC 规则。 让bootstrap token 访问 CSR（证书签名请求） 签名 API Configure auto-approval for new CSR requests. 对CSR 请求（证书签名请求）配置自动同意。 通过 API server 安装 DNS 服务器 （CoreDNS） 和 kube-proxy 组件。在 Kubernetes 版本 1.11 和更高版本中，CoreDNS 是默认 DNS 服务器。要安装 kube-dns 而不是 CoreDNS，必须在 kubeadm 配置文件的ClusterConfiguration 字段中配置 DNS 附加组件(通过 kubeadm config 文件）。请注意，虽然已部署 DNS 服务器，但安装 CNI 前该POD 不会被调度到节点（可以理解为不回被实际部署，或不会生效）。 kubeadm init phase 的用法 查看 kubeadm init phase 列表 [root@rancher ~]# kubeadm init phase Use this command to invoke single phase of the init workflow Usage: kubeadm init phase [command] Available Commands: addon Install required addons for passing Conformance tests bootstrap-token Generates bootstrap tokens used to join a node to a cluster certs Certificate generation control-plane Generate all static Pod manifest files necessary to establish the control plane etcd Generate static Pod manifest file for local etcd kubeconfig Generate all kubeconfig files necessary to establish the control plane and the admin kubeconfig file kubelet-start Write kubelet settings and (re)start the kubelet mark-control-plane Mark a node as a control-plane preflight Run pre-flight checks upload-certs Upload certificates to kubeadm-certs upload-config Upload the kubeadm and kubelet configuration to a ConfigMap 可以查看某个具体的phase下的子phase 列表 [root@rancher ~]# kubeadm init phase control-plane --help This command is not meant to be run on its own. See list of available subcommands. Usage: kubeadm init phase control-plane [flags] kubeadm init phase control-plane [command] Available Commands: #下面的就是子phase all Generate all static Pod manifest files apiserver Generates the kube-apiserver static Pod manifest controller-manager Generates the kube-controller-manager static Pod manifest scheduler Generates the kube-scheduler static Pod manifest 查看 control-plane phase 下 controller-manager 子 phase 的用法详情 [root@rancher ~]# kubeadm init phase control-plane controller-manager --help Generates the kube-controller-manager static Pod manifest Usage: kubeadm init phase control-plane controller-manager [flags] Flags: --cert-dir string The path where to save and store the certificates. (default \"/etc/kubernetes/pki\") --config string Path to a kubeadm configuration file. --controller-manager-extra-args mapStringString A set of extra flags to pass to the Controller Manager or override default ones in form of = -h, --help help for controller-manager --image-repository string Choose a container registry to pull control plane images from (default \"k8s.gcr.io\") --kubernetes-version string Choose a specific Kubernetes version for the control plane. (default \"stable-1\") --pod-network-cidr string Specify range of IP addresses for the pod network. If set, the control plane will automatically allocate CIDRs for every node. 执行某个 phase 或者跳过某个 phase sudo kubeadm init phase control-plane all --config=configfile.yaml sudo kubeadm init phase etcd local --config=configfile.yaml # you can now modify the control plane and etcd manifest files sudo kubeadm init --skip-phases=control-plane,etcd --config=configfile.yaml kubeadm config 文件 注意，这个 config 文件特性在1.15 中依然是 beta，在将来可能改变 查看 kubeadm config print的帮助 [root@rancher ~]# kubeadm config print -h This command prints configurations for subcommands provided. Usage: kubeadm config print [flags] kubeadm config print [command] Available Commands: init-defaults Print default init configuration, that can be used for 'kubeadm init' join-defaults Print default join configuration, that can be used for 'kubeadm join' 打印默认的init 配置文件 [root@rancher ~]# kubeadm config print init-defaults > initconfig.yaml 打开 initconfig， 内容如下 apiVersion: kubeadm.k8s.io/v1beta2 bootstrapTokens: - groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authentication kind: InitConfiguration localAPIEndpoint: advertiseAddress: 1.2.3.4 bindPort: 6443 nodeRegistration: criSocket: /var/run/dockershim.sock name: rancher.local taints: - effect: NoSchedule key: node-role.kubernetes.io/master --- apiServer: timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta2 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controllerManager: {} dns: type: CoreDNS etcd: local: dataDir: /var/lib/etcd imageRepository: k8s.gcr.io kind: ClusterConfiguration kubernetesVersion: v1.14.0 networking: dnsDomain: cluster.local serviceSubnet: 10.96.0.0/12 scheduler: {} 上面的内容只包含额了最简话的InitConfiguration type 的内容，kubeadm 完整的内容包含5大部分，如下，每个type 之间，需要用yaml的 --- 文档隔离进行分离。 init-full-config.yaml 文件结构 --- apiVersion: kubeadm.k8s.io/v1beta2 kind: InitConfiguration --- apiVersion: kubeadm.k8s.io/v1beta2 kind: ClusterConfiguration --- apiVersion: kubelet.config.k8s.io/v1beta1 kind: KubeletConfiguration --- apiVersion: kubeproxy.config.k8s.io/v1alpha1 kind: KubeProxyConfiguration --- apiVersion: kubeadm.k8s.io/v1beta2 kind: JoinConfiguration 想细的内容可以参阅kubeadm api，kube-proxy配置部分的内容细节在这里KubeProxyConfiguration 比如我要修改kube-proxy的模式为IPVS 那么修改后的init-full-config.yaml 内容为如下 --- apiVersion: kubeadm.k8s.io/v1beta2 kind: InitConfiguration --- apiVersion: kubeadm.k8s.io/v1beta2 kind: ClusterConfiguration --- apiVersion: kubelet.config.k8s.io/v1beta1 kind: KubeletConfiguration --- apiVersion: kubeproxy.config.k8s.io/v1alpha1 kind: KubeProxyConfiguration mode: \"ipvs\" 修改在这里 --- apiVersion: kubeadm.k8s.io/v1beta2 kind: JoinConfiguration 关于如何通过kubeadm 配置启用 IPVS 请参阅 关于如何定制化 control plane 请参阅 使用自定义镜像仓库 对于google 提供的镜像，在众所周知的原因下，无法访问。所以需要使用国内镜像或者自建的镜像仓库。 kubeadm 提供了参数，同事也支持修改 kubeadm config 文件来指定定制化的仓库 # imageRepository: k8s.gcr.io imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers 通过如下命令，可以查看和拉取 init 所需的镜像。 kubeadm config images list kubeadm config images pull --config init-full-config.yaml kubeadm 配置 cri runtime kubelet 默认使用 docker 作为runtime 并使用内建的 dockershim 进行交互。 其他的runtime包括: cri-containerd cri-o frakti rkt 安装文档 CRI installation instructions 根据安装文档安装好runtime后，需要对kubeadm 和kubelet 做如下配置 1.在每个节点安装runtime 对应的 shim，如何安装在runtime 说明文档中有介绍 2.配置 kubelet 使用远程 CRI runtime （实际是使用linux sockets），记得修改 RUNTIME_ENDPOINT 为你自己对应的值，比如 /var/run/{your_runtime}.sock: 比如，如下是cri的配置文件。 cat > /etc/systemd/system/kubelet.service.d/20-cri.conf 你也可以通过kubeadm init/reset 的 --cri-socket 参数来是先同样的事情。 kubeadm 自动化 与其像kubeadm 基础教程中那样，将从 kubeadm init 获得的令牌复制到每个节点，不如并行化令牌分发，以便更轻松地实现自动化。要实现此自动化，您必须知道控制平面节点在启动后将具有的 IP 地址。 步骤 1.使用 kubeadm 生成令牌（token） kubeadm token generate 2.用此令牌(token)同时启动控制平面节点和工作节点。当它们启动时，它们会找到彼此并形成集群。相同的 --token 参数可以在kubeadm init和kubeadm join上使用 3.可以用同样的方法来添加master节点，通过设置 --certificate-key 参数来达到加入的目的。可以通过如下命令来生成key，给每个master 节点使用 kubeadm alpha certs certificate-key 集群启动之后，可以通过/etc/kubernetes/admin.conf中的凭证来和集群信。 这种方式不允许root ca 通过--discovery-token-ca-cert-hash 来验证证书hash 所以有一定的安全隐患。 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/k8s/k8s下载/下载k8s二进制包.html":{"url":"linux/k8s/k8s下载/下载k8s二进制包.html","title":"k8s二进制包下载","keywords":"","body":"下载k8s二进制包 登陆github，搜索kubernetes，然后点击项目进入 点击releases 选择要下载的版本，然后点击CHANGELOG/CHANGELOG-1.18.md 注意看准版本，在Server Binaries下下载二进制包 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/k8s/k8s知识点/k8s设置通过kubeconfig登陆dashboard.html":{"url":"linux/k8s/k8s知识点/k8s设置通过kubeconfig登陆dashboard.html","title":"k8s设置通过kubeconfig登陆dashboard","keywords":"","body":"k8s设置通过kubeconfig登陆dashboard k8s 官方的dashboard每次登陆都需要输入token，而这个token一会特么就过期了，我就是本机实验，每次都得手动粘贴一大串命令获取token然后再登陆，非常麻烦 使用如下命令获取登陆dashboard的token kubectl get secret `kubectl get secret -n kube-system|grep admin-token|awk '{print $1}'` -o jsonpath={.data.token} -n kube-system |base64 -d && echo 查看secrets $ kubectl get secrets NAME TYPE DATA AGE default-token-jlz9f kubernetes.io/service-account-token 3 45h 1.创建cluster kubectl config set-cluster kubernetes --certificate-authority=/etc/kubernetes/pki/ca.crt --server=10.0.0.130:6443 --kubeconfig=/root/dashbord-admin.conf 2.获取token DASH_TOCKEN=$(kubectl get secret -n kube-system `kubectl get secret -n kube-system |grep dashboard |awk '{print $1}'` -o jsonpath={.data.token}|base64 -d) 3.创建credentials kubectl config set-credentials dashboard-admin --token=$DASH_TOCKEN --kubeconfig=/root/dashbord-admin.conf 4.创建context kubectl config set-context dashboard-admin@kubernetes --cluster=kubernetes --user=dashboard-admin --kubeconfig=/root/dashbord-admin.conf 5.切换context的current-context是dashboard-admin@kubernetes kubectl config use-context dashboard-admin@kubernetes --kubeconfig=/root/dashbord-admin.conf 下载dashboard-admin.conf然后登陆的时候选择这个文件即可 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/k8s/k8s安装/1.使用 kubeadm 搭建 v1.15.3 版本 Kubernetes 集群.html":{"url":"linux/k8s/k8s安装/1.使用 kubeadm 搭建 v1.15.3 版本 Kubernetes 集群.html","title":"1.15","keywords":"","body":"使用 kubeadm 搭建 v1.15.3 版本 Kubernetes 集群 一、环境准备 1.1实验环境 角色 IP地址 主机名 docker版本 硬件配置 系统 内核 master 10.0.0.130 k8s-master 18.09.9 2c2g CentOS7.6 3.10.0-957.el7.x86_64 node1 10.0.0.131 k8s-node1 18.09.9 2c1g CentOS7.6 3.10.0-957.el7.x86_64 node2 10.0.0.132 k8s-node2 18.09.9 2c1g CentOS7.6 3.10.0-957.el7.x86_64 1.2每个节点配置host信息 cat >> /etc/hosts 1.3禁用防火墙和selinux //禁用防火墙 systemctl stop firewalld && systemctl disable firewalld //禁用selinux #临时修改 setenforce 0 #永久修改，重启服务器后生效 sed -i '7s/enforcing/disabled/' /etc/selinux/config 1.4创建/etc/sysctl.d/k8s.conf文件，添加如下内容 //向文件中写入以下内容 cat >/etc/sysctl.d/k8s.conf 1.5安装ipvs 脚本创建了的/etc/sysconfig/modules/ipvs.modules文件，保证在节点重启后能自动加载所需模块。使用lsmod | grep -e ip_vs -e nf_conntrack_ipv4命令查看是否已经正确加载所需的内核模块 //向文件中写入以下内容 cat > /etc/sysconfig/modules/ipvs.modules 安装ipset和ipvsadm(便于查看 ipvs 的代理规则) yum -y install ipset ipvsadm 1.6同步服务器时间 //安装chrony yum -y install chrony //修改同步服务器地址为阿里云 sed -i.bak '3,6d' /etc/chrony.conf && sed -i '3cserver ntp1.aliyun.com iburst' \\ /etc/chrony.conf //启动chronyd及加入开机自启 systemctl start chronyd && systemctl enable chronyd //查看同步结果 chronyc sources 210 Number of sources = 1 MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^* 120.25.115.20 2 6 37 13 +194us[+6131us] +/- 33ms 1.7关闭swap分区 修改/etc/fstab文件，注释掉 SWAP 的自动挂载，使用free -m确认 swap 已经关闭 //手动关闭swap swapoff -a //修改fstab文件，注释swap自动挂载 sed -i '/^\\/dev\\/mapper\\/centos-swap/c#/dev/mapper/centos-swap swap swap defaults 0 0' /etc/fstab //查看swap是否关闭 free -m total used free shared buff/cache available Mem: 1994 682 612 9 699 1086 Swap: 0 0 0 swappiness 参数调整，修改/etc/sysctl.d/k8s.conf添加下面一行 cat >>/etc/sysctl.d/k8s.conf 1.8安装docker18.09.9 1.添加阿里云yum源 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 2.查看可用版本 yum list docker-ce --showduplicates | sort -r 已加载插件：fastestmirror, langpacks 可安装的软件包 * updates: mirrors.aliyun.com Loading mirror speeds from cached hostfile * extras: mirrors.aliyun.com docker-ce.x86_64 3:19.03.5-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.4-3.el7 docker-ce-stable 。。。。。。 docker-ce.x86_64 3:18.09.9-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.8-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.7-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.6-3.el7 docker-ce-stable 。。。。。。 3.安装docker18.09.9 yum -y install docker-ce-18.09.9-3.el7 docker-ce-cli-18.09.9 4.启动docker并设置开机自启 systemctl enable docker && systemctl start docker 5.配置阿里云docker镜像加速 cat > /etc/docker/daemon.json 1.9安装Kubeadm 需要科学上网 cat >/etc/yum.repos.d/kubernetes.repo 使用阿里云yum源 cat >/etc/yum.repos.d/kubernetes.repo 安装 kubeadm、kubelet、kubectl(阿里云yum源会随官方更新最新版，因此指定版本) yum -y install kubelet-1.15.3 kubeadm-1.15.3 kubectl-1.15.3 --disableexcludes=kubernetes //查看版本 kubeadm version kubeadm version: &version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.3\", GitCommit:\"2d3c76f9091b6bec110a5e63777c332469e0cba2\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T11:11:18Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"} 设置kubelet开机自启 systemctl enable kubelet 设置k8s命令自动补全 yum -y install bash-completion source /usr/share/bash-completion/bash_completion source > ~/.bashrc 到此，基本环境安装完成!!! 二、初始化集群 2.1master节点操作，配置 kubeadm 初始化文件 //初始化kubeadm文件，这里的路径为/root kubeadm config print init-defaults > kubeadm.yaml //查看生成的默认文件 cat kubeadm.yaml apiVersion: kubeadm.k8s.io/v1beta2 bootstrapTokens: - groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authentication kind: InitConfiguration localAPIEndpoint: advertiseAddress: 1.2.3.4 bindPort: 6443 nodeRegistration: criSocket: /var/run/dockershim.sock name: k8s-master taints: - effect: NoSchedule key: node-role.kubernetes.io/master --- apiServer: timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta2 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controllerManager: {} dns: type: CoreDNS etcd: local: dataDir: /var/lib/etcd imageRepository: k8s.gcr.io kind: ClusterConfiguration kubernetesVersion: v1.15.0 networking: dnsDomain: cluster.local serviceSubnet: 10.96.0.0/12 scheduler: {} 然后根据我们自己的需求修改配置，比如修改 imageRepository 的值，kube-proxy 的模式为 ipvs，另外需要注意的是我们这里是准备安装 calico 网络插件的，需要将 networking.podSubnet 设置为192.168.0.0/16 修改后的文件内容如下 cat > kubeadm.yaml 2.2初始化master kubeadm init --config kubeadm.yaml 完整输出结果 [init] Using Kubernetes version: v1.15.3 [preflight] Running pre-flight checks [WARNING IsDockerSystemdCheck]: detected \"cgroupfs\" as the Docker cgroup driv er. The recommended driver is \"systemd\". Please follow the guide at https://kubernete s.io/docs/setup/cri/ [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using 'kubeadm config imag es pull' [kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet /kubeadm-flags.env\" [kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\" [kubelet-start] Activating the kubelet service [certs] Using certificateDir folder \"/etc/kubernetes/pki\" [certs] Generating \"ca\" certificate and key [certs] Generating \"apiserver\" certificate and key [certs] apiserver serving cert is signed for DNS names [k8s-master kubernetes kuberne tes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10. 96.0.1 10.0.0.130] [certs] Generating \"apiserver-kubelet-client\" certificate and key [certs] Generating \"etcd/ca\" certificate and key [certs] Generating \"apiserver-etcd-client\" certificate and key [certs] Generating \"etcd/healthcheck-client\" certificate and key [certs] Generating \"etcd/server\" certificate and key [certs] etcd/server serving cert is signed for DNS names [k8s-master localhost] and IPs [10.0.0.130 127.0.0.1 ::1] [certs] Generating \"etcd/peer\" certificate and key [certs] etcd/peer serving cert is signed for DNS names [k8s-master localhost] and IPs [10.0.0.130 127.0.0.1 ::1] [certs] Generating \"front-proxy-ca\" certificate and key [certs] Generating \"front-proxy-client\" certificate and key [certs] Generating \"sa\" key and public key [kubeconfig] Using kubeconfig folder \"/etc/kubernetes\" [kubeconfig] Writing \"admin.conf\" kubeconfig file [kubeconfig] Writing \"kubelet.conf\" kubeconfig file [kubeconfig] Writing \"controller-manager.conf\" kubeconfig file [kubeconfig] Writing \"scheduler.conf\" kubeconfig file [control-plane] Using manifest folder \"/etc/kubernetes/manifests\" [control-plane] Creating static Pod manifest for \"kube-apiserver\" [control-plane] Creating static Pod manifest for \"kube-controller-manager\" [control-plane] Creating static Pod manifest for \"kube-scheduler\" [etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\" [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s [apiclient] All control plane components are healthy after 19.003902 seconds [upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace [kubelet] Creating a ConfigMap \"kubelet-config-1.15\" in namespace kube-system with the configuration for the kubelets in the cluster [upload-certs] Skipping phase. Please see --upload-certs [mark-control-plane] Marking the node k8s-master as control-plane by adding the label \"node-role.kubernetes.io/master=''\" [mark-control-plane] Marking the node k8s-master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule] [bootstrap-token] Using token: abcdef.0123456789abcdef [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [bootstrap-token] Creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config You should now deploy a pod network to the cluster. Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 10.0.0.130:6443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:b29cbd05af6924b95b74964f949a65e3367402d76a268295c333e792c3eb7ad2 #kubeadm init --config kubeadm.yaml初始化master下载的镜像 gcr.azk8s.cn/google_containers/kube-proxy v1.15.3 232b5c793146 6 months ago 82.4MB gcr.azk8s.cn/google_containers/kube-apiserver v1.15.3 5eb2d3fc7a44 6 months ago 207MB gcr.azk8s.cn/google_containers/kube-controller-manager v1.15.3 e77c31de5547 6 months ago 159MB gcr.azk8s.cn/google_containers/kube-scheduler v1.15.3 703f9c69a5d5 6 months ago 81.1MB gcr.azk8s.cn/google_containers/coredns 1.3.1 eb516548c180 14 months ago 40.3MB gcr.azk8s.cn/google_containers/etcd 3.3.10 2c4adeb21b4f 15 months ago 258MB gcr.azk8s.cn/google_containers/pause 3.1 da86e6ba6ca1 2 years ago 742kB #启动的容器 ab18a4a6f78c 232b5c793146 \"/usr/local/bin/kube…\" About an hour ago Up About an hour k8s_kube-proxy_kube-proxy-zns59_kube-system_7b431cd3-6572-4a5e-981e-c536bbad32ea_0 b8b3f6cf6702 gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" About an hour ago Up About an hour k8s_POD_kube-proxy-zns59_kube-system_7b431cd3-6572-4a5e-981e-c536bbad32ea_0 dc2db22d2a84 e77c31de5547 \"kube-controller-man…\" About an hour ago Up About an hour k8s_kube-controller-manager_kube-controller-manager-k8s-master_kube-system_5a41bf631425471a02fc0cca5725518d_0 8a25922bf185 2c4adeb21b4f \"etcd --advertise-cl…\" About an hour ago Up About an hour k8s_etcd_etcd-k8s-master_kube-system_3c2a1c3e9bec3ffe168c550fd855d63f_0 f90159ea56c4 5eb2d3fc7a44 \"kube-apiserver --ad…\" About an hour ago Up About an hour k8s_kube-apiserver_kube-apiserver-k8s-master_kube-system_6eb25fe257b281826a14a7e276a75d61_0 b70fe56aab46 703f9c69a5d5 \"kube-scheduler --bi…\" About an hour ago Up About an hour k8s_kube-scheduler_kube-scheduler-k8s-master_kube-system_f1217bcf1fd2d00391bfd0ec41d69a25_0 f084bc0cf4ae gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" About an hour ago Up About an hour k8s_POD_kube-controller-manager-k8s-master_kube-system_5a41bf631425471a02fc0cca5725518d_0 e93a8bebe038 gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" About an hour ago Up About an hour k8s_POD_kube-scheduler-k8s-master_kube-system_f1217bcf1fd2d00391bfd0ec41d69a25_0 4d6cac595d0b gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" About an hour ago Up About an hour k8s_POD_kube-apiserver-k8s-master_kube-system_6eb25fe257b281826a14a7e276a75d61_0 f49e9fa0ba1d gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" About an hour ago Up About an hour k8s_POD_etcd-k8s-master_kube-system_3c2a1c3e9bec3ffe168c550fd855d63f_0 拷贝 kubeconfig 文件 //这里的路径为/root mkdir -p $HOME/.kube cp -i /etc/kubernetes/admin.conf $HOME/.kube/config chown $(id -u):$(id -g) $HOME/.kube/config 2.3master添加节点 node1和node2相同操作 将master节点上的$HOME/.kube/config 文件拷贝到node节点对应的文件中 1.创建目录，这里的路径为/root mkdir -p $HOME/.kube 2.把master节点上的config文件拷贝到node1和node2的$HOME/.kube scp k8s-master:~/.kube/config $HOME/.kube 3.修改权限 chown $(id -u):$(id -g) $HOME/.kube/config 将node1和node2加入到集群中 这里需要用到2.2中初始化master最后生成的token和sha256值 kubeadm join 10.0.0.130:6443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:b29cbd05af6924b95b74964f949a65e3367402d76a268295c333e792c3eb7ad2 输出结果 [preflight] Running pre-flight checks [WARNING IsDockerSystemdCheck]: detected \"cgroupfs\" as the Docker cgroup driver. The recommended driver is \"systemd\". Please follow the guide at https://kubernetes.io/docs/setup/cri/ [preflight] Reading configuration from the cluster... [preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' [kubelet-start] Downloading configuration for the kubelet from the \"kubelet-config-1.15\" ConfigMap in the kube-system namespace [kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\" [kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\" [kubelet-start] Activating the kubelet service [kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap... This node has joined the cluster: * Certificate signing request was sent to apiserver and a response was received. * The Kubelet was informed of the new secure connection details. Run 'kubectl get nodes' on the control-plane to see this node join the cluster. 如果忘记了token和sha256值，可以在master节点使用如下命令查看 //查看token kubeadm token list TOKEN TTL EXPIRES USAGES DESCRIPTION EXTRA GROUPS abcdef.0123456789abcdef 23h 2019-12-11T16:52:56+08:00 authentication,signing system:bootstrappers:kubeadm:default-node-token //查看sha256 openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //' b29cbd05af6924b95b74964f949a65e3367402d76a268295c333e792c3eb7ad2 //同时查看token和sha256 kubeadm token create --print-join-command kubeadm join 10.0.0.130:6443 --token h8lbi6.27rrq8c6khonopqe --discovery-token-ca-cert-hash sha256:b29cbd05af6924b95b74964f949a65e3367402d76a268295c333e792c3eb7ad2 master节点查看node，发现状态都是NotReady，因为还没有安装网络插件，这里我们安装calio官方插件文档 kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-master NotReady master 19m v1.15.3 k8s-node1 NotReady 4m10s v1.15.3 k8s-node2 NotReady 4m3s v1.15.3 2.4master节点安装网络插件calio //下载文件 wget https://docs.projectcalico.org/v3.8/manifests/calico.yaml //因为有节点是多网卡，所以需要在资源清单文件中指定内网网卡，修改calico.yaml文件中以下几处 582行-594行，原内容如下 containers: 583 # Runs calico-node container on each Kubernetes node. This 584 # container programs network policy and routes on each 585 # host. 586 - name: calico-node 587 image: calico/node:v3.8.5 588 env: 589 # Use Kubernetes API as the backing datastore. 590 - name: DATASTORE_TYPE 591 value: \"kubernetes\" 592 # Wait for the datastore. 593 - name: WAIT_FOR_DATASTORE 594 value: \"true\" 现修改为如下（增加了一个环境变量） containers: # Runs calico-node container on each Kubernetes node. This # container programs network policy and routes on each # host. - name: calico-node image: calico/node:v3.8.5 env: # Use Kubernetes API as the backing datastore. - name: DATASTORE_TYPE value: \"kubernetes\" - name: IP_AUTODETECTION_METHOD # DaemonSet中添加该环境变量 value: interface=eth0 # 指定内网网卡 # Wait for the datastore. - name: WAIT_FOR_DATASTORE value: \"true\" //修改完成后安装calico网络插件 kubectl apply -f calico.yaml //安装完成后稍等一会查看pods状态 kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE calico-kube-controllers-5bbc8f45cb-rpm96 1/1 Running 0 6m17s calico-node-cbmcz 1/1 Running 0 6m17s calico-node-jbjw4 1/1 Running 0 6m17s calico-node-qfnfm 1/1 Running 0 6m17s coredns-cf8fb6d7f-vkst4 1/1 Running 0 50m coredns-cf8fb6d7f-z622t 1/1 Running 0 50m etcd-k8s-master 1/1 Running 0 49m kube-apiserver-k8s-master 1/1 Running 0 49m kube-controller-manager-k8s-master 1/1 Running 0 50m kube-proxy-68wzg 1/1 Running 0 35m kube-proxy-fbc95 1/1 Running 0 35m kube-proxy-g4xkc 1/1 Running 0 50m kube-scheduler-k8s-master 1/1 Running 0 49m //查看node状态 kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-master Ready master 55m v1.15.3 k8s-node1 Ready 39m v1.15.3 k8s-node2 Ready 39m v1.15.3 #kubectl apply -f calico.yaml安装网络插件calico下载的镜像 calico/node v3.8.6 1b9ca446b4da 2 months ago 192MB calico/pod2daemon-flexvol v3.8.6 97bfbee02d48 2 months ago 9.38MB calico/cni v3.8.6 33af7d7d46b6 2 months ago 161MB #启动的容器 4cfb387bd9a0 calico/node \"start_runit\" 5 minutes ago Up 5 minutes k8s_calico-node_calico-node-xc2tg_kube-system_0c89a070-b9e4-419e-916e-058b32ac64d1_0 b75783c7934c calico/pod2daemon-flexvol \"/usr/local/bin/flex…\" 5 minutes ago Exited (0) 5 minutes ago k8s_flexvol-driver_calico-node-xc2tg_kube-system_0c89a070-b9e4-419e-916e-058b32ac64d1_0 9e4766d2fa80 33af7d7d46b6 \"/install-cni.sh\" 6 minutes ago Exited (0) 6 minutes ago k8s_install-cni_calico-node-xc2tg_kube-system_0c89a070-b9e4-419e-916e-058b32ac64d1_0 f7f752fd62dc calico/cni \"/opt/cni/bin/calico…\" 6 minutes ago Exited (0) 6 minutes ago k8s_upgrade-ipam_calico-node-xc2tg_kube-system_0c89a070-b9e4-419e-916e-058b32ac64d1_0 2.5安装Dashboard 下载文件及修改内容 //下载文件 wget https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml //修改镜像名称 注释112行，添加如下两行 在这一行下添加如下两行 - name: kubernetes-dashboard image: gcr.azk8s.cn/google_containers/kubernetes-dashboard-amd64:v1.10.1 imagePullPolicy: IfNotPresent //修改Service为NodePort类型，文件最后一行加入以下内容 selector: k8s-app: kubernetes-dashboard type: NodePort #新增这一行，注意与selector在同一级 部署dashboard kubectl apply -f kubernetes-dashboard.yaml #下载的镜像 gcr.azk8s.cn/google_containers/kubernetes-dashboard-amd64 v1.10.1 f9aed6605b81 15 months ago 122MB #启动的容器 7fddf75bb284 gcr.azk8s.cn/google_containers/kubernetes-dashboard-amd64 \"/dashboard --insecu…\" 9 seconds ago Up 9 seconds k8s_kubernetes-dashboard_kubernetes-dashboard-fcfb4cbc-v7lfh_kube-system_268913c8-f9df-4e9a-9f89-c9dda9462d38_0 查看dashboard的运行状态及外网访问端口 //查看dashboard运行状态 kubectl get pods -n kube-system -l k8s-app=kubernetes-dashboard NAME READY STATUS RESTARTS AGE kubernetes-dashboard-fcfb4cbc-fcczh 1/1 Running 0 3m40s //查看dashboard外网访问端口 kubectl get svc -n kube-system -l k8s-app=kubernetes-dashboard NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes-dashboard NodePort 10.96.100.138 443:31758/TCP 4m42s 通过上边的31758端口访问dashboard，注意是https 由于 dashboard 默认是自建的 https 证书，该证书是不受浏览器信任的，所以我们需要强制跳转就可以了 然后创建一个具有全局所有权限的用户来登录Dashboard //编辑admin.yaml文件 cat > admin.yaml 然后粘贴上述生成的base64字符串登陆dashboard，在登陆页面选择令牌一项 登陆后的首界面 到此，使用kubeadm安装k8s 1.15.3完成！！！ 获取令牌命令 kubectl get secret `kubectl get secret -n kube-system|grep admin-token|awk '{print $1}'` -o jsonpath={.data.token} -n kube-system |base64 -d 1.15.3启动的容器及下载的镜像 #启动的容器 7fddf75bb284 gcr.azk8s.cn/google_containers/kubernetes-dashboard-amd64 \"/dashboard --insecu…\" 8 minutes ago Up 8 minutes k8s_kubernetes-dashboard_kubernetes-dashboard-fcfb4cbc-v7lfh_kube-system_268913c8-f9df-4e9a-9f89-c9dda9462d38_0 fa592650d469 gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" 8 minutes ago Up 8 minutes k8s_POD_kubernetes-dashboard-fcfb4cbc-v7lfh_kube-system_268913c8-f9df-4e9a-9f89-c9dda9462d38_0 4cfb387bd9a0 calico/node \"start_runit\" 18 minutes ago Up 18 minutes k8s_calico-node_calico-node-xc2tg_kube-system_0c89a070-b9e4-419e-916e-058b32ac64d1_0 b75783c7934c calico/pod2daemon-flexvol \"/usr/local/bin/flex…\" 18 minutes ago Exited (0) 18 minutes ago k8s_flexvol-driver_calico-node-xc2tg_kube-system_0c89a070-b9e4-419e-916e-058b32ac64d1_0 9e4766d2fa80 33af7d7d46b6 \"/install-cni.sh\" 18 minutes ago Exited (0) 18 minutes ago k8s_install-cni_calico-node-xc2tg_kube-system_0c89a070-b9e4-419e-916e-058b32ac64d1_0 f7f752fd62dc calico/cni \"/opt/cni/bin/calico…\" 18 minutes ago Exited (0) 18 minutes ago k8s_upgrade-ipam_calico-node-xc2tg_kube-system_0c89a070-b9e4-419e-916e-058b32ac64d1_0 2cd3749c5b37 gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" 19 minutes ago Up 19 minutes k8s_POD_calico-node-xc2tg_kube-system_0c89a070-b9e4-419e-916e-058b32ac64d1_0 ab18a4a6f78c 232b5c793146 \"/usr/local/bin/kube…\" 2 hours ago Up 2 hours k8s_kube-proxy_kube-proxy-zns59_kube-system_7b431cd3-6572-4a5e-981e-c536bbad32ea_0 b8b3f6cf6702 gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" 2 hours ago Up 2 hours k8s_POD_kube-proxy-zns59_kube-system_7b431cd3-6572-4a5e-981e-c536bbad32ea_0 dc2db22d2a84 e77c31de5547 \"kube-controller-man…\" 2 hours ago Up 2 hours k8s_kube-controller-manager_kube-controller-manager-k8s-master_kube-system_5a41bf631425471a02fc0cca5725518d_0 8a25922bf185 2c4adeb21b4f \"etcd --advertise-cl…\" 2 hours ago Up 2 hours k8s_etcd_etcd-k8s-master_kube-system_3c2a1c3e9bec3ffe168c550fd855d63f_0 f90159ea56c4 5eb2d3fc7a44 \"kube-apiserver --ad…\" 2 hours ago Up 2 hours k8s_kube-apiserver_kube-apiserver-k8s-master_kube-system_6eb25fe257b281826a14a7e276a75d61_0 b70fe56aab46 703f9c69a5d5 \"kube-scheduler --bi…\" 2 hours ago Up 2 hours k8s_kube-scheduler_kube-scheduler-k8s-master_kube-system_f1217bcf1fd2d00391bfd0ec41d69a25_0 f084bc0cf4ae gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" 2 hours ago Up 2 hours k8s_POD_kube-controller-manager-k8s-master_kube-system_5a41bf631425471a02fc0cca5725518d_0 e93a8bebe038 gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" 2 hours ago Up 2 hours k8s_POD_kube-scheduler-k8s-master_kube-system_f1217bcf1fd2d00391bfd0ec41d69a25_0 4d6cac595d0b gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" 2 hours ago Up 2 hours k8s_POD_kube-apiserver-k8s-master_kube-system_6eb25fe257b281826a14a7e276a75d61_0 f49e9fa0ba1d gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" 2 hours ago Up 2 hours k8s_POD_etcd-k8s-master_kube-system_3c2a1c3e9bec3ffe168c550fd855d63f_0 #下载的镜像 calico/node v3.8.6 1b9ca446b4da 2 months ago 192MB calico/pod2daemon-flexvol v3.8.6 97bfbee02d48 2 months ago 9.38MB calico/cni v3.8.6 33af7d7d46b6 2 months ago 161MB gcr.azk8s.cn/google_containers/kube-proxy v1.15.3 232b5c793146 6 months ago 82.4MB gcr.azk8s.cn/google_containers/kube-apiserver v1.15.3 5eb2d3fc7a44 6 months ago 207MB gcr.azk8s.cn/google_containers/kube-scheduler v1.15.3 703f9c69a5d5 6 months ago 81.1MB gcr.azk8s.cn/google_containers/kube-controller-manager v1.15.3 e77c31de5547 6 months ago 159MB gcr.azk8s.cn/google_containers/coredns 1.3.1 eb516548c180 14 months ago 40.3MB gcr.azk8s.cn/google_containers/kubernetes-dashboard-amd64 v1.10.1 f9aed6605b81 15 months ago 122MB gcr.azk8s.cn/google_containers/etcd 3.3.10 2c4adeb21b4f 15 months ago 258MB gcr.azk8s.cn/google_containers/pause 3.1 da86e6ba6ca1 2 years ago 742kB k8s切换命名空间工具 git clone https://github.com.cnpmjs.org/ahmetb/kubectx cp kubectx/kubens /usr/local/bin #查看所有命名空间 kubens #切换到kube-system命名空间 kubens kube-system Context \"kubernetes-admin@kubernetes\" modified. Active namespace is \"kube-system\". 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/k8s/k8s安装/2.使用 kubeadm 搭建 v1.16.3 版本 Kubernetes 集群.html":{"url":"linux/k8s/k8s安装/2.使用 kubeadm 搭建 v1.16.3 版本 Kubernetes 集群.html","title":"1.16","keywords":"","body":"使用 kubeadm 搭建 v1.16.3 版本 Kubernetes 集群 一、环境准备 1.1实验环境 角色 IP地址 主机名 docker版本 硬件配置 系统 内核 master 10.0.0.130 k8s-master 18.09.9 2c2g CentOS7.6 3.10.0-957.el7.x86_64 node1 10.0.0.131 k8s-node1 18.09.9 2c1g CentOS7.6 3.10.0-957.el7.x86_64 node2 10.0.0.132 k8s-node2 18.09.9 2c1g CentOS7.6 3.10.0-957.el7.x86_64 1.2每个节点配置host信息 cat >> /etc/hosts 1.3禁用防火墙和selinux //禁用防火墙 systemctl stop firewalld && systemctl disable firewalld //禁用selinux #临时修改 setenforce 0 #永久修改，重启服务器后生效 sed -i '7s/enforcing/disabled/' /etc/selinux/config 1.4创建/etc/sysctl.d/k8s.conf文件，添加如下内容 //向文件中写入以下内容 cat >/etc/sysctl.d/k8s.conf 1.5安装ipvs 脚本创建了的/etc/sysconfig/modules/ipvs.modules文件，保证在节点重启后能自动加载所需模块。使用lsmod | grep -e ip_vs -e nf_conntrack_ipv4命令查看是否已经正确加载所需的内核模块 //向文件中写入以下内容 cat > /etc/sysconfig/modules/ipvs.modules 安装ipset和ipvsadm(便于查看 ipvs 的代理规则) yum -y install ipset ipvsadm 1.6同步服务器时间 //安装chrony yum -y install chrony //修改同步服务器地址为阿里云 sed -i.bak '3,6d' /etc/chrony.conf && sed -i '3cserver ntp1.aliyun.com iburst' \\ /etc/chrony.conf //启动chronyd及加入开机自启 systemctl start chronyd && systemctl enable chronyd //查看同步结果 chronyc sources 210 Number of sources = 1 MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^* 120.25.115.20 2 6 37 13 +194us[+6131us] +/- 33ms 1.7关闭swap分区 修改/etc/fstab文件，注释掉 SWAP 的自动挂载，使用free -m确认 swap 已经关闭 //手动关闭swap swapoff -a //修改fstab文件，注释swap自动挂载 sed -i '/^\\/dev\\/mapper\\/centos-swap/c#/dev/mapper/centos-swap swap swap defaults 0 0' /etc/fstab //查看swap是否关闭 free -m total used free shared buff/cache available Mem: 1994 682 612 9 699 1086 Swap: 0 0 0 swappiness 参数调整，修改/etc/sysctl.d/k8s.conf添加下面一行 cat >>/etc/sysctl.d/k8s.conf 1.8安装docker18.09.9 1.添加阿里云yum源 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 2.查看可用版本 yum list docker-ce --showduplicates | sort -r 已加载插件：fastestmirror, langpacks 可安装的软件包 * updates: mirrors.aliyun.com Loading mirror speeds from cached hostfile * extras: mirrors.aliyun.com docker-ce.x86_64 3:19.03.5-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.4-3.el7 docker-ce-stable 。。。。。。 docker-ce.x86_64 3:18.09.9-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.8-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.7-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.6-3.el7 docker-ce-stable 。。。。。。 3.安装docker18.09.9 yum -y install docker-ce-18.09.9-3.el7 docker-ce-cli-18.09.9 4.启动docker并设置开机自启 systemctl enable docker && systemctl start docker 5.配置阿里云docker镜像加速 cat > /etc/docker/daemon.json 1.9修改docker Cgroup Driver为systemd #修改docker Cgroup Driver为systemd 将/usr/lib/systemd/system/docker.service文件中的这一行 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock 修改为 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --exec-opt native.cgroupdriver=systemd 如果不修改，在添加 worker 节点时可能会碰到如下错误 [WARNING IsDockerSystemdCheck]: detected \"cgroupfs\" as the Docker cgroup driver. The recommended driver is \"systemd\". Please follow the guide at https://kubernetes.io/docs/setup/cri/ //使用如下命令修改 sed -i.bak \"s#^ExecStart=/usr/bin/dockerd.*#ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --exec-opt native.cgroupdriver=systemd#g\" /usr/lib/systemd/system/docker.service //重启docker systemctl daemon-reload && systemctl restart docker 1.10安装Kubeadm 需要科学上网 cat >/etc/yum.repos.d/kubernetes.repo 使用阿里云yum源 cat >/etc/yum.repos.d/kubernetes.repo 安装 kubeadm、kubelet、kubectl(阿里云yum源会随官方更新最新版，因此指定版本) //安装1.16.3版本 yum -y install kubelet-1.16.3 kubeadm-1.16.3 kubectl-1.16.3 //查看版本 kubeadm version kubeadm version: &version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.3\", GitCommit:\"2d3c76f9091b6bec110a5e63777c332469e0cba2\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T11:11:18Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"} 设置kubelet开机自启 systemctl enable kubelet 设置k8s命令自动补全 yum -y install bash-completion source /usr/share/bash-completion/bash_completion source > ~/.bashrc 到此，基本环境安装完成!!! 二、初始化集群 2.1master节点操作，配置 kubeadm 初始化文件 cat ./kubeadm-config.yaml apiVersion: kubeadm.k8s.io/v1beta2 kind: ClusterConfiguration kubernetesVersion: v1.16.3 imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers #dnsName controlPlaneEndpoint: \"10.0.0.130:6443\" networking: serviceSubnet: \"10.96.0.0/16\" #k8s容器组所在的网段 podSubnet: \"10.100.0.1/16\" dnsDomain: \"cluster.local\" EOF 2.2初始化master ⚠️如果想要重新初始化，需要执行命令kubeadm reset -f #kubeadm init --config=kubeadm-config.yaml --upload-certs 完整输出结果 kubeadm init --config=kubeadm-config.yaml [init] Using Kubernetes version: v1.16.3 [preflight] Running pre-flight checks [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using 'kubeadm config images pull' [kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\" [kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\" [kubelet-start] Activating the kubelet service [certs] Using certificateDir folder \"/etc/kubernetes/pki\" [certs] Generating \"ca\" certificate and key [certs] Generating \"apiserver\" certificate and key [certs] apiserver serving cert is signed for DNS names [k8s-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 10.0.0.130 10.0.0.130] [certs] Generating \"apiserver-kubelet-client\" certificate and key [certs] Generating \"front-proxy-ca\" certificate and key [certs] Generating \"front-proxy-client\" certificate and key [certs] Generating \"etcd/ca\" certificate and key [certs] Generating \"etcd/server\" certificate and key [certs] etcd/server serving cert is signed for DNS names [k8s-master localhost] and IPs [10.0.0.130 127.0.0.1 ::1] [certs] Generating \"etcd/peer\" certificate and key [certs] etcd/peer serving cert is signed for DNS names [k8s-master localhost] and IPs [10.0.0.130 127.0.0.1 ::1] [certs] Generating \"etcd/healthcheck-client\" certificate and key [certs] Generating \"apiserver-etcd-client\" certificate and key [certs] Generating \"sa\" key and public key [kubeconfig] Using kubeconfig folder \"/etc/kubernetes\" [kubeconfig] Writing \"admin.conf\" kubeconfig file [kubeconfig] Writing \"kubelet.conf\" kubeconfig file [kubeconfig] Writing \"controller-manager.conf\" kubeconfig file [kubeconfig] Writing \"scheduler.conf\" kubeconfig file [control-plane] Using manifest folder \"/etc/kubernetes/manifests\" [control-plane] Creating static Pod manifest for \"kube-apiserver\" [control-plane] Creating static Pod manifest for \"kube-controller-manager\" [control-plane] Creating static Pod manifest for \"kube-scheduler\" [etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\" [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s [apiclient] All control plane components are healthy after 16.501777 seconds [upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace [kubelet] Creating a ConfigMap \"kubelet-config-1.16\" in namespace kube-system with the configuration for the kubelets in the cluster [upload-certs] Skipping phase. Please see --upload-certs [mark-control-plane] Marking the node k8s-master as control-plane by adding the label \"node-role.kubernetes.io/master=''\" [mark-control-plane] Marking the node k8s-master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule] [bootstrap-token] Using token: px979r.mphk9ee5ya8fgy44 [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [bootstrap-token] Creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config You should now deploy a pod network to the cluster. Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ You can now join any number of control-plane nodes by copying certificate authorities and service account keys on each node and then running the following as root: kubeadm join 10.0.0.130:6443 --token px979r.mphk9ee5ya8fgy44 \\ --discovery-token-ca-cert-hash sha256:5e7c7cd1cc1f86c0761e54b9380de22968b6b221cb98939c14ab2942223f6f51 \\ --control-plane Then you can join any number of worker nodes by running the following on each as root: kubeadm join 10.0.0.130:6443 --token px979r.mphk9ee5ya8fgy44 \\ --discovery-token-ca-cert-hash sha256:5e7c7cd1cc1f86c0761e54b9380de22968b6b221cb98939c14ab2942223f6f51 #kubeadm init --config=kubeadm-config.yaml --upload-certs初始化master下载的镜像 gcr.azk8s.cn/google_containers/kube-proxy v1.16.3 9b65a0f78b09 4 months ago 86.1MB gcr.azk8s.cn/google_containers/kube-apiserver v1.16.3 df60c7526a3d 4 months ago 217MB gcr.azk8s.cn/google_containers/kube-controller-manager v1.16.3 bb16442bcd94 4 months ago 163MB gcr.azk8s.cn/google_containers/kube-scheduler v1.16.3 98fecf43a54f 4 months ago 87.3MB gcr.azk8s.cn/google_containers/etcd 3.3.15-0 b2756210eeab 6 months ago 247MB gcr.azk8s.cn/google_containers/coredns 1.6.2 bf261d157914 7 months ago 44.1MB gcr.azk8s.cn/google_containers/pause 3.1 da86e6ba6ca1 2 years ago 742kB 拷贝 kubeconfig 文件 //这里的路径为/root mkdir -p $HOME/.kube cp -i /etc/kubernetes/admin.conf $HOME/.kube/config chown $(id -u):$(id -g) $HOME/.kube/config 2.3master添加节点 node1和node2相同操作 将master节点上的$HOME/.kube/config 文件拷贝到node节点对应的文件中 1.创建目录，这里的路径为/root mkdir -p $HOME/.kube 2.把master节点上的config文件拷贝到node1和node2的$HOME/.kube scp k8s-master:~/.kube/config $HOME/.kube 3.修改权限 chown $(id -u):$(id -g) $HOME/.kube/config 将node1和node2加入到集群中 这里需要用到2.2中初始化master最后生成的token和sha256值 #kubeadm join 10.0.0.130:6443 --token px979r.mphk9ee5ya8fgy44 --discovery-token-ca-cert-hash sha256:5e7c7cd1cc1f86c0761e54b9380de22968b6b221cb98939c14ab2942223f6f51 输出结果 [preflight] Running pre-flight checks [WARNING IsDockerSystemdCheck]: detected \"cgroupfs\" as the Docker cgroup driver. The recommended driver is \"systemd\". Please follow the guide at https://kubernetes.io/docs/setup/cri/ [preflight] Reading configuration from the cluster... [preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' [kubelet-start] Downloading configuration for the kubelet from the \"kubelet-config-1.16\" ConfigMap in the kube-system namespace [kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\" [kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\" [kubelet-start] Activating the kubelet service [kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap... This node has joined the cluster: * Certificate signing request was sent to apiserver and a response was received. * The Kubelet was informed of the new secure connection details. Run 'kubectl get nodes' on the control-plane to see this node join the cluster. 如果忘记了token和sha256值，可以在master节点使用如下命令查看 //查看token #kubeadm token list TOKEN TTL EXPIRES USAGES DESCRIPTION EXTRA GROUPS px979r.mphk9ee5ya8fgy44 20h 2020-03-18T13:49:48+08:00 authentication,signing system:bootstrappers:kubeadm:default-node-token //查看sha256 #openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //' 5e7c7cd1cc1f86c0761e54b9380de22968b6b221cb98939c14ab2942223f6f51 //同时查看token和sha256 #kubeadm token create --print-join-command kubeadm join 10.0.0.130:6443 --token 9b28zg.oyt0kvvpmtrem4bg --discovery-token-ca-cert-hash sha256:5e7c7cd1cc1f86c0761e54b9380de22968b6b221cb98939c14ab2942223f6f51 master节点查看node，发现状态都是NotReady，因为还没有安装网络插件，这里我们安装calio官方插件文档 kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-master NotReady master 19m v1.16.3 k8s-node1 NotReady 4m10s v1.16.3 k8s-node2 NotReady 4m3s v1.16.3 2.4master节点安装网络插件calio //下载文件 wget https://docs.projectcalico.org/v3.8/manifests/calico.yaml wget https://kuboard.cn/install-script/calico/calico-3.9.2.yaml 将文件中的620行改为如下，因为在上边kubeadm-config.yaml配置文件中指定了容器组IP 620行 value: \"10.100.0.1/16\" //修改完成后安装calico网络插件 #kubectl apply -f calico-3.9.2.yaml //安装完成后稍等一会查看pods状态 #kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE calico-kube-controllers-dc6cb64cb-8sh59 1/1 Running 0 6m22s calico-node-89s9k 1/1 Running 0 6m22s calico-node-dkt7w 1/1 Running 0 6m22s calico-node-tgg2h 1/1 Running 0 6m22s coredns-667f964f9b-7hrj9 1/1 Running 0 33m coredns-667f964f9b-8q7sh 1/1 Running 0 33m etcd-k8s-master 1/1 Running 0 33m kube-apiserver-k8s-master 1/1 Running 0 32m kube-controller-manager-k8s-master 1/1 Running 0 33m kube-proxy-b2r5d 1/1 Running 0 12m kube-proxy-nd982 1/1 Running 0 11m kube-proxy-zh6cz 1/1 Running 0 33m kube-scheduler-k8s-master 1/1 Running 0 32m //查看node状态 [root@k8s-master ~]# kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-master Ready master 31m v1.16.3 k8s-node1 Ready 9m46s v1.16.3 k8s-node2 Ready 9m22s v1.16.3 #kubectl apply -f calico.yaml安装网络插件calico下载的镜像 calico/node v3.9.2 14a380c92c40 5 months ago 195MB calico/cni v3.9.2 c0d73dd53e71 5 months ago 160MB calico/pod2daemon-flexvol v3.9.2 523f0356e07b 5 months ago 9.78MB #启动的容器 03df44242d90 calico/node \"start_runit\" 8 minutes ago Up 8 minutes k8s_calico-node_calico-node-89s9k_kube-system_ff5384c4-72b2-4bfa-b8ea-77f38c2a2112_0 c2a56feedc7c calico/pod2daemon-flexvol \"/usr/local/bin/flex…\" 9 minutes ago Exited (0) 9 minutes ago k8s_flexvol-driver_calico-node-89s9k_kube-system_ff5384c4-72b2-4bfa-b8ea-77f38c2a2112_0 ca9febcebaa8 c0d73dd53e71 \"/install-cni.sh\" 10 minutes ago Exited (0) 10 minutes ago k8s_install-cni_calico-node-89s9k_kube-system_ff5384c4-72b2-4bfa-b8ea-77f38c2a2112_0 b581894b1b91 calico/cni \"/opt/cni/bin/calico…\" 10 minutes ago Exited (0) 10 minutes ago k8s_upgrade-ipam_calico-node-89s9k_kube-system_ff5384c4-72b2-4bfa-b8ea-77f38c2a2112_0 2.5安装Dashboard(可选) 下载文件及修改内容 这里查看dashboard对应的k8s版本 //下载文件 v2.0.0-rc3是中文版本，beta8是英文版本 wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta8/aio/deploy/recommended.yaml wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-rc3/aio/deploy/recommended.yaml //修改Service为NodePort类型 42行下增加一行 nodePort: 30001 44行下增加一行 type: NodePort //原先内容 spec: ports: - port: 443 targetPort: 8443 selector: k8s-app: kubernetes-dashboard //修改后内容 spec: ports: - port: 443 targetPort: 8443 nodePort: 30001 #增加，指定nodeport端口 selector: k8s-app: kubernetes-dashboard type: NodePort #增加，修改类型为nodeport 部署dashboard #kubectl apply -f recommended.yaml #下载的镜像 kubernetesui/metrics-scraper v1.0.3 3327f0dbcb4a 6 weeks ago 40.1MB kubernetesui/dashboard v2.0.0-beta8 eb51a3597525 3 months ago 90.8MB #启动的容器 8bc24b355d78 kubernetesui/dashboard \"/dashboard --insecu…\" 7 minutes ago Up 7 minutes k8s_kubernetes-dashboard_kubernetes-dashboard-5996555fd8-2ppc5_kubernetes-dashboard_7f46632c-8b7b-41e4-aeb3-a1fbadd29782_0 查看dashboard的运行状态及外网访问端口 //查看dashboard运行状态 #kubectl get pods -n kubernetes-dashboard -l k8s-app=kubernetes-dashboard NAME READY STATUS RESTARTS AGE kubernetes-dashboard-5996555fd8-2ppc5 1/1 Running 0 8m16s //查看dashboard外网访问端口，命名空间为kubernetes-dashboard #kubectl get svc -n kubernetes-dashboard -l k8s-app=kubernetes-dashboard kubectl get svc -n kubernetes-dashboard -l k8s-app=kubernetes-dashboard NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes-dashboard NodePort 10.96.142.172 443:30001/TCP 8m37s 通过上边的30001端口访问dashboard，注意是https ⚠️k8s1.16.3这个版本中，使用的dashboard版本是2.0.0-beta8，只有火狐浏览器可以访问，其余浏览器都不能访问，会报错如下 使用火狐浏览器访问，由于 dashboard 默认是自建的 https 证书，该证书是不受浏览器信任的，所以我们需要强制跳转就可以了 然后创建一个具有全局所有权限的用户来登录Dashboard //编辑admin.yaml文件 cat > admin.yaml 然后粘贴上述生成的base64字符串登陆dashboard，在登陆页面选择令牌一项 登陆后的首界面 获取令牌命令 kubectl get secret `kubectl get secret -n kube-system|grep admin-token|awk '{print $1}'` -o jsonpath={.data.token} -n kube-system |base64 -d 2.6安装kuboard(可选) kuboard是Kubernetes 的一款图形化管理界面 安装kuboard kubectl apply -f https://kuboard.cn/install-script/kuboard.yaml kubectl apply -f https://addons.kuboard.cn/metrics-server/0.3.6/metrics-server.yaml 查看运行状态 #kubectl get pods -l k8s.eip.work/name=kuboard -n kube-system NAME READY STATUS RESTARTS AGE kuboard-756d46c4d4-tvhjq 1/1 Running 0 40s 获取token //获取管理员token kubectl -n kube-system get secret $(kubectl -n kube-system get secret | grep kuboard-user | awk '{print $1}') -o go-template='{{.data.token}}' | base64 -d && echo //获取只读token kubectl -n kube-system get secret $(kubectl -n kube-system get secret | grep kuboard-viewer | awk '{print $1}') -o go-template='{{.data.token}}' | base64 -d && echo 访问kuboard Kuboard Service 使用了 NodePort 的方式暴露服务，NodePort 为 32567 k8s集群的任意一个节点都可以访问到 登陆首界面 kuboard下载的镜像和启动的容器 #启动的容器 5d800a6ee8ad eipwork/kuboard \"/entrypoint.sh\" 9 minutes ago Up 9 minutes k8s_kuboard_kuboard-756d46c4d4-tvhjq_kube-system_6b88b7b5-64d8-4af3-8065-999b19722c86_0 #下载的镜像，本文中为1.0.8.2版本 eipwork/kuboard latest c6d652bbdf90 About an hour ago 180MB 到此，使用kubeadm安装k8s 1.16.3完成！！！ 1.16.3master启动的容器及下载的镜像 #下载的镜像 kubernetesui/metrics-scraper v1.0.3 3327f0dbcb4a 6 weeks ago 40.1MB kubernetesui/dashboard v2.0.0-beta8 eb51a3597525 3 months ago 90.8MB gcr.azk8s.cn/google_containers/kube-apiserver v1.16.3 df60c7526a3d 4 months ago 217MB gcr.azk8s.cn/google_containers/kube-proxy v1.16.3 9b65a0f78b09 4 months ago 86.1MB gcr.azk8s.cn/google_containers/kube-controller-manager v1.16.3 bb16442bcd94 4 months ago 163MB gcr.azk8s.cn/google_containers/kube-scheduler v1.16.3 98fecf43a54f 4 months ago 87.3MB calico/node v3.9.2 14a380c92c40 5 months ago 195MB calico/cni v3.9.2 c0d73dd53e71 5 months ago 160MB calico/pod2daemon-flexvol v3.9.2 523f0356e07b 5 months ago 9.78MB gcr.azk8s.cn/google_containers/etcd 3.3.15-0 b2756210eeab 6 months ago 247MB gcr.azk8s.cn/google_containers/coredns 1.6.2 bf261d157914 7 months ago 44.1MB kubernetesui/metrics-scraper v1.0.1 709901356c11 8 months ago 40.1MB gcr.azk8s.cn/google_containers/pause 3.1 da86e6ba6ca1 2 years ago 742kB #启动的容器 8bc24b355d78 kubernetesui/dashboard \"/dashboard --insecu…\" 19 minutes ago Up 19 minutes k8s_kubernetes-dashboard_kubernetes-dashboard-5996555fd8-2ppc5_kubernetes-dashboard_7f46632c-8b7b-41e4-aeb3-a1fbadd29782_0 4ebd793dc31f gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" 19 minutes ago Up 19 minutes k8s_POD_kubernetes-dashboard-5996555fd8-2ppc5_kubernetes-dashboard_7f46632c-8b7b-41e4-aeb3-a1fbadd29782_0 03df44242d90 calico/node \"start_runit\" 6 hours ago Up 6 hours k8s_calico-node_calico-node-89s9k_kube-system_ff5384c4-72b2-4bfa-b8ea-77f38c2a2112_0 c2a56feedc7c calico/pod2daemon-flexvol \"/usr/local/bin/flex…\" 6 hours ago Exited (0) 6 hours ago k8s_flexvol-driver_calico-node-89s9k_kube-system_ff5384c4-72b2-4bfa-b8ea-77f38c2a2112_0 ca9febcebaa8 c0d73dd53e71 \"/install-cni.sh\" 6 hours ago Exited (0) 6 hours ago k8s_install-cni_calico-node-89s9k_kube-system_ff5384c4-72b2-4bfa-b8ea-77f38c2a2112_0 b581894b1b91 calico/cni \"/opt/cni/bin/calico…\" 6 hours ago Exited (0) 6 hours ago k8s_upgrade-ipam_calico-node-89s9k_kube-system_ff5384c4-72b2-4bfa-b8ea-77f38c2a2112_0 2b58aa8cbc01 gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" 6 hours ago Up 6 hours k8s_POD_calico-node-89s9k_kube-system_ff5384c4-72b2-4bfa-b8ea-77f38c2a2112_0 8ff547ee27a4 9b65a0f78b09 \"/usr/local/bin/kube…\" 7 hours ago Up 7 hours k8s_kube-proxy_kube-proxy-zh6cz_kube-system_7a02864d-77cd-4636-ac70-aa56ad8c1df0_0 4c5be9765eaf gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" 7 hours ago Up 7 hours k8s_POD_kube-proxy-zh6cz_kube-system_7a02864d-77cd-4636-ac70-aa56ad8c1df0_0 09ae85c8b8f5 df60c7526a3d \"kube-apiserver --ad…\" 7 hours ago Up 7 hours k8s_kube-apiserver_kube-apiserver-k8s-master_kube-system_a8b1669c873ef7b41dacef818eb65aa9_0 6f17c0d51694 98fecf43a54f \"kube-scheduler --au…\" 7 hours ago Up 7 hours k8s_kube-scheduler_kube-scheduler-k8s-master_kube-system_8abfe947f8f4e810a2308b65bb933780_0 da743be3ec06 bb16442bcd94 \"kube-controller-man…\" 7 hours ago Up 7 hours k8s_kube-controller-manager_kube-controller-manager-k8s-master_kube-system_018dbc8aa2984b8851a80fc82254cb97_0 123d4d44a34f b2756210eeab \"etcd --advertise-cl…\" 7 hours ago Up 7 hours k8s_etcd_etcd-k8s-master_kube-system_6ba6d49a08f1a79cf377b8d0029e9a22_0 c4e04b936c8e gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" 7 hours ago Up 7 hours k8s_POD_kube-apiserver-k8s-master_kube-system_a8b1669c873ef7b41dacef818eb65aa9_0 f9411212bc50 gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" 7 hours ago Up 7 hours k8s_POD_kube-scheduler-k8s-master_kube-system_8abfe947f8f4e810a2308b65bb933780_0 20c18e3366ae gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" 7 hours ago Up 7 hours k8s_POD_etcd-k8s-master_kube-system_6ba6d49a08f1a79cf377b8d0029e9a22_0 1e74a3ddf17b gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" 7 hours ago Up 7 hours k8s_POD_kube-controller-manager-k8s-master_kube-system_018dbc8aa2984b8851a80fc82254cb97_0 1.16.3node启动的容器及下载的镜像 每个node都有的镜像 kube-proxy pause calico/node calico/cni calico/pod2daemon-flexvol coredns、calico/kube-controllers会随机在一个node上 //node1 #下载的镜像 gcr.azk8s.cn/google_containers/kube-proxy v1.16.3 9b65a0f78b09 4 months ago 86.1MB calico/node v3.9.2 14a380c92c40 5 months ago 195MB calico/cni v3.9.2 c0d73dd53e71 5 months ago 160MB calico/kube-controllers v3.9.2 7f7ed50db9fb 5 months ago 56MB calico/pod2daemon-flexvol v3.9.2 523f0356e07b 5 months ago 9.78MB gcr.azk8s.cn/google_containers/coredns 1.6.2 bf261d157914 7 months ago 44.1MB gcr.azk8s.cn/google_containers/pause 3.1 da86e6ba6ca1 2 years ago 742kB #启动的容器 958f160a7e79 calico/kube-controllers \"/usr/bin/kube-contr…\" 4 minutes ago Up 4 minutes k8s_calico-kube-controllers_calico-kube-controllers-dc6cb64cb-c6cng_kube-system_072a1596-42e8-4375-983c-fd6f9b173424_0 f3a7fbbb8e49 gcr.azk8s.cn/google_containers/coredns \"/coredns -conf /etc…\" 5 minutes ago Up 5 minutes k8s_coredns_coredns-667f964f9b-qz88x_kube-system_f18743bb-37af-4e8a-8268-9e328d3e0000_0 18150cf23c39 gcr.azk8s.cn/google_containers/coredns \"/coredns -conf /etc…\" 5 minutes ago Up 5 minutes k8s_coredns_coredns-667f964f9b-sdkc9_kube-system_712e4a15-923a-437b-a1dc-bfefaf30f920_0 e120da514c18 gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" 5 minutes ago Up 5 minutes k8s_POD_calico-kube-controllers-dc6cb64cb-c6cng_kube-system_072a1596-42e8-4375-983c-fd6f9b173424_24 b5e3c36224ad gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" 5 minutes ago Up 5 minutes k8s_POD_coredns-667f964f9b-qz88x_kube-system_f18743bb-37af-4e8a-8268-9e328d3e0000_23 c4cd7571e098 gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" 5 minutes ago Up 5 minutes k8s_POD_coredns-667f964f9b-sdkc9_kube-system_712e4a15-923a-437b-a1dc-bfefaf30f920_24 f497eb8c1b1a calico/node \"start_runit\" 5 minutes ago Up 5 minutes k8s_calico-node_calico-node-rcnts_kube-system_ebfce9a1-ad69-46e7-8e24-e9d3c51678bc_0 a55cab0bd81c calico/pod2daemon-flexvol \"/usr/local/bin/flex…\" 5 minutes ago Exited (0) 5 minutes ago k8s_flexvol-driver_calico-node-rcnts_kube-system_ebfce9a1-ad69-46e7-8e24-e9d3c51678bc_0 4b3f60e0d519 c0d73dd53e71 \"/install-cni.sh\" 6 minutes ago Exited (0) 6 minutes ago k8s_install-cni_calico-node-rcnts_kube-system_ebfce9a1-ad69-46e7-8e24-e9d3c51678bc_0 ee4493f6c482 calico/cni \"/opt/cni/bin/calico…\" 6 minutes ago Exited (0) 6 minutes ago k8s_upgrade-ipam_calico-node-rcnts_kube-system_ebfce9a1-ad69-46e7-8e24-e9d3c51678bc_0 87fe130ab10d gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" 6 minutes ago Up 6 minutes k8s_POD_calico-node-rcnts_kube-system_ebfce9a1-ad69-46e7-8e24-e9d3c51678bc_0 ba408469e7bc gcr.azk8s.cn/google_containers/kube-proxy \"/usr/local/bin/kube…\" 9 minutes ago Up 9 minutes k8s_kube-proxy_kube-proxy-q2tj7_kube-system_3c629796-9972-491a-87e7-3cc14264088e_0 272708e9251a gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" 9 minutes ago Up 9 minutes k8s_POD_kube-proxy-q2tj7_kube-system_3c629796-9972-491a-87e7-3cc14264088e_0 //node2 #下载的镜像 gcr.azk8s.cn/google_containers/kube-proxy v1.16.3 9b65a0f78b09 4 months ago 86.1MB calico/node v3.9.2 14a380c92c40 5 months ago 195MB calico/cni v3.9.2 c0d73dd53e71 5 months ago 160MB calico/pod2daemon-flexvol v3.9.2 523f0356e07b 5 months ago 9.78MB gcr.azk8s.cn/google_containers/pause 3.1 da86e6ba6ca1 2 years ago 742kB #启动的容器 acc3f199861e calico/node \"start_runit\" 6 minutes ago Up 6 minutes k8s_calico-node_calico-node-kdlz8_kube-system_e879923e-1028-4108-bdcc-29b8c7044127_0 8ff828ca0423 calico/pod2daemon-flexvol \"/usr/local/bin/flex…\" 6 minutes ago Exited (0) 6 minutes ago k8s_flexvol-driver_calico-node-kdlz8_kube-system_e879923e-1028-4108-bdcc-29b8c7044127_0 0bd0e1544cf7 c0d73dd53e71 \"/install-cni.sh\" 6 minutes ago Exited (0) 6 minutes ago k8s_install-cni_calico-node-kdlz8_kube-system_e879923e-1028-4108-bdcc-29b8c7044127_0 7bc2a912fda6 calico/cni \"/opt/cni/bin/calico…\" 6 minutes ago Exited (0) 6 minutes ago k8s_upgrade-ipam_calico-node-kdlz8_kube-system_e879923e-1028-4108-bdcc-29b8c7044127_0 1409a1dbc779 gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" 7 minutes ago Up 7 minutes k8s_POD_calico-node-kdlz8_kube-system_e879923e-1028-4108-bdcc-29b8c7044127_0 dda871e9daab gcr.azk8s.cn/google_containers/kube-proxy \"/usr/local/bin/kube…\" 10 minutes ago Up 10 minutes k8s_kube-proxy_kube-proxy-trqdv_kube-system_c572710b-0867-4baf-a629-8262f6511d15_0 a5c5c619ec67 gcr.azk8s.cn/google_containers/pause:3.1 \"/pause\" 10 minutes ago Up 10 minutes k8s_POD_kube-proxy-trqdv_kube-system_c572710b-0867-4baf-a629-8262f6511d15_0 k8s切换命名空间工具 git clone https://github.com.cnpmjs.org/ahmetb/kubectx cp kubectx/kubens /usr/local/bin #查看所有命名空间 kubens #切换到kube-system命名空间 kubens kube-system Context \"kubernetes-admin@kubernetes\" modified. Active namespace is \"kube-system\". 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/k8s/k8s安装/3.使用 kubeadm 搭建 v1.17.4 版本 Kubernetes 集群.html":{"url":"linux/k8s/k8s安装/3.使用 kubeadm 搭建 v1.17.4 版本 Kubernetes 集群.html","title":"1.17","keywords":"","body":"使用 kubeadm 搭建 v1.17.4 版本 Kubernetes 集群 一、环境准备 1.1实验环境 角色 IP地址 主机名 docker版本 硬件配置 系统 内核 master 10.0.0.130 k8s-master 19.03.4 2c2g CentOS7.6 3.10.0-957.el7.x86_64 node1 10.0.0.131 k8s-node1 19.03.4 2c1g CentOS7.6 3.10.0-957.el7.x86_64 node2 10.0.0.132 k8s-node2 19.03.4 2c1g CentOS7.6 3.10.0-957.el7.x86_64 1.2每个节点配置host信息 cat >> /etc/hosts 1.3禁用防火墙和selinux //禁用防火墙 systemctl stop firewalld && systemctl disable firewalld //禁用selinux #临时修改 setenforce 0 #永久修改，重启服务器后生效 sed -i '7s/enforcing/disabled/' /etc/selinux/config 1.4创建/etc/sysctl.d/k8s.conf文件，添加如下内容 //向文件中写入以下内容 cat >/etc/sysctl.d/k8s.conf 1.5安装ipvs(可选) 脚本创建了的/etc/sysconfig/modules/ipvs.modules文件，保证在节点重启后能自动加载所需模块。使用lsmod | grep -e ip_vs -e nf_conntrack_ipv4命令查看是否已经正确加载所需的内核模块 //向文件中写入以下内容 cat > /etc/sysconfig/modules/ipvs.modules 安装ipset和ipvsadm(便于查看 ipvs 的代理规则) yum -y install ipset ipvsadm 1.6同步服务器时间 //安装chrony yum -y install chrony //修改同步服务器地址为阿里云 sed -i.bak '3,6d' /etc/chrony.conf && sed -i '3cserver ntp1.aliyun.com iburst' \\ /etc/chrony.conf //启动chronyd及加入开机自启 systemctl start chronyd && systemctl enable chronyd //查看同步结果 chronyc sources 210 Number of sources = 1 MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^* 120.25.115.20 2 6 37 13 +194us[+6131us] +/- 33ms 1.7关闭swap分区 修改/etc/fstab文件，注释掉 SWAP 的自动挂载，使用free -m确认 swap 已经关闭 //手动关闭swap swapoff -a //修改fstab文件，注释swap自动挂载 sed -i '/^\\/dev\\/mapper\\/centos-swap/c#/dev/mapper/centos-swap swap swap defaults 0 0' /etc/fstab //查看swap是否关闭 free -m total used free shared buff/cache available Mem: 1994 682 612 9 699 1086 Swap: 0 0 0 swappiness 参数调整，修改/etc/sysctl.d/k8s.conf添加下面一行 cat >>/etc/sysctl.d/k8s.conf 1.8安装docker19.03.4 1.卸载旧版本 yum remove -y docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine 2.安装依赖包 yum install -y yum-utils device-mapper-persistent-data lvm2 3.添加阿里云yum源 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 4.查看可用版本 yum list docker-ce --showduplicates | sort -r 已加载插件：fastestmirror, langpacks 可安装的软件包 * updates: mirrors.aliyun.com Loading mirror speeds from cached hostfile * extras: mirrors.aliyun.com docker-ce.x86_64 3:19.03.5-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.4-3.el7 docker-ce-stable 。。。。。。 docker-ce.x86_64 3:18.09.9-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.8-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.7-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.6-3.el7 docker-ce-stable 。。。。。。 5.安装docker19.03.4 yum install -y docker-ce-19.03.4 docker-ce-cli-19.03.4 containerd.io 6.启动docker并设置开机自启 systemctl enable docker && systemctl start docker 7.配置阿里云docker镜像加速 cat > /etc/docker/daemon.json 1.9安装Kubeadm 需要科学上网 cat >/etc/yum.repos.d/kubernetes.repo 使用阿里云yum源 cat >/etc/yum.repos.d/kubernetes.repo 安装 kubeadm、kubelet、kubectl(阿里云yum源会随官方更新最新版，因此指定版本) yum -y install kubelet-1.17.4 kubeadm-1.17.4 kubectl-1.17.4 //查看版本 kubeadm version kubeadm version: &version.Info{Major:\"1\", Minor:\"17\", GitVersion:\"v1.17.4\", GitCommit:\"8d8aa39598534325ad77120c120a22b3a990b5ea\", GitTreeState:\"clean\", BuildDate:\"2020-03-12T21:01:11Z\", GoVersion:\"go1.13.8\", Compiler:\"gc\", Platform:\"linux/amd64\"} 设置kubelet开机自启 ⚠️此时kubelet是无法启动的，因为只有完成master的kubeadm init 的操作，kubelet才能正常启动 systemctl enable kubelet 设置k8s命令自动补全 yum -y install bash-completion source /usr/share/bash-completion/bash_completion source > ~/.bashrc 1.10修改docker Cgroup Driver为systemd #修改docker Cgroup Driver为systemd 将/usr/lib/systemd/system/docker.service文件中的这一行 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock 修改为 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --exec-opt native.cgroupdriver=systemd 如果不修改，在添加 worker 节点时可能会碰到如下错误 [WARNING IsDockerSystemdCheck]: detected \"cgroupfs\" as the Docker cgroup driver. The recommended driver is \"systemd\". Please follow the guide at https://kubernetes.io/docs/setup/cri/ //使用如下命令修改 sed -i.bak \"s#^ExecStart=/usr/bin/dockerd.*#ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --exec-opt native.cgroupdriver=systemd#g\" /usr/lib/systemd/system/docker.service //重启docker systemctl daemon-reload && systemctl restart docker 到此，基本环境安装完成!!! 二、初始化集群 2.1master节点操作，配置 kubeadm 初始化文件 方法一 命令初始化 kubeadm init --apiserver-advertise-address=10.0.0.130 --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.17.4 --service-cidr=10.96.0.0/16 --pod-network-cidr=10.20.0.0/16 --apiserver-advertise-address= #master节点IP --image-repository registry.aliyuncs.com/google_containers #镜像仓库 --kubernetes-version v1.17.4 #k8s版本 --service-cidr=10.96.0.0/16 #service IP网段 --pod-network-cidr=10.20.0.0/16 #pod IP网段，后续网络插件会用到 方法二 文件初始化 cat > kubeadm.yaml 2.2初始化master kubeadm init --config kubeadm.yaml 完整输出结果 W0319 22:59:56.631407 12367 validation.go:28] Cannot validate kubelet config - no validator is available W0319 22:59:56.631444 12367 validation.go:28] Cannot validate kube-proxy config - no validator is available [init] Using Kubernetes version: v1.17.4 [preflight] Running pre-flight checks [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using 'kubeadm config images pull' [kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\" [kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\" [kubelet-start] Starting the kubelet [certs] Using certificateDir folder \"/etc/kubernetes/pki\" [certs] Generating \"ca\" certificate and key [certs] Generating \"apiserver\" certificate and key [certs] apiserver serving cert is signed for DNS names [k8s-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 10.0.0.130] [certs] Generating \"apiserver-kubelet-client\" certificate and key [certs] Generating \"front-proxy-ca\" certificate and key [certs] Generating \"front-proxy-client\" certificate and key [certs] Generating \"etcd/ca\" certificate and key [certs] Generating \"etcd/server\" certificate and key [certs] etcd/server serving cert is signed for DNS names [k8s-master localhost] and IPs [10.0.0.130 127.0.0.1 ::1] [certs] Generating \"etcd/peer\" certificate and key [certs] etcd/peer serving cert is signed for DNS names [k8s-master localhost] and IPs [10.0.0.130 127.0.0.1 ::1] [certs] Generating \"etcd/healthcheck-client\" certificate and key [certs] Generating \"apiserver-etcd-client\" certificate and key [certs] Generating \"sa\" key and public key [kubeconfig] Using kubeconfig folder \"/etc/kubernetes\" [kubeconfig] Writing \"admin.conf\" kubeconfig file [kubeconfig] Writing \"kubelet.conf\" kubeconfig file [kubeconfig] Writing \"controller-manager.conf\" kubeconfig file [kubeconfig] Writing \"scheduler.conf\" kubeconfig file [control-plane] Using manifest folder \"/etc/kubernetes/manifests\" [control-plane] Creating static Pod manifest for \"kube-apiserver\" [control-plane] Creating static Pod manifest for \"kube-controller-manager\" W0319 23:01:45.692056 12367 manifests.go:214] the default kube-apiserver authorization-mode is \"Node,RBAC\"; using \"Node,RBAC\" [control-plane] Creating static Pod manifest for \"kube-scheduler\" W0319 23:01:45.692762 12367 manifests.go:214] the default kube-apiserver authorization-mode is \"Node,RBAC\"; using \"Node,RBAC\" [etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\" [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s [apiclient] All control plane components are healthy after 16.502774 seconds [upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace [kubelet] Creating a ConfigMap \"kubelet-config-1.17\" in namespace kube-system with the configuration for the kubelets in the cluster [upload-certs] Skipping phase. Please see --upload-certs [mark-control-plane] Marking the node k8s-master as control-plane by adding the label \"node-role.kubernetes.io/master=''\" [mark-control-plane] Marking the node k8s-master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule] [bootstrap-token] Using token: abcdef.0123456789abcdef [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [bootstrap-token] Creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace [kubelet-finalize] Updating \"/etc/kubernetes/kubelet.conf\" to point to a rotatable kubelet client certificate and key [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config You should now deploy a pod network to the cluster. Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 10.0.0.130:6443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:27b37276c4451b54c99106f73cb38c3b0bb6e2e178c142808e9ff00300ac7eaf #kubeadm init --config kubeadm.yaml初始化master下载的镜像 registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy v1.17.4 6dec7cfde1e5 6 days ago 116MB registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver v1.17.4 2e1ba57fe95a 6 days ago 171MB registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager v1.17.4 7f997fcf3e94 6 days ago 161MB registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler v1.17.4 5db16c1c7aff 6 days ago 94.4MB registry.cn-hangzhou.aliyuncs.com/google_containers/coredns 1.6.5 70f311871ae1 4 months ago 41.6MB registry.cn-hangzhou.aliyuncs.com/google_containers/etcd 3.4.3-0 303ce5db0e90 4 months ago 288MB registry.cn-hangzhou.aliyuncs.com/google_containers/pause 3.1 da86e6ba6ca1 2 years ago 742kB #启动的容器 5220dac932a8 6dec7cfde1e5 \"/usr/local/bin/kube…\" 2 minutes ago Up 2 minutes k8s_kube-proxy_kube-proxy-jlwfd_kube-system_5af2149d-dc6c-4a6b-a99b-fb0af734d1fb_0 20a9003d1a55 registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 \"/pause\" 2 minutes ago Up 2 minutes k8s_POD_kube-proxy-jlwfd_kube-system_5af2149d-dc6c-4a6b-a99b-fb0af734d1fb_0 48c86b9adbf1 7f997fcf3e94 \"kube-controller-man…\" 3 minutes ago Up 3 minutes k8s_kube-controller-manager_kube-controller-manager-k8s-master_kube-system_c06ae2244175d69b82dd8327536a3f47_0 beed6b3671bd 5db16c1c7aff \"kube-scheduler --au…\" 3 minutes ago Up 3 minutes k8s_kube-scheduler_kube-scheduler-k8s-master_kube-system_0621ae8690c69d1d72f746bc2de0667e_0 fe47bd324d10 2e1ba57fe95a \"kube-apiserver --ad…\" 3 minutes ago Up 3 minutes k8s_kube-apiserver_kube-apiserver-k8s-master_kube-system_ffa9ef4a4e85500fbc6d35b5a88efb43_0 cfbf4d126eae 303ce5db0e90 \"etcd --advertise-cl…\" 3 minutes ago Up 3 minutes k8s_etcd_etcd-k8s-master_kube-system_ba1d164d5064efe1d13e5645859a6dec_0 aff7b239f5ef registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 \"/pause\" 3 minutes ago Up 3 minutes k8s_POD_kube-scheduler-k8s-master_kube-system_0621ae8690c69d1d72f746bc2de0667e_0 1266cf8da7d9 registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 \"/pause\" 3 minutes ago Up 3 minutes k8s_POD_kube-controller-manager-k8s-master_kube-system_c06ae2244175d69b82dd8327536a3f47_0 7415d07612a9 registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 \"/pause\" 3 minutes ago Up 3 minutes k8s_POD_kube-apiserver-k8s-master_kube-system_ffa9ef4a4e85500fbc6d35b5a88efb43_0 fef33ef8bb46 registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 \"/pause\" 3 minutes ago Up 3 minutes k8s_POD_etcd-k8s-master_kube-system_ba1d164d5064efe1d13e5645859a6dec_0 拷贝 kubeconfig 文件 //这里的路径为/root mkdir -p $HOME/.kube cp -i /etc/kubernetes/admin.conf $HOME/.kube/config chown $(id -u):$(id -g) $HOME/.kube/config 2.3master添加节点 node1和node2相同操作 将master节点上的$HOME/.kube/config 文件拷贝到node节点对应的文件中 1.创建目录，这里的路径为/root mkdir -p $HOME/.kube 2.把master节点上的config文件拷贝到node1和node2的$HOME/.kube scp k8s-master:~/.kube/config $HOME/.kube 3.修改权限 chown $(id -u):$(id -g) $HOME/.kube/config 将node1和node2加入到集群中 这里需要用到2.2中初始化master最后生成的token和sha256值 kubeadm join 10.0.0.130:6443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:27b37276c4451b54c99106f73cb38c3b0bb6e2e178c142808e9ff00300ac7eaf 输出结果 W0319 23:06:51.048079 4137 join.go:346] [preflight] WARNING: JoinControlPane.controlPlane settings will be ignored when control-plane flag is not set. [preflight] Running pre-flight checks [preflight] Reading configuration from the cluster... [preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' [kubelet-start] Downloading configuration for the kubelet from the \"kubelet-config-1.17\" ConfigMap in the kube-system namespace [kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\" [kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\" [kubelet-start] Starting the kubelet [kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap... This node has joined the cluster: * Certificate signing request was sent to apiserver and a response was received. * The Kubelet was informed of the new secure connection details. Run 'kubectl get nodes' on the control-plane to see this node join the cluster. 将node节点加入到k8s集群后，node节点会运行kube-proxy #下载的镜像 registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy v1.17.4 6dec7cfde1e5 6 days ago 116MB registry.cn-hangzhou.aliyuncs.com/google_containers/pause 3.1 da86e6ba6ca1 2 years ago 742kB #启动的容器 f8dff6a9caf5 registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy \"/usr/local/bin/kube…\" About a minute ago Up About a minute k8s_kube-proxy_kube-proxy-g8lfq_kube-system_72e60b6a-0023-4d25-b8e0-73e98bb4b1ea_0 64752d1e78b3 registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 \"/pause\" 2 minutes ago Up 2 minutes k8s_POD_kube-proxy-g8lfq_kube-system_72e60b6a-0023-4d25-b8e0-73e98bb4b1ea_0 如果忘记了token和sha256值，可以在master节点使用如下命令查看 //查看token kubeadm token list TOKEN TTL EXPIRES USAGES DESCRIPTION EXTRA GROUPS abcdef.0123456789abcdef 23h 2020-03-20T23:02:03+08:00 authentication,signing system:bootstrappers:kubeadm:default-node-token //查看sha256 openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //' 27b37276c4451b54c99106f73cb38c3b0bb6e2e178c142808e9ff00300ac7eaf //同时查看token和sha256 kubeadm token create --print-join-command W0319 23:07:44.720182 16201 validation.go:28] Cannot validate kube-proxy config - no validator is available W0319 23:07:44.720215 16201 validation.go:28] Cannot validate kubelet config - no validator is available kubeadm join 10.0.0.130:6443 --token 36t7ur.rtigrd344emr5urd --discovery-token-ca-cert-hash sha256:27b37276c4451b54c99106f73cb38c3b0bb6e2e178c142808e9ff00300ac7eaf master节点查看node，发现状态都是NotReady，因为还没有安装网络插件，这里我们安装calio官方插件文档 kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-master NotReady master 19m v1.15.3 k8s-node1 NotReady 4m10s v1.15.3 k8s-node2 NotReady 4m3s v1.15.3 2.4master节点安装网络插件calio //下载文件 wget https://kuboard.cn/install-script/calico/calico-3.13.1.yaml https://docs.projectcalico.org //修改完成后安装calico网络插件 kubectl apply -f calico-3.13.1.yaml //安装完成后稍等一会查看pods状态 kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE calico-kube-controllers-788d6b9876-4lls7 1/1 Running 0 5m58s calico-node-jfn5g 1/1 Running 0 5m59s calico-node-k6f84 1/1 Running 0 5m59s calico-node-vm4m6 1/1 Running 0 5m59s coredns-7f9c544f75-5p2mf 1/1 Running 0 30m coredns-7f9c544f75-prdlb 1/1 Running 0 30m etcd-k8s-master 1/1 Running 0 30m kube-apiserver-k8s-master 1/1 Running 0 30m kube-controller-manager-k8s-master 1/1 Running 0 30m kube-proxy-g8lfq 1/1 Running 0 25m kube-proxy-jlwfd 1/1 Running 0 30m kube-proxy-x8twc 1/1 Running 0 25m kube-scheduler-k8s-master 1/1 Running 0 30m //查看node状态 kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-master Ready master 30m v1.17.4 k8s-node1 Ready 25m v1.17.4 k8s-node2 Ready 25m v1.17.4 #kubectl apply -f calico-3.13.1.yaml安装网络插件calico下载的镜像 calico/node v3.13.1 2e5029b93d4a 6 days ago 260MB calico/pod2daemon-flexvol v3.13.1 e8c600448aae 6 days ago 111MB calico/cni v3.13.1 6912ec2cfae6 6 days ago 207MB #启动的容器 70d8a967cc69 calico/node \"start_runit\" 2 minutes ago Up 2 minutes k8s_calico-node_calico-node-jfn5g_kube-system_b86bd096-addf-4665-8a72-ec7c9e4a97f9_0 f9830c017734 calico/pod2daemon-flexvol \"/usr/local/bin/flex…\" 4 minutes ago Exited (0) 4 minutes ago k8s_flexvol-driver_calico-node-jfn5g_kube-system_b86bd096-addf-4665-8a72-ec7c9e4a97f9_0 8fe868ba10d4 6912ec2cfae6 \"/install-cni.sh\" 5 minutes ago Exited (0) 5 minutes ago k8s_install-cni_calico-node-jfn5g_kube-system_b86bd096-addf-4665-8a72-ec7c9e4a97f9_0 ae71689904ca calico/cni \"/opt/cni/bin/calico…\" 5 minutes ago Exited (0) 5 minutes ago k8s_upgrade-ipam_calico-node-jfn5g_kube-system_b86bd096-addf-4665-8a72-ec7c9e4a97f9_0 node节点 #都有的镜像 calico/node calico/pod2daemon-flexvol calico/cni #calico/kube-controllers 、registry.cn-hangzhou.aliyuncs.com/google_containers/coredns会随机在一个node上 2.5安装Dashboard 下载文件及修改内容 这里查看dashboard对应的k8s版本 //下载文件 v2.0.0-rc3是中文版本，beta8是英文版本 wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta8/aio/deploy/recommended.yaml wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-rc3/aio/deploy/recommended.yaml //修改Service为NodePort类型 42行下增加一行 nodePort: 30001 44行下增加一行 type: NodePort //原先内容 spec: ports: - port: 443 targetPort: 8443 selector: k8s-app: kubernetes-dashboard //修改后内容 spec: ports: - port: 443 targetPort: 8443 nodePort: 30001 #增加，指定nodeport端口 selector: k8s-app: kubernetes-dashboard type: NodePort #增加，修改类型为nodeport 部署dashboard #kubectl apply -f recommended.yaml #下载的镜像 kubernetesui/dashboard v2.0.0-rc3 4a0a1cf1b459 6 weeks ago 126MB #启动的容器 62a551c0a0e6 kubernetesui/dashboard \"/dashboard --insecu…\" 9 seconds ago Up 8 seconds k8s_kubernetes-dashboard_kubernetes-dashboard-7867cbccbb-z9vzj_kubernetes-dashboard_de95d4c3-6234-4f7a-8d80-d326c52b65c0_0 查看dashboard的运行状态及外网访问端口 //查看dashboard运行状态 kubectl get pods -n kubernetes-dashboard -l k8s-app=kubernetes-dashboard NAME READY STATUS RESTARTS AGE kubernetes-dashboard-7867cbccbb-z9vzj 1/1 Running 0 50s //查看dashboard外网访问端口 kubectl get svc -n kubernetes-dashboard -l k8s-app=kubernetes-dashboard NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes-dashboard NodePort 10.96.222.222 443:30001/TCP 82s 通过上边的30001端口访问dashboard，注意是https ⚠️k8s1.16.3这个版本中，使用的dashboard版本是2.0.0-beta8，只有火狐浏览器可以访问，其余浏览器都不能访问，会报错如下 只有火狐浏览器可以！ 然后创建一个具有全局所有权限的用户来登录Dashboard //编辑admin.yaml文件 cat > admin.yaml 然后粘贴上述生成的base64字符串登陆dashboard，在登陆页面选择令牌一项 登陆后的首界面 2.6安装kuboard(可选) kuboard是Kubernetes 的一款图形化管理界面 安装kuboard kubectl apply -f https://kuboard.cn/install-script/kuboard.yaml kubectl apply -f https://addons.kuboard.cn/metrics-server/0.3.6/metrics-server.yaml 查看运行状态 #kubectl get pods -l k8s.eip.work/name=kuboard -n kube-system NAME READY STATUS RESTARTS AGE kuboard-756d46c4d4-tvhjq 1/1 Running 0 40s 获取token //获取管理员token kubectl -n kube-system get secret $(kubectl -n kube-system get secret | grep kuboard-user | awk '{print $1}') -o go-template='{{.data.token}}' | base64 -d && echo //获取只读token kubectl -n kube-system get secret $(kubectl -n kube-system get secret | grep kuboard-viewer | awk '{print $1}') -o go-template='{{.data.token}}' | base64 -d && echo 访问kuboard Kuboard Service 使用了 NodePort 的方式暴露服务，NodePort 为 32567 k8s集群的任意一个节点都可以访问到 登陆首界面 kuboard下载的镜像和启动的容器 #启动的容器 11171ab07891 eipwork/kuboard \"/entrypoint.sh\" 3 minutes ago Up 3 minutes k8s_kuboard_kuboard-756d46c4d4-jfx4t_kube-system_8f509c5b-fbee-40b0-8d74-9f2b8485639a_0d #下载的镜像，本文中为1.0.8.2版本 eipwork/kuboard latest c6d652bbdf90 About an hour ago 180MB 到此，使用kubeadm安装k8s 1.17.4完成！！！ 获取令牌命令 kubectl get secret `kubectl get secret -n kube-system|grep admin-token|awk '{print $1}'` -o jsonpath={.data.token} -n kube-system |base64 -d && echo 1.17.4master启动的容器及下载的镜像 #启动的容器 11171ab07891 eipwork/kuboard \"/entrypoint.sh\" 4 minutes ago Up 4 minutes k8s_kuboard_kuboard-756d46c4d4-jfx4t_kube-system_8f509c5b-fbee-40b0-8d74-9f2b8485639a_0 f8e5d82cf8ee registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 \"/pause\" 6 minutes ago Up 6 minutes k8s_POD_kuboard-756d46c4d4-jfx4t_kube-system_8f509c5b-fbee-40b0-8d74-9f2b8485639a_0 62a551c0a0e6 kubernetesui/dashboard \"/dashboard --insecu…\" 10 hours ago Up 10 hours k8s_kubernetes-dashboard_kubernetes-dashboard-7867cbccbb-z9vzj_kubernetes-dashboard_de95d4c3-6234-4f7a-8d80-d326c52b65c0_0 40ad4724f6f1 registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 \"/pause\" 10 hours ago Up 10 hours k8s_POD_kubernetes-dashboard-7867cbccbb-z9vzj_kubernetes-dashboard_de95d4c3-6234-4f7a-8d80-d326c52b65c0_0 70d8a967cc69 calico/node \"start_runit\" 10 hours ago Up 10 hours k8s_calico-node_calico-node-jfn5g_kube-system_b86bd096-addf-4665-8a72-ec7c9e4a97f9_0 f9830c017734 calico/pod2daemon-flexvol \"/usr/local/bin/flex…\" 10 hours ago Exited (0) 10 hours ago k8s_flexvol-driver_calico-node-jfn5g_kube-system_b86bd096-addf-4665-8a72-ec7c9e4a97f9_0 8fe868ba10d4 6912ec2cfae6 \"/install-cni.sh\" 10 hours ago Exited (0) 10 hours ago k8s_install-cni_calico-node-jfn5g_kube-system_b86bd096-addf-4665-8a72-ec7c9e4a97f9_0 ae71689904ca calico/cni \"/opt/cni/bin/calico…\" 10 hours ago Exited (0) 10 hours ago k8s_upgrade-ipam_calico-node-jfn5g_kube-system_b86bd096-addf-4665-8a72-ec7c9e4a97f9_0 cd04477d7393 registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 \"/pause\" 10 hours ago Up 10 hours k8s_POD_calico-node-jfn5g_kube-system_b86bd096-addf-4665-8a72-ec7c9e4a97f9_0 5220dac932a8 6dec7cfde1e5 \"/usr/local/bin/kube…\" 10 hours ago Up 10 hours k8s_kube-proxy_kube-proxy-jlwfd_kube-system_5af2149d-dc6c-4a6b-a99b-fb0af734d1fb_0 20a9003d1a55 registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 \"/pause\" 10 hours ago Up 10 hours k8s_POD_kube-proxy-jlwfd_kube-system_5af2149d-dc6c-4a6b-a99b-fb0af734d1fb_0 48c86b9adbf1 7f997fcf3e94 \"kube-controller-man…\" 10 hours ago Up 10 hours k8s_kube-controller-manager_kube-controller-manager-k8s-master_kube-system_c06ae2244175d69b82dd8327536a3f47_0 beed6b3671bd 5db16c1c7aff \"kube-scheduler --au…\" 10 hours ago Up 10 hours k8s_kube-scheduler_kube-scheduler-k8s-master_kube-system_0621ae8690c69d1d72f746bc2de0667e_0 fe47bd324d10 2e1ba57fe95a \"kube-apiserver --ad…\" 10 hours ago Up 10 hours k8s_kube-apiserver_kube-apiserver-k8s-master_kube-system_ffa9ef4a4e85500fbc6d35b5a88efb43_0 cfbf4d126eae 303ce5db0e90 \"etcd --advertise-cl…\" 10 hours ago Up 10 hours k8s_etcd_etcd-k8s-master_kube-system_ba1d164d5064efe1d13e5645859a6dec_0 aff7b239f5ef registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 \"/pause\" 10 hours ago Up 10 hours k8s_POD_kube-scheduler-k8s-master_kube-system_0621ae8690c69d1d72f746bc2de0667e_0 1266cf8da7d9 registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 \"/pause\" 10 hours ago Up 10 hours k8s_POD_kube-controller-manager-k8s-master_kube-system_c06ae2244175d69b82dd8327536a3f47_0 7415d07612a9 registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 \"/pause\" 10 hours ago Up 10 hours k8s_POD_kube-apiserver-k8s-master_kube-system_ffa9ef4a4e85500fbc6d35b5a88efb43_0 fef33ef8bb46 registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 \"/pause\" 10 hours ago Up 10 hours k8s_POD_etcd-k8s-master_kube-system_ba1d164d5064efe1d13e5645859a6dec_0 #下载的镜像 eipwork/kuboard latest c6d652bbdf90 2 days ago 180MB registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy v1.17.4 6dec7cfde1e5 7 days ago 116MB registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver v1.17.4 2e1ba57fe95a 7 days ago 171MB registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager v1.17.4 7f997fcf3e94 7 days ago 161MB registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler v1.17.4 5db16c1c7aff 7 days ago 94.4MB calico/node v3.13.1 2e5029b93d4a 7 days ago 260MB calico/pod2daemon-flexvol v3.13.1 e8c600448aae 7 days ago 111MB calico/cni v3.13.1 6912ec2cfae6 7 days ago 207MB kubernetesui/dashboard v2.0.0-rc3 4a0a1cf1b459 7 weeks ago 126MB registry.cn-hangzhou.aliyuncs.com/google_containers/coredns 1.6.5 70f311871ae1 4 months ago 41.6MB registry.cn-hangzhou.aliyuncs.com/google_containers/etcd 3.4.3-0 303ce5db0e90 4 months ago 288MB registry.cn-hangzhou.aliyuncs.com/google_containers/pause 3.1 da86e6ba6ca1 2 years ago 742kB 1.17.4node启动的容器和下载的镜像 #启动的容器 59b6a4cd2f44 registry.cn-hangzhou.aliyuncs.com/google_containers/coredns \"/coredns -conf /etc…\" 10 hours ago Up 10 hours k8s_coredns_coredns-7f9c544f75-prdlb_kube-system_77f42046-8348-4247-b37b-6ce3dc62db18_0 c73eac71d7e4 calico/kube-controllers \"/usr/bin/kube-contr…\" 10 hours ago Up 10 hours k8s_calico-kube-controllers_calico-kube-controllers-788d6b9876-4lls7_kube-system_25992c41-0bfe-4e84-8a04-70b63c969627_0 947909b16d67 registry.cn-hangzhou.aliyuncs.com/google_containers/coredns \"/coredns -conf /etc…\" 10 hours ago Up 10 hours k8s_coredns_coredns-7f9c544f75-5p2mf_kube-system_305e69d6-6ae6-4c48-a32d-6dddc290fa8a_0 e2b467f4fb14 registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 \"/pause\" 10 hours ago Up 10 hours k8s_POD_coredns-7f9c544f75-prdlb_kube-system_77f42046-8348-4247-b37b-6ce3dc62db18_104 a5683b681459 registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 \"/pause\" 10 hours ago Up 10 hours k8s_POD_coredns-7f9c544f75-5p2mf_kube-system_305e69d6-6ae6-4c48-a32d-6dddc290fa8a_105 11a2725d9030 registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 \"/pause\" 10 hours ago Up 10 hours k8s_POD_calico-kube-controllers-788d6b9876-4lls7_kube-system_25992c41-0bfe-4e84-8a04-70b63c969627_104 a0064abf6347 calico/node \"start_runit\" 10 hours ago Up 10 hours k8s_calico-node_calico-node-vm4m6_kube-system_de38b605-5188-4db0-8123-061bb253be9d_0 ad86e37926e4 calico/pod2daemon-flexvol \"/usr/local/bin/flex…\" 10 hours ago Exited (0) 10 hours ago k8s_flexvol-driver_calico-node-vm4m6_kube-system_de38b605-5188-4db0-8123-061bb253be9d_0 0946ccc79ba8 6912ec2cfae6 \"/install-cni.sh\" 10 hours ago Exited (0) 10 hours ago k8s_install-cni_calico-node-vm4m6_kube-system_de38b605-5188-4db0-8123-061bb253be9d_0 fee74eaf355d calico/cni \"/opt/cni/bin/calico…\" 10 hours ago Exited (0) 10 hours ago k8s_upgrade-ipam_calico-node-vm4m6_kube-system_de38b605-5188-4db0-8123-061bb253be9d_0 7635ac40c020 registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 \"/pause\" 10 hours ago Up 10 hours k8s_POD_calico-node-vm4m6_kube-system_de38b605-5188-4db0-8123-061bb253be9d_0 f8dff6a9caf5 registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy \"/usr/local/bin/kube…\" 10 hours ago Up 10 hours k8s_kube-proxy_kube-proxy-g8lfq_kube-system_72e60b6a-0023-4d25-b8e0-73e98bb4b1ea_0 64752d1e78b3 registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 \"/pause\" 10 hours ago Up 10 hours k8s_POD_kube-proxy-g8lfq_kube-system_72e60b6a-0023-4d25-b8e0-73e98bb4b1ea_0 #下载的镜像 registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy v1.17.4 6dec7cfde1e5 7 days ago 116MB calico/node v3.13.1 2e5029b93d4a 7 days ago 260MB calico/pod2daemon-flexvol v3.13.1 e8c600448aae 7 days ago 111MB calico/cni v3.13.1 6912ec2cfae6 7 days ago 207MB calico/kube-controllers v3.13.1 3971f13f2c6c 7 days ago 56.6MB registry.cn-hangzhou.aliyuncs.com/google_containers/coredns 1.6.5 70f311871ae1 4 months ago 41.6MB registry.cn-hangzhou.aliyuncs.com/google_containers/pause 3.1 da86e6ba6ca1 2 years ago 742kB k8s切换命名空间工具 git clone https://github.com.cnpmjs.org/ahmetb/kubectx cp kubectx/kubens /usr/local/bin #查看所有命名空间 kubens #切换到kube-system命名空间 kubens kube-system Context \"kubernetes-admin@kubernetes\" modified. Active namespace is \"kube-system\". 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/k8s/k8s安装/8.centos8.2二进制安装单master k8s1.18.5.html":{"url":"linux/k8s/k8s安装/8.centos8.2二进制安装单master k8s1.18.5.html","title":"1.18","keywords":"","body":"centos8.2二进制安装单master k8s1.18.5 一、环境准备 单master架构图 1.1 实验环境 角色 IP地址 主机名 docker版本 硬件配置 系统 内核 安装组件 master1 10.0.0.30 k8s-master1 19.03.4 2c4g CentOS8.2 4.18.0-193.el8.x86_64 kube-apiserver，kube-controller-manager，kube-scheduler，etcd node1 10.0.0.33 k8s-node1 19.03.4 2c4g CentOS8.2 4.18.0-193.el8.x86_64 kubelet，kube-proxy，docker，etcd node2 10.0.0.34 k8s-node2 19.03.4 2c4g CentOS8.2 4.18.0-193.el8.x86_64 kubelet，kube-proxy，docker，etcd CentOS8.2采用最小化安装，并执行了以下脚本 #!/usr/bin/env bash # #修改系统yum源为aliyun并添加epel源 mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bak [ ! -e /etc/yum.repos.d/CentOS-Base.repo ] && curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-8.repo dnf clean all dnf makecache yum install -y https://mirrors.aliyun.com/epel/epel-release-latest-8.noarch.rpm sed -i 's|^#baseurl=https://download.fedoraproject.org/pub|baseurl=https://mirrors.aliyun.com|' /etc/yum.repos.d/epel* sed -i 's|^metalink|#metalink|' /etc/yum.repos.d/epel* dnf -y install tar wget net-tools git vim tree lrzsz htop iftop iotop psmisc python36 python3-devel zlib zlib-devel gcc gcc-c++ conntrack-tools jq socat bash-completion telnet nload strace tcpdump lsof sysstat #关闭防火墙、selinux、NetworkManager systemctl disable firewalld NetworkManager sed -i '7s/enforcing/disabled/' /etc/selinux/config #同步时间计划任务 #rpm -ivh http://mirrors.wlnmp.com/centos/wlnmp-release-centos.noarch.rpm && dnf -y install wntp #sed -i '/*\\/10 \\* \\* \\* \\* \\/usr\\/sbin\\/ntpdate ntp2\\.aliyun\\.com &>\\/dev\\/null/d' /var/spool/cron/root #echo \"*/10 * * * * /usr/local/bin/ntpdate ntp2.aliyun.com &>/dev/null\" >>/var/spool/cron/root #历史命令显示时间 sed -i '/HISTFILESIZE=2000/d' /etc/bashrc sed -i '/HISTSIZE=2000/d' /etc/bashrc sed -i '/HISTTIMEFORMAT=\"%Y-%m-%d %H:%M:%S \"/d' /etc/bashrc sed -i '/export HISTTIMEFORMAT/d' /etc/bashrc cat >>/etc/bashrc>/etc/security/limits.conf~/.pip/pip.conf 1.2 配置master节点可以免密登陆node节点 生成密钥对 ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa &>/dev/null 编辑expect自动化交互脚本 这里机器用户名是root，密码是国际标准通用密码1 cat >ssh.exp 编辑shell脚本循环执行expect脚本 #编辑脚本 cat > ssh.sh 1.3 编辑环境变量脚本 mkdir -p /opt/k8s/script cat >/opt/k8s/script/env.sh 1.4 每个节点配置host信息 source /opt/k8s/script/env.sh for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" ssh root@${node_ip} 'cat >> /etc/hosts 1.5 禁用防火墙和selinux source /opt/k8s/script/env.sh for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" ssh root@${node_ip} 'systemctl stop firewalld && systemctl disable firewalld && setenforce 0' done #永久修改，重启服务器后生效 sed -i '7s/enforcing/disabled/' /etc/selinux/config 1.6 关闭swap ⚠️centos7中是 /dev/mapper/centos-swap swap swap defaults 0 0 ⚠️centos8中/dev/mapper/cl-swap swap swap defaults 0 0 source /opt/k8s/script/env.sh for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" ssh root@${node_ip} \"swapoff -a && sed -i 's/^\\/dev\\/mapper\\/cl-swap/#&/' /etc/fstab\" done 1.7 将桥接的IPv4流量传递到iptables的链 source /opt/k8s/script/env.sh for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" ssh root@${node_ip} 'cat >/etc/sysctl.d/k8s.conf 1.6 配置时间同步 master节点操作 source /opt/k8s/script/env.sh for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" ssh root@${node_ip} dnf -y install chrony done #修改服务器地址为阿里云 sed -i -e '/^pool/cserver ntp1.aliyun.com iburst' -e '/^#allow/callow 10.0.0.0/24' /etc/chrony.conf #node节点修改同步服务器为master节点 export NODE_IPS=(10.0.0.33 10.0.0.34) for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" ssh root@${node_ip} sed -in '/^pool/cserver\\ k8s-master1\\ iburst' /etc/chrony.conf done #启动NTP服务并设置开机自启 source /opt/k8s/script/env.sh for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" ssh root@${node_ip} 'systemctl enable chronyd && systemctl start chronyd' done #检查端口，chronyd监听udp323端口 source /opt/k8s/script/env.sh for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" ssh root@${node_ip} netstat -nupl|grep chronyd done #正确输出 >>> 10.0.0.30 udp 0 0 127.0.0.1:323 0.0.0.0:* 4535/chronyd udp6 0 0 ::1:323 :::* 4535/chronyd >>> 10.0.0.33 udp 0 0 127.0.0.1:323 0.0.0.0:* 5984/chronyd udp6 0 0 ::1:323 :::* 5984/chronyd >>> 10.0.0.34 udp 0 0 127.0.0.1:323 0.0.0.0:* 5674/chronyd udp6 0 0 ::1:323 :::* 5674/chronyd #验证同步服务器 for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" ssh root@${node_ip} chronyc sources done #正确输出 >>> 10.0.0.30 210 Number of sources = 1 MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^* 120.25.115.20 2 6 17 7 +5664us[+8204us] +/- 34ms >>> 10.0.0.33 210 Number of sources = 1 MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^* k8s-master1 3 6 17 3 -632us[ +70us] +/- 4645ms >>> 10.0.0.34 210 Number of sources = 1 MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^* k8s-master1 3 6 17 2 -33us[ -93us] +/- 4940ms 二、创建CA根证书和秘钥 CA根证书说明 为确保安全，kubernetes 系统各组件需要使用 x509 证书对通信进行加密和认证。 CA (Certificate Authority) 是自签名的根证书，用来签名后续创建的其它证书。 CA证书是集群所有节点共享的，只需要创建一次，后续用它签名其它所有证书。 本文档使用 CloudFlare 的 PKI 工具集 cfssl 创建所有证书。 2.1 创建存放CA根证书的目录 mkdir -p /opt/k8s/cert && cd /opt/k8s/cert 2.2 下载并配置cfssl工具集 cfssl官网 cfssl github地址 cfssl是一个开源的证书管理工具，使用json文件生成证书，相比openssl更方便使用。 #下载cfssl工具集 wget https://github.com/cloudflare/cfssl/releases/download/v1.4.1/cfssl-certinfo_1.4.1_linux_amd64 wget https://github.com/cloudflare/cfssl/releases/download/v1.4.1/cfssljson_1.4.1_linux_amd64 wget https://github.com/cloudflare/cfssl/releases/download/v1.4.1/cfssl_1.4.1_linux_amd64 #给予执行权限 chmod +x cfssl* #修改名称并移动到/usr/local/bin mv cfssl_1.4.1_linux_amd64 /usr/local/bin/cfssl mv cfssljson_1.4.1_linux_amd64 /usr/local/bin/cfssljson mv cfssl-certinfo_1.4.1_linux_amd64 /usr/local/bin/cfssl-certinfo 2.3 创建CA根证书配置文件 cd /opt/k8s/cert cat > ca-config.json 配置文件中的一些参数说明 signing：表示该证书可用于签名其它证书（生成的 ca.pem 证书中 CA=TRUE）； server auth：表示 client 可以用该该证书对 server 提供的证书进行验证； client auth：表示 server 可以用该该证书对 client 提供的证书进行验证； \"expiry\": \"876000h\"：证书有效期设置为 100 年； 2.4 创建证书签名请求文件 cd /opt/k8s/cert cat > ca-csr.json 配置文件中的一些参数说明 CN：Common Name：kube-apiserver 从证书中提取该字段作为请求的用户名 (User Name)，浏览器使用该字段验证网站是否合法； O：Organization：kube-apiserver 从证书中提取该字段作为请求用户所属的组 (Group)； kube-apiserver 将提取的 User、Group 作为 RBAC 授权的用户标识； ⚠️注意： 不同证书 csr 文件的 CN、C、ST、L、O、OU 组合必须不同，否则可能出现 PEER'S CERTIFICATE HAS AN INVALID SIGNATURE 错误； 后续创建证书的 csr 文件时，CN 都不相同（C、ST、L、O、OU 相同），以达到区分的目的； 2.5 生成 CA 证书和私钥 cd /opt/k8s/cert cfssl gencert -initca ca-csr.json | cfssljson -bare ca ls ca*pem #命令执行成功后会生成如下3个文件 ca.csr ca-key.pem ca.pem 三、部署etcd集群 etcd 是基于 Raft 的分布式 KV 存储系统，由 CoreOS 开发，常用于服务发现、共享配置以及并发控制（如 leader 选举、分布式锁等）。 kubernetes 使用 etcd 集群持久化存储所有 API 对象、运行数据。 本文档介绍部署一个三节点高可用 etcd 集群的步骤： 下载和分发 etcd 二进制文件； 创建 etcd 集群各节点的 x509 证书，用于加密客户端(如 etcdctl) 与 etcd 集群、etcd 集群之间的通信； 创建 etcd 的 systemd unit 文件，配置服务参数； 检查集群工作状态； etcd 集群节点名称和 IP 如下： k8s-master1：10.0.0.30 k8s-node1：10.0.0.33 k8s-node2：10.0.0.34 3.1 创建etcd证书和私钥 3.1.1 创建证书签名请求 hosts：指定授权使用该证书的 etcd 节点 IP 列表，需要将 etcd 集群所有节点 IP 都列在其中 ⚠️文件中的IP是etcd节点的IP，哪些节点部署了etcd就写哪些节点的IP，为了方便后期扩展这里还可以多写几个IP cd /opt/k8s/cert cat > etcd-csr.json 3.1.2 生成证书和私钥 cd /opt/k8s/cert cfssl gencert -ca=ca.pem \\ -ca-key=ca-key.pem \\ -config=ca-config.json \\ -profile=kubernetes etcd-csr.json | cfssljson -bare etcd ls etcd*pem #以上命令执行成功后会生成如下文件 etcd.csr etcd-key.pem etcd.pem 3.2 下载etcd二进制文件 etcd github地址 etcd官网 创建目录 mkdir /opt/k8s/etcd && cd /opt/k8s/etcd 下载二进制文件 wget https://github.com/etcd-io/etcd/releases/download/v3.4.9/etcd-v3.4.9-linux-amd64.tar.gzr tar xf etcd-v3.4.9-linux-amd64.tar.gz 拷贝etcd命令到/usr/local/bin cp etcd-v3.4.9-linux-amd64/{etcd,etcdctl} /usr/local/bin 3.3 创建etcd配置文件 这里先创建一个template模版，后续会用sed替换 mkdir /opt/k8s/etcd/cfg && cd /opt/k8s/etcd/cfg cat > etcd.conf.template etcd配置文件参数说明 参数 说明 ETCD_NAME 节点名称，集群中唯一 ETCD_DATA_DIR 数据目录 ETCD_LISTEN_PEER_URLS 集群通信监听地址 ETCD_LISTEN_CLIENT_URLS 客户端访问监听地址 ETCD_INITIAL_ADVERTISE_PEER_URLS 集群通告地址 ETCD_ADVERTISE_CLIENT_URLS 客户端通告地址 ETCD_INITIAL_CLUSTER 集群节点地址 ETCD_INITIAL_CLUSTER_TOKEN 集群Token ETCD_INITIAL_CLUSTER_STATE 加入集群的当前状态，new是新集群，existing表示加入已有集群 3.4 使用systemd管理etcd cat > /usr/lib/systemd/system/etcd.service 3.5 拷贝相关文件到其余node节点 拷贝证书 export NODE_IPS=(10.0.0.33 10.0.0.34) for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" ssh root@${node_ip} mkdir -p /opt/k8s/cert scp -p /opt/k8s/cert/{etcd-key.pem,etcd.pem,ca-key.pem,ca.pem} root@${node_ip}:/opt/k8s/cert done 拷贝systemd文件 export NODE_IPS=(10.0.0.33 10.0.0.34) for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" scp -r /usr/lib/systemd/system/etcd.service root@${node_ip}:/usr/lib/systemd/system/ done 拷贝etcd配置文件 #先做sed替换，把之前的模版文件中的NODE_IP和ETCD_NAME替换成相对应的 source /opt/k8s/script/env.sh cd /opt/k8s/etcd/cfg for (( i=0; i etcd-${NODE_IPS[i]}.conf done #拷贝etcd配置文件 for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" ssh root@${node_ip} mkdir -p /opt/k8s/etcd/cfg scp etcd-${node_ip}.conf root@${node_ip}:/opt/k8s/etcd/cfg/etcd.conf done 拷贝etcd命令 export NODE_IPS=(10.0.0.33 10.0.0.34) for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" scp -p /usr/local/bin/{etcd,etcdctl} root@${node_ip}:/usr/local/bin done 3.6 启动etcd source /opt/k8s/script/env.sh for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" ssh root@${node_ip} \"systemctl daemon-reload && systemctl enable etcd && systemctl restart etcd \" & done 检查启动结果，确保状态为 active (running)，否则使用命令journalctl -u etcd查看日志，确认原因 source /opt/k8s/script/env.sh for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" ssh root@${node_ip} \"systemctl status etcd|grep Active\" done 正确输出 >>> 10.0.0.30 Active: active (running) since Tue 2020-07-07 00:39:54 CST; 1min 5s ago >>> 10.0.0.33 Active: active (running) since Tue 2020-07-07 00:39:54 CST; 1min 5s ago >>> 10.0.0.34 Active: active (running) since Tue 2020-07-07 00:39:54 CST; 1min 5s ago 3.7 验证服务状态 部署完 etcd 集群后，在任一 etcd 节点上执行如下命令 source /opt/k8s/script/env.sh for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" /usr/local/bin/etcdctl \\ --endpoints=https://${node_ip}:2379 \\ --cacert=/opt/k8s/cert/ca.pem \\ --cert=/opt/k8s/cert/etcd.pem \\ --key=/opt/k8s/cert/etcd-key.pem endpoint health done 正确输出 >>> 10.0.0.30 https://10.0.0.30:2379 is healthy: successfully committed proposal: took = 7.228637ms >>> 10.0.0.33 https://10.0.0.33:2379 is healthy: successfully committed proposal: took = 7.620834ms >>> 10.0.0.34 https://10.0.0.34:2379 is healthy: successfully committed proposal: took = 6.689841ms 3.8 查看当前etcd集群 leader export ETCD_ENDPOINTS=\"https://10.0.0.30:2379,https://10.0.0.33:2379,https://10.0.0.34:2379\" etcdctl \\ -w table --cacert=/opt/k8s/cert/ca.pem \\ --cert=/opt/k8s/cert/etcd.pem \\ --key=/opt/k8s/cert/etcd-key.pem \\ --endpoints=${ETCD_ENDPOINTS} endpoint status 输出结果，可见当前的 etcd leader 是10.0.0.30 +------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+ | ENDPOINT | ID | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS | +------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+ | https://10.0.0.30:2379 | dd4b95995dc266b1 | 3.4.9 | 16 kB | true | false | 2 | 8 | 8 | | | https://10.0.0.33:2379 | f1ec1f6015c9d4a4 | 3.4.9 | 20 kB | false | false | 2 | 8 | 8 | | | https://10.0.0.34:2379 | 22353e8ece256e71 | 3.4.9 | 20 kB | false | false | 2 | 8 | 8 | | +------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+ 四、安装docker docker官网 docker-ce github地址 docker官方二进制下载地址 所有节点操作 4.1 下载二进制安装包并解压缩 创建目录 mkdir /opt/k8s/docker && cd /opt/k8s/docker 下载包并解压缩 wget https://download.docker.com/linux/static/stable/x86_64/docker-19.03.12.tgz tar xf docker-19.03.12.tgz 4.2 导出docker命令环境变量 cd /opt/k8s/docker source /opt/k8s/script/env.sh for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" scp -p docker/* root@${node_ip}:/usr/local/bin done 4.3 使用systemd管理docker cat > /usr/lib/systemd/system/docker.service 把docker systemd文件拷贝到所有node节点 export NODE_IPS=(10.0.0.33 10.0.0.34) for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" scp -p /usr/lib/systemd/system/docker.service root@${node_ip}:/usr/lib/systemd/system/docker.service done 4.4 创建docker配置文件 所有机器配置加速源并配置docker的启动参数使用systemd，使用systemd是官方的建议 mkdir /etc/docker cat > /etc/docker/daemon.json 拷贝docker配置文件到node节点 export NODE_IPS=(10.0.0.33 10.0.0.34) for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" ssh root@${node_ip} mkdir /etc/docker scp -p /etc/docker/daemon.json root@${node_ip}:/etc/docker/daemon.json done 4.5 启动docker并设置开机自启 source /opt/k8s/script/env.sh for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" ssh root@${node_ip} \"systemctl daemon-reload && systemctl enable docker && systemctl start docker \" done 4.6 检查docker启动状态 确保所有节点docker都为running状态 source /opt/k8s/script/env.sh for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" ssh root@${node_ip} \"systemctl status docker|grep Active\" done 正确输出 >>> 10.0.0.30 Active: active (running) since Tue 2020-07-07 09:07:57 CST; 21s ago >>> 10.0.0.33 Active: active (running) since Tue 2020-07-07 09:07:58 CST; 20s ago >>> 10.0.0.34 Active: active (running) since Tue 2020-07-07 09:07:59 CST; 20s ago 4.7 设置docker命令自动补全 yum安装的docker会有一个文件/usr/share/bash-completion/completions/docker，这个文件就是自动补全docker命令的文件，二进制安装的没有，把这个文件拷贝过来即可 五、部署Mster Node kubernetes master 节点运行如下组件： kube-apiserver kube-scheduler kube-controller-manager 5.1 部署 kube-apiserver 5.1.1 生成 kube-apiserver 证书和私钥 创建证书签名请求 cd /opt/k8s/cert cat > kube-apiserver-csr.json 生成证书和私钥 /opt/k8s/cert cfssl gencert -ca=ca.pem \\ -ca-key=ca-key.pem \\ -config=ca-config.json \\ -profile=kubernetes kube-apiserver-csr.json | cfssljson -bare kube-apiserver ls kube-api*pem #上述命令执行成功后会生成如下文件 kube-apiserver.csr kube-apiserver-key.pem kube-apiserver.pem 5.1.2 下载 kubernetes-server 二进制包 mkdir /opt/k8s/kubernetes-server && cd /opt/k8s/kubernetes-server wget https://dl.k8s.io/v1.18.5/kubernetes-server-linux-amd64.tar.gz tar xf kubernetes-server-linux-amd64.tar.gz 导出命令 cp kubernetes/server/bin/{apiextensions-apiserver,kubeadm,kube-apiserver,kube-controller-manager,kubectl,kubelet,kube-proxy,kube-scheduler,mounter} /usr/local/bin/ 5.1.3 创建 kube-apiserver 配置文件 mkdir /opt/k8s/{cfg,logs} cat > /opt/k8s/cfg/kube-apiserver.conf –logtostderr：启用日志 —v：日志等级 –log-dir：日志目录 –etcd-servers：etcd集群地址 –bind-address：监听地址 –secure-port：https安全端口 –advertise-address：集群通告地址 –allow-privileged：启用授权 –service-cluster-ip-range：Service虚拟IP地址段 –enable-admission-plugins：准入控制模块 –authorization-mode：认证授权，启用RBAC授权和节点自管理 –enable-bootstrap-token-auth：启用TLS bootstrap机制 –token-auth-file：bootstrap token文件 –service-node-port-range：Service nodeport类型默认分配端口范围 –kubelet-client-xxx：apiserver访问kubelet客户端证书 –tls-xxx-file：apiserver https证书 –etcd-xxxfile：连接Etcd集群证书 –audit-log-xxx：审计日志 5.1.4 启用 TLS Bootstrapping 机制 TLS Bootstraping： Master apiserver启用TLS认证后，Node节点kubelet和kube-proxy要与kube-apiserver进行通信，必须使用CA签发的有效证书才可以，当Node节点很多时，这种客户端证书颁发需要大量工作，同样也会增加集群扩展复杂度。为了简化流程，Kubernetes引入了TLS bootstraping机制来自动颁发客户端证书，kubelet会以一个低权限用户自动向apiserver申请证书，kubelet的证书由apiserver动态签署。所以强烈建议在Node上使用这种方式，目前主要用于kubelet，kube-proxy还是由我们统一颁发一个证书。 TLS bootstraping 工作流程： 创建kube-apiserver配置文件中/opt/k8s/cfg/kube-apiserver.conf指定的 --token-auth-file=/opt/k8s/cfg/token.csv 格式：token，用户名，UID，用户组 cd /opt/k8s/cfg export TOKEN_CSV=`head -c 16 /dev/urandom | od -An -t x | tr -d ' '` cat > /opt/k8s/cfg/token.csv 5.1.5 使用systemd管理kube-apiserver cat > /usr/lib/systemd/system/kube-apiserver.service 5.1.6 启动 kube-apiserver 并设置开机自启 systemctl daemon-reload systemctl start kube-apiserver && systemctl enable kube-apiserver 检查 kube-apiserver 是否正确启动，如果没有正确启动，使用命令journalctl -u kube-apiserver查看日志 $ systemctl status kube-apiserver |grep Active Active: active (running) since Tue 2020-07-07 10:01:15 CST; 37s ago 5.1.7 授权 kubelet-bootstrap 用户允许请求证书 kubectl create clusterrolebinding kubelet-bootstrap \\ --clusterrole=system:node-bootstrapper \\ --user=kubelet-bootstrap 5.2 部署 kube-controller-manager 5.2.1 创建配置文件 cat > /opt/k8s/cfg/kube-controller-manager.conf –master：通过本地非安全端口8080连接apiserver。 –leader-elect：当该组件启动多个时，自动选举（HA） –cluster-signing-cert-file/–cluster-signing-key-file：自动为kubelet颁发证书的CA，与apiserver保持一致 5.2.2 systemd管理 kube-controller-manager cat > /usr/lib/systemd/system/kube-controller-manager.service 5.2.3 启动 kube-controller-manager 并设置开机自启 systemctl daemon-reload systemctl start kube-controller-manager && systemctl enable kube-controller-manager 检查 kube-controller-manager 是否正确启动，如果没有正确启动，使用命令journalctl -u kube-controller-manager查看日志 $ systemctl status kube-controller-manager |grep Active Active: active (running) since Tue 2020-07-07 10:01:15 CST; 37s ago 5.3 部署 kube-scheduler 5.3.1 创建 kube-scheduler 配置文件 cat > /opt/k8s/cfg/kube-scheduler.conf –master：通过本地非安全本地端口8080连接apiserver。 –leader-elect：当该组件启动多个时，自动选举（HA） 5.3.2 使用systemd管理 kube-scheduler cat > /usr/lib/systemd/system/kube-scheduler.service 5.3.3 启动 kube-scheduler 并设置开机自启 systemctl daemon-reload systemctl start kube-scheduler && systemctl enable kube-scheduler 检查 kube-scheduler 是否正确启动，如果没有正确启动，使用命令journalctl -u kube-scheduler查看日志 $ systemctl status kube-scheduler |grep Active Active: active (running) since Wed 2020-07-08 09:45:23 CST; 44s ago 5.4 k8s命令自动补全、切换命名空间 5.4.1 设置k8s命令自动补全 dnf -y install bash-completion source /usr/share/bash-completion/bash_completion source > ~/.bashrc 5.4.2 配置k8s切换命名空间工具 #克隆工具 git clone https://github.com.cnpmjs.org/ahmetb/kubectx cp kubectx/kubens /usr/local/bin #查看所有命名空间 $ kubens #切换到kube-system命名空间 $ kubens kube-system Context \"kubernetes-admin@kubernetes\" modified. Active namespace is \"kube-system\". 5.5 查看Master Node节点集群状态 $ kubectl get cs NAME STATUS MESSAGE ERROR scheduler Healthy ok controller-manager Healthy ok etcd-2 Healthy {\"health\":\"true\"} etcd-0 Healthy {\"health\":\"true\"} etcd-1 Healthy {\"health\":\"true\"} 六、部署Worker Node kubernetes worker 节点运行如下组件： kubelet kube-proxy flannel ⚠️如果后续有pod需要部署在master节点，则在master节点也需要部署kubelet和kube-proxy ⚠️这里把master节点也复用为node节点，即master节点上部署node 6.1 Worker Node节点创建工作目录 在所有worker node节点创建工作目录 export NODE_IPS=(10.0.0.33 10.0.0.34) for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" ssh root@${node_ip} mkdir -p /opt/k8s/{logs,cfg} done 6.2 部署 kubelet 6.2.1 创建 kukelet 配置文件 pause-amd64:3.0原先地址是gcr.io/google-containers/pause-amd64:3.0 ⚠️kubelet配置文件中的--hostname-override要与主机名相对应 先做一个模版，后续会用sed替换文件中的主机名--hostname-override mkdir /opt/k8s/kubelet && cd /opt/k8s/kubelet cat > kubelet.template –hostname-override：显示名称，集群中唯一 –network-plugin：启用CNI –kubeconfig：空路径，会自动生成，后面用于连接apiserver –bootstrap-kubeconfig：首次启动向apiserver申请证书 –config：配置参数文件 –cert-dir：kubelet证书生成目录 –pod-infra-container-image：管理Pod网络容器的镜像 使用sed做替换 source /opt/k8s/script/env.sh cd /opt/k8s/kubelet for (( i=0; i kubelet-${NODE_IPS[i]}.conf done #替换完成后会生成如下文件，每一个节点文件中的--hostname-override就是自己的主机名 ls *.conf kubelet-10.0.0.30.conf kubelet-10.0.0.33.conf kubelet-10.0.0.34.conf 拷贝文件到所有节点 source /opt/k8s/script/env.sh cd /opt/k8s/kubelet for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" scp kubelet-${node_ip}.conf root@${node_ip}:/opt/k8s/cfg/kubelet.conf done 6.2.2 创建 kubelet 参数配置文件 ⚠️因为安装的docker已经使用了systemd，因此参数配置文件中的cgroupDriver: systemd也要做修改 source /opt/k8s/script/env.sh for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" ssh root@${node_ip} 'cat > /opt/k8s/cfg/kubelet-config.yml 6.2.3 生成bootstrap.kubeconfig文件 这个配置文件就是能让kubelet连接kube-apiserver，去请求颁发证书 cd /opt/k8s/cfg export KUBE_APISERVER=\"https://10.0.0.30:6443\" # apiserver IP:PORT export TOKEN=`awk -F, '{print $1}' /opt/k8s/cfg/token.csv` # 与token.csv里保持一致 # 生成 kubelet bootstrap kubeconfig 配置文件 kubectl config set-cluster kubernetes \\ --certificate-authority=/opt/k8s/cert/ca.pem \\ --embed-certs=true \\ --server=${KUBE_APISERVER} \\ --kubeconfig=bootstrap.kubeconfig kubectl config set-credentials \"kubelet-bootstrap\" \\ --token=${TOKEN} \\ --kubeconfig=bootstrap.kubeconfig kubectl config set-context default \\ --cluster=kubernetes \\ --user=\"kubelet-bootstrap\" \\ --kubeconfig=bootstrap.kubeconfig kubectl config use-context default --kubeconfig=bootstrap.kubeconfig 拷贝bootstrap.kubeconfig到node节点 export NODE_IPS=(10.0.0.33 10.0.0.34) /opt/k8s/cfg for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" scp bootstrap.kubeconfig root@${node_ip}:/opt/k8s/cfg done 6.2.4 拷贝kubelet、kube-proxy命令到node节点 export NODE_IPS=(10.0.0.33 10.0.0.34) for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" scp -p /usr/local/bin/{kubelet,kube-proxy} ${node_ip}:/usr/local/bin done 6.2.5 使用systemd管理 kubelet cat > /usr/lib/systemd/system/kubelet.service 拷贝文件到node节点 export NODE_IPS=(10.0.0.33 10.0.0.34) for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" scp -p /usr/lib/systemd/system/kubelet.service root@${node_ip}:/usr/lib/systemd/system done 6.2.6 启动 kubelet 并设置开机自启 source /opt/k8s/script/env.sh for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" ssh root@${node_ip} 'systemctl daemon-reload && systemctl start kubelet && systemctl enable kubelet' done 验证 kubelet 启动状态 source /opt/k8s/script/env.sh for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" ssh root@${node_ip} 'systemctl status kubelet|grep active' done 正确输出 >>> 10.0.0.30 Active: active (running) since Tue 2020-07-07 13:27:37 CST; 19s ago >>> 10.0.0.33 Active: active (running) since Tue 2020-07-07 13:27:52 CST; 4s ago >>> 10.0.0.34 Active: active (running) since Tue 2020-07-07 13:27:52 CST; 4s ago 6.2.7 批准kubelet证书申请并加入集群 ⚠️当kubelet启动成功的时候就会有节点过来请求颁发证书，使用命令kubectl get csr查看 查看kukelet证书请求，可以看到有3个节点请求颁发证书 $ kubectl get csr NAME AGE SIGNERNAME REQUESTOR CONDITION node-csr-4YfUpgFR7xndRzDFy4HHOfvRhO_p7iucRgB8dGptrIM 2m53s kubernetes.io/kube-apiserver-client-kubelet kubelet-bootstrap Pending node-csr-Fh0hY-oE3W6d7_TlO06d-eV9CD93iF3r3dSQSk9dtSo 2m37s kubernetes.io/kube-apiserver-client-kubelet kubelet-bootstrap Pending node-csr-kG8QBmV1SUcR39FGV2JtSDpJzEHxlRpJnEJhLv2W7fI 2m38s kubernetes.io/kube-apiserver-client-kubelet kubelet-bootstrap Pending 使用命令kubectl certificate approve csr名车批准申请 #使用如下命令批量操作 for i in `kubectl get csr|awk 'NR>1{print $1}'` do kubectl certificate approve $i done certificatesigningrequest.certificates.k8s.io/node-csr-4YfUpgFR7xndRzDFy4HHOfvRhO_p7iucRgB8dGptrIM approved certificatesigningrequest.certificates.k8s.io/node-csr-Fh0hY-oE3W6d7_TlO06d-eV9CD93iF3r3dSQSk9dtSo approved certificatesigningrequest.certificates.k8s.io/node-csr-kG8QBmV1SUcR39FGV2JtSDpJzEHxlRpJnEJhLv2W7fI approved 再次查看kubelet证书请求 $ kubectl get csr NAME AGE SIGNERNAME REQUESTOR CONDITION node-csr-4YfUpgFR7xndRzDFy4HHOfvRhO_p7iucRgB8dGptrIM 6m35s kubernetes.io/kube-apiserver-client-kubelet kubelet-bootstrap Approved,Issued node-csr-Fh0hY-oE3W6d7_TlO06d-eV9CD93iF3r3dSQSk9dtSo 6m19s kubernetes.io/kube-apiserver-client-kubelet kubelet-bootstrap Approved,Issued node-csr-kG8QBmV1SUcR39FGV2JtSDpJzEHxlRpJnEJhLv2W7fI 6m20s kubernetes.io/kube-apiserver-client-kubelet kubelet-bootstrap Approved,Issued 6.3 部署 kube-proxy 6.3.1 创建 kube-proxy 配置文件 export NODE_IPS=(10.0.0.30 10.0.0.33 10.0.0.34) for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" ssh root@${node_ip} 'cat > /opt/k8s/cfg/kube-proxy.conf 6.3.2 创建 kube-proxy 参数文件 先生成一个模版文件，后续会用sed替换文件中的主机名hostnameOverride mkdir /opt/k8s/kube-proxy && cd /opt/k8s/kube-proxy cat > kube-proxy-config.yml.template 使用sed做替换 source /opt/k8s/script/env.sh cd /opt/k8s/kube-proxy for (( i=0; i kube-proxy-config-${NODE_IPS[i]}.yml done #替换完成后会生成如下文件，每一个节点文件中的hostnameOverride就是本机主机名 ls kube*.yml kube-proxy-config-10.0.0.30.yml kube-proxy-config-10.0.0.33.yml kube-proxy-config-10.0.0.34.yml 拷贝文件到所有节点 source /opt/k8s/script/env.sh cd /opt/k8s/kube-proxy for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" scp kube-proxy-config-${node_ip}.yml root@${node_ip}:/opt/k8s/cfg/kube-proxy-config.yml done 6.3.3 生成kube-proxy证书 创建证书请求文件 cd /opt/k8s/cert cat > kube-proxy-csr.json 生成证书 cfssl gencert -ca=/opt/k8s/cert/ca.pem -ca-key=/opt/k8s/cert/ca-key.pem -config=/opt/k8s/cert/ca-config.json -profile=kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxy #以上命令执行成功后会生成如下文件 ls kube-proxy*pem kube-proxy-key.pem kube-proxy.pem kube-proxy.csr 6.3.3 生成 kube-proxy.kubeconfig 文件 export KUBE_APISERVER=\"https://10.0.0.30:6443\" cd /opt/k8s/cfg kubectl config set-cluster kubernetes \\ --certificate-authority=/opt/k8s/cert/ca.pem \\ --embed-certs=true \\ --server=${KUBE_APISERVER} \\ --kubeconfig=kube-proxy.kubeconfig kubectl config set-credentials kube-proxy \\ --client-certificate=/opt/k8s/cert/kube-proxy.pem \\ --client-key=/opt/k8s/cert/kube-proxy-key.pem \\ --embed-certs=true \\ --kubeconfig=kube-proxy.kubeconfig kubectl config set-context default \\ --cluster=kubernetes \\ --user=kube-proxy \\ --kubeconfig=kube-proxy.kubeconfig kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig 拷贝 kube-proxy.kubeconfig 到node节点 export NODE_IPS=(10.0.0.33 10.0.0.34) cd /opt/k8s/cfg for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" scp -p kube-proxy.kubeconfig root@${node_ip}:/opt/k8s/cfg done 6.3.4 使用systemd管理 kube-proxy cat > /usr/lib/systemd/system/kube-proxy.service 拷贝文件到node节点 export NODE_IPS=(10.0.0.33 10.0.0.34) for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" scp -p /usr/lib/systemd/system/kube-proxy.service root@${node_ip}:/usr/lib/systemd/system done 6.3.5 启动 kube-proxy 并设置开机自启 source /opt/k8s/script/env.sh for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" ssh root@${node_ip} 'systemctl daemon-reload && systemctl start kube-proxy && systemctl enable kube-proxy' done 验证 kube-proxy 启动状态 source /opt/k8s/script/env.sh for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" ssh root@${node_ip} 'systemctl status kube-proxy|grep active' done 正确输出 >>> 10.0.0.30 Active: active (running) since Tue 2020-07-07 14:06:01 CST; 10s ago >>> 10.0.0.33 Active: active (running) since Tue 2020-07-07 14:03:18 CST; 2min 53s ago >>> 10.0.0.34 Active: active (running) since Tue 2020-07-07 14:03:18 CST; 2min 53s ago 6.4 部署CNI网络 创建目录 mkdir /opt/k8s/cni && cd /opt/k8s/cni 下载安装包 wget https://github.com/containernetworking/plugins/releases/download/v0.8.6/cni-plugins-linux-amd64-v0.8.6.tgz 导出命令 包解压后全是可执行的二进制文件 mkdir -p /opt/cni/bin tar xf cni-plugins-linux-amd64-v0.8.6.tgz -C /opt/cni/bin 拷贝命令到node节点 source /opt/k8s/script/env.sh for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" scp -rp /opt/cni root@${node_ip}:/opt done 下载yaml文件 #下载yaml文件并替换镜像仓库地址 cd /opt/k8s/cni wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml sed -i -r \"s#quay.io/coreos/flannel:.*-amd64#pptfz/flannel:v0.12.0-amd64#g\" kube-flannel.yml 部署CNI网络 kubectl apply -f kube-flannel.yml 6.5 授权apiserver访问kubelet cd /opt/k8s/cfg cat > apiserver-to-kubelet-rbac.yaml 6.6 验证 网络插件flannel pod状态必须全部为running $ kubectl -n kube-system get pods NAME READY STATUS RESTARTS AGE kube-flannel-ds-amd64-ncrzv 1/1 Running 0 11m kube-flannel-ds-amd64-spn7q 1/1 Running 0 11m kube-flannel-ds-amd64-vk5qr 1/1 Running 0 11m 网络部署完成后，所有节点状态就都变为了Ready $ kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-master1 Ready 18m v1.18.5 k8s-node1 Ready 18m v1.18.5 k8s-node2 Ready 18m v1.18.5 删除node节点的kubelet证书文件 ⚠️这几个文件是证书申请审批后自动生成的，每个Node不同，必须删除重新生成 export NODE_IPS=(10.0.0.33 10.0.0.34) for node_ip in ${NODE_IPS[@]} do echo \">>> ${node_ip}\" ssh root@${node_ip} rm -rf /opt/k8s/cert/kubelet* done 七、部署CoreDNS 创建目录 mkdir /opt/k8s/coredns && cd /opt/k8s/coredns 下载CoreDNS项目 git clone https://github.com.cnpmjs.org/coredns/deployment.git cd deployment/kubernetes 默认情况下 CLUSTER_DNS_IP 是自动获取kube-dns的集群ip的，但是由于没有部署kube-dns所以只能手动指定一个集群ip。 编辑文件deploy.sh，注释文件中的 CLUSTER_DNS_IP=$(kubectl get service --namespace kube-system kube-dns -o jsonpath=\"{.spec.clusterIP}\")，修改为CLUSTER_DNS_IP=172.16.0.2，因为在kubelet参数配置文件/opt/k8s/cfg/kubelet-config.yml中指定了clusterDNS=172.16.0.2 #原先内容 103行处 if [[ -z $CLUSTER_DNS_IP ]]; then # Default IP to kube-dns IP CLUSTER_DNS_IP=$(kubectl get service --namespace kube-system kube-dns -o jsonpath=\"{.spec.clusterIP}\") #修改为如下 if [[ -z $CLUSTER_DNS_IP ]]; then # Default IP to kube-dns IP # CLUSTER_DNS_IP=$(kubectl get service --namespace kube-system kube-dns -o jsonpath=\"{.spec.clusterIP}\") CLUSTER_DNS_IP=172.16.0.2 部署CoreDNS #查看执行效果，并未真正开始部署 ./deploy.sh #执行部署 ./deploy.sh | kubectl apply -f - # 查看 CoreDNS $ kubectl get svc,pods -n kube-system| grep coredns pod/coredns-85b4878f78-2ndvz 0/1 Running 0 9s 测试 CoreDNS 解析 mkdir /opt/k8s/yaml && cd /opt/k8s/yaml cat > busybox.yaml #返回以下内容说明解析正常 $ kubectl exec -i busybox -n default nslookup kubernetes kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl kubectl exec [POD] -- [COMMAND] instead. Server: 172.16.0.2 Address 1: 172.16.0.2 kube-dns.kube-system.svc.cluster.local Name: kubernetes Address 1: 172.16.0.1 kubernetes.default.svc.cluster.local 八、部署dashboard 8.1 部署官方dashboard 下载yaml文件 cd /opt/k8s/yaml wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.3/aio/deploy/recommended.yaml 默认Dashboard只能集群内部访问，修改Service为NodePort类型，暴露到外部 #原先内容 spec: ports: - port: 443 targetPort: 8443 selector: k8s-app: kubernetes-dashboard #修改为如下 spec: ports: - port: 443 targetPort: 8443 nodePort: 30001 type: NodePort selector: k8s-app: kubernetes-dashboard 创建dashboard #应用文件 kubectl apply -f recommended.yaml #查看pod运行状态 $ kubectl get pods -A |grep kubernetes-dashboard kubernetes-dashboard dashboard-metrics-scraper-6b4884c9d5-lrz94 1/1 Running 0 47s kubernetes-dashboard kubernetes-dashboard-7f99b75bf4-ndztw 1/1 Running 0 47s 创建service account并绑定默认cluster-admin管理员集群角色 kubectl create serviceaccount dashboard-admin -n kube-system kubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin 查看token kubectl describe secrets -n kube-system $(kubectl -n kube-system get secret | awk '/dashboard-admin/{print $1}') 浏览器访问 https://集群任意节点IP:30001 ⚠️只能用火狐浏览器访问 登陆后首界面 8.2 部署kuboard kuboard官网 安装 kubectl apply -f https://kuboard.cn/install-script/kuboard.yaml kubectl apply -f https://addons.kuboard.cn/metrics-server/0.3.6/metrics-server.yaml 查看kuboard运行状态 $ kubectl get pods -l k8s.kuboard.cn/name=kuboard -n kube-system NAME READY STATUS RESTARTS AGE kuboard-7bb89b4cc4-7rqh4 1/1 Running 0 78s 获取管理员token，此Token拥有 ClusterAdmin 的权限，可以执行所有操作 echo $(kubectl -n kube-system get secret $(kubectl -n kube-system get secret | grep kuboard-user | awk '{print $1}') -o go-template='{{.data.token}}' | base64 -d) 访问kuboard Kuboard Service 使用了 NodePort 的方式暴露服务，NodePort 为 32567，浏览器访问http://任意一个Worker节点的IP地址:32567/ 登陆后首界面 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/k8s/k8s证书/kubeam安装k8s生成的证书.html":{"url":"linux/k8s/k8s证书/kubeam安装k8s生成的证书.html","title":"kubeadm","keywords":"","body":"本文严重抄袭至互联网 傻傻分不清楚的kubernetes证书 kubeadm 生成的一坨证书是不是让人很蒙逼，这些东西没那么神奇，来深入扒扒其内裤。 root@k8s-master:/etc/kubernetes/pki# tree . |-- apiserver.crt |-- apiserver-etcd-client.crt |-- apiserver-etcd-client.key |-- apiserver.key |-- apiserver-kubelet-client.crt |-- apiserver-kubelet-client.key |-- ca.crt |-- ca.key |-- etcd | |-- ca.crt | |-- ca.key | |-- healthcheck-client.crt | |-- healthcheck-client.key | |-- peer.crt | |-- peer.key | |-- server.crt | `-- server.key |-- front-proxy-ca.crt |-- front-proxy-ca.key |-- front-proxy-client.crt |-- front-proxy-client.key |-- sa.key `-- sa.pub 1 directory, 22 files 从RSA说起 要深入了解证书的作用，首先需要了解一些原理和具备一些基本知识，比如什么是非对称加密，什么是公钥，私钥，数字签名是啥等。先从RSA算法说起。 非对称加密会生成一个密钥对，如上面的sa.key sa.pub就是密钥对，一个用于加密一个用于解密。 明文 + 公钥 => 密文 密文 + 私钥 => 明文 那么此时没有私钥，就很难把密文解密。 进一步再详细看看其原理, 不想关注的可以跳过下面原理部分： 假设我们想加密一个单词Caesar, 先把它变成一串数字，比如Ascii码 X = 067097101115097114 这也就是我们需要加密的 明码。 现在来对X进行加密。 找两个很大的质数 P 和 Q 计算他们的乘积 N = P * Q 再令M = (P - 1)(Q - 1) 找到一个数E满足E和M除了1以外没有公约数 找到一个数D满足E乘以D除以M余1, E * D mod M = 1 现在 E就是公钥，可以公开给任何人进行加密 D就是私钥，用于解密，一定要自己保存好 联系公钥和私钥的N是公开的, 为什么这个可以公开，就是因为根据P Q算出N很简单，但是把N分解成P Q两个大质数非常的难，所以公开了现有的计算机算力也很难破解 现在来加密： pow(X,E) mod N = Y Y就是密文，现在没有D(私钥) 神仙也没法算出X(明文) 解密： pow(Y,D) mod N = X X是明文，明文就出来了。 数学是不是很神奇，现在可认为 sa.key = D sa.pub = E 数字签名 假设你写一封信给老板，内容是\"老板我崇拜你\"，然后让同事把信送给老板，怎么确定这信就是你写的，而且怎么防止同事送信过程中把信改成 \"老板你是个SB\"? 可以这样做，首先你生成一个密钥对，把公钥给老板，然后对信的内容做一个hash摘要，再用私钥对摘要进行加密，结果就是签名 这样老板拿到信之后用公钥进行解密，发现得到的hash值与信的hash值是一致的，这样确定了信就是你写的 所以数字签名是加密技术的一种运用，与完全加密信息的区别是这里信息是公开的，你的同事可以看到你吹捧老板。 数字证书 根证书与证书 通常我们配置https服务时需要到\"权威机构\"申请证书。 过程是这样的： 网站创建一个密钥对，提供公钥和组织以及个人信息给权威机构 权威机构颁发证书 浏览网页的朋友利用权威机构的根证书公钥解密签名，对比摘要，确定合法性 客户端验证域名信息有效时间等（浏览器基本都内置各大权威机构的CA公钥） 这个证书包含如下内容： 申请者公钥 申请者组织和个人信息 签发机构CA信息，有效时间，序列号等 以上信息的签名 根证书又名自签名证书，也就是自己给自己颁发的证书。CA(Certificate Authority)被称为证书授权中心，k8s中的ca证书就是根证书。 kubernetes证书 有了以上基础，下面咱们正式开始。。。 先分类： 密钥对：sa.key sa.pub 根证书：ca.crt etcd/ca 私钥 ： ca.key 等 其它证书 首先其它证书都是由CA根证书颁发的，kubernetes与etcd使用了不同的CA, 很重要的一点是证书是用于客户端校验还是服务端校验。 下面一个一个来看： service Account密钥对 sa.key sa.pub 提供给 kube-controller-manager 使用. kube-controller-manager 通过 sa.key 对 token 进行签名, master 节点通过公钥 sa.pub 进行签名的验证 如 kube-proxy 是以 pod 形式运行的, 在 pod 中, 直接使用 service account 与 kube-apiserver 进行认证, 此时就不需要再单独为 kube-proxy 创建证书了, 会直接使用token校验 根证书 pki/ca.crt pki/ca.key 为k8s集群证书签发机构 apiserver 证书 pki/apiserver.crt pki/apiserver.key kubelet证书 pki/apiserver-kubelet-client.crt pki/apiserver-kubelet-client.key kubelet要主动访问kube-apiserver, kube-apiserver也需要主动向kubelet发起请求, 所以双方都需要有自己的根证书以及使用该根证书签发的服务端证书和客户端证书. 在kube-apiserver中, 一般明确指定用于https访问的服务端证书和带有CN用户名信息的客户端证书. 而在kubelet的启动配置中, 一般只指定了ca根证书, 而没有明确指定用于https访问的服务端证书,在生成服务端证书时, 一般会指定服务端地址或主机名, kube-apiserver相对变化不是很频繁, 所以在创建集群之初就可以预先分配好用作 kube-apiserver的IP 或主机名/域名, 但是由于部署在node节点上的kubelet会因为集群规模的变化而频繁变化, 而无法预知node的所有IP信息, 所以kubelet上一般不会明确指定服务端证书, 而是只指定ca根证书, 让kubelet根据本地主机信息自动生成服务端证书并保存到配置的cert-dir文件夹中 Aggregation 证书 代理根证书： pki/front-proxy-ca.crt pki/front-proxy-ca.key 由代理根证书签发的客户端证书： pki/front-proxy-client.crt pki/front-proxy-client.key 比如使用kubectl proxy代理访问时，kube-apiserver使用这个证书来验证客户端证书是否是自己签发的证书。 etcd 根证书 pki/etcd/ca.crt pki/etcd/ca.key etcd节点间相互通信 peer证书 由根证书签发 pki/etcd/peer.crt pki/etcd/peer.key pod中Liveness探针客户端证书 pki/etcd/healthcheck-client.crt pki/etcd/healthcheck-client.key 可查看yaml探活配置： Liveness: exec [/bin/sh -ec ETCDCTL_API=3 etcdctl \\ --endpoints=https://[127.0.0.1]:2379 \\ --cacert=/etc/kubernetes/pki/etcd/ca.crt \\ --cert=/etc/kubernetes/pki/etcd/healthcheck-client.crt \\ --key=/etc/kubernetes/pki/etcd/healthcheck-client.key get foo] \\ delay=15s timeout=15s period=10s #success=1 #failure=8 apiserver访问etcd的证书 pki/apiserver-etcd-client.crt pki/apiserver-etcd-client.key 这里注意一下客户端证书与服务端证书区别，服务端证书通常会校验地址域名等。 代码实现 kubeadm把证书时间写死成了1年（client-go就写死了），这是个悲伤的故事，导致sealos不得不把证书生成的逻辑剥离出来以让安装支持任意过期时间。 下面根据源码来深入体验下kubeadm的证书生成，直接看kubeadm代码可能有点累，sealos/cert目录剥离出核心的代码更容易读懂一些。 以下为了突出核心逻辑，代码中删除一些错误处理细节，有兴趣可阅读github.com/fanux/sealos/cert源码 密钥对生成 // create sa.key sa.pub for service Account func GenerateServiceAccountKeyPaire(dir string) error { key, err := NewPrivateKey(x509.RSA) pub := key.Public() err = WriteKey(dir, \"sa\", key) return WritePublicKey(dir, \"sa\", pub) } 生成私钥, 这里的keyType是x509.RSA func NewPrivateKey(keyType x509.PublicKeyAlgorithm) (crypto.Signer, error) { if keyType == x509.ECDSA { return ecdsa.GenerateKey(elliptic.P256(), rand.Reader) } return rsa.GenerateKey(rand.Reader, rsaKeySize) } 生成CA证书 会返回ca.crt（自签名证书） ca.key(私钥) func NewCaCertAndKey(cfg Config) (*x509.Certificate, crypto.Signer, error) { key, err := NewPrivateKey(x509.UnknownPublicKeyAlgorithm) cert, err := NewSelfSignedCACert(key, cfg.CommonName, cfg.Organization, cfg.Year) return cert, key, nil } 根据私钥生成自签名证书, NotAfter就是证书过期时间，我们很友好的加了个变量而不是写死： // NewSelfSignedCACert creates a CA certificate func NewSelfSignedCACert(key crypto.Signer, commonName string, organization []string, year time.Duration) (*x509.Certificate, error) { now := time.Now() tmpl := x509.Certificate{ SerialNumber: new(big.Int).SetInt64(0), Subject: pkix.Name{ CommonName: commonName, Organization: organization, }, NotBefore: now.UTC(), NotAfter: now.Add(duration365d * year).UTC(), KeyUsage: x509.KeyUsageKeyEncipherment | x509.KeyUsageDigitalSignature | x509.KeyUsageCertSign, BasicConstraintsValid: true, IsCA: true, } certDERBytes, err := x509.CreateCertificate(rand.Reader, &tmpl, &tmpl, key.Public(), key) return x509.ParseCertificate(certDERBytes) } 非常要注意里面的CommonName和Organization字段，非常有用，比如我们创建一个k8s用户指定该用户属于哪个用户组，对应上面这两个字段。 比如证书中 fanux 属于 sealyun这个组织，那么生成一个kubeconfig, 就相当于有了fanux这个用户，这样k8s在做认证时只需要校验签名就行，而不需要去访问 数据库来做认证，这非常有利于apiserver的横向扩展。 生成其它证书 密钥对还是自己生成，然后签证书时会把根证书信息带上 func NewCaCertAndKeyFromRoot(cfg Config, caCert *x509.Certificate, caKey crypto.Signer) (*x509.Certificate, crypto.Signer, error) { key, err := NewPrivateKey(x509.UnknownPublicKeyAlgorithm) cert, err := NewSignedCert(cfg, key, caCert, caKey) return cert, key, nil } 此时就必须要求有CommonName了，Usages也得指定是服务端使用还是客户端使用, 注意与上面SelfSign的区别 // NewSignedCert creates a signed certificate using the given CA certificate and key func NewSignedCert(cfg Config, key crypto.Signer, caCert *x509.Certificate, caKey crypto.Signer) (*x509.Certificate, error) { serial, err := rand.Int(rand.Reader, new(big.Int).SetInt64(math.MaxInt64)) if len(cfg.CommonName) == 0 { return nil, errors.New(\"must specify a CommonName\") } if len(cfg.Usages) == 0 { return nil, errors.New(\"must specify at least one ExtKeyUsage\") } certTmpl := x509.Certificate{ Subject: pkix.Name{ CommonName: cfg.CommonName, Organization: cfg.Organization, }, DNSNames: cfg.AltNames.DNSNames, IPAddresses: cfg.AltNames.IPs, SerialNumber: serial, NotBefore: caCert.NotBefore, NotAfter: time.Now().Add(duration365d * cfg.Year).UTC(), KeyUsage: x509.KeyUsageKeyEncipherment | x509.KeyUsageDigitalSignature, ExtKeyUsage: cfg.Usages, } certDERBytes, err := x509.CreateCertificate(rand.Reader, &certTmpl, caCert, key.Public(), caKey) return x509.ParseCertificate(certDERBytes) } kubernetes中的所有证书 根证书列表 var caList = []Config{ { Path: BasePath, BaseName: \"ca\", CommonName: \"kubernetes\", Organization: nil, Year: 100, AltNames: AltNames{}, Usages: nil, }, { Path: BasePath, BaseName: \"front-proxy-ca\", CommonName: \"front-proxy-ca\", Organization: nil, Year: 100, AltNames: AltNames{}, Usages: nil, }, { Path: EtcdBasePath, BaseName: \"ca\", CommonName: \"etcd-ca\", Organization: nil, Year: 100, AltNames: AltNames{}, Usages: nil, }, } 其它签名证书列表 var certList = []Config{ { Path: BasePath, BaseName: \"apiserver\", CAName: \"kubernetes\", CommonName: \"kube-apiserver\", Organization: nil, Year: 100, AltNames: AltNames{// 实际安装时还需要把服务器IP用户自定义域名加上 DNSNames: []string{ \"apiserver.cluster.local\", \"localhost\", \"master\", \"kubernetes\", \"kubernetes.default\", \"kubernetes.default.svc\", }, IPs: []net.IP{ {127,0,0,1}, }, }, Usages: []x509.ExtKeyUsage{x509.ExtKeyUsageServerAuth}, // 用途是服务端校验 }, { Path: BasePath, BaseName: \"apiserver-kubelet-client\", CAName: \"kubernetes\", CommonName: \"kube-apiserver-kubelet-client\", Organization: []string{\"system:masters\"}, Year: 100, AltNames: AltNames{}, Usages: []x509.ExtKeyUsage{x509.ExtKeyUsageClientAuth}, }, { Path: BasePath, BaseName: \"front-proxy-client\", CAName: \"front-proxy-ca\", CommonName: \"front-proxy-client\", Organization: nil, Year: 100, AltNames: AltNames{}, Usages: []x509.ExtKeyUsage{x509.ExtKeyUsageClientAuth}, }, { Path: BasePath, BaseName: \"apiserver-etcd-client\", CAName: \"etcd-ca\", CommonName: \"kube-apiserver-etcd-client\", Organization: []string{\"system:masters\"}, Year: 100, AltNames: AltNames{}, Usages: []x509.ExtKeyUsage{x509.ExtKeyUsageClientAuth}, }, { Path: EtcdBasePath, BaseName: \"server\", CAName: \"etcd-ca\", CommonName: \"etcd\", // kubeadm etcd server证书common name使用节点名，这也是调用时需要改动的 Organization: nil, Year: 100, AltNames: AltNames{}, // 调用时需要把节点名，节点IP等加上 Usages: []x509.ExtKeyUsage{x509.ExtKeyUsageServerAuth, x509.ExtKeyUsageClientAuth}, }, { Path: EtcdBasePath, BaseName: \"peer\", CAName: \"etcd-ca\", CommonName: \"etcd-peer\", // 与etcd server同理 Organization: nil, Year: 100, AltNames: AltNames{}, // 与etcd server同理 Usages: []x509.ExtKeyUsage{x509.ExtKeyUsageServerAuth, x509.ExtKeyUsageClientAuth}, }, { Path: EtcdBasePath, BaseName: \"healthcheck-client\", CAName: \"etcd-ca\", CommonName: \"kube-etcd-healthcheck-client\", Organization: []string{\"system:masters\"}, Year: 100, AltNames: AltNames{}, Usages: []x509.ExtKeyUsage{x509.ExtKeyUsageClientAuth}, }, } 上面非常要注意的是server端校验的证书安装时需要把IP和域名加上，etcd的commonName也要设置成node name。 看最后生成的证书信息： apiserver: [root@iZ2ze4ry74x8bh3cweeg69Z pki]# openssl x509 -in /etc/kubernetes/pki/apiserver.crt -text -noout Certificate: ... Signature Algorithm: sha256WithRSAEncryption Issuer: CN=kubernetes Validity Not Before: Mar 31 09:18:06 2020 GMT Not After : Mar 8 09:18:06 2119 GMT Subject: CN=kube-apiserver ... X509v3 extensions: X509v3 Key Usage: critical Digital Signature, Key Encipherment X509v3 Extended Key Usage: TLS Web Server Authentication X509v3 Subject Alternative Name: DNS:iz2ze4ry74x8bh3cweeg69z, DNS:kubernetes, DNS:kubernetes.default, DNS:kubernetes.default.svc, DNS:kubernetes.default.svc.cluster.local, DNS:apiserver.cluster.local, DNS:apiserver.cluster.local, IP Address:10.96.0.1, IP Address:172.16.9.192, IP Address:127.0.0.1, IP Address:172.16.9.192, IP Address:172.16.9.193, IP Address:172.16.9.194, IP Address:10.103.97.2 Signature Algorithm: sha256WithRSAEncryption etcd server: [root@iZ2ze4ry74x8bh3cweeg69Z pki]# openssl x509 -in /etc/kubernetes/pki/etcd/server.crt -text -noout Certificate: Data: Version: 3 (0x2) Serial Number: 1930981199811083392 (0x1acc392ba2b27c80) Signature Algorithm: sha256WithRSAEncryption Issuer: CN=etcd-ca Validity Not Before: Mar 31 09:18:07 2020 GMT Not After : Mar 8 09:18:07 2119 GMT Subject: CN=iz2ze4ry74x8bh3cweeg69z ... X509v3 Extended Key Usage: TLS Web Server Authentication, TLS Web Client Authentication X509v3 Subject Alternative Name: DNS:iz2ze4ry74x8bh3cweeg69z, DNS:localhost, IP Address:172.16.9.192, IP Address:127.0.0.1, IP Address:0:0:0:0:0:0:0:1 Signature Algorithm: sha256WithRSAEncryption 生成用户证书和kubeconfig 现在有个实习生小明来公司了，也想用用k8s，果断不放心把admin 的kubeconfig交给他，那怎么办？ 有了上面基础，再进一步教你怎么为实习生小明分配一个单独的kubeconfig 从磁盘加载根证书,和私钥 生成fanux这个用户的证书, common name就是fanux 编码成pem格式 写kubeconfig, 写磁盘 func GenerateKubeconfig(conf Config) error{ certs, err := cert.CertsFromFile(conf.CACrtFile) caCert := certs[0] cert := EncodeCertPEM(caCert) caKey,err := TryLoadKeyFromDisk(conf.CAKeyFile) // 这里conf.User就是fanux, conf.Groups就是用户组，可以是多个 clientCert,clientKey,err := NewCertAndKey(caCert,caKey,conf.User,conf.Groups,conf.DNSNames,conf.IPAddresses) encodedClientKey,err := keyutil.MarshalPrivateKeyToPEM(clientKey) encodedClientCert := EncodeCertPEM(clientCert) // 构建kubeconfig的三元组信息 config := &api.Config{ Clusters: map[string]*api.Cluster{ conf.ClusterName: { Server: conf.Apiserver, // 集群地址 如 https://apiserver.cluster.local:6443 CertificateAuthorityData: cert, // pem格式的根证书，用于https }, }, Contexts: map[string]*api.Context{ ctx: { // 三元组信息，用户名 fanux, 上面的cluster名，以及namespace这里没写 Cluster: conf.ClusterName, AuthInfo: conf.User, }, }, AuthInfos: map[string]*api.AuthInfo{ // 用户信息, 所以你直接改kubeconfig里的user是没用的，因为k8s只认证书里的名字 conf.User:&api.AuthInfo{ ClientCertificateData: encodedClientCert, // pem格式的用户证书 ClientKeyData: encodedClientKey, // pem格式的用户私钥 }, }, CurrentContext: ctx, // 当前上下文, kubeconfig可以很好支持多用户和多集群 } err = clientcmd.WriteToFile(*config, conf.OutPut) return nil } 用户证书和私钥生成, 和上面签名证书一样，user就是funax, group是用户组： func NewCertAndKey(caCert *x509.Certificate, caKey crypto.Signer, user string, groups []string, DNSNames []string,IPAddresses []net.IP) (*x509.Certificate, crypto.Signer, error) { key,err := rsa.GenerateKey(rand.Reader, 2048) serial, err := rand.Int(rand.Reader, new(big.Int).SetInt64(math.MaxInt64)) certTmpl := x509.Certificate{ Subject: pkix.Name{ CommonName: user, Organization: groups, }, DNSNames: DNSNames, IPAddresses: IPAddresses, SerialNumber: serial, NotBefore: caCert.NotBefore, NotAfter: time.Now().Add(time.Hour * 24 * 365 * 99).UTC(), KeyUsage: x509.KeyUsageKeyEncipherment | x509.KeyUsageDigitalSignature, ExtKeyUsage: []x509.ExtKeyUsage{x509.ExtKeyUsageClientAuth}, } certDERBytes, err := x509.CreateCertificate(rand.Reader, &certTmpl, caCert, key.Public(), caKey) cert,err := x509.ParseCertificate(certDERBytes) return cert,key,nil } 然后这位小伙伴的kubeconfig就生成了，此时没有任何权限： kubectl --kubeconfig ./kube/config get pod Error from server (Forbidden): pods is forbidden: User \"fanux\" cannot list resource \"pods\" in API group ... 最后发挥一下RBAC就可以了，这里就直接绑定个管理员权限了 kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: user-admin-test subjects: - kind: User name: \"fanux\" # Name is case sensitive apiGroup: rbac.authorization.k8s.io roleRef: kind: ClusterRole name: cluster-admin # using admin role apiGroup: rbac.authorization.k8s.io 总结 证书与k8s的认证原理在集群安装以及开发多租户容器平台时非常有用，希望本文能让大家有个整体细致全面的了解。 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/k8s/k8s资源对象/pod/1.k8s YAML文件.html":{"url":"linux/k8s/k8s资源对象/pod/1.k8s YAML文件.html","title":"YAML文件","keywords":"","body":"k8s YAML文件 本文严重抄袭至互联网 k8s 1.18 api官方文档 YAML 基础 它的基本语法规则如下： 大小写敏感 使用缩进表示层级关系 缩进时不允许使用Tab键，只允许使用空格。 缩进的空格数目不重要，只要相同层级的元素左侧对齐即可 # 表示注释，从这个字符一直到行尾，都会被解析器忽略。 在我们的 kubernetes 中，你只需要两种结构类型就行了： Lists Maps 也就是说，你可能会遇到 Lists 的 Maps 和 Maps 的 Lists，等等。不过不用担心，你只要掌握了这两种结构也就可以了，其他更加复杂的我们暂不讨论。 Maps 首先我们来看看 Maps，我们都知道 Map 是字典，就是一个key:value的键值对，Maps 可以让我们更加方便的去书写配置信息，例如： --- apiVersion: v1 kind: Pod 第一行的---是分隔符，是可选的，在单一文件中，可用连续三个连字号---区分多个文件。这里我们可以看到，我们有两个键： apiVersion和kind ，他们对应的值分别是：v1 和Pod。上面的 YAML 文件转换成 JSON 格式的话，你肯定就容易明白了： { \"apiVersion\": \"v1\", \"kind\": \"pod\" } 我们在创建一个相对复杂一点的 YAML 文件，创建一个 KEY 对应的值不是字符串而是一个 Maps： --- apiVersion: v1 kind: Pod metadata: name: kube100-site labels: app: web 上面的 YAML 文件，metadata 这个 KEY 对应的值就是一个 Maps 了，而且嵌套的 labels 这个 KEY 的值又是一个 Map，你可以根据你自己的情况进行多层嵌套。 上面我们也提到了 YAML 文件的语法规则，YAML 处理器是根据行缩进来知道内容之间的关联性的。比如我们上面的 YAML 文件，我用了两个空格作为缩进，空格的数量并不重要，但是你得保持一致，并且至少要求一个空格（什么意思？就是你别一会缩进两个空格，一会缩进4个空格）。 我们可以看到 name 和 labels 是相同级别的缩进，所以 YAML 处理器就知道了他们属于同一个 MAP，而 app 是 labels 的值是因为 app 的缩进更大。 注意：在 YAML 文件中绝对不要使用 tab 键。 同样的，我们可以将上面的 YAML 文件转换成 JSON 文件： { \"apiVersion\": \"v1\", \"kind\": \"Pod\", \"metadata\": { \"name\": \"kube100-site\", \"labels\": { \"app\": \"web\" } } } 或许你对上面的 JSON 文件更熟悉，但是你不得不承认 YAML 文件的语义化程度更高吧？ Lists Lists 就是列表，说白了就是数组，在 YAML 文件中我们可以这样定义： args - Cat - Dog - Fish 你可以有任何数量的项在列表中，每个项的定义以破折号（-）开头的，与父元素直接可以缩进一个空格。对应的 JSON 格式如下： { \"args\": [\"Cat\", \"Dog\", \"Fish\"] } 当然，list 的子项也可以是 Maps，Maps 的子项也可以是list如下所示： --- apiVersion: v1 kind: Pod metadata: name: kube100-site labels: app: web spec: containers: - name: front-end image: nginx ports: - containerPort: 80 - name: flaskapp-demo image: jcdemo/flaskapp ports: - containerPort: 5000 比如这个 YAML 文件，我们定义了一个叫 containers 的 List 对象，每个子项都由 name、image、ports 组成，每个 ports 都有一个 key 为 containerPort 的 Map 组成，同样的，我们可以转成如下 JSON 格式文件： { \"apiVersion\": \"v1\", \"kind\": \"Pod\", \"metadata\": { \"name\": \"kube100-site\", \"labels\": { \"app\": \"web\" } }, \"spec\": { \"containers\": [{ \"name\": \"front-end\", \"image\": \"nginx\", \"ports\": [{ \"containerPort\": 80 }] }, { \"name\": \"flaskapp-demo\", \"image\": \"jcdemo/flaskapp\", \"ports\": [{ \"containerPort\": 5000 }] }] } } 是不是觉得用 JSON 格式的话文件明显比 YAML 文件更复杂了呢？ 使用 YAML 创建 Pod 现在我们已经对 YAML 文件有了大概的了解了，我相信你应该没有之前那么懵逼了吧？我们还是来使用 YAML 文件来创建一个 Deployment 吧。 创建 Pod --- apiVersion: v1 kind: Pod metadata: name: kube100-site labels: app: web spec: containers: - name: front-end image: nginx ports: - containerPort: 80 - name: flaskapp-demo image: jcdemo/flaskapp ports: - containerPort: 5000 这是我们上面定义的一个普通的 POD 文件，我们先来简单分析下文件内容： apiVersion，这里它的值是 v1，这个版本号需要根据我们安装的 kubernetes 版本和资源类型进行变化的，记住不是写死的 kind，这里我们创建的是一个 Pod，当然根据你的实际情况，这里资源类型可以是 Deployment、Job、Ingress、Service 等待。 metadata：包含了我们定义的 Pod 的一些 meta 信息，比如名称、namespace、标签等等信息。 spec：包括一些 containers，storage，volumes，或者其他 Kubernetes 需要知道的参数，以及诸如是否在容器失败时重新启动容器的属性。你可以在特定 Kubernetes API 找到完整的 Kubernetes Pod 的属性。 让我们来看一个典型的容器的定义： …spec: containers: - name: front-end image: nginx ports: - containerPort: 80 … 在这个例子中，这是一个简单的最小定义：一个名字（front-end），基于 nginx 的镜像，以及容器 将会监听的一个端口（80）。在这些当中，只有名字是非常需要的，你也可以指定一个更加复杂的属性，例如在容器启动时运行的命令，应使用的参数，工作目录，或每次实例化时是否拉取映像的新副本。以下是一些容器可选的设置属性： name image command args workingDir ports env resources volumeMounts livenessProbe readinessProbe livecycle terminationMessagePath imagePullPolicy securityContext stdin stdinOnce tty 明白了 POD 的定义后，我们将上面创建 POD 的 YAML 文件保存成 pod.yaml，然后使用kubectl创建 POD： $ kubectl create -f pod.yaml pod \"kube100-site\" created 然后我们就可以使用我们前面比较熟悉的 kubectl 命令来查看 POD 的状态了： $ kubectl get pods NAME READY STATUS RESTARTS AGE kube100-site 2/2 Running 0 1m 到这里我们的 POD 就创建成功了，如果你在创建过程中有任何问题，我们同样可以使用前面的kubectl describe 进行排查。我们先删除上面创建的 POD： $ kubectl delete -f pod.yaml pod \"kube100-site\" deleted 创建 Deployment 现在我们可以来创建一个真正的 Deployment。在上面的例子中，我们只是单纯的创建了一个 POD 实例，但是如果这个 POD 出现了故障的话，我们的服务也就挂掉了，所以 kubernetes 提供了一个Deployment的概念，可以让 kubernetes 去管理一组 POD 的副本，也就是副本集，这样就可以保证一定数量的副本一直可用的，不会因为一个 POD 挂掉导致整个服务挂掉。我们可以这样定义一个 Deployment： --- apiVersion: extensions/v1beta1 kind: Deployment metadata: name: kube100-site spec: replicas: 2 注意这里的apiVersion对应的值是extensions/v1beta1，当然 kind 要指定为 Deployment，因为这就是我们需要的，然后我们可以指定一些 meta 信息，比如名字，或者标签之类的。最后，最重要的是spec配置选项，这里我们定义需要两个副本，当然还有很多可以设置的属性，比如一个 Pod 在没有任何错误变成准备的情况下必须达到的最小秒数。 我们可以在Kubernetes v1beta1 API(官方已修改，早就404了，天天瞎鸡吧改，都尼玛找不到了)参考中找到一个完整的 Depolyment 可指定的参数列表。 现在我们来定义一个完整的 Deployment 的 YAML 文件： --- apiVersion: extensions/v1beta1 kind: Deployment metadata: name: kube100-site spec: replicas: 2 template: metadata: labels: app: web spec: containers: - name: front-end image: nginx ports: - containerPort: 80 - name: flaskapp-demo image: jcdemo/flaskapp ports: - containerPort: 5000 看起来是不是和我们上面的 pod.yaml 很类似啊，注意其中的 template，其实就是对 POD 对象的定义。将上面的 YAML 文件保存为 deployment.yaml，然后创建 Deployment： $ kubectl create -f deployment.yaml deployment \"kube100-site\" created 同样的，想要查看它的状态，我们可以检查 Deployment的列表： $ kubectl get deployments NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE kube100-site 2 2 2 2 2m 我们可以看到所有的 Pods 都已经正常运行了。 到这里我们就完成了使用 YAML 文件创建 Kubernetes Deployment 的过程，在了解了 YAML 文件的基础后，定义 YAML 文件其实已经很简单了，最主要的是要根据实际情况去定义 YAML 文件，所以查阅 Kubernetes 文档很重要。 可以使用yaml文件检测网站去检验 YAML 文件的合法性。 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/k8s/k8s资源对象/pod/k8s pod.html":{"url":"linux/k8s/k8s资源对象/pod/k8s pod.html","title":"k8s pod","keywords":"","body":"k8s pod kubectl run命令中文网站 kubectl run generator参数官网说明 pod容器分类 Infrastructure Container：基础容器 维护整个Pod网络空间 InitContainers：初始化容器 先于业务容器开始执行 Containers：业务容器 并行启动 pod操作 1.1 创建pod 命令方式 --generator=run-pod/v1就是指定创建的类型为pod kubectl run nginx --image=nginx:1.16 --replicas=3 --generator=run-pod/v1 yaml文件方式 cat >nginx-pod.yaml 创建pod过程中遇到的问题 镜像是使用了master本机的register私有仓库，配置了认证，创建pod拉取镜像报错如下 Warning Failed 14m (x4 over 15m) kubelet, k8s-node2 Failed to pull image \"10.0.0.130:5000/nginx:latest\": rpc error: code = Unknown desc = Error response from daemon: Get http://10.0.0.130:5000/v2/nginx/manifests/latest: no basic auth credentials 解决方法： 创建一个register的认证，名称为myregistrykey，然后在pod的yaml文件中定义如下即可 imagePullSecrets: name: myregistrykey #创建认证 kubectl create secret docker-registry myregistrykey --docker-server=10.0.0.130:5000 --docker-username=test --docker-password=123456 secret/myregistrykey created #删除认证 kubectl delete secrets myregistrykey 1.2 查看pod #查看所有pod kubectl get pods #指定pod查看 kubectl get pod pod-name #查看pod详细信息 kubectl describe pod pod-name 1.3 删除pod #删除pod kubectl delete pod pod-name 静态pod 1.静态pod说明 静态 Pod 直接由特定节点上的kubelet进程来管理，不通过 master 节点上的apiserver。无法与我们常用的控制器Deployment或者DaemonSet进行关联，它由kubelet进程自己来监控，当pod崩溃时重启该pod，kubelet也无法对他们进行健康检查。静态 pod 始终绑定在某一个kubelet，并且始终运行在同一个节点上。 kubelet会自动为每一个静态 pod 在 Kubernetes 的 apiserver 上创建一个镜像 Pod（Mirror Pod），因此我们可以在 apiserver 中查询到该 pod，但是不能通过 apiserver 进行控制（例如不能删除）。 kubeadm安装的k8s中，etcd 、kube-apiserver、 kube-controller-manager、kube-scheduler都是以静态pod的方式部署，路径为/etc/kubernetes/manifests/，只需要把yaml文件放在此路径就会启动静态pod，移除yaml文件则会删除静态pod 静态pod使用kubectl delete命令无法删除，但是在1.17.4版本中官方的dashboard中可以删除，其余版本没有测试 2.创建静态pod 创建静态 Pod 有两种方式：配置文件和 HTTP 两种方式 配置文件方式 配置文件就是放在特定目录下的标准的 JSON 或 YAML 格式的 pod 定义文件。用kubelet --pod-manifest-path=来启动kubelet进程，kubelet 定期的去扫描这个目录，根据这个目录下出现或消失的 YAML/JSON 文件来创建或删除静态 pod。 比如我们在 node01 这个节点上用静态 pod 的方式来启动一个 nginx 的服务。我们登录到node01节点上面，可以通过下面命令找到kubelet对应的启动配置文件 $ systemctl status kubelet kubelet.service - kubelet: The Kubernetes Node Agent Loaded: loaded (/usr/lib/systemd/system/kubelet.service; enabled; vendor preset: disabled) Drop-In: /usr/lib/systemd/system/kubelet.service.d └─10-kubeadm.conf Active: active (running) since Tue 2020-03-31 20:08:43 CST; 1 weeks 2 days ago Docs: https://kubernetes.io/docs/ Main PID: 20088 (kubelet) Tasks: 17 Memory: 177.3M CGroup: /system.slice/kubelet.service └─20088 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=... 配置文件路径为： /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf # Note: This dropin only works with kubeadm and kubelet v1.11+ [Service] Environment=\"KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf\" Environment=\"KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml\" # This is a file that \"kubeadm init\" and \"kubeadm join\" generates at runtime, populating the KUBELET_KUBEADM_ARGS variable dynamically EnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env # This is a file that the user can use for overrides of the kubelet args as a last resort. Preferably, the user should use # the .NodeRegistration.KubeletExtraArgs object in the configuration files instead. KUBELET_EXTRA_ARGS should be sourced from this file. EnvironmentFile=-/etc/sysconfig/kubelet ExecStart= ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS 打开这个文件我们可以看到其中有一条如下的环境变量配置： Environment=\"KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml\"这个文件的内容如下 apiVersion: kubelet.config.k8s.io/v1beta1 authentication: anonymous: enabled: false webhook: cacheTTL: 0s enabled: true x509: clientCAFile: /etc/kubernetes/pki/ca.crt authorization: mode: Webhook webhook: cacheAuthorizedTTL: 0s cacheUnauthorizedTTL: 0s clusterDNS: - 10.96.0.10 clusterDomain: cluster.local cpuManagerReconcilePeriod: 0s evictionPressureTransitionPeriod: 0s fileCheckFrequency: 0s healthzBindAddress: 127.0.0.1 healthzPort: 10248 httpCheckFrequency: 0s imageMinimumGCAge: 0s kind: KubeletConfiguration nodeStatusReportFrequency: 0s nodeStatusUpdateFrequency: 0s rotateCertificates: true runtimeRequestTimeout: 0s staticPodPath: /etc/kubernetes/manifests streamingConnectionIdleTimeout: 0s syncFrequency: 0s volumeStatsAggPeriod: 0s 其中有一项staticPodPath: /etc/kubernetes/manifests 所以如果我们通过kubeadm的方式来安装的集群环境，对应的kubelet已经配置了我们的静态 Pod 文件的路径，那就是/etc/kubernetes/manifests，所以我们只需要在该目录下面创建一个标准的 Pod 的 JSON 或者 YAML 文件即可： 如果你的 kubelet 启动参数中没有配置上面的--pod-manifest-path参数的话，那么添加上这个参数然后重启 kubelet 即可。 cat >/etc/kubernetes/manifest/static-web.yaml HTTP方式 kubelet 周期地从–manifest-url=参数指定的地址下载文件，并且把它翻译成 JSON/YAML 格式的 pod 定义。此后的操作方式与–pod-manifest-path=相同，kubelet 会不时地重新下载该文件，当文件变化时对应地终止或启动静态 pod。 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/k8s/k8s资源对象/pod/pod健康检查.html":{"url":"linux/k8s/k8s资源对象/pod/pod健康检查.html","title":"pod健康检查","keywords":"","body":"pod健康检查 探针分类 1 liveness probe（存活探针） kubelet 通过使用 liveness probe 来确定你的应用程序是否正在运行，通俗点讲就是是否还活着。一般来说，如果你的程序一旦崩溃了， Kubernetes 就会立刻知道这个程序已经终止了，然后就会重启这个程序。而我们的 liveness probe 的目的就是来捕获到当前应用程序还有没有终止，还有没有崩溃，如果出现了这些情况，那么就重启处于该状态下的容器，使应用程序在存在 bug 的情况下依然能够继续运行下去。 2 readiness probe（可读性探针） kubelet 使用 readiness probe 来确定容器是否已经就绪可以接收流量过来了。这个探针通俗点讲就是说是否准备好了，现在可以开始工作了。只有当 Pod 中的容器都处于就绪状态的时候 kubelet 才会认定该 Pod 处于就绪状态，因为一个 Pod 下面可能会有多个容器。当然 Pod 如果处于非就绪状态，那么我们就会将他从我们的工作队列(实际上就是Service)中移除出来，这样我们的流量就不会被路由到这个 Pod 里面来了。 Pod中容器的生命周期的两个钩子函数，PostStart与PreStop，其中PostStart是在容器创建后立即执行的，而PreStop这个钩子函数则是在容器终止之前执行的。除了上面这两个钩子函数以外，还有一项配置会影响到容器的生命周期的，那就是健康检查的探针。 在Kubernetes集群当中，我们可以通过配置liveness probe（存活探针）和readiness probe（可读性探针）来影响容器的生存周期。 和前面的钩子函数一样的，我们这两个探针的支持三种配置方式： exec：执行一段命令 http：检测某个 http 请求 tcpSocket：使用此配置， kubelet 将尝试在指定端口上打开容器的套接字。如果可以建立连接，容器被认为是健康的，如果不能就认为是失败的。实际上就是检查端口 探针配置方式 1. exec 好，我们先来给大家演示下存活探针的使用方法，首先我们用exec执行命令的方式来检测容器的存活，如下: cat >liveness-exec.yaml 我们这里需要用到一个新的属性：livenessProbe，下面通过exec执行一段命令，其中periodSeconds属性表示让kubelet每隔5秒执行一次存活探针，也就是每5秒执行一次上面的cat /tmp/healthy命令，如果命令执行成功了，将返回0，那么kubelet就会认为当前这个容器是存活的并且很健康，如果返回的是非0值，那么kubelet就会把该容器杀掉然后重启它。 另外一个属性initialDelaySeconds表示在第一次执行探针的时候要等待5秒，这样能够确保我们的容器能够有足够的时间启动起来。大家可以想象下，如果你的第一次执行探针等候的时间太短，是不是很有可能容器还没正常启动起来，所以存活探针很可能始终都是失败的，这样就会无休止的重启下去了，对吧？所以一个合理的initialDelaySeconds非常重要。 另外我们在容器启动的时候，执行了如下命令： /bin/sh -c \"touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600\" 意思是说在容器最开始的30秒内有一个/tmp/healthy文件，在这30秒内执行cat /tmp/healthy命令都会返回一个成功的返回码。30秒后，我们删除这个文件，现在执行cat /tmp/healthy是不是就会失败了，这个时候就会重启容器了。 我们来创建下该Pod，在30秒内，查看Pod的Event： kubectl describe pod liveness-exec Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 106s default-scheduler Successfully assigned default/liveness-exec to k8s-node1 Warning Unhealthy 44s (x3 over 54s) kubelet, k8s-node1 Liveness probe failed: cat: can't open '/tmp/healthy': No such file or directory Normal Killing 44s kubelet, k8s-node1 Container liveness failed liveness probe, will be restarted Normal Pulling 14s (x2 over 106s) kubelet, k8s-node1 Pulling image \"busybox\" Normal Pulled 10s (x2 over 89s) kubelet, k8s-node1 Successfully pulled image \"busybox\" Normal Created 10s (x2 over 89s) kubelet, k8s-node1 Created container liveness Normal Started 10s (x2 over 89s) kubelet, k8s-node1 Started container liveness 我们可以观察到容器是正常启动的，在隔一会儿，比如40s后，再查看下Pod的Event，在最下面有一条信息显示 liveness probe失败了，容器被删掉并重新创建。 然后通过kubectl get pod liveness-exec可以看到RESTARTS值加1了。 2. http 同样的，我们还可以使用HTTP GET请求来配置我们的存活探针，我们这里使用一个liveness镜像来验证演示下， cat >liveness-http.yaml 同样的，根据periodSeconds属性我们可以知道kubelet需要每隔3秒执行一次liveness probe，该探针将向容器中的 server 的8080端口发送一个 HTTP GET 请求。如果 server 的 /healthz 路径的 handler 返回一个成功的返回码，kubelet就会认定该容器是活着的并且很健康,如果返回失败的返回码，kubelet将杀掉该容器并重启它。initialDelaySeconds 指定kubelet在该执行第一次探测之前需要等待3秒钟。 通常来说，任何大于200小于400的返回码都会认定是成功的返回码。其他返回码都会被认为是失败的返回码。 我们可以来查看下上面的healthz的实现： http.HandleFunc(\"/healthz\", func(w http.ResponseWriter, r *http.Request) { duration := time.Now().Sub(started) if duration.Seconds() > 10 { w.WriteHeader(500) w.Write([]byte(fmt.Sprintf(\"error: %v\", duration.Seconds()))) } else { w.WriteHeader(200) w.Write([]byte(\"ok\")) } }) 大概意思就是最开始前10s返回状态码200，10s过后就返回500的status_code了。所以当容器启动3秒后，kubelet 开始执行健康检查。第一次健康监测会成功，因为是在10s之内，但是10秒后，健康检查将失败，因为现在返回的是一个错误的状态码了，所以kubelet将会杀掉和重启容器。 同样的，我们来创建下该Pod测试下效果，10秒后，查看 Pod 的 event，确认liveness probe失败并重启了容器。 kubectl describe pod liveness-http 3. tcpSocket 然后我们来通过端口的方式来配置存活探针，使用此配置，kubelet将尝试在指定端口上打开容器的套接字。 如果可以建立连接，容器被认为是健康的，如果不能就认为是失败的。 cat >tcpsocket.yaml 我们可以看到，TCP 检查的配置与 HTTP 检查非常相似，只是将httpGet替换成了tcpSocket。 而且我们同时使用了readiness probe和liveness probe两种探针。 容器启动后5秒后，kubelet将发送第一个readiness probe（可读性探针）。 该探针会去连接容器的8080端口，如果连接成功，则该 Pod 将被标记为就绪状态。然后Kubelet将每隔10秒钟执行一次该检查。 除了readiness probe之外，该配置还包括liveness probe。 容器启动15秒后，kubelet将运行第一个 liveness probe。 就像readiness probe一样，这将尝试去连接到容器的8080端口。如果liveness probe失败，容器将重新启动。 有的时候，应用程序可能暂时无法对外提供服务，例如，应用程序可能需要在启动期间加载大量数据或配置文件。 在这种情况下，你不想杀死应用程序，也不想对外提供服务。 那么这个时候我们就可以使用readiness probe来检测和减轻这些情况。 Pod中的容器可以报告自己还没有准备，不能处理Kubernetes服务发送过来的流量。 从上面的YAML文件我们可以看出readiness probe的配置跟liveness probe很像，基本上一致的。唯一的不同是使用readinessProbe而不是livenessProbe。两者如果同时使用的话就可以确保流量不会到达还未准备好的容器，准备好过后，如果应用程序出现了错误，则会重新启动容器。 另外除了上面的initialDelaySeconds和periodSeconds属性外，探针还可以配置如下几个参数： timeoutSeconds：探测超时时间，默认1秒，最小1秒。 successThreshold：探测失败后，最少连续探测成功多少次才被认定为成功。默认是 1，但是如果是liveness则必须是 1。最小值是 1。 failureThreshold：探测成功后，最少连续探测失败多少次才被认定为失败。默认是 3，最小值是 1。 这就是liveness probe（存活探针）和readiness probe（可读性探针）的使用方法。在Pod的生命周期当中，我们已经学习了容器生命周期中的钩子函数和探针检测，下节课给大家讲解Pod层面生命周期的一个阶段：初始化容器。 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/k8s/k8s资源对象/pod/图解kubernetes Pod创建流程大揭秘.html":{"url":"linux/k8s/k8s资源对象/pod/图解kubernetes Pod创建流程大揭秘.html","title":"k8s 创建pod流程","keywords":"","body":"图解kubernetes Pod创建流程大揭秘 本文严重抄袭至互联网 kubernetes中的容器创建无疑是个复杂的过程，涉及内部各种组件的统一协作，还有对接外部的CRI运行时，本文尝试初探一下容器创建流程中的各种细节，了解其各种组件协作流程，从而在后续出现问题的时候，也好能大概有点排查方向 1. 基础筑基 1.1 容器管理线程模型 kubelet中的线程模型属于master/wroker模型，通过单master来监听各种事件源，并为每个Pod创建一个goroutine来进行Pod业务逻辑的处理，master和wroker之间通过一个状态管道来进行通信 1.2 基于事件驱动的状态最终一致性 在通过yaml创建Pod之后，kubernetes会根据当前的事件和当前的Pod状态，来不断进行调整，从而达到最终目标状态的一致性 1.3 组件协作流程 kubelet的结构体声明就高达300多行代码，可见其复杂程度，但是我们按照容器创建这个流程，我们去观察其核心流程，其实主要可以概括为三部分：kubelet、containerRuntime、CRI容器运行时 2.Kubelet创建容器流程 2.1 获取Pod进行准入检查 kubelet的事件源主要包含两个部分：静态Pod和Apiserver，我们这里只考虑普通的Pod，则会直接将Pod加入到PodManager来进行管理，并且进行准入检查 准入检查主要包含两个关键的控制器：驱逐管理与预选检查驱逐管理主要是根据当前的资源压力，检测对应的Pod是否容忍当前的资源压力；预选检查则是根据当前活跃的容器和当前节点的信息来检查是否满足当前Pod的基础运行环境，例如亲和性检查，同时如果当前的Pod的优先级特别高或者是静态Pod，则会尝试为其进行资源抢占，会按照QOS等级逐级来进行抢占从而满足其运行环境 2.2 创建事件管道与容器管理主线程 kubelet接收到一个新创建的Pod首先会为其创建一个事件管道，并且启动一个容器管理的主线程消费管道里面的事件，并且会基于最后同步时间来等待当前kubelet中最新发生的事件(从本地的podCache中获取)，如果是一个新建的Pod，则主要是通过PLEG中更新时间操作，广播的默认空状态来作为最新的状态 2.3 同步最新状态 当从本地的podCache中获取到最新的状态信息和从事件源获取的Pod信息后，会结合当前当前statusManager和probeManager里面的Pod里面的容器状态来更新，从而获取当前感知到的最新的Pod状态 2.4 准入控制检查 之前的准入检查是Pod运行的资源硬性限制的检查，而这里的准入检查则是软状态即容器运行时和版本的一些软件运行环境检查，如果这里检查失败，则会讲对应的容器状态设置为Blocked 2.5 更新容器状态 在通过准入检查之后，会调用statusManager来进行POd最新状态的同步，此处可能会同步给apiserver 2.6 Cgroup配置 在更新完成状态之后会启动一个PodCOntainerManager主要作用则是为对应的Pod根据其QOS等级来进行Cgroup配置的更新 2.7Pod基础运行环境准备 接下来kubelet会为Pod的创建准备基础的环境，包括Pod数据目录的创建、镜像秘钥的获取、等待volume挂载完成等操作创建Pod的数据目录主要是创建 Pod运行所需要的Pod、插件、Volume目录，并且会通过Pod配置的镜像拉取秘钥生成秘钥信息，到此kubelet创建容器的工作就已经基本完成 3.ContainerRuntime 前面我们提到过针对Pod的操作，最终都是基于事件和状态的同步而完成，在containerRUntime并不会区分对应的事件是创建还是更新操作，只是根据当前的Pod的信息与目标状态来进行对比，从而构建出对应的操作，达到目标状态 3.1 计算Pod容器变更 计算容器变更主要包括：Pod的sandbox是否变更、短声明周期容器、初始化容器是否完成、业务容器是否已经完成，相应的我们会得到一个几个对应的容器列表：需要被kill掉的容器列表、需要启动的容器列表，注意如果我们的初始化容器未完成，则不会进行将要运行的业务容器加入到需要启动的容器列表，可以看到这个地方是两个阶段 3.2 初始化失败尝试终止 如果之前检测到之前的初始化容器失败，则会检查当前Pod的所有容器和sandbox关联的容器如果有在运行的容器，会全部进行Kill操作，并且等待操作完成 3.3 未知状态容器补偿 当一些Pod的容器已经运行，但是其状态仍然是Unknow的时候，在这个地方会进行统一的处理，全部kill掉，从而为接下来的重新启动做清理操作，此处和3.2只会进行一个分支，但核心的目标都是清理那些运行失败或者无法获取状态的容器 3.4 创建容器沙箱 在启动Pod的容器之前，首先会为其创建一个sandbox容器，当前Pod的所有容器都和Pod对应的sandbox共享同一个namespace从而共享一个namespace里面的资源，创建Sandbox比较复杂，后续会继续介绍 3.5 启动Pod相关容器 Pod的容器目前分为三大类：短生命周期容器、初始化容器、业务容器，启动顺序也是从左到右依次进行,如果对于的容器创建失败，则会通过backoff机制来延缓容器的创建，这里我们顺便介绍下containerRuntime启动容器的流程 3.5.1 检查容器镜像是否拉取 镜像的拉取首先会进行对应容器镜像的拼接，然后将之前获取的拉取的秘钥信息和镜像信息，一起交给CRI运行时来进行底层容器镜像的拉取，当然这里也会各种backoff机制，从而避免频繁拉取失败影响kubelet的性能 3.5.2 创建容器配置 创建容器配置主要是为了容器的运行创建对应的配置数据，主要包括：Pod的主机名、域名、挂载的volume、configMap、secret、环境变量、挂载的设备信息、要挂载的目录信息、端口映射信息、根据环境生成执行的命令、日志目录等信息 3.5.3 调用runtimeService完成容器的创建 调用runtimeService传递容器的配置信息，调用CRI，并且最终调用容器的创建接口完成容器的状态 3.5.4 调用runtimeService启动容器 通过之前创建容器返回的容器ID，来进行对应的容器的启动，并且会为容器创建对应的日志目录 3.5.5 执行容器的回调钩子 如果容器配置了PostStart钩子，则会在此处进行对应钩子的执行，如果钩子的类型是Exec类则会调用CNI的EXec接口完成在容器内的执行 4. 运行沙箱容器 4.1 拉取sandbox镜像 首先会拉取sandbox镜像 4.2 创建沙箱容器 4.2.1 应用SecurityContext 在创建容器之前会先根据SecurityContext里面的配资信息，来进行容器SecurityContext的配置，主要包括特权等级、只读目录、运行账户组等信息 4.2 其余基础信息 除了应用SecurityContext还会进行断开、OOMScoreAdj、Cgroup驱动等信息的映射 4.3 创建容器 根据上面的各种配置信息来进行容器的创建 4.3 创建checkpoint checkpoint主要是将当前sandbox的配置信息进行序列化，并且存储其当前的快照信息 4.4 启动sandbox容器 启动sandbox容器则会直接调用StartContainer同时传入之前创建容器返回的ID完成容器的启动，并且此时会重写覆盖容器的dns配置文件 4.5 容器网络设置 容器的网络配置主要是调用CNI插件来完成容器网络的配置，这里就先不展开了 5. Pod容器启动总结 kubelet是容器管理的核心大管家，其负责各种准入控制、状态管理、探测管理、volume管理、QOS管理、CSI对接的统一调度，并且为Runtime运行时准备基础的数据和并反馈Pod当前的最新状态 Runtime层则将kubelet组装的数据，按照CRI运行时的目标配置和kubelet管理的资源配置信息来进行资源的重组，并且根据Pod的容器的状态来决策容器的启停、创建等操作，并完成容器的基础配置环境的构建，并最终调用CRI完成容器的创建，而CRI运行时，则会讲传递过来的各种数据进行进一步的组合，并应用到主机和对应的namespace资源限制，并根据自己的容器服务组织数据，调用容器服务完成容器的最终创建 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/k8s/k8s资源对象/pod/Pod创建流程代码版本kubelet篇.html":{"url":"linux/k8s/k8s资源对象/pod/Pod创建流程代码版本kubelet篇.html","title":"pod创建流程代码版本kubelet篇","keywords":"","body":"Pod创建流程代码版本kubelet篇 本文严重抄袭至互联网 1. 前言 在k8s的面试中Pod的创建流程是一个常问的问题，而kubelet则无疑重中之重，之前也写过一篇Pod的运行，不过没有涉及到具体的代码，本文尝试用代码的方式，来复数整个核心的流程，同时为了方便记忆，又将整个过程分为：准备、配置、清理、构建运行四个阶段，让我们一起来看下吧， 文末有大图总结 2. 准备阶段 当获取到Pod添加的事件的时候，首先会进行一些基础的工作，我吧这个过程称为准备阶段，准备阶段主要做的事情有如下：1）加入PodManager 2）准入控制检查 3）分发事件 4）根据Pod添加对应的探针， 让我们一起来看下关键实现 2.1 加入PodManager PodManager中的功能除了存储Pod的信息，还会进行对应Pod的configMap和secret的管理，当心加入Pod的时候，会检查对应的Pod是否有对应的configMap和secret配置，如果有则就会创建对应的监听器，监听资源的变化，进行本地缓存 除此之外，如果对应的Pod的BootstrapCheckpointAnnotationKey有设定，则还会创建对应的checkpoint,即将pod的配置数据写入到本地磁盘 kl.podManager.AddPod(pod) 2.2 准入控制检查 准入控制检查主要是在运行Pod之前在kubelet上进行Pod运行条件的检查，检查当前节点在scheduler决策完成后到感知到Pod运行这段时间资源是否依旧满足，并且检查Pod的一些特殊资源比如比如sysctl、security等检查，这里我感觉比较重要的两个分别是eviction和predicate, 如果不满足准入检查，则会直接拒绝 2.2.1 eviction准入检查 如果当前节点只存在内存压力，则会根据对应的Pod的QOS等级来判断，如果说不是BestEffort或者容忍内存压力的污点，则会允许，否则则会拒绝运行 nodeOnlyHasMemoryPressureCondition := hasNodeCondition(m.nodeConditions, v1.NodeMemoryPressure) && len(m.nodeConditions) == 1 if nodeOnlyHasMemoryPressureCondition { // 如果不是PodQOSBestEffort, 则都会尝试运行 notBestEffort := v1.PodQOSBestEffort != v1qos.GetPodQOS(attrs.Pod) if notBestEffort { return lifecycle.PodAdmitResult{Admit: true} } // 如果对应的Pod容忍内存压力的污点，则就可以继续进行其他准入控制器的检查 if v1helper.TolerationsTolerateTaint(attrs.Pod.Spec.Tolerations, &v1.Taint{ Key: v1.TaintNodeMemoryPressure, Effect: v1.TaintEffectNoSchedule, }) { return lifecycle.PodAdmitResult{Admit: true} } } 2.2.2 predicate准入检查 predicate准入控制器中的逻辑主要是分为两个部分：1）检查对应的资源是否满足分配请求，同时会记录缺少的资源2）如果是Critical类型的Pod则会按照QOS等级来进行资源的抢占，满足这些高优先的Pod这里的Critical类型的Pod主要包含如下三类：静态Pod、镜像Pod、高优先Pod(优先级高于2000000000) func (w *predicateAdmitHandler) Admit(attrs *PodAdmitAttributes) PodAdmitResult { node, err := w.getNodeAnyWayFunc() // 踢出扩展资源，只进行内存和CPU资源的检查 podWithoutMissingExtendedResources := removeMissingExtendedResources(admitPod, nodeInfo) // 进行预选算法筛选， 筛选出那些资源不足的资源 fit, reasons, err := predicates.GeneralPredicates(podWithoutMissingExtendedResources, nil, nodeInfo) if !fit { // 如果预选失败，则尝试进行抢占 fit, reasons, err = w.admissionFailureHandler.HandleAdmissionFailure(admitPod, reasons) } } 2.3 探针管理 k8s里面的探针主要分为三类：startup、readiness、liveness，在Pod通过准入控制检查后，会根据Pod的探针配置创建对应的探针，但是这里的探针并不会真正的进行探测，因为当前还无法感知到对应的pod的状态 kl.probeManager.AddPod(pod) 2.4 分发事件 在kubelet中会为每个Pod都创建一个对应的goroutine和事件管道，后续新的事件也都通过管道发送给对应的goroutine func (p *podWorkers) UpdatePod(options *UpdatePodOptions) { // 获取pod信息 pod := options.Pod uid := pod.UID var podUpdates chan UpdatePodOptions var exists bool p.podLock.Lock() defer p.podLock.Unlock() // kubelet会为每个pod创建一个goroutine, 并且通过管道来进行通信 if podUpdates, exists = p.podUpdates[uid]; !exists { podUpdates = make(chan UpdatePodOptions, 1) p.podUpdates[uid] = podUpdates // 为当前pod启动一个goroutine go func() { defer runtime.HandleCrash() p.managePodLoop(podUpdates) }() } if !p.isWorking[pod.UID] { p.isWorking[pod.UID] = true // 更新Pod的事件发送到管道 podUpdates 至此一个Pod的启动的准备阶段就基本完成了，检查运行环境、拉取对应的cofnigMap和secret资源、创建探针、启动负责Pod状态维护的线程，至此准备阶段完成 3.配置阶段 在kubelet最终的状态同步都是由syncPod来完成，该函数会根据传递进来的目标状态和Pod的当前状态来进行决策，从而满足目标状态，因为内部逻辑的复杂，会分为：配置阶段、清理阶段、构建运行阶段，这里先看下配置阶段 配置阶段主要是获取当前的Pod状态、应用CGOUP配置、Pod数据目录构建、等待VOlume挂载、获取镜像拉取的secret等 3.1 计算Pod的状态 Pod的状态数据主要包含当前阶段、Conditions(容器Condition、初始化容器Condition、PodReadyCondition),而这些状态则需要根据当前的PodStatus里面的状态计算，还有probeManager里面探测的数据两部分共同完成 func (kl *Kubelet) generateAPIPodStatus(pod *v1.Pod, podStatus *kubecontainer.PodStatus) v1.PodStatus { allStatus := append(append([]v1.ContainerStatus{}, s.ContainerStatuses...), s.InitContainerStatuses...) // 根据Pod的容器状态，设定当前的的阶段 s.Phase = getPhase(spec, allStatus) kl.probeManager.UpdatePodStatus(pod.UID, s) s.Conditions = append(s.Conditions, status.GeneratePodInitializedCondition(spec, s.InitContainerStatuses, s.Phase)) s.Conditions = append(s.Conditions, status.GeneratePodReadyCondition(spec, s.Conditions, s.ContainerStatuses, s.Phase)) s.Conditions = append(s.Conditions, status.GenerateContainersReadyCondition(spec, s.ContainerStatuses, s.Phase)) return *s } 3.2 运行环境准入检查 该运行环境是指的一些软件状态的，这里主要涉及到Appmor、特权模式、proc挂载，实现机制就是检测对应的Pod是否需要对应的操作，并且SecurityContext中是否允许对应的操作，从而确定Pod是否能够进行运行 func (kl *Kubelet) canRunPod(pod *v1.Pod) lifecycle.PodAdmitResult { // 准入控制插件 for _, handler := range kl.softAdmitHandlers { if result := handler.Admit(attrs); !result.Admit { return result } } return lifecycle.PodAdmitResult{Admit: true} } 3.3 更新状态 更新状态主要是为了probeManager来进行状态检查的，如果probeManager无法获取到对应的状态，就不会执行对应的健康探针的检查，这里的状态就是根据之前的各种计算在kubelet上对应Pod的当前状态 kl.statusManager.SetPodStatus(pod, apiPodStatus) 3.4 网络运行时检查 if err := kl.runtimeState.networkErrors(); err != nil && !kubecontainer.IsHostNetworkPod(pod) { kl.recorder.Eventf(pod, v1.EventTypeWarning, events.NetworkNotReady, \"%s: %v\", NetworkNotReadyErrorMsg, err) return fmt.Errorf(\"%s: %v\", NetworkNotReadyErrorMsg, err) } 3.5 CGroup配置 Cgroup的配置主要是按照QOS等级来进行cgroup目录的构建，并且更新当前Pod的配置 pcm := kl.containerManager.NewPodContainerManager() // cgroup应用cgroup if !kl.podIsTerminated(pod) { podKilled := false if !pcm.Exists(pod) && !firstSync { // 如果对于的cgroup不存在，并且也不是第一次运行，就先将之前的pod沙雕 if err := kl.killPod(pod, nil, podStatus, nil); err == nil { podKilled = true } } if !(podKilled && pod.Spec.RestartPolicy == v1.RestartPolicyNever) { if !pcm.Exists(pod) { // 更新qoscgroup设置 if err := kl.containerManager.UpdateQOSCgroups(); err != nil { } // 更新podde的cgroup配置 if err := pcm.EnsureExists(pod); err != nil { } } } } 3.6 镜像Pod的检查 因为要通过镜像Pod来向apiserver传递静态Pod的状态，所以该阶段主要是为静态Pod创建对应的镜像Pod if kubetypes.IsStaticPod(pod) { // 静态pod podFullName := kubecontainer.GetPodFullName(pod) deleted := false if mirrorPod != nil { if mirrorPod.DeletionTimestamp != nil || !kl.podManager.IsMirrorPodOf(mirrorPod, pod) { deleted, err = kl.podManager.DeleteMirrorPod(podFullName, &mirrorPod.ObjectMeta.UID) } } if mirrorPod == nil || deleted { if err := kl.podManager.CreateMirrorPod(pod); err != nil { } } } } 3.7 创建Pod的数据目录 Pod的数据目录主要是包含三个部分：Pod目录、Volume目录、Plugin目录三个目录 if err := kl.makePodDataDirs(pod); err != nil { return err } 3.8 等待volume的挂载 if !kl.podIsTerminated(pod) { if err := kl.volumeManager.WaitForAttachAndMount(pod); err != nil { } } 3.9 获取镜像拉取的secrets pullSecrets := kl.getPullSecretsForPod(pod) 3.10 调用容器的运行时进行同步 着可能是最复杂的一部分了，接下来就进入到下一个阶段：清理阶段 result := kl.containerRuntime.SyncPod(pod, podStatus, pullSecrets, kl.backOff) kl.reasonCache.Update(pod.UID, result) 4. 清理阶段 在Pod运行前可能已经有部分容器已经在运行，则此时就需要根据当前的状态，来进行一些容器的清理工作，为接下来的构建运行阶段提供一个相对干净的环境 4.1 计算Pod状态变更 在k8s中Pod的状态主要包含sandbox容器状态、初始化容器状态、临时容器状态、业务容器状态等几部分，我们依次来看下关键的实现 podContainerChanges := m.computePodActions(pod, podStatus) 沙箱状态计算：当且仅有一个Ready的沙箱并且沙箱的IP不为空的情况，沙箱的状态才不需要更改，其他情况下，都需要重新进行沙箱的构建，并且需要kill掉Pod关联的所有容器 func (m *kubeGenericRuntimeManager) podSandboxChanged(pod *v1.Pod, podStatus *kubecontainer.PodStatus) (bool, uint32, string) { if len(podStatus.SandboxStatuses) == 0 { return true, 0, \"\" } readySandboxCount := 0 for _, s := range podStatus.SandboxStatuses { if s.State == runtimeapi.PodSandboxState_SANDBOX_READY { readySandboxCount++ } } sandboxStatus := podStatus.SandboxStatuses[0] if readySandboxCount > 1 { return true, sandboxStatus.Metadata.Attempt + 1, sandboxStatus.Id } if sandboxStatus.State != runtimeapi.PodSandboxState_SANDBOX_READY { return true, sandboxStatus.Metadata.Attempt + 1, sandboxStatus.Id } if sandboxStatus.GetLinux().GetNamespaces().GetOptions().GetNetwork() != networkNamespaceForPod(pod) { return true, sandboxStatus.Metadata.Attempt + 1, \"\" } if !kubecontainer.IsHostNetworkPod(pod) && sandboxStatus.Network.Ip == \"\" { return true, sandboxStatus.Metadata.Attempt + 1, sandboxStatus.Id } return false, sandboxStatus.Metadata.Attempt, sandboxStatus.Id } 计算Pod的容器状态计算逻辑相对长一些，这里我就不贴代码了，其如要流程分为两个部分： 1.需要创建sandbox: 在该状态下，如果存在初始化容器，则会先进行初始化容器的初始化，即当前步骤只创建第一个初始化容器，如果没有初始化容器，则就将所有的业务容器加入到启动的列表里面 2.不需要创建sandbox: 该状态下会检查遍历所有的临时容器，初始化容器(如果存在失败的初始化容器，则就先启动初始化容器，不会进行业务容器的启动)，业务容器，最终会构建一个需要kill掉的容器列表，还有两个启动的容器列表 4.2 killPod全部清理 需要进行KillPod的状态有两种： sanbbox状态变更 即当sandbox状态不满足要求，则此时需要将Pod的所有容器都杀掉，然后进行重建 无需进行保留的容器 如果Pod对应的容器的hash值变更、状态为失败，则就需要重建 if podContainerChanges.KillPod { // 杀死当前所有的pod killResult := m.killPodWithSyncResult(pod, kubecontainer.ConvertPodStatusToRunningPod(m.runtimeName, podStatus), nil) if podContainerChanges.CreateSandbox { // 终止初始化运行 m.purgeInitContainers(pod, podStatus) } } 4.3 部分清理 如果容器当前的状态是正常的，并且hash没有发生变化，则就不需要进行变更，此时就只需要将当前状态不正常的容器进行清理重建即可 for containerID, containerInfo := range podContainerChanges.ContainersToKill { if err := m.killContainer(pod, containerID, containerInfo.name, containerInfo.message, nil); err != nil { return } } 清理初始化容器 在正式启动容器之前，除了上面两部分，还会进行初始化容器的清理工作 m.pruneInitContainersBeforeStart(pod, podStatus) 5.构建运行阶段 构建运行阶段，主要分为两个大的部分：创建并运行sandbox容器、运行用户容器 5.1 运行sandbox 检查需要创建sandbox,则会首先创建sandbox容器，并获取状态，然后填充当前的Pod的IP信息 // Step 4: Create a sandbox for the pod if necessary. // 创建沙箱环境 podSandboxID := podContainerChanges.SandboxID if podContainerChanges.CreateSandbox { podSandboxID, msg, err = m.createPodSandbox(pod, podContainerChanges.Attempt) podSandboxStatus, err := m.runtimeService.PodSandboxStatus(podSandboxID) if !kubecontainer.IsHostNetworkPod(pod) { podIPs = m.determinePodSandboxIPs(pod.Namespace, pod.Name, podSandboxStatus) } } 5.2 创建sandbox主流程 创建sandbox的主流程主要就三个步骤：创建配置信息、创建日志目录、调用cri运行sandbox生成配置阶段主要包含端口映射、主机名、DNS、Linux中的SecurityContext灯的配置 func (m *kubeGenericRuntimeManager) createPodSandbox(pod *v1.Pod, attempt uint32) (string, string, error) { // 获取沙箱配置 podSandboxConfig, err := m.generatePodSandboxConfig(pod, attempt) // 创建目录 err = m.osInterface.MkdirAll(podSandboxConfig.LogDirectory, 0755) runtimeHandler := \"\" if utilfeature.DefaultFeatureGate.Enabled(features.RuntimeClass) && m.runtimeClassManager != nil { // 获取当前的runtimeHandler runtimeHandler, err = m.runtimeClassManager.LookupRuntimeHandler(pod.Spec.RuntimeClassName) } // 运行Sandbox podSandBoxID, err := m.runtimeService.RunPodSandbox(podSandboxConfig, runtimeHandler) return podSandBoxID, \"\", nil } 5.3 cri中的RunSandbox sandbox的启动主要包含下面几部分：1) 拉取sanbox容器镜像 2)创建sandbox容器 3)创建sandbox的checkpoint 4)启动sandbox容器 5)为sandbox启动网络(如果不是主机网络) func (ds *dockerService) RunPodSandbox(ctx context.Context, r *runtimeapi.RunPodSandboxRequest) (*runtimeapi.RunPodSandboxResponse, error) { config := r.GetConfig() // Step 1: Pull the image for the sandbox. // 拉取sandbox沙箱 // defaultPodSandboxImageName = \"k8s.gcr.io/pause\" // defaultPodSandboxImageVersion = \"3.1\" image := defaultSandboxImage podSandboxImage := ds.podSandboxImage if len(podSandboxImage) != 0 { image = podSandboxImage } // 拉取镜像 if err := ensureSandboxImageExists(ds.client, image); err != nil { return nil, err } // 2.创建sandbox容器 if r.GetRuntimeHandler() != \"\" && r.GetRuntimeHandler() != runtimeName { return nil, fmt.Errorf(\"RuntimeHandler %q not supported\", r.GetRuntimeHandler()) } // 创建沙箱配置 createConfig, err := ds.makeSandboxDockerConfig(config, image) // 创建容器 createResp, err := ds.client.CreateContainer(*createConfig) resp := &runtimeapi.RunPodSandboxResponse{PodSandboxId: createResp.ID} ds.setNetworkReady(createResp.ID, false) defer func(e *error) { // Set networking ready depending on the error return of // the parent function if *e == nil { ds.setNetworkReady(createResp.ID, true) } }(&err) // Step 3: 创建sandbox checkpoint if err = ds.checkpointManager.CreateCheckpoint(createResp.ID, constructPodSandboxCheckpoint(config)); err != nil { return nil, err } // Step 4: Start the sandbox container. // // 4.启动sandbox容器 err = ds.client.StartContainer(createResp.ID) if err != nil { return nil, fmt.Errorf(\"failed to start sandbox container for pod %q: %v\", config.Metadata.Name, err) } //重写docker生成的resolv.conf文件。 if dnsConfig := config.GetDnsConfig(); dnsConfig != nil { containerInfo, err := ds.client.InspectContainer(createResp.ID) if err != nil { return nil, fmt.Errorf(\"failed to inspect sandbox container for pod %q: %v\", config.Metadata.Name, err) } // DNS写配置文件 if err := rewriteResolvFile(containerInfo.ResolvConfPath, dnsConfig.Servers, dnsConfig.Searches, dnsConfig.Options); err != nil { return nil, fmt.Errorf(\"rewrite resolv.conf failed for pod %q: %v\", config.Metadata.Name, err) } } // 如果处于主机网络模式，请不要调用网络插件。 if config.GetLinux().GetSecurityContext().GetNamespaceOptions().GetNetwork() == runtimeapi.NamespaceMode_NODE { return resp, nil } // Step 5: 设置sandbox容器的网络 //所有的pod网络都是由启动时发现的CNI插件设置的。 //这个插件分配pod ip，在沙盒内设置路由，创建接口等。理论上，它的管辖权以pod沙盒网络结束， // 但它也可能在主机上插入iptables规则或打开端口，以满足CNI标准尚未识别的pod规范的部分要求。 cID := kubecontainer.BuildContainerID(runtimeName, createResp.ID) networkOptions := make(map[string]string) if dnsConfig := config.GetDnsConfig(); dnsConfig != nil { // Build DNS options. dnsOption, err := json.Marshal(dnsConfig) if err != nil { return nil, fmt.Errorf(\"failed to marshal dns config for pod %q: %v\", config.Metadata.Name, err) } // 设置网络dns networkOptions[\"dns\"] = string(dnsOption) } // 网络信息 err = ds.network.SetUpPod(config.GetMetadata().Namespace, config.GetMetadata().Name, cID, config.Annotations, networkOptions) return resp, nil } 5.4 容器启动函数 容器启动函数中会通过闭包来保存上面创建的sandbox的信息，同时根据当前容器的配置，创建新的业务容器 start := func(typeName string, container *v1.Container) error { klog.V(4).Infof(\"Creating %v %+v in pod %v\", typeName, container, format.Pod(pod)) if msg, err := m.startContainer(podSandboxID, podSandboxConfig, container, pod, podStatus, pullSecrets, podIP, podIPs); err != nil { startContainerResult.Fail(err, msg) } return nil } 5.5 启动容器 容器的启动，主要包含四个流程：1.拉取镜像 2.创建容器&PreStart钩子回调 3) 启动容器 4）postStart启动容器 func (m *kubeGenericRuntimeManager) startContainer(podSandboxID string, podSandboxConfig *runtimeapi.PodSandboxConfig, container *v1.Container, pod *v1.Pod, podStatus *kubecontainer.PodStatus, pullSecrets []v1.Secret, podIP string, podIPs []string) (string, error) { // 启动容器 // Step 1: pull the image. imageRef, msg, err := m.imagePuller.EnsureImageExists(pod, container, pullSecrets, podSandboxConfig) // Step 2: create the container. ref, err := kubecontainer.GenerateContainerRef(pod, container) // 获取容器配置， 里面会进行各种文件目录的挂载 containerConfig, cleanupAction, err := m.generateContainerConfig(container, pod, restartCount, podIP, imageRef, podIPs) if cleanupAction != nil { defer cleanupAction() } if err != nil { s, _ := grpcstatus.FromError(err) m.recordContainerEvent(pod, container, \"\", v1.EventTypeWarning, events.FailedToCreateContainer, \"Error: %v\", s.Message()) return s.Message(), ErrCreateContainerConfig } // 创建容器 containerID, err := m.runtimeService.CreateContainer(podSandboxID, containerConfig, podSandboxConfig) // 启动容器钩子 err = m.internalLifecycle.PreStartContainer(pod, container, containerID) m.recordContainerEvent(pod, container, containerID, v1.EventTypeNormal, events.CreatedContainer, fmt.Sprintf(\"Created container %s\", container.Name)) if ref != nil { m.containerRefManager.SetRef(kubecontainer.ContainerID{ Type: m.runtimeName, ID: containerID, }, ref) } // Step 3: 启动容器 err = m.runtimeService.StartContainer(containerID) if err != nil { s, _ := grpcstatus.FromError(err) m.recordContainerEvent(pod, container, containerID, v1.EventTypeWarning, events.FailedToStartContainer, \"Error: %v\", s.Message()) return s.Message(), kubecontainer.ErrRunContainer } containerMeta := containerConfig.GetMetadata() sandboxMeta := podSandboxConfig.GetMetadata() legacySymlink := legacyLogSymlink(containerID, containerMeta.Name, sandboxMeta.Name, sandboxMeta.Namespace) // 容器日志 containerLog := filepath.Join(podSandboxConfig.LogDirectory, containerConfig.LogPath) if _, err := m.osInterface.Stat(containerLog); !os.IsNotExist(err) { if err := m.osInterface.Symlink(containerLog, legacySymlink); err != nil { } } // Step 4: 执行postStart钩子 if container.Lifecycle != nil && container.Lifecycle.PostStart != nil { msg, handlerErr := m.runner.Run(kubeContainerID, pod, container, container.Lifecycle.PostStart) if handlerErr != nil { if err := m.killContainer(pod, kubeContainerID, container.Name, \"FailedPostStartHook\", nil); err != nil { } } } return \"\", nil } 5.6 cri.CreateContainer CreateContainer中会首先根据k8s里面传递的配置信息，根据当前平台和对应的参数来进行docker容器运行的配置，然后调用docker接口进行容器的配置 func (ds *dockerService) CreateContainer(_ context.Context, r *runtimeapi.CreateContainerRequest) (*runtimeapi.CreateContainerResponse, error) { podSandboxID := r.PodSandboxId config := r.GetConfig() sandboxConfig := r.GetSandboxConfig() containerName := makeContainerName(sandboxConfig, config) // 创建容器配置 createConfig := dockertypes.ContainerCreateConfig{ Name: containerName, Config: &dockercontainer.Config{ // TODO: set User. Entrypoint: dockerstrslice.StrSlice(config.Command), Cmd: dockerstrslice.StrSlice(config.Args), Env: generateEnvList(config.GetEnvs()), Image: image, WorkingDir: config.WorkingDir, Labels: labels, // Interactive containers: OpenStdin: config.Stdin, StdinOnce: config.StdinOnce, Tty: config.Tty, // Disable Docker's health check until we officially support it // (https://github.com/kubernetes/kubernetes/issues/25829). Healthcheck: &dockercontainer.HealthConfig{ Test: []string{\"NONE\"}, }, }, HostConfig: &dockercontainer.HostConfig{ Binds: generateMountBindings(config.GetMounts()), RestartPolicy: dockercontainer.RestartPolicy{ Name: \"no\", }, }, } hc := createConfig.HostConfig err = ds.updateCreateConfig(&createConfig, config, sandboxConfig, podSandboxID, securityOptSeparator, apiVersion) if err != nil { return nil, fmt.Errorf(\"failed to update container create config: %v\", err) } // 设置容器devices devices := make([]dockercontainer.DeviceMapping, len(config.Devices)) for i, device := range config.Devices { devices[i] = dockercontainer.DeviceMapping{ PathOnHost: device.HostPath, PathInContainer: device.ContainerPath, CgroupPermissions: device.Permissions, } } hc.Resources.Devices = devices securityOpts, err := ds.getSecurityOpts(config.GetLinux().GetSecurityContext().GetSeccompProfilePath(), securityOptSeparator) if err != nil { return nil, fmt.Errorf(\"failed to generate security options for container %q: %v\", config.Metadata.Name, err) } hc.SecurityOpt = append(hc.SecurityOpt, securityOpts...) cleanupInfo, err := ds.applyPlatformSpecificDockerConfig(r, &createConfig) if err != nil { return nil, err } createResp, createErr := ds.client.CreateContainer(createConfig) if createErr != nil { createResp, createErr = recoverFromCreationConflictIfNeeded(ds.client, createConfig, createErr) } if createResp != nil { containerID := createResp.ID if cleanupInfo != nil { // we don't perform the clean up just yet at that could destroy information // needed for the container to start (e.g. Windows credentials stored in // registry keys); instead, we'll clean up when the container gets removed ds.containerCleanupInfos[containerID] = cleanupInfo } return &runtimeapi.CreateContainerResponse{ContainerId: containerID}, nil } return nil, createErr } 更新容器配置 func (ds *dockerService) updateCreateConfig( createConfig *dockertypes.ContainerCreateConfig, config *runtimeapi.ContainerConfig, sandboxConfig *runtimeapi.PodSandboxConfig, podSandboxID string, securityOptSep rune, apiVersion *semver.Version) error { if lc := config.GetLinux(); lc != nil { rOpts := lc.GetResources() if rOpts != nil { // 更新资源配置信息 createConfig.HostConfig.Resources = dockercontainer.Resources{ Memory: rOpts.MemoryLimitInBytes, MemorySwap: rOpts.MemoryLimitInBytes, CPUShares: rOpts.CpuShares, CPUQuota: rOpts.CpuQuota, CPUPeriod: rOpts.CpuPeriod, } createConfig.HostConfig.OomScoreAdj = int(rOpts.OomScoreAdj) } // 应用SecurityContext if err := applyContainerSecurityContext(lc, podSandboxID, createConfig.Config, createConfig.HostConfig, securityOptSep); err != nil { return fmt.Errorf(\"failed to apply container security context for container %q: %v\", config.Metadata.Name, err) } } // 应用cgroup配置 if lc := sandboxConfig.GetLinux(); lc != nil { // Apply Cgroup options. cgroupParent, err := ds.GenerateExpectedCgroupParent(lc.CgroupParent) createConfig.HostConfig.CgroupParent = cgroupParent } return nil } 5.7 cri.StartContainer 其实就直接掉Docker的接口启动容器即可 func (ds *dockerService) StartContainer(_ context.Context, r *runtimeapi.StartContainerRequest) (*runtimeapi.StartContainerResponse, error) { err := ds.client.StartContainer(r.ContainerId) return &runtimeapi.StartContainerResponse{}, nil } 6. 总结 Pod启动的核心流程大概就这些，里面会有一些笔认购具体参数数据的构建，没有写明，但是如果对代码感兴趣的，可以顺着这个核心流程基本可以读下来，如果对代码不感兴趣，则后面这张图可以算作一个精简版的，面试可用的Pod创建流程图 kubernetes学习笔记地址: https://www.yuque.com/baxiaoshi/tyado3 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/k8s/kubesphere/在k8s集群安装kubesphere2.1.html":{"url":"linux/k8s/kubesphere/在k8s集群安装kubesphere2.1.html","title":"kubesphere","keywords":"","body":"在 Kubernetes集群中 安装 KubeSphere2.1 安装介绍 完整安装、高可用安装、升级、可插拔功能组件安装等等全在kubesphere官网了，写的非常详细，如果有一些解决不了的问题就在 kubesphere论坛 发帖(发帖前最好自己尝试解决一下，尤其是持久化存储这一块！！！) 文档说明 本文将使用kubeadm安装k8s1.16.9版本，并且在k8s集群中安装kubesphere2.1 官方文档中明确说明了如果要完全安装kubesphere，集群机器配置至少是8c16g，而最小化安装机器配置最少为2g内存，所以这里仅仅是最小化安装体验 使用 kubeadm 搭建 v1.16.9 版本 Kubernetes 集群 一、环境准备 1.1实验环境 角色 IP地址 主机名 docker版本 硬件配置 系统 内核 master 192.168.9.10 k8s-master 18.09.9 2c4g CentOS7.7 3.10.0-1062.el7.x86_64 node1 192.168.9.13 k8s-node1 18.09.9 2c6g CentOS7.7 3.10.0-1062.el7.x86_64 node2 192.168.9.14 k8s-node2 18.09.9 2c6g CentOS7.7 3.10.0-1062.el7.x86_64 1.2每个节点配置host信息 cat >> /etc/hosts 1.3禁用防火墙和selinux //禁用防火墙 systemctl stop firewalld && systemctl disable firewalld //禁用selinux #临时修改 setenforce 0 #永久修改，重启服务器后生效 sed -i '7s/enforcing/disabled/' /etc/selinux/config 1.4创建/etc/sysctl.d/k8s.conf文件，添加如下内容 //向文件中写入以下内容 cat >/etc/sysctl.d/k8s.conf 1.5安装ipvs 脚本创建了的/etc/sysconfig/modules/ipvs.modules文件，保证在节点重启后能自动加载所需模块。使用lsmod | grep -e ip_vs -e nf_conntrack_ipv4命令查看是否已经正确加载所需的内核模块 //向文件中写入以下内容 cat > /etc/sysconfig/modules/ipvs.modules 安装ipset和ipvsadm(便于查看 ipvs 的代理规则) yum -y install ipset ipvsadm 1.6同步服务器时间 //安装chrony yum -y install chrony //修改同步服务器地址为阿里云 sed -i.bak '3,6d' /etc/chrony.conf && sed -i '3cserver ntp1.aliyun.com iburst' \\ /etc/chrony.conf //启动chronyd及加入开机自启 systemctl start chronyd && systemctl enable chronyd //查看同步结果 chronyc sources 210 Number of sources = 1 MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^* 120.25.115.20 2 6 37 13 +194us[+6131us] +/- 33ms 1.7关闭swap分区 修改/etc/fstab文件，注释掉 SWAP 的自动挂载，使用free -m确认 swap 已经关闭 //手动关闭swap swapoff -a //修改fstab文件，注释swap自动挂载 sed -i '/^\\/dev\\/mapper\\/centos-swap/c#/dev/mapper/centos-swap swap swap defaults 0 0' /etc/fstab //查看swap是否关闭 free -m total used free shared buff/cache available Mem: 1994 682 612 9 699 1086 Swap: 0 0 0 swappiness 参数调整，修改/etc/sysctl.d/k8s.conf添加下面一行 cat >>/etc/sysctl.d/k8s.conf 1.8安装docker18.09.9 1.添加阿里云yum源 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 2.查看可用版本 yum list docker-ce --showduplicates | sort -r 已加载插件：fastestmirror, langpacks 可安装的软件包 * updates: mirrors.aliyun.com Loading mirror speeds from cached hostfile * extras: mirrors.aliyun.com docker-ce.x86_64 3:19.03.5-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.4-3.el7 docker-ce-stable 。。。。。。 docker-ce.x86_64 3:18.09.9-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.8-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.7-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.6-3.el7 docker-ce-stable 。。。。。。 3.安装docker18.09.9 yum -y install docker-ce-18.09.9-3.el7 docker-ce-cli-18.09.9 4.启动docker并设置开机自启 systemctl enable docker && systemctl start docker 5.配置阿里云docker镜像加速 cat > /etc/docker/daemon.json 1.9修改docker Cgroup Driver为systemd #修改docker Cgroup Driver为systemd 将/usr/lib/systemd/system/docker.service文件中的这一行 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock 修改为 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --exec-opt native.cgroupdriver=systemd 如果不修改，在添加 worker 节点时可能会碰到如下错误 [WARNING IsDockerSystemdCheck]: detected \"cgroupfs\" as the Docker cgroup driver. The recommended driver is \"systemd\". Please follow the guide at https://kubernetes.io/docs/setup/cri/ //使用如下命令修改 sed -i.bak \"s#^ExecStart=/usr/bin/dockerd.*#ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --exec-opt native.cgroupdriver=systemd#g\" /usr/lib/systemd/system/docker.service //重启docker systemctl daemon-reload && systemctl restart docker 1.10安装Kubeadm 需要科学上网 cat >/etc/yum.repos.d/kubernetes.repo 使用阿里云yum源 cat >/etc/yum.repos.d/kubernetes.repo 安装 kubeadm、kubelet、kubectl(阿里云yum源会随官方更新最新版，因此指定版本) //安装1.16.9版本 yum -y install kubelet-1.16.9 kubeadm-1.16.9 kubectl-1.16.9 //查看版本 kubeadm version kubeadm version: &version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.9\", GitCommit:\"a17149e1a189050796ced469dbd78d380f2ed5ef\", GitTreeState:\"clean\", BuildDate:\"2020-04-16T11:42:30Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"} 设置kubelet开机自启 systemctl enable kubelet 设置k8s命令自动补全 yum -y install bash-completion source /usr/share/bash-completion/bash_completion source > ~/.bashrc 到此，基本环境安装完成!!! 二、初始化集群 2.1master节点操作，配置 kubeadm 初始化文件 cat ./kubeadm-config.yaml apiVersion: kubeadm.k8s.io/v1beta2 kind: ClusterConfiguration kubernetesVersion: v1.16.9 imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers #master地址 controlPlaneEndpoint: \"192.168.9.10:6443\" networking: serviceSubnet: \"10.96.0.0/16\" #k8s容器组所在的网段 podSubnet: \"10.20.0.1/16\" dnsDomain: \"cluster.local\" EOF 2.2初始化master ⚠️如果想要重新初始化，需要执行命令kubeadm reset -f #kubeadm init --config=kubeadm-config.yaml --upload-certs 完整输出结果 kubeadm init --config=kubeadm-config.yaml [init] Using Kubernetes version: v1.16.9 [preflight] Running pre-flight checks [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using 'kubeadm config images pull' [kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\" [kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\" [kubelet-start] Activating the kubelet service [certs] Using certificateDir folder \"/etc/kubernetes/pki\" [certs] Generating \"ca\" certificate and key [certs] Generating \"apiserver\" certificate and key [certs] apiserver serving cert is signed for DNS names [k8s-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.9.10 192.168.9.10] [certs] Generating \"apiserver-kubelet-client\" certificate and key [certs] Generating \"front-proxy-ca\" certificate and key [certs] Generating \"front-proxy-client\" certificate and key [certs] Generating \"etcd/ca\" certificate and key [certs] Generating \"etcd/server\" certificate and key [certs] etcd/server serving cert is signed for DNS names [k8s-master localhost] and IPs [192.168.9.10 127.0.0.1 ::1] [certs] Generating \"etcd/peer\" certificate and key [certs] etcd/peer serving cert is signed for DNS names [k8s-master localhost] and IPs [192.168.9.10 127.0.0.1 ::1] [certs] Generating \"etcd/healthcheck-client\" certificate and key [certs] Generating \"apiserver-etcd-client\" certificate and key [certs] Generating \"sa\" key and public key [kubeconfig] Using kubeconfig folder \"/etc/kubernetes\" [kubeconfig] Writing \"admin.conf\" kubeconfig file [kubeconfig] Writing \"kubelet.conf\" kubeconfig file [kubeconfig] Writing \"controller-manager.conf\" kubeconfig file [kubeconfig] Writing \"scheduler.conf\" kubeconfig file [control-plane] Using manifest folder \"/etc/kubernetes/manifests\" [control-plane] Creating static Pod manifest for \"kube-apiserver\" [control-plane] Creating static Pod manifest for \"kube-controller-manager\" [control-plane] Creating static Pod manifest for \"kube-scheduler\" [etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\" [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s [apiclient] All control plane components are healthy after 16.501777 seconds [upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace [kubelet] Creating a ConfigMap \"kubelet-config-1.16\" in namespace kube-system with the configuration for the kubelets in the cluster [upload-certs] Skipping phase. Please see --upload-certs [mark-control-plane] Marking the node k8s-master as control-plane by adding the label \"node-role.kubernetes.io/master=''\" [mark-control-plane] Marking the node k8s-master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule] [bootstrap-token] Using token: px979r.mphk9ee5ya8fgy44 [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [bootstrap-token] Creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config You should now deploy a pod network to the cluster. Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ You can now join any number of control-plane nodes by copying certificate authorities and service account keys on each node and then running the following as root: kubeadm join 192.168.9.10:6443 --token px979r.mphk9ee5ya8fgy44 \\ --discovery-token-ca-cert-hash sha256:5e7c7cd1cc1f86c0761e54b9380de22968b6b221cb98939c14ab2942223f6f51 \\ --control-plane Then you can join any number of worker nodes by running the following on each as root: kubeadm join 192.168.9.10:6443 --token px979r.mphk9ee5ya8fgy44 \\ --discovery-token-ca-cert-hash sha256:5e7c7cd1cc1f86c0761e54b9380de22968b6b221cb98939c14ab2942223f6f51 拷贝 kubeconfig 文件 //这里的路径为/root mkdir -p $HOME/.kube cp -i /etc/kubernetes/admin.conf $HOME/.kube/config chown $(id -u):$(id -g) $HOME/.kube/config 2.3master添加节点 node1和node2相同操作 将master节点上的$HOME/.kube/config 文件拷贝到node节点对应的文件中 1.创建目录，这里的路径为/root mkdir -p $HOME/.kube 2.把master节点上的config文件拷贝到node1和node2的$HOME/.kube scp k8s-master1:~/.kube/config $HOME/.kube 3.修改权限 chown $(id -u):$(id -g) $HOME/.kube/config 将node1和node2加入到集群中 这里需要用到2.2中初始化master最后生成的token和sha256值 #kubeadm join 192.168.9.10:6443 --token px979r.mphk9ee5ya8fgy44 --discovery-token-ca-cert-hash sha256:5e7c7cd1cc1f86c0761e54b9380de22968b6b221cb98939c14ab2942223f6f51 输出结果 [preflight] Running pre-flight checks [WARNING IsDockerSystemdCheck]: detected \"cgroupfs\" as the Docker cgroup driver. The recommended driver is \"systemd\". Please follow the guide at https://kubernetes.io/docs/setup/cri/ [preflight] Reading configuration from the cluster... [preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' [kubelet-start] Downloading configuration for the kubelet from the \"kubelet-config-1.16\" ConfigMap in the kube-system namespace [kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\" [kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\" [kubelet-start] Activating the kubelet service [kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap... This node has joined the cluster: * Certificate signing request was sent to apiserver and a response was received. * The Kubelet was informed of the new secure connection details. Run 'kubectl get nodes' on the control-plane to see this node join the cluster. 如果忘记了token和sha256值，可以在master节点使用如下命令查看 //查看token #kubeadm token list TOKEN TTL EXPIRES USAGES DESCRIPTION EXTRA GROUPS px979r.mphk9ee5ya8fgy44 20h 2020-03-18T13:49:48+08:00 authentication,signing system:bootstrappers:kubeadm:default-node-token //查看sha256 #openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //' 5e7c7cd1cc1f86c0761e54b9380de22968b6b221cb98939c14ab2942223f6f51 //同时查看token和sha256 #kubeadm token create --print-join-command kubeadm join 192.168.9.10:6443 --token 9b28zg.oyt0kvvpmtrem4bg --discovery-token-ca-cert-hash sha256:5e7c7cd1cc1f86c0761e54b9380de22968b6b221cb98939c14ab2942223f6f51 master节点查看node，发现状态都是NotReady，因为还没有安装网络插件，这里我们安装calio官方插件文档 kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-master NotReady master 19m v1.16.9 k8s-node1 NotReady 4m10s v1.16.9 k8s-node2 NotReady 4m3s v1.16.9 2.4master节点安装网络插件calio //下载文件 wget https://docs.projectcalico.org/v3.8/manifests/calico.yaml 将文件中的620行改为如下，因为在上边kubeadm-config.yaml配置文件中指定了容器组IP 620行 value: \"10.20.0.1/16\" //修改完成后安装calico网络插件 kubectl apply -f calico.yaml //安装完成后稍等一会查看pods状态 kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE calico-kube-controllers-dc6cb64cb-8sh59 1/1 Running 0 6m22s calico-node-89s9k 1/1 Running 0 6m22s calico-node-dkt7w 1/1 Running 0 6m22s calico-node-tgg2h 1/1 Running 0 6m22s coredns-667f964f9b-7hrj9 1/1 Running 0 33m coredns-667f964f9b-8q7sh 1/1 Running 0 33m etcd-k8s-master 1/1 Running 0 33m kube-apiserver-k8s-master 1/1 Running 0 32m kube-controller-manager-k8s-master 1/1 Running 0 33m kube-proxy-b2r5d 1/1 Running 0 12m kube-proxy-nd982 1/1 Running 0 11m kube-proxy-zh6cz 1/1 Running 0 33m kube-scheduler-k8s-master 1/1 Running 0 32m //查看node状态 [root@k8s-master ~]# kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-master Ready master 31m v1.16.9 k8s-node1 Ready 9m46s v1.16.9 k8s-node2 Ready 9m22s v1.16.9 2.5安装Dashboard(可选) 下载文件及修改内容 这里查看dashboard对应的k8s版本 //下载文件 v2.0.0-rc3是中文版本，beta8是英文版本 wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta8/aio/deploy/recommended.yaml wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-rc3/aio/deploy/recommended.yaml //修改Service为NodePort类型 42行下增加一行 nodePort: 30001 44行下增加一行 type: NodePort //原先内容 spec: ports: - port: 443 targetPort: 8443 selector: k8s-app: kubernetes-dashboard //修改后内容 spec: ports: - port: 443 targetPort: 8443 nodePort: 30001 #增加，指定nodeport端口 selector: k8s-app: kubernetes-dashboard type: NodePort #增加，修改类型为nodeport 部署dashboard kubectl apply -f recommended.yaml 查看dashboard的运行状态及外网访问端口 //查看dashboard运行状态 #kubectl get pods -n kubernetes-dashboard -l k8s-app=kubernetes-dashboard NAME READY STATUS RESTARTS AGE kubernetes-dashboard-5996555fd8-2ppc5 1/1 Running 0 8m16s //查看dashboard外网访问端口，命名空间为kubernetes-dashboard #kubectl get svc -n kubernetes-dashboard -l k8s-app=kubernetes-dashboard kubectl get svc -n kubernetes-dashboard -l k8s-app=kubernetes-dashboard NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes-dashboard NodePort 10.96.142.172 443:30001/TCP 8m37s 通过上边的30001端口访问dashboard，注意是https ⚠️k8s1.16.9这个版本中，使用的dashboard版本是2.0.0-beta8，只有火狐浏览器可以访问，其余浏览器都不能访问，会报错如下 使用火狐浏览器访问，由于 dashboard 默认是自建的 https 证书，该证书是不受浏览器信任的，所以我们需要强制跳转就可以了 然后创建一个具有全局所有权限的用户来登录Dashboard //编辑admin.yaml文件 cat > admin.yaml 2.6安装k8s切换命名空间工具 git clone https://github.com.cnpmjs.org/ahmetb/kubectx cp kubectx/kubens /usr/local/bin #查看所有命名空间 kubens #切换到kube-system命名空间 kubens kube-system Context \"kubernetes-admin@kubernetes\" modified. Active namespace is \"kube-system\". 到此，使用kubeadm安装k8s 1.16.3完成！！！ 三、在k8s集群中安装kubesphere 官网中安装kubesphere的前提条件如下 Kubernetes版本： 1.15.x ≤ K8s version ≤ 1.17.x； Helm版本： 2.10.0 ≤ Helm Version ＜ 3.0.0（不支持 helm 2.16.0 #6894），且已安装了 Tiller，参考 如何安装与配置 Helm （预计 3.0 支持 Helm v3）； 集群已有默认的存储类型（StorageClass），若还没有准备存储请参考 安装 OpenEBS 创建 LocalPV 存储类型 用作开发测试环境。 集群能够访问外网，若无外网请参考 在 Kubernetes 离线安装 KubeSphere。 3.1安装helm2.16.3 客户端helm安装 3.1.1下载helm客户端 wget https://get.helm.sh/helm-v2.16.3-linux-amd64.tar.gz 3.1.2解压缩并拷贝helm二进制文件 tar xf helm-v2.16.3-linux-amd64.tar.gz cp linux-amd64/helm /usr/local/bin 服务端tiller安装 3.1.3集群每个节点安装socat 否则会报错Error: cannot connect to Tiller yum install -y socat 3.1.4初始化helm，部署tiller Tiller 是以 Deployment 方式部署在 Kubernetes 集群中的，只需执行helm init命令便可简单的完成安装，但是Helm默认会去 storage.googleapis.com 拉取镜像。。。。。。这里需要使用阿里云的仓库完成安装 #添加阿里云的仓库 helm init --client-only --stable-repo-url https://aliacs-app-catalog.oss-cn-hangzhou.aliyuncs.com/charts/ helm repo add incubator https://aliacs-app-catalog.oss-cn-hangzhou.aliyuncs.com/charts-incubator/ helm repo update #创建服务端 使用-i指定阿里云仓库 helm init --service-account tiller --upgrade -i registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.16.3 --stable-repo-url https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts #创建TLS认证服务端，参考地址：#https://github.com/gjmzj/kubeasz/blob/master/docs/guide/helm.md helm init --service-account tiller --upgrade -i registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.16.3 --tiller-tls-cert /etc/kubernetes/ssl/tiller001.pem --tiller-tls-key /etc/kubernetes/ssl/tiller001-key.pem --tls-ca-cert /etc/kubernetes/ssl/ca.pem --tiller-namespace kube-system --stable-repo-url https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts 3.1.5给tiller授权 因为 Helm 的服务端 Tiller 是一个部署在 Kubernetes 中 kube-system namespace下的deployment，它会去连接 kube-api在Kubernetes里创建和删除应用。 而从Kubernetes1.6版本开始，API Server 启用了RBAC授权。目前的Tiller部署时默认没有定义授权的ServiceAccount，这会导致访问API Server时被拒绝。所以我们需要明确为Tiller部署添加授权。 创建 Kubernetes 的服务帐号和绑定角色 #创建serviceaccount kubectl create serviceaccount --namespace kube-system tiller #创建角色绑定 kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller 为tiller设置帐号 #使用kubectl patch更新API对象 kubectl patch deploy --namespace kube-system tiller-deploy -p '{\"spec\":{\"template\":{\"spec\":{\"serviceAccount\":\"tiller\"}}}}' #验证是否授权成功 kubectl get deploy --namespace kube-system tiller-deploy --output yaml|grep serviceAccount serviceAccount: tiller serviceAccountName: tiller 3.1.6验证tiller是否安装成功 kubectl -n kube-system get pods|grep tiller tiller-deploy-6d8dfbb696-4cbcz 1/1 Running 0 88s 输入命令 helm version 显示结果以下既为成功 Client: &version.Version{SemVer:\"v2.16.3\", GitCommit:\"1ee0254c86d4ed6887327dabed7aa7da29d7eb0d\", GitTreeState:\"clean\"} Server: &version.Version{SemVer:\"v2.16.3\", GitCommit:\"1ee0254c86d4ed6887327dabed7aa7da29d7eb0d\", GitTreeState:\"clean\"} 3.1.7卸载helm服务端tiller $ helm reset 或 $ helm reset -f 强制删除 3.2安装nfs存储 官方提供的openebs存储貌似不太好使，反正我是安装完后pod的状态一直是pending nfs存储比较简单，适合实验环境 也可以使用别的持久化存储 安装nfs参考文章 nfs这里选择在master安装，上边的参考文章中说nfs server安装在master节点会有问题，但是我这里没有 3.2.1安装配置nfs client端，这里为两个node节点 yum -y install nfs-utils server端，master节点 1.安装包 yum -y install nfs-utils rpcbind 2.编辑配置文件 ⚠️配置文件中的*是允许所有网段，根据自己实际情况写明网段 cat >/etc/exports 配置storageclass，注意修改nfs服务端IP和共享目录 cat >storageclass.yaml 创建storageclass kubectl apply -f storageclass.yaml 设置默认strorageclass kubectl patch storageclass nfs-storage -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\":\"true\"}}}' 检查nfs-client pod状态 #这里是在default命名空间下创建的 kubectl get pods NAME READY STATUS RESTARTS AGE nfs-client-provisioner-7b9746695c-nrz4n 1/1 Running 0 2m38s 检查默认存储 #这里是在default命名空间下创建的 kubectl get sc NAME PROVISIONER AGE nfs-storage (default) fuseim.pri/ifs 7m22s 3.3部署kubesphere 官方文档 3.3.1最小化安装 KubeSphere kubectl apply -f https://raw.githubusercontent.com/kubesphere/ks-installer/master/kubesphere-minimal.yaml 3.3.2查看安装日志 #使用如下命令查看安装日志 kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l app=ks-install -o jsonpath='{.items[0].metadata.name}') -f 当日志最后提示如下即表明安装完成，但是还是要等待一些pod完全运行起来才可以 Start installing monitoring ************************************************** task monitoring status is successful total: 1 completed:1 ************************************************** ##################################################### ### Welcome to KubeSphere! ### ##################################################### Console: http://192.168.9.10:30880 Account: admin Password: P@88w0rd NOTES： 1. After logging into the console, please check the monitoring status of service components in the \"Cluster Status\". If the service is not ready, please wait patiently. You can start to use when all components are ready. 2. Please modify the default password after login. ##################################################### 安装日志中会有一个报错如下，但是没有影响 TASK [ks-core/ks-core : KubeSphere | Delete Ingress-controller configmap] ****** fatal: [localhost]: FAILED! => {\"changed\": true, \"cmd\": \"/usr/local/bin/kubectl delete cm -n kubesphere-system ks-router-config\\n\", \"delta\": \"0:00:00.562513\", \"end\": \"2020-04-28 07:18:28.772284\", \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2020-04-28 07:18:28.209771\", \"stderr\": \"Error from server (NotFound): configmaps \\\"ks-router-config\\\" not found\", \"stderr_lines\": [\"Error from server (NotFound): configmaps \\\"ks-router-config\\\" not found\"], \"stdout\": \"\", \"stdout_lines\": []} ...ignoring 检查所有pod状态，都为running才可以 kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE default nfs-client-provisioner-7b9746695c-nrz4n 1/1 Running 0 18m kube-system calico-kube-controllers-bc44d789c-ksgnt 1/1 Running 0 39h kube-system calico-node-2t4gr 1/1 Running 0 39h kube-system calico-node-5bzjl 1/1 Running 0 39h kube-system calico-node-fjdll 1/1 Running 0 39h kube-system coredns-58cc8c89f4-8jrlt 1/1 Running 0 39h kube-system coredns-58cc8c89f4-nt5z5 1/1 Running 0 39h kube-system etcd-k8s-master1 1/1 Running 0 39h kube-system kube-apiserver-k8s-master1 1/1 Running 0 39h kube-system kube-controller-manager-k8s-master1 1/1 Running 0 39h kube-system kube-proxy-b7vj4 1/1 Running 0 39h kube-system kube-proxy-bghx7 1/1 Running 0 39h kube-system kube-proxy-ntrxx 1/1 Running 0 39h kube-system kube-scheduler-k8s-master1 1/1 Running 0 39h kube-system kuboard-756d46c4d4-dwzwt 1/1 Running 0 39h kube-system metrics-server-78cff478b7-lwcfl 1/1 Running 0 39h kube-system tiller-deploy-6d8dfbb696-ldpjd 1/1 Running 0 40m kubernetes-dashboard dashboard-metrics-scraper-b68468655-t2wgd 1/1 Running 0 39h kubernetes-dashboard kubernetes-dashboard-64999dbccd-zwnn5 1/1 Running 1 39h kubesphere-controls-system default-http-backend-5d464dd566-5hlzs 1/1 Running 0 6m9s kubesphere-controls-system kubectl-admin-6c664db975-kp6r5 1/1 Running 0 3m10s kubesphere-monitoring-system kube-state-metrics-566cdbcb48-cc4fv 4/4 Running 0 5m32s kubesphere-monitoring-system node-exporter-5lvpx 2/2 Running 0 5m32s kubesphere-monitoring-system node-exporter-hlfbh 2/2 Running 0 5m32s kubesphere-monitoring-system node-exporter-qxkm6 2/2 Running 0 5m32s kubesphere-monitoring-system prometheus-k8s-0 3/3 Running 1 4m32s kubesphere-monitoring-system prometheus-k8s-system-0 3/3 Running 1 4m32s kubesphere-monitoring-system prometheus-operator-6b97679cfd-6dztx 1/1 Running 0 5m32s kubesphere-system ks-account-596657f8c6-kzx9w 1/1 Running 0 5m56s kubesphere-system ks-apigateway-78bcdc8ffc-2rvbg 1/1 Running 0 5m58s kubesphere-system ks-apiserver-5b548d7c5c-dxqt7 1/1 Running 0 5m57s kubesphere-system ks-console-78bcf96dbf-kdh7q 1/1 Running 0 5m53s kubesphere-system ks-controller-manager-696986f8d9-fklzv 1/1 Running 0 5m55s kubesphere-system ks-installer-75b8d89dff-zm6fl 1/1 Running 0 7m49s kubesphere-system openldap-0 1/1 Running 0 6m21s kubesphere-system redis-6fd6c6d6f9-dqh2s 1/1 Running 0 6m25s 访问kubesphere:30880 登陆后首界面 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/openstack/mitaka/1.centos7.8搭建openstack Mitaka版.html":{"url":"linux/openstack/mitaka/1.centos7.8搭建openstack Mitaka版.html","title":"centos7.8搭建openstack Mitaka版","keywords":"","body":"centos7.8搭建openstack Mitaka版 openstack中文文档 mitaka版官方文档 mitaka版密码说明 密码名称 描述 数据库密码(不能使用变量) 数据库的root密码 ADMIN_PASS admin 用户密码 CEILOMETER_DBPASS Telemetry 服务的数据库密码 CEILOMETER_PASS Telemetry 服务的 ceilometer 用户密码 CINDER_DBPASS 块设备存储服务的数据库密码 CINDER_PASS 块设备存储服务的 cinder 密码 DASH_DBPASS Database password for the dashboard DEMO_PASS demo 用户的密码 GLANCE_DBPASS 镜像服务的数据库密码 GLANCE_PASS 镜像服务的 glance 用户密码 HEAT_DBPASS Orchestration服务的数据库密码 HEAT_DOMAIN_PASS Orchestration 域的密码 HEAT_PASS Orchestration 服务中heat用户的密码 KEYSTONE_DBPASS 认证服务的数据库密码 NEUTRON_DBPASS 网络服务的数据库密码 NEUTRON_PASS 网络服务的 neutron 用户密码 NOVA_DBPASS 计算服务的数据库密码 NOVA_PASS 计算服务中nova用户的密码 RABBIT_PASS RabbitMQ的guest用户密码 SWIFT_PASS 对象存储服务用户swift的密码 实验环境 角色 IP 主机名 默认网关 硬件环境 虚拟化 防火墙 selinux 控制节点 10.0.0.11/24 controller 10.0.0.1 4G内存，50G硬盘 开启 关闭 关闭 计算节点 10.0.0.31/24 compute1 10.0.0.1 4G内存，50G硬盘 开启 关闭 关闭 一、基础环境配置 1.1 关闭防火墙和selinux //禁用防火墙 systemctl stop firewalld && systemctl disable firewalld //禁用selinux #临时修改 setenforce 0 #永久修改，重启服务器后生效 sed -i '7s/enforcing/disabled/' /etc/selinux/config 1.2 配置hosts解析 #控制节点和计算节点相同操作 cat >> /etc/hosts 1.3 配置NTP服务，要保证控制节点和计算节点时间一致 控制节点 1.安装chrony yum -y install chrony 2.编辑chrony配置文件/etc/chrony.conf /删除以下4行，使用阿里云NTP服务器 server 0.centos.pool.ntp.org iburst server 1.centos.pool.ntp.org iburst server 2.centos.pool.ntp.org iburst server 3.centos.pool.ntp.org iburst 修改为 server ntp1.aliyun.com iburst /允许连接控制节点的网段，24行增加以下一行 allow 10.0.0.0/24 #用以下命令修改 sed -i '3,6d' /etc/chrony.conf && sed -i '3cserver ntp1.aliyun.com iburst' \\ /etc/chrony.conf && sed -i '23callow 10.0.0.0/24' /etc/chrony.conf 3.启动NTP服务并设置开机自启 systemctl enable chronyd && systemctl start chronyd 4.检查端口，监听udp323端口 netstat -nupl|grep chronyd udp 0 0 127.0.0.1:323 0.0.0.0:* 29356/chronyd udp 0 0 0.0.0.0:123 0.0.0.0:* 29356/chronyd udp6 0 0 ::1:323 :::* 29356/chronyd 5.验证 chronyc sources 210 Number of sources = 1 MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^* 8.8.8.8 2 6 37 29 +43us[ -830us] +/- 22ms 计算节点 1.安装chrony yum -y install chrony 2.编辑chrony配置文件/etc/chrony.conf /删除以下4行，指定控制节点为NTP服务器 server 0.centos.pool.ntp.org iburst server 1.centos.pool.ntp.org iburst server 2.centos.pool.ntp.org iburst server 3.centos.pool.ntp.org iburst 修改为 server controller iburst #用以下命令修改 sed -i '3,6d' /etc/chrony.conf && sed -i '3cserver controller iburst' /etc/chrony.conf 3.启动NTP服务并设置开机自启 systemctl enable chronyd && systemctl start chronyd 4.检查端口，监听udp323端口 netstat -nupl|grep chronyd udp 0 0 127.0.0.1:323 0.0.0.0:* 1327/chronyd udp6 0 0 ::1:323 :::* 1327/chronyd 5.验证，计算节点显示的是控制节点 chronyc sources 210 Number of sources = 1 MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^? controller 3 6 200 50 +1319ms[+1319ms] +/- 14.4s 1.4下载openstack官方yum源安装openstack客户端 ⚠️Mitaka版官方文档中直接安装centos-release-openstack-mitaka会提示没有可用包(使用的是阿里云的yum源)，得先下载一个包才可以继续安装！！！ 下载官方yum源提示无包可用解决方法 关于m版安装的坑，提示无安装包 具体解决方法 控制节点和计算节点相同操作 #下载yum源并安装openstack客户端 wget https://cbs.centos.org/kojifiles/packages/centos-release-openstack-mitaka/1/1.el7/noarch/centos-release-openstack-mitaka-1-1.el7.noarch.rpm yum -y localinstall centos-release-openstack-mitaka-1-1.el7.noarch.rpm yum -y install python-openstackclient 到此，控制节点和计算节点操作完成！！！ 二、控制节点环境安装 2.1 安装mariadb数据库 1.安装mariadb数据库 yum -y install mariadb mariadb-server python2-PyMySQL 2.创建并编辑 /etc/my.cnf.d/openstack.cnf 在[mysqld]中，设置“bind-address”值为控制节点的管理网络IP地址以使得其他节点可以通过管理网络访问访问数据库。设置其他关键字来设置一些有用的选项和UTF-8编码 cat > /etc/my.cnf.d/openstack.cnf 2.2 安装MongoDB数据库 Telemetry 服务使用 NoSQL 数据库来存储信息，典型地，这个数据库运行在控制节点上。向导中使用MongoDB。 mongodb监听tcp/27017 1.安装MongoDB数据库 yum -y install mongodb-server mongodb 2.编辑文件/etc/mongod.conf 配置 bind_ip 使用控制节点管理网卡的IP地址 修改第6行为 bind_ip = 10.0.0.11 默认情况下，MongoDB会在``/var/lib/mongodb/journal`` 目录下创建几个1GB大小的日志文件。如果你想将每个日志文件大小减小到128MB并且限制日志文件占用的总空间为512MB，配置 smallfiles 的值 取消第113行注释 smallfiles = true #用以下命令修改 sed -i.bak '/^bind_ip/cbind_ip = 10.0.0.11' /etc/mongod.conf \\ && sed -i 's/#smallfiles = true/smallfiles = true/' /etc/mongod.conf 3.启动MongoDB并设置为开机自启 systemctl enable mongod && systemctl start mongod 2.3 安装消息队列rabbitmq OpenStack 使用 message queue 协调操作和各服务的状态信息。消息队列服务一般运行在控制节点上 rabbitmq会启动2个端口 tcp/5672 rabbitmq服务端口 tcp/25672 多个rabbitmq通信用到的端口 1.安装rabbitmq yum -y install rabbitmq-server 2.启动消息队列rabbitmq并设置为开机自启 systemctl enable rabbitmq-server && systemctl start rabbitmq-server 3.添加openstack用户 rabbitmqctl add_user openstack RABBIT_PASS Creating user \"openstack\" 4.给openstack用户设置读和写权限 3个.*分别是 可读、可写、可配置 rabbitmqctl set_permissions openstack \".*\" \".*\" \".*\" Setting permissions for user \"openstack\" in vhost \"/\" 5.启动rabbitmq一个插件，启动之后会监听tcp/15672，是一个web管理界面，默认用户名密码guest rabbitmq-plugins enable rabbitmq_management The following plugins have been enabled: amqp_client cowlib cowboy rabbitmq_web_dispatch rabbitmq_management_agent rabbitmq_management Applying plugin configuration to rabbit@controller... started 6 plugins. 2.4 安装memcached 认证服务认证缓存使用Memcached缓存令牌。缓存服务memecached运行在控制节点。在生产部署中，我们推荐联合启用防火墙、认证和加密保证它的安全。 memcache监听 tcp/udp 11211端口 1.安装软件包 yum -y install memcached python-memcached 2.修改配置文件，设置memcache监听端口为控制节点，默认监听127.0.0.1 sed -i.bak 's#127.0.0.1#10.0.0.11#g' /etc/sysconfig/memcached 3.启动memcached并设置为开机自启 systemctl enable memcached && systemctl start memcached 到此，控制节点环境安装完成！！！ 三、控制节点认证服务keystone安装 keystone认证服务功能：认证管理、授权管理、服务目录 认证：用户名和密码 授权：授权管理，例如一些技术网站(掘金、csdn)可以授权微信、QQ登陆 服务目录：相当于通讯录，即要访问openstack的镜像、网络、存储等服务，只需要找到keystone即可，而不需要再单独记住各个服务的访问地址 后续每安装一个服务都需要在keystone上注册 3.1 创建keystone数据库并授权 #用以下命令操作 mysql -e \"CREATE DATABASE keystone;\" mysql -e \"GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'localhost' \\ IDENTIFIED BY 'KEYSTONE_DBPASS';\" mysql -e \"GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'%' \\ IDENTIFIED BY 'KEYSTONE_DBPASS';\" 3.2 配置keystron 3.2.1 安装和配置keystron keystone借助apache访问 mod_wsgi是帮助apache连接python程序 监听端口 5000(普通用户访问) 35357(管理员用户访问)，apache做了2个多端口的站点 1.安装相关包 yum -y install openstack-keystone httpd mod_wsgi openstack-utils.noarch 2.编辑文件 /etc/keystone/keystone.conf 并完成如下动作： 在 [database] 部分，配置数据库访问： [root@controller ~]# vim /etc/keystone/keystone.conf [database] connection = mysql+pymysql://keystone:KEYSTONE_DBPASS@controller/keystone 在[token]部分，配置Fernet UUID令牌的提供者 [token] provider = fernet #用以下命令修改 \\cp /etc/keystone/keystone.conf{,.bak} grep -Ev '^$|#' /etc/keystone/keystone.conf.bak >/etc/keystone/keystone.conf openstack-config --set /etc/keystone/keystone.conf DEFAULT admin_token ADMIN_TOKEN openstack-config --set /etc/keystone/keystone.conf database connection mysql+pymysql://keystone:KEYSTONE_DBPASS@controller/keystone openstack-config --set /etc/keystone/keystone.conf token provider fernet MD5值 md5sum /etc/keystone/keystone.conf d5acb3db852fe3f247f4f872b051b7a9 /etc/keystone/keystone.conf 3.初始化身份认证服务的数据库（切换到keystone用户，使用的shell是/bin/sh，执行 -c后的命令） su -s /bin/sh -c \"keystone-manage db_sync\" keystone 上一步操作为导入表，以下命令执行返回有表即为正确 mysql keystone -e \"show tables;\"|wc -l 38 4.初始化Fernet key keystone-manage fernet_setup --keystone-user keystone \\ --keystone-group keystone 5.配置Apache服务器 5.1编辑/etc/httpd/conf/httpd.conf`文件，配置``ServerName`` 选项为控制节点 96行下入以下一行 ServerName controller #用以下命令修改 sed -i.bak '96cServerName controller' /etc/httpd/conf/httpd.conf MD5值 md5sum /etc/httpd/conf/httpd.conf eaf0e2ae3fea84bac3e5a842f64bdfdb /etc/httpd/conf/httpd.conf 5.2创建文件/etc/httpd/conf.d/wsgi-keystone.conf cat > /etc/httpd/conf.d/wsgi-keystone.conf WSGIDaemonProcess keystone-public processes=5 threads=1 user=keystone group=keystone display-name=%{GROUP} WSGIProcessGroup keystone-public WSGIScriptAlias / /usr/bin/keystone-wsgi-public WSGIApplicationGroup %{GLOBAL} WSGIPassAuthorization On ErrorLogFormat \"%{cu}t %M\" ErrorLog /var/log/httpd/keystone-error.log CustomLog /var/log/httpd/keystone-access.log combined Require all granted WSGIDaemonProcess keystone-admin processes=5 threads=1 user=keystone group=keystone display-name=%{GROUP} WSGIProcessGroup keystone-admin WSGIScriptAlias / /usr/bin/keystone-wsgi-admin WSGIApplicationGroup %{GLOBAL} WSGIPassAuthorization On ErrorLogFormat \"%{cu}t %M\" ErrorLog /var/log/httpd/keystone-error.log CustomLog /var/log/httpd/keystone-access.log combined Require all granted EOF MD5值 md5sum /etc/httpd/conf.d/wsgi-keystone.conf 8f051eb53577f67356ed03e4550315c2 /etc/httpd/conf.d/wsgi-keystone.conf 6.启动apache并设置为开机自启 systemctl enable httpd && systemctl start httpd 3.2.2 创建服务实体和API端点 API端点有3个 public 公共 internal 内部 admin 管理员 1.先决条件 #配置身份验证令牌 export OS_TOKEN=ADMIN_TOKEN #配置端点URL export OS_URL=http://controller:35357/v3 #配置Identity API版本 export OS_IDENTITY_API_VERSION=3 2.创建服务实体和API端点 2.1 Identity服务管理OpenStack环境中的服务目录。服务使用此目录来确定您的环境中可用的其他服务。 为Identity服务创建服务实体 openstack service create --name \\ keystone --description \"OpenStack Identity\" identity +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Identity | | enabled | True | | id | c7c0d1e96d7e4f809c2957099eb8a0d2 | | name | keystone | | type | identity | +-------------+----------------------------------+ 2.2 Identity服务管理与OpenStack环境中的服务关联的API端点的目录。服务使用此目录来确定如何与环境中的其他服务进行通信。 OpenStack为每项服务使用三种API端点变体：admin，internal和public。管理API端点允许默认修改用户和租户，而公共和内部API不允许这些操作。在生产环境中，出于安全原因，变体可能驻留在为不同类型的用户提供服务的单独网络上。例如，公共API网络可能从Internet上可见，因此客户可以管理他们的云。管理API网络可能仅限于管理云基础架构的组织内的运营商。内部API网络可能仅限于包含OpenStack服务的主机。此外，OpenStack支持多个区域以实现可伸缩性。为简单起见，本指南将管理网络用于所有端点变体和默认值 RegionOne地区。 创建Identity Service API端点： #公共普通用户使用5000端口 openstack endpoint create --region RegionOne \\ identity public http://controller:5000/v3 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | f63e9c4450254214947ac75cddd394c1 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | c7c0d1e96d7e4f809c2957099eb8a0d2 | | service_name | keystone | | service_type | identity | | url | http://controller:5000/v3 | +--------------+----------------------------------+ #keystone内部通信使用5000端口 openstack endpoint create --region RegionOne \\ identity internal http://controller:5000/v3 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 9b6a5be720ea46a4a38f403c47ad8b8f | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | c7c0d1e96d7e4f809c2957099eb8a0d2 | | service_name | keystone | | service_type | identity | | url | http://controller:5000/v3 | +--------------+----------------------------------+ #管理员使用35357端口 openstack endpoint create --region RegionOne \\ identity admin http://controller:35357/v3 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 53d4bdc5bea041a0abfb9ea89dff65d6 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | c7c0d1e96d7e4f809c2957099eb8a0d2 | | service_name | keystone | | service_type | identity | | url | http://controller:35357/v3 | +--------------+----------------------------------+ 创建完API端点后使用命令openstack endpoint list验证是否创建成功 openstack endpoint list +----------------------------------+-----------+--------------+--------------+---------+-----------+----------------------------+ | ID | Region | Service Name | Service Type | Enabled | Interface | URL | +----------------------------------+-----------+--------------+--------------+---------+-----------+----------------------------+ | 2f551bb367c045379a8042cdcb7287eb | RegionOne | keystone | identity | True | public | http://controller:5000/v3 | | 77b014a9b8d44d038cb5d608ff6b9d56 | RegionOne | keystone | identity | True | internal | http://controller:5000/v3 | | c2fcc9c1ee0244acb2860124a1575fd0 | RegionOne | keystone | identity | True | admin | http://controller:35357/v3 | +----------------------------------+-----------+--------------+--------------+---------+-----------+----------------------------+ 删除API端点使用openstack delete 3.3 创建域、项目、用户和角色 3.3.1 创建默认域 openstack domain create --description \"Default Domain\" default +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Default Domain | | enabled | True | | id | fad8700e172044e6ac4869c9eed6d2c3 | | name | default | +-------------+----------------------------------+ 3.3.2 为环境中的管理操作创建管理项目，用户和角色 1.创建管理项目 openstack project create --domain default \\ --description \"Admin Project\" admin +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Admin Project | | domain_id | fad8700e172044e6ac4869c9eed6d2c3 | | enabled | True | | id | 9c1b0cb2b3914507b429f3f7b0c6b5e4 | | is_domain | False | | name | admin | | parent_id | fad8700e172044e6ac4869c9eed6d2c3 | +-------------+----------------------------------+ 2.创建管理员用户，密码设置为ADMIN_PASS //这里交互式创建密码和非交互式选择其中一种 #非交互式设置密码 openstack user create --domain default \\ --password ADMIN_PASS admin +-----------+----------------------------------+ | Field | Value | +-----------+----------------------------------+ | domain_id | 984cb3d5f3054e16b029676de97b6ca6 | | enabled | True | | id | 273c94d5f389418b83ee6738376a6bdf | | name | admin | +-----------+----------------------------------+ #交互式设置密码 openstack user create --domain default \\ --password-prompt admin User Password: Repeat User Password: +-----------+----------------------------------+ | Field | Value | +-----------+----------------------------------+ | domain_id | fad8700e172044e6ac4869c9eed6d2c3 | | enabled | True | | id | cc0f0af9f5c1492aa8919bf936c1c19b | | name | admin | +-----------+----------------------------------+ 3.创建管理员角色 openstack role create admin +-----------+----------------------------------+ | Field | Value | +-----------+----------------------------------+ | domain_id | None | | id | 921e36b9338141479f52f7c46c04f9ef | | name | admin | +-----------+----------------------------------+ 4.将admin角色添加到admin项目和用户 openstack role add --project admin --user admin admin 3.3.3 本指南使用的服务项目包含您添加到环境中的每项服务的唯一用户 创建服务项目 #service，后期用于关联openstack系统用户glance、nova、neutron openstack project create --domain default \\ --description \"Service Project\" service +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Service Project | | domain_id | fad8700e172044e6ac4869c9eed6d2c3 | | enabled | True | | id | ae31639e04be474cbabcad502be62cac | | is_domain | False | | name | service | | parent_id | fad8700e172044e6ac4869c9eed6d2c3 | +-------------+----------------------------------+ 3.3.4 常规（非管理员）任务应该使用非特权项目和用户。例如，本指南创建了演示项目和用户 1.创建演示项目 openstack project create --domain default \\ --description \"Demo Project\" demo +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Demo Project | | domain_id | fad8700e172044e6ac4869c9eed6d2c3 | | enabled | True | | id | 6244aa0291104859b255990cef3eacd6 | | is_domain | False | | name | demo | | parent_id | fad8700e172044e6ac4869c9eed6d2c3 | +-------------+----------------------------------+ 2.创建演示用户，密码设置为123456 //这里交互式创建密码和非交互式选择其中一种 #非交互式创建密码 openstack user create --domain default \\ --password 123456 demo +-----------+----------------------------------+ | Field | Value | +-----------+----------------------------------+ | domain_id | af51b1180eb14a66b0380e4cd134df90 | | enabled | True | | id | c75ad14657d0497190cb479ba50f531b | | name | demo | +-----------+----------------------------------+ #交互式创建密码 openstack user create --domain default \\ --password-prompt demo User Password: Repeat User Password: +-----------+----------------------------------+ | Field | Value | +-----------+----------------------------------+ | domain_id | fad8700e172044e6ac4869c9eed6d2c3 | | enabled | True | | id | 4639e42215a946b4be7e588d36979c64 | | name | demo | +-----------+----------------------------------+ 3.创建用户角色 openstack role create user +-----------+----------------------------------+ | Field | Value | +-----------+----------------------------------+ | domain_id | None | | id | a35f989b04d1403e92a19895cae21c9d | | name | user | +-----------+----------------------------------+ 4.将用户角色添加到演示项目和用户 openstack role add --project demo --user demo user 3.4 验证操作 3.4.1 出于安全原因，请禁用临时身份验证令牌机制： 编辑文件/etc/keystone/keystone-paste.ini并且移除admin_token_auth 从[pipeline:public_api], [pipeline:admin_api],和[pipeline:api_v3] 部分 这一步操作可能会造成后续keystone认证失败！！！，实验的时候可以不执行！！！ sed -i.bak '51,64d' /etc/keystone/keystone-paste.ini 3.4.2 取消设置临时OS_TOKEN和OS_URL环境变量 unset OS_TOKEN OS_URL 3.4.3 作为admin用户，请求身份验证令牌，密码为ADMIN_PASS openstack --os-auth-url http://controller:35357/v3 \\ --os-project-domain-name default --os-user-domain-name default \\ --os-project-name admin --os-username admin token issue Password: +------------+----------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +------------+----------------------------------------------------------------------------------------------------------------------------------------------+ | expires | 2019-01-31T05:46:45.000000Z | | id | gAAAAABcUn21ftl6WYlhMsqIffRDo9Pg6Ei35hUlg8D_kzw1Azy- | | | 4Ly1DeL0s3YbMOlz88jVFWnMyg2gaxFoVsS2pZYnRhVlnclg1yofFFHOENz39XHsuCUYICuDq4XqOLEbKWyS9IfZuNbWtKjEQa-jQaoe4PCk0fyFG0B6nE3vn9gNkOvXiTA | | project_id | 9c1b0cb2b3914507b429f3f7b0c6b5e4 | | user_id | cc0f0af9f5c1492aa8919bf936c1c19b | +------------+----------------------------------------------------------------------------------------------------------------------------------------------+ 3.4.4 作为演示用户，请求身份验证令牌 ⚠️执行3.4.1就会有问题，会报错HTTP 500 openstack --os-auth-url http://controller:5000/v3 \\ --os-project-domain-name default --os-user-domain-name default \\ --os-project-name demo --os-username demo token issue Password: Discovering versions from the identity service failed when creating the password plugin. Attempting to determine version from URL. Internal Server Error (HTTP 500) 不执行3.4.1，验证就没有问题 openstack --os-auth-url http://controller:5000/v3 \\ --os-project-domain-name default --os-user-domain-name default \\ --os-project-name demo --os-username demo token issue +------------+-----------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +------------+-----------------------------------------------------------------------------------------------------------------------------------------+ | expires | 2019-01-31T10:30:43.000000Z | | id | gAAAAABeym2jDfXll4iZ2JcCP1XY1mHbu8Ovgaf8BMWe1FsoBp9XkaEqsnphx_BIuY0RFC-goS-JVZJ0xbiOajLnob7nWYKz5zlPlGkybvtDWd6L3jRMGD20RE- | | | H5gRz5oBXPPRUt9e5Kxbc-5_WXu_nfjw3ASXPIu25inoeeXsvd1aeg9FzgBE | | project_id | d08b00aa3c6944afa7095c280319acb9 | | user_id | ec75d657d09c4899894d40364011f552 | +------------+-----------------------------------------------------------------------------------------------------------------------------------------+ 3.5 创建OpenStack客户端环境脚本 3.5.1 创建脚本 编辑admin-openrc文件并添加以下内容,这里放在/opt下 cat > /opt/admin-openrc 3.5.2 使用脚本 1.加载admin-openrc文件，使用Identity服务的位置以及admin项目和用户凭据填充环境变量 source /opt/admin-openrc 2.请求身份验证令牌（注意expires中是UTC时间，落后中国8个小时，我国是东八区，使用timedatectl查看时间及时区，默认过期时间1小时） openstack token issue +------------+----------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +------------+----------------------------------------------------------------------------------------------------------------------------------------------+ | expires | 2019-01-31T10:49:41.000000Z | | id | gAAAAABcUsS1O_B3QETf0hx8KWiuUyTBz23e2E70mY6DeWPvZreQrX58bEyJcMVgLGazsrKrqaJw0gSK75JHT0WNHf7V6VxNR5-uYLJKsGIuaUzNe9RMdTys_CcK680L- | | | NU9VdSDllR6GQvbu4EqejSm_1d5iarR2cQD8n8kG1PcV_SNijApskk | | project_id | e33e3feaef784a5bb45bd9c766bc0f46 | | user_id | aaa8bfce5b5d451b956bb76dee235b9e | +------------+----------------------------------------------------------------------------------------------------------------------------------------------+ 到此，控制节点认证服务keystone安装完成！！！ 四、控制节点镜像服务glance安装 OpenStack镜像服务包括以下组件： glance-api 接收镜像API的调用，诸如镜像发现、恢复、存储 glance-registry 存储、处理和恢复镜像的元数据(属性)，元数据包括项诸如大小和类型 glance服务监听两个端口 glance-api 9292 glance-registry 9191 4.1 创建glance数据库并授权 #用以下命令修改 mysql -e \"CREATE DATABASE glance;\" mysql -e \"GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'localhost' \\ IDENTIFIED BY 'GLANCE_DBPASS';\" mysql -e \"GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'%' \\ IDENTIFIED BY 'GLANCE_DBPASS';\" 4.2 获取管理员凭据以获取对仅管理员CLI命令的访问 source /opt/admin-openrc 4.3 创建服务凭据 4.3.1 创建glance用户，密码设置为GLANCE_PASS //这里交互式创建密码和非交互式选择其中一种 #非交互式设置密码 openstack user create --domain default --password GLANCE_PASS glance +-----------+----------------------------------+ | Field | Value | +-----------+----------------------------------+ | domain_id | af51b1180eb14a66b0380e4cd134df90 | | enabled | True | | id | 593894e4dabc411ebecf8cbe8f3f1109 | | name | glance | +-----------+----------------------------------+ #交互式设置密码 openstack user create --domain default --password-prompt glance User Password: Repeat User Password: +-----------+----------------------------------+ | Field | Value | +-----------+----------------------------------+ | domain_id | b245194b1e8749d0b3c51a78e05d7734 | | enabled | True | | id | ff135a9cce5e4a55842dd2beaffa67e2 | | name | glance | +-----------+----------------------------------+ 4.3.2 将管理角色添加到glance用户和服务项目中 openstack role add --project service --user glance admin 4.3.3 创建glance服务实体 openstack service create --name glance \\ --description \"OpenStack Image\" image +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Image | | enabled | True | | id | de2e6d60f6234918a96f768516a36e9a | | name | glance | | type | image | +-------------+----------------------------------+ 删除服务实体使用命令openstack service delete 使用命令openstack service list查看service-id然后根据id删除 4.3.4 创建Image服务API端点 openstack endpoint create --region RegionOne \\ image public http://controller:9292 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 7aede44313aa4f98971c513fb6aa37b9 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | de2e6d60f6234918a96f768516a36e9a | | service_name | glance | | service_type | image | | url | http://controller:9292 | +--------------+----------------------------------+ openstack endpoint create --region RegionOne \\ image internal http://controller:9292 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 8edf9fd9452347d99d1a419b5f631f2c | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | de2e6d60f6234918a96f768516a36e9a | | service_name | glance | | service_type | image | | url | http://controller:9292 | +--------------+----------------------------------+ openstack endpoint create --region RegionOne \\ image admin http://controller:9292 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 89ced10fcf444d5a95c9ad5fd9381040 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | de2e6d60f6234918a96f768516a36e9a | | service_name | glance | | service_type | image | | url | http://controller:9292 | +--------------+----------------------------------+ 删除API端点使用命令openstack endpoint delete 使用命令openstack endpoint list查看endpoint-id然后根据id删除 4.4 安装和配置组件 4.4.1 安装包 yum -y install openstack-glance 4.4.2 编辑/etc/glance/glance-api.conf文件并完成以下操作 1.在[database]部分中，配置数据库访问 [database] ... connection = mysql+pymysql://glance:GLANCE_DBPASS@controller/glance 2.在[keystone_authtoken]和[paste_deploy]部分中，配置身份服务访问 [keystone_authtoken] ... auth_uri = http://controller:5000 auth_url = http://controller:35357 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = glance password = GLANCE_PASS [paste_deploy] ... flavor = keystone 3.在[glance_store]部分中，配置本地文件系统存储和映像文件的位置 [glance_store] ... stores = file,http default_store = file filesystem_store_datadir = /var/lib/glance/images/ #用以下命令修改 \\cp /etc/glance/glance-api.conf{,.bak} grep '^[a-Z\\[]' /etc/glance/glance-api.conf.bak >/etc/glance/glance-api.conf openstack-config --set /etc/glance/glance-api.conf database connection mysql+pymysql://glance:GLANCE_DBPASS@controller/glance openstack-config --set /etc/glance/glance-api.conf glance_store stores file,http openstack-config --set /etc/glance/glance-api.conf glance_store default_store file openstack-config --set /etc/glance/glance-api.conf glance_store filesystem_store_datadir /var/lib/glance/images/ openstack-config --set /etc/glance/glance-api.conf keystone_authtoken auth_uri http://controller:5000 openstack-config --set /etc/glance/glance-api.conf keystone_authtoken auth_url http://controller:35357 openstack-config --set /etc/glance/glance-api.conf keystone_authtoken memcached_servers controller:11211 openstack-config --set /etc/glance/glance-api.conf keystone_authtoken auth_type password openstack-config --set /etc/glance/glance-api.conf keystone_authtoken project_domain_name default openstack-config --set /etc/glance/glance-api.conf keystone_authtoken user_domain_name default openstack-config --set /etc/glance/glance-api.conf keystone_authtoken project_name service openstack-config --set /etc/glance/glance-api.conf keystone_authtoken username glance openstack-config --set /etc/glance/glance-api.conf keystone_authtoken password GLANCE_PASS openstack-config --set /etc/glance/glance-api.conf paste_deploy flavor keystone MD5值 md5sum /etc/glance/glance-api.conf 3e1a4234c133eda11b413788e001cba3 /etc/glance/glance-api.conf 4.4.3 编辑/etc/glance/glance-registry.conf文件并完成以下操作 1.在[database]部分中，配置数据库访问： [database] ... connection = mysql+pymysql://glance:GLANCE_DBPASS@controller/glance 2.在[keystone_authtoken]和[paste_deploy]部分中，配置身份服务访问： ... auth_uri = http://controller:5000 auth_url = http://controller:35357 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = glance password = GLANCE_PASS [paste_deploy] ... flavor = keystone #用以下命令修改 \\cp /etc/glance/glance-registry.conf{,.bak} grep '^[a-Z\\[]' /etc/glance/glance-registry.conf.bak > /etc/glance/glance-registry.conf openstack-config --set /etc/glance/glance-registry.conf database connection mysql+pymysql://glance:GLANCE_DBPASS@controller/glance openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken auth_uri http://controller:5000 openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken auth_url http://controller:35357 openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken memcached_servers controller:11211 openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken auth_type password openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken project_domain_name default openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken user_domain_name default openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken project_name service openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken username glance openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken password GLANCE_PASS openstack-config --set /etc/glance/glance-registry.conf paste_deploy flavor keystone MD5值 md5sum /etc/glance/glance-registry.conf 46acabd81a65b924256f56fe34d90b8f /etc/glance/glance-registry.conf 4.4.4 同步数据库 注意：忽略此输出中的任何弃用消息 su -s /bin/sh -c \"glance-manage db_sync\" glance Option \"verbose\" from group \"DEFAULT\" is deprecated for removal. Its value may be silently ignored in the future. /usr/lib/python2.7/site-packages/oslo_db/sqlalchemy/enginefacade.py:1056: OsloDBDeprecationWarning: EngineFacade is deprecated; please use oslo_db.sqlalchemy.enginefacade expire_on_commit=expire_on_commit, _conf=conf) /usr/lib/python2.7/site-packages/pymysql/cursors.py:170: Warning: (1831, u'Duplicate index `ix_image_properties_image_id_name`. This is deprecated and will be disallowed in a future release.') result = self._query(query) #有输出即为正确 mysql glance -e \"show tables;\" | wc -l 21 4.4.5 启动glance服务并设置为开机自启（glance-api和glance-registry） systemctl enable openstack-glance-api openstack-glance-registry && \\ systemctl start openstack-glance-api openstack-glance-registry 4.4.6 验证操作 1.获取管理员凭据以获取对仅管理员CLI命令的访问权限 source /opt/admin-openrc 2.下载源镜像 wget http://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-disk.img 3.使用QCOW2磁盘格式，裸容器格式和公共可见性将映像上载到映像服务 ，以便所有项目都可以访问它 注意：这一步一定要看执行后输出结果中size大小，如果为0则说明镜像上载有问题 openstack image create \"cirros\" \\ --file cirros-0.3.4-x86_64-disk.img \\ --disk-format qcow2 --container-format bare \\ --public +------------------+------------------------------------------------------+ | Field | Value | +------------------+------------------------------------------------------+ | checksum | ee1eca47dc88f4879d8a229cc70a07c6 | | container_format | bare | | created_at | 2019-01-31T12:26:32Z | | disk_format | qcow2 | | file | /v2/images/ac21b17b-e910-4ca4-b743-914b8fbd0e55/file | | id | ac21b17b-e910-4ca4-b743-914b8fbd0e55 | | min_disk | 0 | | min_ram | 0 | | name | cirros | | owner | e33e3feaef784a5bb45bd9c766bc0f46 | | protected | False | | schema | /v2/schemas/image | | size | 13287936 | //一定要注意这里的大小，为0有错误 | status | active | | tags | | | updated_at | 2019-01-31T12:26:34Z | | virtual_size | None | | visibility | public | +------------------+------------------------------------------------------+ 镜像上传位置 [root@controller images]# pwd /var/lib/glance/images [root@controller images]# ls 6a143876-39c6-4b4a-8056-c3d7fbe0ce75 删除镜像使用命令glance image-delete 镜像id 4.4.7 确认上传图像并验证属性 openstack image list +--------------------------------------+--------+--------+ | ID | Name | Status | +--------------------------------------+--------+--------+ | ac21b17b-e910-4ca4-b743-914b8fbd0e55 | cirros | active | +--------------------------------------+--------+--------+ 到此，控制节点镜像服务glance安装完成！！！ 五、控制节点和计算节点计算服务nova安装 nova相关服务 服务名称 作用 nova-api 接受并响应所有的计算服务请求，管理虚拟机(云主机)生命周期 nova-api-metadata 接受来自虚拟机发送的元数据请求 nova-compute（多个） 真正管理虚拟机 nova-scheduler nova调度器（挑选出最合适的nova-compute来创建虚机） nova-conductor 帮助nova-compute代理修改数据库中虚拟机的状态 nova-network 早期openstack版本管理虚拟机的网络（已弃用，neutron） nova-consoleauth和nova-novncproxy web版的vnc来直接操作云主机 novncproxy web版 vnc客户端 安装和配置控制节点 5.1 创建nova和nova-api数据库并授权 #用以下命令 mysql -e \"CREATE DATABASE nova;\" mysql -e \"CREATE DATABASE nova_api;\" mysql -e \"GRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'localhost' \\ IDENTIFIED BY 'NOVA_DBPASS';\" mysql -e \"GRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'%' \\ IDENTIFIED BY 'NOVA_DBPASS';\" mysql -e \"GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'localhost' \\ IDENTIFIED BY 'NOVA_DBPASS';\" mysql -e \"GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'%' \\ IDENTIFIED BY 'NOVA_DBPASS';\" 5.2 获取管理员凭据以获取对仅管理员CLI命令的访问权限 source /opt/admin-openrc 5.3 创建服务凭据 1.创建nova用户,密码设置为NOVA_PASS //这里交互式创建密码和非交互式选择其中一种 #非交互式创建密码 openstack user create --domain default \\ --password NOVA_PASS nova +-----------+----------------------------------+ | Field | Value | +-----------+----------------------------------+ | domain_id | af51b1180eb14a66b0380e4cd134df90 | | enabled | True | | id | 1ad918dc1de84c279999e89bb7c312bc | | name | nova | +-----------+----------------------------------+ #交互式创建密码 openstack user create --domain default \\ --password-prompt nova User Password: Repeat User Password: +-----------+----------------------------------+ | Field | Value | +-----------+----------------------------------+ | domain_id | b245194b1e8749d0b3c51a78e05d7734 | | enabled | True | | id | b7cd769660c64b96bed91baebb229d54 | | name | nova | +-----------+----------------------------------+ 2.将admin角色添加到nova用户 openstack role add --project service --user nova admin 3.创建nova服务实体 openstack service create --name nova \\ --description \"OpenStack Compute\" compute +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Compute | | enabled | True | | id | 3db049ab4b334d6d979a9ee9a6aea5d5 | | name | nova | | type | compute | +-------------+----------------------------------+ 5.4 创建Compute服务API端点 openstack endpoint create --region RegionOne \\ compute public http://controller:8774/v2.1/%\\(tenant_id\\)s +--------------+-------------------------------------------+ | Field | Value | +--------------+-------------------------------------------+ | enabled | True | | id | 0e1da405775b4a238f4142d8df6b8b58 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 3db049ab4b334d6d979a9ee9a6aea5d5 | | service_name | nova | | service_type | compute | | url | http://controller:8774/v2.1/%(tenant_id)s | +--------------+-------------------------------------------+ openstack endpoint create --region RegionOne \\ compute internal http://controller:8774/v2.1/%\\(tenant_id\\)s +--------------+-------------------------------------------+ | Field | Value | +--------------+-------------------------------------------+ | enabled | True | | id | 36775f0fcbf24ce1888ff714442aea04 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 3db049ab4b334d6d979a9ee9a6aea5d5 | | service_name | nova | | service_type | compute | | url | http://controller:8774/v2.1/%(tenant_id)s | +--------------+-------------------------------------------+ openstack endpoint create --region RegionOne \\ compute admin http://controller:8774/v2.1/%\\(tenant_id\\)s +--------------+-------------------------------------------+ | Field | Value | +--------------+-------------------------------------------+ | enabled | True | | id | 8d575d9584df4c0cb3d903c50688175f | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 3db049ab4b334d6d979a9ee9a6aea5d5 | | service_name | nova | | service_type | compute | | url | http://controller:8774/v2.1/%(tenant_id)s | +--------------+-------------------------------------------+ 5.5 安装和配置组件 5.5.1 安装包 yum -y install openstack-nova-api openstack-nova-conductor \\ openstack-nova-console openstack-nova-novncproxy openstack-nova-scheduler 5.5.2 编辑/etc/nova/nova.conf文件并完成以下操作 1.在[DEFAULT]部分中，仅启用计算和元数据API [DEFAULT] ... enabled_apis = osapi_compute,metadata 2.在[api_database]和[database]部分中，配置数据库访问 [api_database] ... connection = mysql+pymysql://nova:NOVA_DBPASS@controller/nova_api [database] ... connection = mysql+pymysql://nova:NOVA_DBPASS@controller/nova 3.在[DEFAULT]和[oslo_messaging_rabbit]部分中，配置RabbitMQ消息队列访问 [DEFAULT] ... rpc_backend = rabbit [oslo_messaging_rabbit] ... rabbit_host = controller rabbit_userid = openstack rabbit_password = RABBIT_PASS 4.在[DEFAULT]和[keystone_authtoken]部分中，配置身份服务访问 [DEFAULT] ... auth_strategy = keystone [keystone_authtoken] ... auth_uri = http://controller:5000 auth_url = http://controller:35357 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = nova password = NOVA_PASS 5.在[DEFAULT]部分中，配置my_ip选项以使用控制器节点的管理接口IP地址 [DEFAULT] ... my_ip = 10.0.0.11 6.在[DEFAULT]部分中，启用对Networking服务的支持 [DEFAULT] ... use_neutron = True firewall_driver = nova.virt.firewall.NoopFirewallDriver 7.在[vnc]部分中，配置VNC代理以使用控制器节点的管理接口IP地址 [vnc] ... vncserver_listen = $my_ip vncserver_proxyclient_address = $my_ip 8.在[glance]部分中，配置Image服务API的位置 [glance] ... api_servers = http://controller:9292 9.在[oslo_concurrency]部分中，配置锁定路径 [oslo_concurrency] ... lock_path = /var/lib/nova/tmp #用以下命令修改，分开复制，一次性复制无法都执行 cp /etc/nova/nova.conf{,.bak} grep '^[a-Z\\[]' /etc/nova/nova.conf.bak >/etc/nova/nova.conf openstack-config --set /etc/nova/nova.conf DEFAULT enabled_apis osapi_compute,metadata openstack-config --set /etc/nova/nova.conf DEFAULT rpc_backend rabbit openstack-config --set /etc/nova/nova.conf DEFAULT auth_strategy keystone openstack-config --set /etc/nova/nova.conf DEFAULT my_ip 10.0.0.11 openstack-config --set /etc/nova/nova.conf DEFAULT use_neutron True openstack-config --set /etc/nova/nova.conf DEFAULT firewall_driver nova.virt.firewall.NoopFirewallDriver openstack-config --set /etc/nova/nova.conf api_database connection mysql+pymysql://nova:NOVA_DBPASS@controller/nova_api openstack-config --set /etc/nova/nova.conf database connection mysql+pymysql://nova:NOVA_DBPASS@controller/nova openstack-config --set /etc/nova/nova.conf glance api_servers http://controller:9292 openstack-config --set /etc/nova/nova.conf keystone_authtoken auth_uri http://controller:5000 openstack-config --set /etc/nova/nova.conf keystone_authtoken auth_url http://controller:35357 openstack-config --set /etc/nova/nova.conf keystone_authtoken memcached_servers controller:11211 openstack-config --set /etc/nova/nova.conf keystone_authtoken auth_type password openstack-config --set /etc/nova/nova.conf keystone_authtoken project_domain_name default openstack-config --set /etc/nova/nova.conf keystone_authtoken user_domain_name default openstack-config --set /etc/nova/nova.conf keystone_authtoken project_name service openstack-config --set /etc/nova/nova.conf keystone_authtoken username nova openstack-config --set /etc/nova/nova.conf keystone_authtoken password NOVA_PASS openstack-config --set /etc/nova/nova.conf oslo_concurrency lock_path /var/lib/nova/tmp openstack-config --set /etc/nova/nova.conf oslo_messaging_rabbit rabbit_host controller openstack-config --set /etc/nova/nova.conf oslo_messaging_rabbit rabbit_userid openstack openstack-config --set /etc/nova/nova.conf oslo_messaging_rabbit rabbit_password RABBIT_PASS openstack-config --set /etc/nova/nova.conf vnc vncserver_listen '$my_ip' openstack-config --set /etc/nova/nova.conf vnc vncserver_proxyclient_address '$my_ip' MD5值 md5sum /etc/nova/nova.conf 47ded61fdd1a79ab91bdb37ce59ef192 /etc/nova/nova.conf 5.5.3 同步数据库，忽略输出 su -s /bin/sh -c \"nova-manage api_db sync\" nova su -s /bin/sh -c \"nova-manage db sync\" nova /usr/lib/python2.7/site-packages/pymysql/cursors.py:170: Warning: (1831, u'Duplicate index `block_device_mapping_instance_uuid_virtual_name_device_name_idx`. This is deprecated and will be disallowed in a future release.') result = self._query(query) /usr/lib/python2.7/site-packages/pymysql/cursors.py:170: Warning: (1831, u'Duplicate index `uniq_instances0uuid`. This is deprecated and will be disallowed in a future release.') result = self._query(query) #查看数据库，有输出即为正确 mysql nova_api -e \"show tables;\"|wc -l 10 mysql nova -e \"show tables;\"|wc -l 110 5.5.4 启动Compute服务并将其配置为在系统引导时启动 systemctl enable openstack-nova-api.service \\ openstack-nova-consoleauth.service openstack-nova-scheduler.service \\ openstack-nova-conductor.service openstack-nova-novncproxy.service systemctl start openstack-nova-api.service \\ openstack-nova-consoleauth.service openstack-nova-scheduler.service \\ openstack-nova-conductor.service openstack-nova-novncproxy.service 安装完成后会有no VNC 10.0.0.11:6080 安装和配置计算节点 5.6 安装和配置组件 5.6.1 安装包 yum -y install openstack-nova-compute openstack-utils 5.6.2 编辑/etc/nova/nova.conf文件并完成以下操作 1.在[DEFAULT]和[oslo_messaging_rabbit]部分中，配置RabbitMQ消息队列访问 [DEFAULT] ... rpc_backend = rabbit [oslo_messaging_rabbit] ... rabbit_host = controller rabbit_userid = openstack rabbit_password = RABBIT_PASS 2.在[DEFAULT]和[keystone_authtoken]部分中，配置身份服务访问 [DEFAULT] ... auth_strategy = keystone [keystone_authtoken] ... auth_uri = http://controller:5000 auth_url = http://controller:35357 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = nova password = NOVA_PASS 3.在[DEFAULT]部分中，配置my_ip选项，将MANAGEMENT_INTERFACE_IP_ADDRESS替换为计算节点上管理网络接口的IP地址，对于示例体系结构中的第一个节点，通常为10.0.0.31 [DEFAULT] ... my_ip = MANAGEMENT_INTERFACE_IP_ADDRESS 4.在[DEFAULT]部分中，启用对Networking服务的支持 [DEFAULT] ... use_neutron = True firewall_driver = nova.virt.firewall.NoopFirewallDriver 5.在[vnc]部分中，启用并配置远程控制台访问 [vnc] ... enabled = True vncserver_listen = 0.0.0.0 vncserver_proxyclient_address = $my_ip novncproxy_base_url = http://controller:6080/vnc_auto.html 6.在[glance]部分中，配置Image服务API的位置 [glance] ... api_servers = http://controller:9292 7.在[oslo_concurrency]部分中，配置锁定路径 [oslo_concurrency] ... lock_path = /var/lib/nova/tmp #用以下命令修改 cp /etc/nova/nova.conf{,.bak} grep '^[a-Z\\[]' /etc/nova/nova.conf.bak >/etc/nova/nova.conf openstack-config --set /etc/nova/nova.conf DEFAULT rpc_backend rabbit openstack-config --set /etc/nova/nova.conf DEFAULT auth_strategy keystone openstack-config --set /etc/nova/nova.conf DEFAULT my_ip 10.0.0.31 openstack-config --set /etc/nova/nova.conf DEFAULT use_neutron True openstack-config --set /etc/nova/nova.conf DEFAULT firewall_driver nova.virt.firewall.NoopFirewallDriver openstack-config --set /etc/nova/nova.conf glance api_servers http://controller:9292 openstack-config --set /etc/nova/nova.conf keystone_authtoken auth_uri http://controller:5000 openstack-config --set /etc/nova/nova.conf keystone_authtoken auth_url http://controller:35357 openstack-config --set /etc/nova/nova.conf keystone_authtoken memcached_servers controller:11211 openstack-config --set /etc/nova/nova.conf keystone_authtoken auth_type password openstack-config --set /etc/nova/nova.conf keystone_authtoken project_domain_name default openstack-config --set /etc/nova/nova.conf keystone_authtoken user_domain_name default openstack-config --set /etc/nova/nova.conf keystone_authtoken project_name service openstack-config --set /etc/nova/nova.conf keystone_authtoken username nova openstack-config --set /etc/nova/nova.conf keystone_authtoken password NOVA_PASS openstack-config --set /etc/nova/nova.conf oslo_concurrency lock_path /var/lib/nova/tmp openstack-config --set /etc/nova/nova.conf oslo_messaging_rabbit rabbit_host controller openstack-config --set /etc/nova/nova.conf oslo_messaging_rabbit rabbit_userid openstack openstack-config --set /etc/nova/nova.conf oslo_messaging_rabbit rabbit_password RABBIT_PASS openstack-config --set /etc/nova/nova.conf vnc enabled True openstack-config --set /etc/nova/nova.conf vnc vncserver_listen 0.0.0.0 openstack-config --set /etc/nova/nova.conf vnc vncserver_proxyclient_address '$my_ip' openstack-config --set /etc/nova/nova.conf vnc novncproxy_base_url http://controller:6080/vnc_auto.html MD5值 md5sum /etc/nova/nova.conf 2f53f4e0848bc5927493925a4ea61f63 /etc/nova/nova.conf 5.6.3 确定您的计算节点是否支持虚拟机的硬件加速 egrep -c '(vmx|svm)' /proc/cpuinfo 1 #说明 如果此命令返回值1或更大，则计算节点支持硬件加速，通常不需要其他配置。 如果此命令返回零值，则计算节点不支持硬件加速，您必须将libvirt配置为使用QEMU而不是KVM。 编辑/etc/nova/nova.conf文件中的[libvirt]部分， 如下所示： [libvirt] ...... virt_type = qemu 5.6.4 启动Compute服务及其依赖项，并将它们配置为在系统引导时自动启动 systemctl enable libvirtd.service openstack-nova-compute.service && \\ systemctl start libvirtd.service openstack-nova-compute.service 验证操作，在控制节点执行 5.7 验证Compute服务的运行 5.7.1 获取管理员凭据以获取对仅管理员CLI命令的访问权限 source /opt/admin-openrc 5.7.2 列出服务组件以验证每个进程的成功启动和注册 此输出应指示控制器节点上启用的三个服务组件以及计算节点上启用的一个服务组件 openstack compute service list +----+------------------+------------+----------+---------+-------+----------------------------+ | Id | Binary | Host | Zone | Status | State | Updated At | +----+------------------+------------+----------+---------+-------+----------------------------+ | 1 | nova-conductor | controller | internal | enabled | up | 2019-02-01T14:33:13.000000 | | 2 | nova-consoleauth | controller | internal | enabled | up | 2019-02-01T14:33:18.000000 | | 3 | nova-scheduler | controller | internal | enabled | up | 2019-02-01T14:33:13.000000 | | 6 | nova-compute | compute1 | nova | enabled | up | 2019-02-01T14:33:19.000000 | +----+------------------+------------+----------+---------+-------+----------------------------+ 到此，控制节点和计算节点计算服务nova安装完成！！！ 六、控制节点、计算节点网络服务neutron安装 neutron相关服务 服务名 说明 neutron-server 端口(9696) api 接受和响应外部的网络管理请求 neutron-linuxbridge-agent 负责创建桥接网卡 neutron-dhcp-agent 负责分配IP neutron-metadata-agent 配合nova-metadata-api实现虚拟机的定制化操作 L3-agent 实现三层网络(网络层) 安装和配置控制节点 6.1 创建neutron数据库并授权 #用以下命令 mysql -e \"CREATE DATABASE neutron;\" mysql -e \"GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'localhost' \\ IDENTIFIED BY 'NEUTRON_DBPASS';\" mysql -e \"GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'%' \\ IDENTIFIED BY 'NEUTRON_DBPASS';\" 6.2 获取管理员凭据以获取对仅管理员CLI命令的访问权限 source /opt/admin-openrc 6.3 创建服务凭证 6.3.1 创建neutron用户，密码设置为NEUTRON_PASS //这里交互式创建密码和非交互式选择其中一种 #非交互式创建密码 openstack user create --domain default --password NEUTRON_PASS neutron +-----------+----------------------------------+ | Field | Value | +-----------+----------------------------------+ | domain_id | af51b1180eb14a66b0380e4cd134df90 | | enabled | True | | id | c0ac0eda2eca4a698eade50b060dd2ce | | name | neutron | +-----------+----------------------------------+ #交互式创建密码 openstack user create --domain default --password-prompt neutron User Password: Repeat User Password: +-----------+----------------------------------+ | Field | Value | +-----------+----------------------------------+ | domain_id | b245194b1e8749d0b3c51a78e05d7734 | | enabled | True | | id | 98f34dc4ddf346b3833de4a0320f7bc9 | | name | neutron | +-----------+----------------------------------+ 6.3.2 将admin角色添加到neutron用户 openstack role add --project service --user neutron admin 6.3.3 创建neutron服务实体 openstack service create --name neutron \\ --description \"OpenStack Networking\" network +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Networking | | enabled | True | | id | 86251b67e0c94b699489ee1b331c33a6 | | name | neutron | | type | network | +-------------+----------------------------------+ 6.4 创建网络服务API端点 openstack endpoint create --region RegionOne \\ network public http://controller:9696 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 48b0ab77e4e74a0788f88b0916e8b696 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 86251b67e0c94b699489ee1b331c33a6 | | service_name | neutron | | service_type | network | | url | http://controller:9696 | +--------------+----------------------------------+ openstack endpoint create --region RegionOne \\ network internal http://controller:9696 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 5b2be24de46f455694a77e8a096916fb | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 86251b67e0c94b699489ee1b331c33a6 | | service_name | neutron | | service_type | network | | url | http://controller:9696 | +--------------+----------------------------------+ openstack endpoint create --region RegionOne \\ network admin http://controller:9696 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 0f06a3d409bc41cb9b6651de68006102 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 86251b67e0c94b699489ee1b331c33a6 | | service_name | neutron | | service_type | network | | url | http://controller:9696 | +--------------+----------------------------------+ 6.5 配置网络选项，控制节点操作 6.5.1 安装包 yum -y install openstack-neutron openstack-neutron-ml2 \\ openstack-neutron-linuxbridge ebtables 6.5.2 配置服务器组件 编辑/etc/neutron/neutron.conf文件并完成以下操作 1.在[database]部分中，配置数据库访问： [database] ... connection = mysql+pymysql://neutron:NEUTRON_DBPASS@controller/neutron 2.在[DEFAULT]部分中，启用Modular Layer 2（ML2）插件并禁用其他插件： [DEFAULT] ... core_plugin = ml2 service_plugins = 3.在[DEFAULT]和[oslo_messaging_rabbit]部分中，配置RabbitMQ消息队列访问： [DEFAULT] ... rpc_backend = rabbit [oslo_messaging_rabbit] ... rabbit_host = controller rabbit_userid = openstack rabbit_password = RABBIT_PASS 4.在[DEFAULT]和[keystone_authtoken]部分中，配置身份服务访问： [DEFAULT] ... auth_strategy = keystone [keystone_authtoken] ... auth_uri = http://controller:5000 auth_url = http://controller:35357 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = NEUTRON_PASS 5.在[DEFAULT]和[nova]部分中，配置Networking以通知Compute网络拓扑更改： [DEFAULT] ... notify_nova_on_port_status_changes = True notify_nova_on_port_data_changes = True [nova] ... auth_url = http://controller:35357 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = nova password = NOVA_PASS 6.在[oslo_concurrency]部分中，配置锁定路径： [oslo_concurrency] ... lock_path = /var/lib/neutron/tmp #用以下命令修改 \\cp /etc/neutron/neutron.conf{,.bak} grep '^[a-Z\\[]' /etc/neutron/neutron.conf.bak >/etc/neutron/neutron.conf openstack-config --set /etc/neutron/neutron.conf DEFAULT core_plugin ml2 openstack-config --set /etc/neutron/neutron.conf DEFAULT service_plugins openstack-config --set /etc/neutron/neutron.conf DEFAULT rpc_backend rabbit openstack-config --set /etc/neutron/neutron.conf DEFAULT auth_strategy keystone openstack-config --set /etc/neutron/neutron.conf DEFAULT notify_nova_on_port_status_changes True openstack-config --set /etc/neutron/neutron.conf DEFAULT notify_nova_on_port_data_changes True openstack-config --set /etc/neutron/neutron.conf database connection mysql+pymysql://neutron:NEUTRON_DBPASS@controller/neutron openstack-config --set /etc/neutron/neutron.conf keystone_authtoken auth_uri http://controller:5000 openstack-config --set /etc/neutron/neutron.conf keystone_authtoken auth_url http://controller:35357 openstack-config --set /etc/neutron/neutron.conf keystone_authtoken memcached_servers controller:11211 openstack-config --set /etc/neutron/neutron.conf keystone_authtoken auth_type password openstack-config --set /etc/neutron/neutron.conf keystone_authtoken project_domain_name default openstack-config --set /etc/neutron/neutron.conf keystone_authtoken user_domain_name default openstack-config --set /etc/neutron/neutron.conf keystone_authtoken project_name service openstack-config --set /etc/neutron/neutron.conf keystone_authtoken username neutron openstack-config --set /etc/neutron/neutron.conf keystone_authtoken password NEUTRON_PASS openstack-config --set /etc/neutron/neutron.conf nova auth_url http://controller:35357 openstack-config --set /etc/neutron/neutron.conf nova auth_type password openstack-config --set /etc/neutron/neutron.conf nova project_domain_name default openstack-config --set /etc/neutron/neutron.conf nova user_domain_name default openstack-config --set /etc/neutron/neutron.conf nova region_name RegionOne openstack-config --set /etc/neutron/neutron.conf nova project_name service openstack-config --set /etc/neutron/neutron.conf nova username nova openstack-config --set /etc/neutron/neutron.conf nova password NOVA_PASS openstack-config --set /etc/neutron/neutron.conf oslo_concurrency lock_path /var/lib/neutron/tmp openstack-config --set /etc/neutron/neutron.conf oslo_messaging_rabbit rabbit_host controller openstack-config --set /etc/neutron/neutron.conf oslo_messaging_rabbit rabbit_userid openstack openstack-config --set /etc/neutron/neutron.conf oslo_messaging_rabbit rabbit_password RABBIT_PASS MD5值 md5sum /etc/neutron/neutron.conf e399b7958cd22f47becc6d8fd6d3521a /etc/neutron/neutron.conf 6.6 配置模块化第2层（ML2）插件 ML2插件使用Linux桥接机制为实例构建第2层（桥接和交换）虚拟网络基础架构 编辑/etc/neutron/plugins/ml2/ml2_conf.ini文件并完成以下操作 1.在[ml2]部分中，启用flat和VLAN网络： [ml2] ... type_drivers = flat,vlan 2.在[ml2]部分中，禁用自助服务网络 [ml2] ... tenant_network_types = 3.在[ml2]部分中，启用Linux桥接机制 [ml2] ... mechanism_drivers = linuxbridge 4.在[ml2]部分中，启用端口安全性扩展驱动程序 [ml2] ... extension_drivers = port_security 5.在[ml2_type_flat]部分中，将提供商虚拟网络配置为扁平网络： [ml2_type_flat] ... flat_networks = provider 6.在[securitygroup]部分中，启用ipset以提高安全组规则的效率 [securitygroup] ... enable_ipset = True #用以下命令修改 \\cp /etc/neutron/plugins/ml2/ml2_conf.ini{,.bak} grep '^[a-Z\\[]' /etc/neutron/plugins/ml2/ml2_conf.ini.bak >/etc/neutron/plugins/ml2/ml2_conf.ini openstack-config --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2 type_drivers flat,vlan openstack-config --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2 tenant_network_types openstack-config --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2 mechanism_drivers linuxbridge openstack-config --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2 extension_drivers port_security openstack-config --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2_type_flat flat_networks provider openstack-config --set /etc/neutron/plugins/ml2/ml2_conf.ini securitygroup enable_ipset True MD5值 md5sum /etc/neutron/plugins/ml2/ml2_conf.ini 2640b5de519fafcd675b30e1bcd3c7d5 /etc/neutron/plugins/ml2/ml2_conf.ini 6.7 配置linux桥接代理 Linux网桥代理为实例构建第2层（桥接和交换）虚拟网络基础架构并处理安全组 编辑/etc/neutron/plugins/ml2/linuxbridge_agent.ini文件并完成以下操作 1.在[linux_bridge]部分中，将提供者虚拟网络映射到提供者物理网络接口，将PROVIDER_INTERFACE_NAME替换 为基础提供程序物理网络接口的名称，这里为eth0 [linux_bridge] physical_interface_mappings = provider:PROVIDER_INTERFACE_NAME 2.在[vxlan]部分中，禁用VXLAN重叠网络 [vxlan] enable_vxlan = False 3.在[securitygroup]部分中，启用安全组并配置Linux网桥iptables防火墙驱动程序 [securitygroup] ... enable_security_group = True firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver #用以下命令修改 \\cp /etc/neutron/plugins/ml2/linuxbridge_agent.ini{,.bak} grep '^[a-Z\\[]' /etc/neutron/plugins/ml2/linuxbridge_agent.ini.bak >/etc/neutron/plugins/ml2/linuxbridge_agent.ini openstack-config --set /etc/neutron/plugins/ml2/linuxbridge_agent.ini linux_bridge physical_interface_mappings provider:eth0 openstack-config --set /etc/neutron/plugins/ml2/linuxbridge_agent.ini securitygroup enable_security_group True openstack-config --set /etc/neutron/plugins/ml2/linuxbridge_agent.ini securitygroup firewall_driver neutron.agent.linux.iptables_firewall.IptablesFirewallDriver openstack-config --set /etc/neutron/plugins/ml2/linuxbridge_agent.ini vxlan enable_vxlan False MD5值 md5sum /etc/neutron/plugins/ml2/linuxbridge_agent.ini 3f474907a7f438b34563e4d3f3c29538 /etc/neutron/plugins/ml2/linuxbridge_agent.ini 6.8 配置DHCP代理 该DHCP代理为虚拟网络提供DHCP服务 编辑/etc/neutron/dhcp_agent.ini文件并完成以下操作 1.在[DEFAULT]部分中，配置Linux桥接接口驱动程序，Dnsmasq DHCP驱动程序，并启用隔离的元数据，以便提供商网络上的实例可以通过网络访问元数据 [DEFAULT] ... interface_driver = neutron.agent.linux.interface.BridgeInterfaceDriver dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq enable_isolated_metadata = True #用以下命令修改 \\cp /etc/neutron/dhcp_agent.ini{,.bak} grep '^[a-Z\\[]' /etc/neutron/dhcp_agent.ini.bak >/etc/neutron/dhcp_agent.ini openstack-config --set /etc/neutron/dhcp_agent.ini DEFAULT interface_driver neutron.agent.linux.interface.BridgeInterfaceDriver openstack-config --set /etc/neutron/dhcp_agent.ini DEFAULT dhcp_driver neutron.agent.linux.dhcp.Dnsmasq openstack-config --set /etc/neutron/dhcp_agent.ini DEFAULT enable_isolated_metadata True MD5值 md5sum /etc/neutron/dhcp_agent.ini d39579607b2f7d92e88f8910f9213520 /etc/neutron/dhcp_agent.ini 6.9 配置元数据代理 所述元数据代理提供配置信息的诸如凭据实例。 编辑/etc/neutron/metadata_agent.ini文件并完成以下操作 在[DEFAULT]部分中，配置元数据主机和共享密钥 [DEFAULT] ... nova_metadata_ip = controller metadata_proxy_shared_secret = METADATA_SECRET #用以下领命修改 \\cp /etc/neutron/metadata_agent.ini{,.bak} grep '^[a-Z\\[]' /etc/neutron/metadata_agent.ini.bak >/etc/neutron/metadata_agent.ini openstack-config --set /etc/neutron/metadata_agent.ini DEFAULT nova_metadata_ip controller openstack-config --set /etc/neutron/metadata_agent.ini DEFAULT metadata_proxy_shared_secret METADATA_SECRET MD5值 md5sum /etc/neutron/metadata_agent.ini e1166b0dfcbcf4507d50860d124335d6 /etc/neutron/metadata_agent.ini 6.10 配置计算以使用网络 编辑/etc/nova/nova.conf文件并执行以下操作： 在[neutron]部分中，配置访问参数，启用元数据代理并配置密码 [neutron] ... url = http://controller:9696 auth_url = http://controller:35357 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = NEUTRON_PASS service_metadata_proxy = True metadata_proxy_shared_secret = METADATA_SECRET #用以下命令修改 openstack-config --set /etc/nova/nova.conf neutron url http://controller:9696 openstack-config --set /etc/nova/nova.conf neutron auth_url http://controller:35357 openstack-config --set /etc/nova/nova.conf neutron auth_type password openstack-config --set /etc/nova/nova.conf neutron project_domain_name default openstack-config --set /etc/nova/nova.conf neutron user_domain_name default openstack-config --set /etc/nova/nova.conf neutron region_name RegionOne openstack-config --set /etc/nova/nova.conf neutron project_name service openstack-config --set /etc/nova/nova.conf neutron username neutron openstack-config --set /etc/nova/nova.conf neutron password NEUTRON_PASS openstack-config --set /etc/nova/nova.conf neutron service_metadata_proxy True openstack-config --set /etc/nova/nova.conf neutron metadata_proxy_shared_secret METADATA_SECRET MD5值 md5sum /etc/nova/nova.conf 6334f359655efdbcf083b812ab94efc1 /etc/nova/nova.conf 6.11 完成安装 6.11.1 联网服务初始化脚本期待一个符号链接 /etc/neutron/plugin.ini指向ML2插件配置文件，/etc/neutron/plugins/ml2/ml2_conf.ini。如果此符号链接不存在，请使用以下命令创建它 ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini 6.11.2 同步数据库，最后提示OK即为正确 su -s /bin/sh -c \"neutron-db-manage --config-file /etc/neutron/neutron.conf \\ --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head\" neutron 6.11.3 重新启动Compute API服务 systemctl restart openstack-nova-api.service 6.11.4 启动网络服务并将其配置为在系统引导时启动 对于官网中的两种网络，这里选择的是第一种网络 #启动网络服务并设置开机自启 systemctl enable neutron-server.service \\ neutron-linuxbridge-agent.service neutron-dhcp-agent.service \\ neutron-metadata-agent.service systemctl start neutron-server.service \\ neutron-linuxbridge-agent.service neutron-dhcp-agent.service \\ neutron-metadata-agent.service #启动服务后提示如下即为正确，alive处都为笑脸 //注意，此处启动比较慢，需要等待几分钟 neutron agent-list +--------------------------------------+--------------------+------------+-------------------+-------+----------------+---------------------------+ | id | agent_type | host | availability_zone | alive | admin_state_up | binary | +--------------------------------------+--------------------+------------+-------------------+-------+----------------+---------------------------+ | 2a79bce3-2492-4d5b-b565-6f18aa7c8bcd | DHCP agent | controller | nova | :-) | True | neutron-dhcp-agent | | 2b3799ae-3162-47f7-82fa-6291d76e0e14 | Metadata agent | controller | | :-) | True | neutron-metadata-agent | | 82ff3326-f570-4f50-bb5c-eec057034fd1 | Linux bridge agent | controller | | :-) | True | neutron-linuxbridge-agent | +--------------------------------------+--------------------+------------+-------------------+-------+----------------+---------------------------+ 安装和配置计算节点 6.12 安装包 yum -y install openstack-neutron-linuxbridge ebtables ipset openstack-utils 6.13 配置公共组件 编辑/etc/neutron/neutron.conf文件并完成以下操作 1.在[database]部分中，注释掉任何连接选项，因为计算节点不直接访问数据库。 在[DEFAULT]和[oslo_messaging_rabbit]部分中，配置RabbitMQ消息队列访问 [DEFAULT] ... rpc_backend = rabbit [oslo_messaging_rabbit] ... rabbit_host = controller rabbit_userid = openstack rabbit_password = RABBIT_PASS 2.在[DEFAULT]和[keystone_authtoken]部分中，配置身份服务访问 [DEFAULT] ... auth_strategy = keystone [keystone_authtoken] ... auth_uri = http://controller:5000 auth_url = http://controller:35357 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = NEUTRON_PASS 3.在[oslo_concurrency]部分中，配置锁定路径 [oslo_concurrency] ... lock_path = /var/lib/neutron/tmp #用以下命令修改 \\cp /etc/neutron/neutron.conf{,.bak} grep '^[a-Z\\[]' /etc/neutron/neutron.conf.bak >/etc/neutron/neutron.conf openstack-config --set /etc/neutron/neutron.conf DEFAULT rpc_backend rabbit openstack-config --set /etc/neutron/neutron.conf DEFAULT auth_strategy keystone openstack-config --set /etc/neutron/neutron.conf keystone_authtoken auth_uri http://controller:5000 openstack-config --set /etc/neutron/neutron.conf keystone_authtoken auth_url http://controller:35357 openstack-config --set /etc/neutron/neutron.conf keystone_authtoken memcached_servers controller:11211 openstack-config --set /etc/neutron/neutron.conf keystone_authtoken auth_type password openstack-config --set /etc/neutron/neutron.conf keystone_authtoken project_domain_name default openstack-config --set /etc/neutron/neutron.conf keystone_authtoken user_domain_name default openstack-config --set /etc/neutron/neutron.conf keystone_authtoken project_name service openstack-config --set /etc/neutron/neutron.conf keystone_authtoken username neutron openstack-config --set /etc/neutron/neutron.conf keystone_authtoken password NEUTRON_PASS openstack-config --set /etc/neutron/neutron.conf oslo_concurrency lock_path /var/lib/neutron/tmp openstack-config --set /etc/neutron/neutron.conf oslo_messaging_rabbit rabbit_host controller openstack-config --set /etc/neutron/neutron.conf oslo_messaging_rabbit rabbit_userid openstack openstack-config --set /etc/neutron/neutron.conf oslo_messaging_rabbit rabbit_password RABBIT_PASS MD5值 md5sum /etc/neutron/neutron.conf 77ffab503797be5063c06e8b956d6ed0 /etc/neutron/neutron.conf 6.14 配置网络选项 6.14.1 配置桥接代理 Linux网桥代理为实例构建第2层（桥接和交换）虚拟网络基础架构并处理安全组。 编辑/etc/neutron/plugins/ml2/linuxbridge_agent.ini文件并完成以下操作： 1.在[linux_bridge]部分中，将提供者虚拟网络映射到提供者物理网络接口，这里为eth0 [linux_bridge] physical_interface_mappings = provider:PROVIDER_INTERFACE_NAME 2.在[vxlan]部分中，禁用VXLAN重叠网络 [vxlan] enable_vxlan = False 3.在[securitygroup]部分中，启用安全组并配置Linux网桥iptables防火墙驱动程序 [securitygroup] ... enable_security_group = True firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver #用以下命令修改 \\cp /etc/neutron/plugins/ml2/linuxbridge_agent.ini{,.bak} grep '^[a-Z\\[]' /etc/neutron/plugins/ml2/linuxbridge_agent.ini.bak >/etc/neutron/plugins/ml2/linuxbridge_agent.ini openstack-config --set /etc/neutron/plugins/ml2/linuxbridge_agent.ini linux_bridge physical_interface_mappings provider:eth0 openstack-config --set /etc/neutron/plugins/ml2/linuxbridge_agent.ini vxlan enable_vxlan False openstack-config --set /etc/neutron/plugins/ml2/linuxbridge_agent.ini securitygroup enable_security_group True openstack-config --set /etc/neutron/plugins/ml2/linuxbridge_agent.ini securitygroup firewall_driver neutron.agent.linux.iptables_firewall.IptablesFirewallDriver MD5值 md5sum /etc/neutron/plugins/ml2/linuxbridge_agent.ini 3f474907a7f438b34563e4d3f3c29538 /etc/neutron/plugins/ml2/linuxbridge_agent.ini 6.14.2 配置计算以使用网络 编辑/etc/nova/nova.conf文件并完成以下操作 在[neutron]部分中，配置访问参数 [neutron] ... url = http://controller:9696 auth_url = http://controller:35357 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = NEUTRON_PASS #使用以下命令修改 openstack-config --set /etc/nova/nova.conf neutron url http://controller:9696 && \\ openstack-config --set /etc/nova/nova.conf neutron auth_url http://controller:35357 && \\ openstack-config --set /etc/nova/nova.conf neutron auth_type password && \\ openstack-config --set /etc/nova/nova.conf neutron project_domain_name default && \\ openstack-config --set /etc/nova/nova.conf neutron user_domain_name default && \\ openstack-config --set /etc/nova/nova.conf neutron region_name RegionOne && \\ openstack-config --set /etc/nova/nova.conf neutron project_name service && \\ openstack-config --set /etc/nova/nova.conf neutron username neutron && \\ openstack-config --set /etc/nova/nova.conf neutron password NEUTRON_PASS MD5值 md5sum /etc/nova/nova.conf 8e6590c8dc3d59beb3da37fdeeadfd1d /etc/nova/nova.conf 6.15 完成安装 6.15.1 重新启动Compute服务 systemctl restart openstack-nova-compute.service 6.15.2 启动Linux网桥代理并将其配置为在系统引导时启动 systemctl enable neutron-linuxbridge-agent.service && \\ systemctl start neutron-linuxbridge-agent.service 6.16 验证操作，在控制节点操作 6.16.1 获取管理员凭据以获取对仅管理员CLI命令的访问权限 source /opt/admin-openrc 6.16.2 列出已加载的扩展以验证neutron-server进程的成功启动 neutron ext-list +---------------------------+-----------------------------------------------+ | alias | name | +---------------------------+-----------------------------------------------+ | default-subnetpools | Default Subnetpools | | availability_zone | Availability Zone | | network_availability_zone | Network Availability Zone | | auto-allocated-topology | Auto Allocated Topology Services | | binding | Port Binding | | agent | agent | | subnet_allocation | Subnet Allocation | | dhcp_agent_scheduler | DHCP Agent Scheduler | | tag | Tag support | | external-net | Neutron external network | | net-mtu | Network MTU | | network-ip-availability | Network IP Availability | | quotas | Quota management support | | provider | Provider Network | | multi-provider | Multi Provider Network | | address-scope | Address scope | | timestamp_core | Time Stamp Fields addition for core resources | | extra_dhcp_opt | Neutron Extra DHCP opts | | security-group | security-group | | rbac-policies | RBAC Policies | | standard-attr-description | standard-attr-description | | port-security | Port Security | | allowed-address-pairs | Allowed Address Pairs | +---------------------------+-----------------------------------------------+ 6.16.3 列出代理以验证成功启动neutron代理，alive处都为笑脸即为正确 neutron agent-list +--------------------------------------+--------------------+------------+-------------------+-------+----------------+---------------------------+ | id | agent_type | host | availability_zone | alive | admin_state_up | binary | +--------------------------------------+--------------------+------------+-------------------+-------+----------------+---------------------------+ | 2a79bce3-2492-4d5b-b565-6f18aa7c8bcd | DHCP agent | controller | nova | :-) | True | neutron-dhcp-agent | | 2b3799ae-3162-47f7-82fa-6291d76e0e14 | Metadata agent | controller | | :-) | True | neutron-metadata-agent | | 82ff3326-f570-4f50-bb5c-eec057034fd1 | Linux bridge agent | controller | | :-) | True | neutron-linuxbridge-agent | | ee271e44-25c3-4024-b414-40d8fa838d68 | Linux bridge agent | compute1 | | :-) | True | neutron-linuxbridge-agent | +--------------------------------------+--------------------+------------+-------------------+-------+----------------+---------------------------+ 到此，控制节点、计算节点网络服务neutron安装完成！！！ 七、计算节点horizon web界面Dashboard安装 7.1 安装包 yum -y install openstack-dashboard 7.2 编辑/etc/openstack-dashboard/local_settings文件并完成以下操作 1.配置仪表板以在控制器节点上使用OpenStack服务 158行，OPENSTACK_HOST = \"127.0.0.1\" 修改为 OPENSTACK_HOST = \"controller\" 2.允许所有主机访问仪表板 30行，ALLOWED_HOSTS = ['horizon.example.com', 'localhost'] 修改为 ALLOWED_HOSTS = ['*', ] 3.配置memcached会话存储服务 134-142行 CACHES = { 'default': { 'BACKEND': 'django.core.cache.backends.locmem.LocMemCache', }, } 修改为 SESSION_ENGINE = 'django.contrib.sessions.backends.file' CACHES = { 'default': { 'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache', 'LOCATION': 'controller:11211', } } 4.启用Identity API版本3 161行 OPENSTACK_KEYSTONE_URL = \"http://%s:5000/v2.0\" % OPENSTACK_HOST 修改为 OPENSTACK_KEYSTONE_URL = \"http://%s:5000/v3\" % OPENSTACK_HOST 5.启用对域的支持 65行 #OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = False 修改为 OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = True 6.配置API版本 55-60行，取消注释 #OPENSTACK_API_VERSIONS = { # \"data-processing\": 1.1, # \"identity\": 3, # \"volume\": 2, # \"compute\": 2, #} 修改为 OPENSTACK_API_VERSIONS = { \"identity\": 3, \"image\": 2, \"volume\": 2, } 7.配置default作为您通过仪表盘创建用户的默认域 71行 #OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = 'default' 修改为 OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = \"default\" 8.将user配置为您通过仪表板创建的用户的默认角色 161行 OPENSTACK_KEYSTONE_DEFAULT_ROLE = \"_member_\" 修改为 OPENSTACK_KEYSTONE_DEFAULT_ROLE = \"user\" 9.如果选择网络选项1，请禁用对第3层网络服务的支持 261-270行 OPENSTACK_NEUTRON_NETWORK = { 'enable_router': True, 'enable_quotas': True, 'enable_ipv6': True, 'enable_distributed_router': False, 'enable_ha_router': False, 'enable_lb': True, 'enable_firewall': True, 'enable_vpn': True, 'enable_fip_topology_check': True, 修改为 OPENSTACK_NEUTRON_NETWORK = { ... 'enable_router': False, 'enable_quotas': False, 'enable_distributed_router': False, 'enable_ha_router': False, 'enable_lb': False, 'enable_firewall': False, 'enable_vpn': False, 'enable_fip_topology_check': False, 10.可选）配置时区 371行 TIME_ZONE = \"UTC\" 修改为 TIME_ZONE = \"Asia/Shanghai\" //有BUG，暂时不用 #用以下命令修改 \\cp /etc/openstack-dashboard/local_settings{,.bak} && \\ sed -i.bak '158cOPENSTACK_HOST = \"controller\"' /etc/openstack-dashboard/local_settings && \\ sed -i '30s/horizon.example.com/*/' /etc/openstack-dashboard/local_settings|sed -i '30s/\\x27localhost\\x27//' /etc/openstack-dashboard/local_settings && \\ sed -i $'137a\\t\\'LOCATION\\': \\'controller:11211\\',' /etc/openstack-dashboard/local_settings /etc/openstack-dashboard/local_settings文件内容 # -*- coding: utf-8 -*- import os from django.utils.translation import ugettext_lazy as _ from openstack_dashboard import exceptions from openstack_dashboard.settings import HORIZON_CONFIG DEBUG = False TEMPLATE_DEBUG = DEBUG # WEBROOT is the location relative to Webserver root # should end with a slash. WEBROOT = '/dashboard/' #LOGIN_URL = WEBROOT + 'auth/login/' #LOGOUT_URL = WEBROOT + 'auth/logout/' # # LOGIN_REDIRECT_URL can be used as an alternative for # HORIZON_CONFIG.user_home, if user_home is not set. # Do not set it to '/home/', as this will cause circular redirect loop #LOGIN_REDIRECT_URL = WEBROOT # If horizon is running in production (DEBUG is False), set this # with the list of host/domain names that the application can serve. # For more information see: # https://docs.djangoproject.com/en/dev/ref/settings/#allowed-hosts ALLOWED_HOSTS = ['*', ] # Set SSL proxy settings: # Pass this header from the proxy after terminating the SSL, # and don't forget to strip it from the client's request. # For more information see: # https://docs.djangoproject.com/en/1.8/ref/settings/#secure-proxy-ssl-header #SECURE_PROXY_SSL_HEADER = ('HTTP_X_FORWARDED_PROTO', 'https') # If Horizon is being served through SSL, then uncomment the following two # settings to better secure the cookies from security exploits #CSRF_COOKIE_SECURE = True #SESSION_COOKIE_SECURE = True # The absolute path to the directory where message files are collected. # The message file must have a .json file extension. When the user logins to # horizon, the message files collected are processed and displayed to the user. #MESSAGES_PATH=None # Overrides for OpenStack API versions. Use this setting to force the # OpenStack dashboard to use a specific API version for a given service API. # Versions specified here should be integers or floats, not strings. # NOTE: The version should be formatted as it appears in the URL for the # service API. For example, The identity service APIs have inconsistent # use of the decimal point, so valid options would be 2.0 or 3. OPENSTACK_API_VERSIONS = { # \"data-processing\": 1.1, \"identity\": 3, \"image\": 2, \"volume\": 2, \"compute\": 2, } # Set this to True if running on multi-domain model. When this is enabled, it # will require user to enter the Domain name in addition to username for login. OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = True # Overrides the default domain used when running on single-domain model # with Keystone V3. All entities will be created in the default domain. # NOTE: This value must be the ID of the default domain, NOT the name. # Also, you will most likely have a value in the keystone policy file like this # \"cloud_admin\": \"rule:admin_required and domain_id:\" # This value must match the domain id specified there. OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = 'default' # Set this to True to enable panels that provide the ability for users to # manage Identity Providers (IdPs) and establish a set of rules to map # federation protocol attributes to Identity API attributes. # This extension requires v3.0+ of the Identity API. #OPENSTACK_KEYSTONE_FEDERATION_MANAGEMENT = False # Set Console type: # valid options are \"AUTO\"(default), \"VNC\", \"SPICE\", \"RDP\", \"SERIAL\" or None # Set to None explicitly if you want to deactivate the console. #CONSOLE_TYPE = \"AUTO\" # If provided, a \"Report Bug\" link will be displayed in the site header # which links to the value of this setting (ideally a URL containing # information on how to report issues). #HORIZON_CONFIG[\"bug_url\"] = \"http://bug-report.example.com\" # Show backdrop element outside the modal, do not close the modal # after clicking on backdrop. #HORIZON_CONFIG[\"modal_backdrop\"] = \"static\" # Specify a regular expression to validate user passwords. #HORIZON_CONFIG[\"password_validator\"] = { # \"regex\": '.*', # \"help_text\": _(\"Your password does not meet the requirements.\"), #} # Disable simplified floating IP address management for deployments with # multiple floating IP pools or complex network requirements. #HORIZON_CONFIG[\"simple_ip_management\"] = False # Turn off browser autocompletion for forms including the login form and # the database creation workflow if so desired. #HORIZON_CONFIG[\"password_autocomplete\"] = \"off\" # Setting this to True will disable the reveal button for password fields, # including on the login form. #HORIZON_CONFIG[\"disable_password_reveal\"] = False LOCAL_PATH = '/tmp' # Set custom secret key: # You can either set it to a specific value or you can let horizon generate a # default secret key that is unique on this machine, e.i. regardless of the # amount of Python WSGI workers (if used behind Apache+mod_wsgi): However, # there may be situations where you would want to set this explicitly, e.g. # when multiple dashboard instances are distributed on different machines # (usually behind a load-balancer). Either you have to make sure that a session # gets all requests routed to the same dashboard instance or you set the same # SECRET_KEY for all of them. SECRET_KEY='65941f1393ea1c265ad7' # We recommend you use memcached for development; otherwise after every reload # of the django development server, you will have to login again. To use # memcached set CACHES to something like SESSION_ENGINE = 'django.contrib.sessions.backends.file' CACHES = { 'default': { 'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache', 'LOCATION': 'controller:11211', }, } #CACHES = { # 'default': { # 'BACKEND': 'django.core.cache.backends.locmem.LocMemCache', # }, #} # Send email to the console by default EMAIL_BACKEND = 'django.core.mail.backends.console.EmailBackend' # Or send them to /dev/null #EMAIL_BACKEND = 'django.core.mail.backends.dummy.EmailBackend' # Configure these for your outgoing email host #EMAIL_HOST = 'smtp.my-company.com' #EMAIL_PORT = 25 #EMAIL_HOST_USER = 'djangomail' #EMAIL_HOST_PASSWORD = 'top-secret!' # For multiple regions uncomment this configuration, and add (endpoint, title). #AVAILABLE_REGIONS = [ # ('http://cluster1.example.com:5000/v2.0', 'cluster1'), # ('http://cluster2.example.com:5000/v2.0', 'cluster2'), #] OPENSTACK_HOST = \"controller\" OPENSTACK_KEYSTONE_URL = \"http://%s:5000/v3\" % OPENSTACK_HOST OPENSTACK_KEYSTONE_DEFAULT_ROLE = \"user\" # Enables keystone web single-sign-on if set to True. #WEBSSO_ENABLED = False # Determines which authentication choice to show as default. #WEBSSO_INITIAL_CHOICE = \"credentials\" # The list of authentication mechanisms which include keystone # federation protocols and identity provider/federation protocol # mapping keys (WEBSSO_IDP_MAPPING). Current supported protocol # IDs are 'saml2' and 'oidc' which represent SAML 2.0, OpenID # Connect respectively. # Do not remove the mandatory credentials mechanism. # Note: The last two tuples are sample mapping keys to a identity provider # and federation protocol combination (WEBSSO_IDP_MAPPING). #WEBSSO_CHOICES = ( # (\"credentials\", _(\"Keystone Credentials\")), # (\"oidc\", _(\"OpenID Connect\")), # (\"saml2\", _(\"Security Assertion Markup Language\")), # (\"acme_oidc\", \"ACME - OpenID Connect\"), # (\"acme_saml2\", \"ACME - SAML2\"), #) # A dictionary of specific identity provider and federation protocol # combinations. From the selected authentication mechanism, the value # will be looked up as keys in the dictionary. If a match is found, # it will redirect the user to a identity provider and federation protocol # specific WebSSO endpoint in keystone, otherwise it will use the value # as the protocol_id when redirecting to the WebSSO by protocol endpoint. # NOTE: The value is expected to be a tuple formatted as: (, ). #WEBSSO_IDP_MAPPING = { # \"acme_oidc\": (\"acme\", \"oidc\"), # \"acme_saml2\": (\"acme\", \"saml2\"), #} # Disable SSL certificate checks (useful for self-signed certificates): #OPENSTACK_SSL_NO_VERIFY = True # The CA certificate to use to verify SSL connections #OPENSTACK_SSL_CACERT = '/path/to/cacert.pem' # The OPENSTACK_KEYSTONE_BACKEND settings can be used to identify the # capabilities of the auth backend for Keystone. # If Keystone has been configured to use LDAP as the auth backend then set # can_edit_user to False and name to 'ldap'. # # TODO(tres): Remove these once Keystone has an API to identify auth backend. OPENSTACK_KEYSTONE_BACKEND = { 'name': 'native', 'can_edit_user': True, 'can_edit_group': True, 'can_edit_project': True, 'can_edit_domain': True, 'can_edit_role': True, } # Setting this to True, will add a new \"Retrieve Password\" action on instance, # allowing Admin session password retrieval/decryption. #OPENSTACK_ENABLE_PASSWORD_RETRIEVE = False # The Launch Instance user experience has been significantly enhanced. # You can choose whether to enable the new launch instance experience, # the legacy experience, or both. The legacy experience will be removed # in a future release, but is available as a temporary backup setting to ensure # compatibility with existing deployments. Further development will not be # done on the legacy experience. Please report any problems with the new # experience via the Launchpad tracking system. # # Toggle LAUNCH_INSTANCE_LEGACY_ENABLED and LAUNCH_INSTANCE_NG_ENABLED to # determine the experience to enable. Set them both to true to enable # both. #LAUNCH_INSTANCE_LEGACY_ENABLED = True #LAUNCH_INSTANCE_NG_ENABLED = False # A dictionary of settings which can be used to provide the default values for # properties found in the Launch Instance modal. #LAUNCH_INSTANCE_DEFAULTS = { # 'config_drive': False, #} # The Xen Hypervisor has the ability to set the mount point for volumes # attached to instances (other Hypervisors currently do not). Setting # can_set_mount_point to True will add the option to set the mount point # from the UI. OPENSTACK_HYPERVISOR_FEATURES = { 'can_set_mount_point': False, 'can_set_password': False, 'requires_keypair': False, } # The OPENSTACK_CINDER_FEATURES settings can be used to enable optional # services provided by cinder that is not exposed by its extension API. OPENSTACK_CINDER_FEATURES = { 'enable_backup': False, } # The OPENSTACK_NEUTRON_NETWORK settings can be used to enable optional # services provided by neutron. Options currently available are load # balancer service, security groups, quotas, VPN service. OPENSTACK_NEUTRON_NETWORK = { 'enable_router': False, 'enable_quotas': False, 'enable_ipv6': False, 'enable_distributed_router': False, 'enable_ha_router': False, 'enable_lb': False, 'enable_firewall': False, 'enable_vpn': False, 'enable_fip_topology_check': False, # Neutron can be configured with a default Subnet Pool to be used for IPv4 # subnet-allocation. Specify the label you wish to display in the Address # pool selector on the create subnet step if you want to use this feature. 'default_ipv4_subnet_pool_label': None, # Neutron can be configured with a default Subnet Pool to be used for IPv6 # subnet-allocation. Specify the label you wish to display in the Address # pool selector on the create subnet step if you want to use this feature. # You must set this to enable IPv6 Prefix Delegation in a PD-capable # environment. 'default_ipv6_subnet_pool_label': None, # The profile_support option is used to detect if an external router can be # configured via the dashboard. When using specific plugins the # profile_support can be turned on if needed. 'profile_support': None, #'profile_support': 'cisco', # Set which provider network types are supported. Only the network types # in this list will be available to choose from when creating a network. # Network types include local, flat, vlan, gre, and vxlan. 'supported_provider_types': ['*'], # Set which VNIC types are supported for port binding. Only the VNIC # types in this list will be available to choose from when creating a # port. # VNIC types include 'normal', 'macvtap' and 'direct'. # Set to empty list or None to disable VNIC type selection. 'supported_vnic_types': ['*'], } # The OPENSTACK_HEAT_STACK settings can be used to disable password # field required while launching the stack. OPENSTACK_HEAT_STACK = { 'enable_user_pass': True, } # The OPENSTACK_IMAGE_BACKEND settings can be used to customize features # in the OpenStack Dashboard related to the Image service, such as the list # of supported image formats. #OPENSTACK_IMAGE_BACKEND = { # 'image_formats': [ # ('', _('Select format')), # ('aki', _('AKI - Amazon Kernel Image')), # ('ami', _('AMI - Amazon Machine Image')), # ('ari', _('ARI - Amazon Ramdisk Image')), # ('docker', _('Docker')), # ('iso', _('ISO - Optical Disk Image')), # ('ova', _('OVA - Open Virtual Appliance')), # ('qcow2', _('QCOW2 - QEMU Emulator')), # ('raw', _('Raw')), # ('vdi', _('VDI - Virtual Disk Image')), # ('vhd', _('VHD - Virtual Hard Disk')), # ('vmdk', _('VMDK - Virtual Machine Disk')), # ], #} # The IMAGE_CUSTOM_PROPERTY_TITLES settings is used to customize the titles for # image custom property attributes that appear on image detail pages. IMAGE_CUSTOM_PROPERTY_TITLES = { \"architecture\": _(\"Architecture\"), \"kernel_id\": _(\"Kernel ID\"), \"ramdisk_id\": _(\"Ramdisk ID\"), \"image_state\": _(\"Euca2ools state\"), \"project_id\": _(\"Project ID\"), \"image_type\": _(\"Image Type\"), } # The IMAGE_RESERVED_CUSTOM_PROPERTIES setting is used to specify which image # custom properties should not be displayed in the Image Custom Properties # table. IMAGE_RESERVED_CUSTOM_PROPERTIES = [] # OPENSTACK_ENDPOINT_TYPE specifies the endpoint type to use for the endpoints # in the Keystone service catalog. Use this setting when Horizon is running # external to the OpenStack environment. The default is 'publicURL'. #OPENSTACK_ENDPOINT_TYPE = \"publicURL\" # SECONDARY_ENDPOINT_TYPE specifies the fallback endpoint type to use in the # case that OPENSTACK_ENDPOINT_TYPE is not present in the endpoints # in the Keystone service catalog. Use this setting when Horizon is running # external to the OpenStack environment. The default is None. This # value should differ from OPENSTACK_ENDPOINT_TYPE if used. #SECONDARY_ENDPOINT_TYPE = \"publicURL\" # The number of objects (Swift containers/objects or images) to display # on a single page before providing a paging element (a \"more\" link) # to paginate results. API_RESULT_LIMIT = 1000 API_RESULT_PAGE_SIZE = 20 # The size of chunk in bytes for downloading objects from Swift SWIFT_FILE_TRANSFER_CHUNK_SIZE = 512 * 1024 # Specify a maximum number of items to display in a dropdown. DROPDOWN_MAX_ITEMS = 30 # The timezone of the server. This should correspond with the timezone # of your entire OpenStack installation, and hopefully be in UTC. TIME_ZONE = \"Asia/Shanghai\" # When launching an instance, the menu of available flavors is # sorted by RAM usage, ascending. If you would like a different sort order, # you can provide another flavor attribute as sorting key. Alternatively, you # can provide a custom callback method to use for sorting. You can also provide # a flag for reverse sort. For more info, see # http://docs.python.org/2/library/functions.html#sorted #CREATE_INSTANCE_FLAVOR_SORT = { # 'key': 'name', # # or # 'key': my_awesome_callback_method, # 'reverse': False, #} # Set this to True to display an 'Admin Password' field on the Change Password # form to verify that it is indeed the admin logged-in who wants to change # the password. #ENFORCE_PASSWORD_CHECK = False # Modules that provide /auth routes that can be used to handle different types # of user authentication. Add auth plugins that require extra route handling to # this list. #AUTHENTICATION_URLS = [ # 'openstack_auth.urls', #] # The Horizon Policy Enforcement engine uses these values to load per service # policy rule files. The content of these files should match the files the # OpenStack services are using to determine role based access control in the # target installation. # Path to directory containing policy.json files POLICY_FILES_PATH = '/etc/openstack-dashboard' # Map of local copy of service policy files. # Please insure that your identity policy file matches the one being used on # your keystone servers. There is an alternate policy file that may be used # in the Keystone v3 multi-domain case, policy.v3cloudsample.json. # This file is not included in the Horizon repository by default but can be # found at # http://git.openstack.org/cgit/openstack/keystone/tree/etc/ \\ # policy.v3cloudsample.json # Having matching policy files on the Horizon and Keystone servers is essential # for normal operation. This holds true for all services and their policy files. #POLICY_FILES = { # 'identity': 'keystone_policy.json', # 'compute': 'nova_policy.json', # 'volume': 'cinder_policy.json', # 'image': 'glance_policy.json', # 'orchestration': 'heat_policy.json', # 'network': 'neutron_policy.json', # 'telemetry': 'ceilometer_policy.json', #} # TODO: (david-lyle) remove when plugins support adding settings. # Note: Only used when trove-dashboard plugin is configured to be used by # Horizon. # Trove user and database extension support. By default support for # creating users and databases on database instances is turned on. # To disable these extensions set the permission here to something # unusable such as [\"!\"]. #TROVE_ADD_USER_PERMS = [] #TROVE_ADD_DATABASE_PERMS = [] # Change this patch to the appropriate list of tuples containing # a key, label and static directory containing two files: # _variables.scss and _styles.scss #AVAILABLE_THEMES = [ # ('default', 'Default', 'themes/default'), # ('material', 'Material', 'themes/material'), #] LOGGING = { 'version': 1, # When set to True this will disable all logging except # for loggers specified in this configuration dictionary. Note that # if nothing is specified here and disable_existing_loggers is True, # django.db.backends will still log unless it is disabled explicitly. 'disable_existing_loggers': False, 'handlers': { 'null': { 'level': 'DEBUG', 'class': 'logging.NullHandler', }, 'console': { # Set the level to \"DEBUG\" for verbose output logging. 'level': 'INFO', 'class': 'logging.StreamHandler', }, }, 'loggers': { # Logging from django.db.backends is VERY verbose, send to null # by default. 'django.db.backends': { 'handlers': ['null'], 'propagate': False, }, 'requests': { 'handlers': ['null'], 'propagate': False, }, 'horizon': { 'handlers': ['console'], 'level': 'DEBUG', 'propagate': False, }, 'openstack_dashboard': { 'handlers': ['console'], 'level': 'DEBUG', 'propagate': False, }, 'novaclient': { 'handlers': ['console'], 'level': 'DEBUG', 'propagate': False, }, 'cinderclient': { 'handlers': ['console'], 'level': 'DEBUG', 'propagate': False, }, 'keystoneclient': { 'handlers': ['console'], 'level': 'DEBUG', 'propagate': False, }, 'glanceclient': { 'handlers': ['console'], 'level': 'DEBUG', 'propagate': False, }, 'neutronclient': { 'handlers': ['console'], 'level': 'DEBUG', 'propagate': False, }, 'heatclient': { 'handlers': ['console'], 'level': 'DEBUG', 'propagate': False, }, 'ceilometerclient': { 'handlers': ['console'], 'level': 'DEBUG', 'propagate': False, }, 'swiftclient': { 'handlers': ['console'], 'level': 'DEBUG', 'propagate': False, }, 'openstack_auth': { 'handlers': ['console'], 'level': 'DEBUG', 'propagate': False, }, 'nose.plugins.manager': { 'handlers': ['console'], 'level': 'DEBUG', 'propagate': False, }, 'django': { 'handlers': ['console'], 'level': 'DEBUG', 'propagate': False, }, 'iso8601': { 'handlers': ['null'], 'propagate': False, }, 'scss': { 'handlers': ['null'], 'propagate': False, }, }, } # 'direction' should not be specified for all_tcp/udp/icmp. # It is specified in the form. SECURITY_GROUP_RULES = { 'all_tcp': { 'name': _('All TCP'), 'ip_protocol': 'tcp', 'from_port': '1', 'to_port': '65535', }, 'all_udp': { 'name': _('All UDP'), 'ip_protocol': 'udp', 'from_port': '1', 'to_port': '65535', }, 'all_icmp': { 'name': _('All ICMP'), 'ip_protocol': 'icmp', 'from_port': '-1', 'to_port': '-1', }, 'ssh': { 'name': 'SSH', 'ip_protocol': 'tcp', 'from_port': '22', 'to_port': '22', }, 'smtp': { 'name': 'SMTP', 'ip_protocol': 'tcp', 'from_port': '25', 'to_port': '25', }, 'dns': { 'name': 'DNS', 'ip_protocol': 'tcp', 'from_port': '53', 'to_port': '53', }, 'http': { 'name': 'HTTP', 'ip_protocol': 'tcp', 'from_port': '80', 'to_port': '80', }, 'pop3': { 'name': 'POP3', 'ip_protocol': 'tcp', 'from_port': '110', 'to_port': '110', }, 'imap': { 'name': 'IMAP', 'ip_protocol': 'tcp', 'from_port': '143', 'to_port': '143', }, 'ldap': { 'name': 'LDAP', 'ip_protocol': 'tcp', 'from_port': '389', 'to_port': '389', }, 'https': { 'name': 'HTTPS', 'ip_protocol': 'tcp', 'from_port': '443', 'to_port': '443', }, 'smtps': { 'name': 'SMTPS', 'ip_protocol': 'tcp', 'from_port': '465', 'to_port': '465', }, 'imaps': { 'name': 'IMAPS', 'ip_protocol': 'tcp', 'from_port': '993', 'to_port': '993', }, 'pop3s': { 'name': 'POP3S', 'ip_protocol': 'tcp', 'from_port': '995', 'to_port': '995', }, 'ms_sql': { 'name': 'MS SQL', 'ip_protocol': 'tcp', 'from_port': '1433', 'to_port': '1433', }, 'mysql': { 'name': 'MYSQL', 'ip_protocol': 'tcp', 'from_port': '3306', 'to_port': '3306', }, 'rdp': { 'name': 'RDP', 'ip_protocol': 'tcp', 'from_port': '3389', 'to_port': '3389', }, } # Deprecation Notice: # # The setting FLAVOR_EXTRA_KEYS has been deprecated. # Please load extra spec metadata into the Glance Metadata Definition Catalog. # # The sample quota definitions can be found in: # /etc/metadefs/compute-quota.json # # The metadata definition catalog supports CLI and API: # $glance --os-image-api-version 2 help md-namespace-import # $glance-manage db_load_metadefs # # See Metadata Definitions on: http://docs.openstack.org/developer/glance/ # TODO: (david-lyle) remove when plugins support settings natively # Note: This is only used when the Sahara plugin is configured and enabled # for use in Horizon. # Indicate to the Sahara data processing service whether or not # automatic floating IP allocation is in effect. If it is not # in effect, the user will be prompted to choose a floating IP # pool for use in their cluster. False by default. You would want # to set this to True if you were running Nova Networking with # auto_assign_floating_ip = True. #SAHARA_AUTO_IP_ALLOCATION_ENABLED = False # The hash algorithm to use for authentication tokens. This must # match the hash algorithm that the identity server and the # auth_token middleware are using. Allowed values are the # algorithms supported by Python's hashlib library. #OPENSTACK_TOKEN_HASH_ALGORITHM = 'md5' # Hashing tokens from Keystone keeps the Horizon session data smaller, but it # doesn't work in some cases when using PKI tokens. Uncomment this value and # set it to False if using PKI tokens and there are 401 errors due to token # hashing. #OPENSTACK_TOKEN_HASH_ENABLED = True # AngularJS requires some settings to be made available to # the client side. Some settings are required by in-tree / built-in horizon # features. These settings must be added to REST_API_REQUIRED_SETTINGS in the # form of ['SETTING_1','SETTING_2'], etc. # # You may remove settings from this list for security purposes, but do so at # the risk of breaking a built-in horizon feature. These settings are required # for horizon to function properly. Only remove them if you know what you # are doing. These settings may in the future be moved to be defined within # the enabled panel configuration. # You should not add settings to this list for out of tree extensions. # See: https://wiki.openstack.org/wiki/Horizon/RESTAPI REST_API_REQUIRED_SETTINGS = ['OPENSTACK_HYPERVISOR_FEATURES', 'LAUNCH_INSTANCE_DEFAULTS'] # Additional settings can be made available to the client side for # extensibility by specifying them in REST_API_ADDITIONAL_SETTINGS # !! Please use extreme caution as the settings are transferred via HTTP/S # and are not encrypted on the browser. This is an experimental API and # may be deprecated in the future without notice. #REST_API_ADDITIONAL_SETTINGS = [] # DISALLOW_IFRAME_EMBED can be used to prevent Horizon from being embedded # within an iframe. Legacy browsers are still vulnerable to a Cross-Frame # Scripting (XFS) vulnerability, so this option allows extra security hardening # where iframes are not used in deployment. Default setting is True. # For more information see: # http://tinyurl.com/anticlickjack #DISALLOW_IFRAME_EMBED = True 7.3 验证操作 7.3.1 修改配置文件，否则后续访问dashboard会报500错误 sed -i.bak '3aWSGIApplicationGroup %{GLOBAL}' \\ /etc/httpd/conf.d/openstack-dashboard.conf #重启httpd systemctl enable httpd && systemctl restart httpd 7.3.2 登录dashboard 10.0.0.31/dashboard 域：default 用户名：admin 密码：ADMIN_PASS 登陆后首界面 到此，计算节点Dashboard安装完成！！！ 如果遇到如下错误 解决方法 安装dashboard节点做以下操作 1.修改配置文件/etc/openstack-dashboard/local_settings 修改 SESSION_ENGINE = 'django.contrib.sessions.backends.cache' 修改为 SESSION_ENGINE = 'django.contrib.sessions.backends.file' 2.重启httpd systemctl restart httpd 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/openstack/mitaka/2.Mitaka版使用命令启动一个实例.html":{"url":"linux/openstack/mitaka/2.Mitaka版使用命令启动一个实例.html","title":"Mitaka版使用命令启动一个实例","keywords":"","body":"Mitaka版使用命令启动一个示例 1.创建网络（网络名+子网） 创建网络名 neutron net-create --shared --provider:physical_network provider \\ --provider:network_type flat pptfz net-create 创建网络 --shared 创建共享网络 --provider:physical_network 指定物理网卡名称 provider网络标签 --provider:network_type 指定网络类型 flat桥接网络 pptfz网络名称 创建子网 neutron subnet-create --name bxb \\ --allocation-pool start=10.0.0.101,end=10.0.0.250 \\ --dns-nameserver 223.5.5.5 --gateway 10.0.0.254 \\ pptfz 10.0.0.0/24 subnet-create 创建子网 --name 指定名称 bxb子网名称 --allocation-pool IP地址范围 pptfz 创建的子网关联到哪个网络 以下为操作 #创建网络 neutron net-create --shared --provider:physical_network provider \\ --provider:network_type flat pptfz Created a new network: +---------------------------+--------------------------------------+ | Field | Value | +---------------------------+--------------------------------------+ | admin_state_up | True | | availability_zone_hints | | | availability_zones | | | created_at | 2019-02-03T09:37:39 | | description | | | id | 9125ad48-6bbe-4baf-8d78-f91a7c0a8ea2 | | ipv4_address_scope | | | ipv6_address_scope | | | mtu | 1500 | | name | pptfz | | port_security_enabled | True | | provider:network_type | flat | | provider:physical_network | provider | | provider:segmentation_id | | | router:external | False | | shared | True | | status | ACTIVE | | subnets | | | tags | | | tenant_id | e33e3feaef784a5bb45bd9c766bc0f46 | | updated_at | 2019-02-03T09:37:39 | +---------------------------+--------------------------------------+ #创建子网 neutron subnet-create --name bxb \\ --allocation-pool start=10.0.0.101,end=10.0.0.250 \\ --dns-nameserver 223.5.5.5 --gateway 10.0.0.1 \\ pptfz 10.0.0.0/24 Created a new subnet: +-------------------+----------------------------------------------+ | Field | Value | +-------------------+----------------------------------------------+ | allocation_pools | {\"start\": \"10.0.0.101\", \"end\": \"10.0.0.250\"} | | cidr | 10.0.0.0/24 | | created_at | 2019-02-03T09:40:37 | | description | | | dns_nameservers | 223.5.5.5 | | enable_dhcp | True | | gateway_ip | 10.0.0.254 | | host_routes | | | id | ad21906e-166d-47e2-8634-18c907c6da3b | | ip_version | 4 | | ipv6_address_mode | | | ipv6_ra_mode | | | name | bxb | | network_id | 9125ad48-6bbe-4baf-8d78-f91a7c0a8ea2 | | subnetpool_id | | | tenant_id | e33e3feaef784a5bb45bd9c766bc0f46 | | updated_at | 2019-02-03T09:40:37 | +-------------------+----------------------------------------------+ 2.创建云主机的硬件配置方案 openstack flavor create --id 0 --vcpus 1 --ram 64 --disk 1 m1.nano +----------------------------+---------+ | Field | Value | +----------------------------+---------+ | OS-FLV-DISABLED:disabled | False | | OS-FLV-EXT-DATA:ephemeral | 0 | | disk | 1 | | id | 0 | | name | m1.nano | | os-flavor-access:is_public | True | | ram | 64 | | rxtx_factor | 1.0 | | swap | | | vcpus | 1 | +----------------------------+---------+ //参数说明 openstack flavor create --id 0 --vcpus 1 --ram 64 --disk 1 m1.nano flavor 硬件配置方案 --id 指定编号 --vcpus cpu个数 --ram 内存（单位：M） --disk 磁盘（单位：G） m1.nano 方案名称 3.创建密钥对 ssh-keygen -q -N \"\" -f ~/.ssh/id_rsa openstack keypair create --public-key ~/.ssh/id_rsa.pub mykey +-------------+-------------------------------------------------+ | Field | Value | +-------------+-------------------------------------------------+ | fingerprint | 0e:af:ab:c3:74:5f:56:1b:e8:46:7d:e5:65:4f:a8:9a | | name | mykey | | user_id | aaa8bfce5b5d451b956bb76dee235b9e | +-------------+-------------------------------------------------+ //参数说明 ssh-keygen -q -N \"\" -f ~/.ssh/id_rsa 非交互式生成密钥对 -q 安静模式 -N 指定加密密码 -f 密钥对存放位置 openstack keypair create --public-key ~/.ssh/id_rsa.pub mykey 上传密钥对 4.创建安全组规则 openstack security group rule create --proto icmp default +-----------------------+--------------------------------------+ | Field | Value | +-----------------------+--------------------------------------+ | id | cb340772-4dd8-4d33-8ae0-2be3f43f26de | | ip_protocol | icmp | | ip_range | 0.0.0.0/0 | | parent_group_id | b6f5f95a-fd52-43c1-bb4c-0625750e4369 | | port_range | | | remote_security_group | | +-----------------------+--------------------------------------+ openstack security group rule create --proto tcp --dst-port 22 default +-----------------------+--------------------------------------+ | Field | Value | +-----------------------+--------------------------------------+ | id | 01c1cea4-76c0-4181-aca9-4b3148fb0397 | | ip_protocol | tcp | | ip_range | 0.0.0.0/0 | | parent_group_id | b6f5f95a-fd52-43c1-bb4c-0625750e4369 | | port_range | 22:22 | | remote_security_group | | +-----------------------+--------------------------------------+ #默认所有端口全部禁止，上边两个命令为允许ping和ssh openstack security group rule create --proto icmp default openstack security group rule create --proto tcp --dst-port 22 default 5.启动一个实例 openstack server create --flavor m1.nano --image cirros \\ --nic net-id=`neutron net-list|awk 'NR==4{print $2}'` --security-group default \\ --key-name mykey pptfz +--------------------------------------+-----------------------------------------------+ | Field | Value | +--------------------------------------+-----------------------------------------------+ | OS-DCF:diskConfig | MANUAL | | OS-EXT-AZ:availability_zone | | | OS-EXT-SRV-ATTR:host | None | | OS-EXT-SRV-ATTR:hypervisor_hostname | None | | OS-EXT-SRV-ATTR:instance_name | instance-00000001 | | OS-EXT-STS:power_state | 0 | | OS-EXT-STS:task_state | scheduling | | OS-EXT-STS:vm_state | building | | OS-SRV-USG:launched_at | None | | OS-SRV-USG:terminated_at | None | | accessIPv4 | | | accessIPv6 | | | addresses | | | adminPass | 8KcNG34aXwuK | | config_drive | | | created | 2019-02-03T12:10:10Z | | flavor | m1.nano (0) | | hostId | | | id | d5e07f54-c70e-4657-9ec5-778edc941e99 | | image | cirros (ac21b17b-e910-4ca4-b743-914b8fbd0e55) | | key_name | mykey | | name | pptfz | | os-extended-volumes:volumes_attached | [] | | progress | 0 | | project_id | e33e3feaef784a5bb45bd9c766bc0f46 | | properties | | | security_groups | [{u'name': u'default'}] | | status | BUILD | | updated | 2019-02-03T12:10:12Z | | user_id | aaa8bfce5b5d451b956bb76dee235b9e | +--------------------------------------+-----------------------------------------------+ #创建完成后查看，状态为ACTIVE即为正确 openstack server list +--------------------------------------+-------+--------+------------------+ | ID | Name | Status | Networks | +--------------------------------------+-------+--------+------------------+ | d5e07f54-c70e-4657-9ec5-778edc941e99 | pptfz | ACTIVE | pptfz=10.0.0.102 | +--------------------------------------+-------+--------+------------------+ 启动实例后会在web界面显示 项目-->计算-->示例 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/openstack/mitaka/3.Mitaka版web界面启动一个实例.html":{"url":"linux/openstack/mitaka/3.Mitaka版web界面启动一个实例.html","title":"Mitaka版web界面启动一个实例","keywords":"","body":"Mitaka版web界面启动一个实例 1.项目-->计算--实例-->启动实例 2.填写实例名称 3.选择镜像，这里只有一个，如果有多个可以任意选择不同的镜像 4.选择实例的配置 5.启动实例 这里因为刚刚安装完成，网络、网络端口、安全组、密钥对都只有一个，所以系统直接默认选择，如果后续创建了这些配置，可以依据实际情况具体选择，这里直接默认即可 6.启动完成 7.连接实例，右边下箭头-->控制台 ⚠️点击控制台后提示找不到controller地址，因为没有做hosts解析，需要先做hosts解析 windows C:\\Windows\\System32\\drivers\\etc\\hosts 10.0.0.11 controller mac /etc/hosts 10.0.0.11 controller 做完hosts解析后刷新，但是此时又有问题，会一直卡在这个界面不动 解决方法： 1.修改计算节点/etc/nova/nova.conf 在[libvirt]下添加如下两行 cpu_mode = none virt_type = qemu 2.重启nova-compute systemctl restart openstack-nova-compute 修改完openstack-nova-compute后，硬重启（相当于拔电源）实例 硬重启实例后就可以登录了，按照提示登录用户名是cirros，密码是cubswin:) ⚠️注意，需要先在周围黑框处点击一下才能进入控制台 登陆成功后，查看ip、主机名、能够上外网即为正确 切换为root，用默认用户登录系统后，执行sudo su - root切换到root用户，然后就可以修改密码了，并且可以直接用xshell或者其他终端连接 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/openstack/rocky/1.centos7.8搭建openstack Rocky版.html":{"url":"linux/openstack/rocky/1.centos7.8搭建openstack Rocky版.html","title":"centos7.8搭建openstack Rocky版","keywords":"","body":"centos7.8搭建openstack Rocky版 官方文档 rocky版中的密码说明 数据库密码（未使用变量） 数据库的根密码 ADMIN_PASS 用户密码 admin CINDER_DBPASS 块存储服务的数据库密码 CINDER_PASS 块存储服务用户密码 cinder DASH_DBPASS 仪表板的数据库密码 DEMO_PASS 用户密码 demo GLANCE_DBPASS 镜像服务的数据库密码 GLANCE_PASS 图片服务用户密码 glance KEYSTONE_DBPASS 身份服务的数据库密码 METADATA_SECRET 元数据代理的秘密 NEUTRON_DBPASS 网络服务的数据库密码 NEUTRON_PASS 网络服务用户密码 neutron NOVA_DBPASS 计算服务的数据库密码 NOVA_PASS 计算服务用户密码 nova PLACEMENT_PASS 展示位置服务用户的密码 placement RABBIT_PASS RabbitMQ用户密码 openstack 实验环境 角色 IP 主机名 默认网关 硬件环境 虚拟化 防火墙 selinux 控制节点 10.0.0.11/24 controller 10.0.0.1 4G内存，50G硬盘 开启 关闭 关闭 计算节点1 10.0.0.31/24 compute1 10.0.0.1 4G内存，50G硬盘 开启 关闭 关闭 存储节点1 10.0.0.41/24 block1 10.0.0.1 2G内存，100G硬盘 开启 关闭 关闭 对象节点1 10.0.0.51/24 object1 10.0.0.1 2G内存，100G硬盘 开启 关闭 关闭 对象节点2 10.0.0.52/24 object2 10.0.0.1 2G内存，100G硬盘 开启 关闭 关闭 把rocky版rpm包做成本地yum源 1.下载包 yum -y install createrepo 2.制作仓库 createrepo openstack-rocky 3.在10.0.0.51安装nginx，因为是采用http方式 yum -y install nginx systemctl enable nginx && systemctl start nginx 4.编辑nginx配置文件，yum安装的nginx根目录是/usr/share/nginx/html，这里个人习惯选择启用一个虚拟主机，监听88端口 cat > /etc/nginx/conf.d/openstack-rocky.repo.conf /etc/yum.repos.d/openstack-rocky.repo >/etc/fstab 6.生成本地缓存 yum makecache 基础环境官方文档 一、基础环境配置 1.1 关闭防火墙和selinux //禁用防火墙 systemctl stop firewalld && systemctl disable firewalld //禁用selinux #临时修改 setenforce 0 #永久修改，重启服务器后生效 sed -i '7s/enforcing/disabled/' /etc/selinux/config 1.2 配置hosts解析 #控制节点和计算节点相同操作 cat >> /etc/hosts 1.3 配置NTP服务，要保证控制节点和计算节点时间一致 控制节点 1.安装chrony yum -y install chrony 2.编辑chrony配置文件/etc/chrony.conf /删除以下4行，使用阿里云NTP服务器 server 0.centos.pool.ntp.org iburst server 1.centos.pool.ntp.org iburst server 2.centos.pool.ntp.org iburst server 3.centos.pool.ntp.org iburst 修改为 server ntp1.aliyun.com iburst /允许连接控制节点的网段，24行增加以下一行 allow 10.0.0.0/24 #用以下命令修改 sed -i '3,6d' /etc/chrony.conf && sed -i '3cserver ntp1.aliyun.com iburst' \\ /etc/chrony.conf && sed -i '23callow 10.0.0.0/24' /etc/chrony.conf 3.启动NTP服务并设置开机自启 systemctl enable chronyd && systemctl start chronyd 4.检查端口，监听udp323端口 $ netstat -nupl|grep chronyd udp 0 0 127.0.0.1:323 0.0.0.0:* 29356/chronyd udp 0 0 0.0.0.0:123 0.0.0.0:* 29356/chronyd udp6 0 0 ::1:323 :::* 29356/chronyd 5.验证 $ chronyc sources 210 Number of sources = 1 MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^* 120.25.115.20 2 6 37 29 +43us[ -830us] +/- 22ms 计算、存储、对象节点 1.安装chrony yum -y install chrony 2.编辑chrony配置文件/etc/chrony.conf /删除以下4行，指定控制节点为NTP服务器 server 0.centos.pool.ntp.org iburst server 1.centos.pool.ntp.org iburst server 2.centos.pool.ntp.org iburst server 3.centos.pool.ntp.org iburst 修改为 server controller iburst #用以下命令修改 sed -i '3,6d' /etc/chrony.conf && sed -i '3cserver controller iburst' /etc/chrony.conf 3.启动NTP服务并设置开机自启 systemctl enable chronyd && systemctl start chronyd 4.检查端口，监听udp323端口 $ netstat -nupl|grep chronyd udp 0 0 127.0.0.1:323 0.0.0.0:* 1327/chronyd udp6 0 0 ::1:323 :::* 1327/chronyd 5.验证，计算节点显示的是控制节点 $ chronyc sources 210 Number of sources = 1 MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^? controller 3 6 200 50 +1319ms[+1319ms] +/- 14.4s 1.4 下载openstack官方yum源安装openstack客户端 控制节点和计算节点相同操作 yum -y install centos-release-openstack-rocky yum -y install python-openstackclient 到此，控制节点和计算、存储、对象节点操作完成！！！ 二、控制节点环境安装 2.1 安装mariadb数据库 2.1.1 安装包 yum -y install mariadb mariadb-server python2-PyMySQL 2.1.2 编辑配置文件 cat > /etc/my.cnf.d/openstack.cnf 2.1.3 启动mariadb并设置开机自启 systemctl enable mariadb && systemctl start mariadb 2.1.4 进行数据库安全设置 $ mysql_secure_installation Enter current password for root (enter for none): /没有密码，直接回车 Set root password? [Y/n] n /不设置root密码 Remove anonymous users? [Y/n] y /移除匿名用户 Disallow root login remotely? [Y/n] y /禁止root远程登陆 Remove test database and access to it? [Y/n] y /移除test数据库 Reload privilege tables now? [Y/n] y /刷新权限表 2.3 安装消息队列rabbitmq OpenStack 使用 message queue 协调操作和各服务的状态信息。消息队列服务一般运行在控制节点上 rabbitmq会启动2个端口 tcp/5672 rabbitmq服务端口 tcp/25672 多个rabbitmq通信用到的端口 2.3.1 安装包 yum -y install rabbitmq-server 2.3.2 启动rabbitmq并设置为开机自启 systemctl enable rabbitmq-server && systemctl start rabbitmq-server 2.3.3 添加openstack用户 $ rabbitmqctl add_user openstack RABBIT_PASS Creating user \"openstack\" ... ...done. 2.3.4 给openstack用户设置读和写权限 3个.*分别是 可读、可写、可配置 $ rabbitmqctl set_permissions openstack \".*\" \".*\" \".*\" Setting permissions for user \"openstack\" in vhost \"/\" ... ...done. 2.3.5 启动rabbitmq一个插件，启动之后会监听tcp/15672，是一个web管理界面，默认用户名和密码都是guest $ rabbitmq-plugins enable rabbitmq_management The following plugins have been enabled: mochiweb webmachine rabbitmq_web_dispatch amqp_client rabbitmq_management_agent rabbitmq_management Plugin configuration has changed. Restart RabbitMQ for changes to take effect. 2.4 安装memcached 认证服务认证缓存使用Memcached缓存令牌。缓存服务memecached运行在控制节点。在生产部署中，我们推荐联合启用防火墙、认证和加密保证它的安全。 memcache监听 tcp/udp 11211端口 2.4.1 安装包 yum -y install memcached python-memcached 2.4.2 修改配置文件 配置服务以使用控制器节点的管理IP地址。这是为了允许其他节点通过管理网络进行访问： sed -i.bak '/OPTIONS/c OPTIONS=\"-l 127.0.0.1,::1,controller\"' /etc/sysconfig/memcached #修改完的配置文件内容如下 cat /etc/sysconfig/memcached PORT=\"11211\" USER=\"memcached\" MAXCONN=\"1024\" CACHESIZE=\"64\" OPTIONS=\"-l 127.0.0.1,::1,controller\" 2.4.3 启动memcached并设置为开机自启 systemctl enable memcached && systemctl start memcached 2.5 安装etcd OpenStack服务可以使用Etcd（分布式可靠键值存储）来进行分布式键锁定，存储配置，跟踪服务活动性和其他情况。 etcd服务在控制器节点上运行。 etcd服务启动后提供给外部客户端通信的端口是2379，而etcd服务中成员间的通信端口是2380 2.5.1 安装包 yum -y install etcd 2.5.2 编辑配置文件 编辑/etc/etcd/etcd.conf文件，并设置ETCD_INITIAL_CLUSTER， ETCD_INITIAL_ADVERTISE_PEER_URLS，ETCD_ADVERTISE_CLIENT_URLS， ETCD_LISTEN_CLIENT_URLS控制器节点，以使经由管理网络通过其他节点的访问的管理IP地址： cat > /etc/etcd/etcd.conf 2.5.3 启动etcd并设置开机自启 systemctl enable etcd && systemctl restart etcd 到此，控制节点环境安装完成！！！ rocky版认证服务keystone安装配置官方文档 三、控制节点认证服务keystone安装 keystone认证服务功能：认证管理、授权管理、服务目录 认证：用户名和密码 授权：授权管理，例如一些技术网站(掘金、csdn)可以授权微信、QQ登陆 服务目录：相当于通讯录，即要访问openstack的镜像、网络、存储等服务，只需要找到keystone即可，而不需要再单独记住各个服务的访问地址 后续每安装一个服务都需要在keystone上注册 3.1 创建keystone数据库并授权 #用以下命令操作 mysql -e \"CREATE DATABASE keystone;\" mysql -e \"GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'localhost' \\ IDENTIFIED BY 'KEYSTONE_DBPASS';\" mysql -e \"GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'%' \\ IDENTIFIED BY 'KEYSTONE_DBPASS';\" 3.2 安装和配置keystron keystone借助apache访问 mod_wsgi是帮助apache连接python程序 监听端口 5000 3.2.1 安装软件包 yum -y install openstack-keystone httpd mod_wsgi openstack-utils.noarch 3.2.2 编辑文件/etc/keystone/keystone.conf 并完成如下操作 在 [database] 部分，配置数据库访问： [root@controller ~]# vim /etc/keystone/keystone.conf [database] connection = mysql+pymysql://keystone:KEYSTONE_DBPASS@controller/keystone 在[token]部分，配置Fernet UUID令牌的提供者 [token] provider = fernet #用以下命令修改 \\cp /etc/keystone/keystone.conf{,.bak} grep -Ev '^$|#' /etc/keystone/keystone.conf.bak >/etc/keystone/keystone.conf openstack-config --set /etc/keystone/keystone.conf database connection mysql+pymysql://keystone:KEYSTONE_DBPASS@controller/keystone openstack-config --set /etc/keystone/keystone.conf token provider fernet MD5值 md5sum /etc/keystone/keystone.conf 3fb8c44724c573eb69394a876cf7da56 /etc/keystone/keystone.conf 3.2.3 初始化身份认证服务的数据库 命令的含义是切换到keystone用户，使用的shell是/bin/sh，执行 -c后的命令 su -s /bin/sh -c \"keystone-manage db_sync\" keystone #上一步操作为导入表，以下命令执行返回有表即为正确 mysql keystone -e \"show tables;\"|wc -l 45 3.2.4 初始化Fernet key keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone keystone-manage credential_setup --keystone-user keystone --keystone-group keystone 3.2.5 引导身份服务 keystone-manage bootstrap --bootstrap-password ADMIN_PASS \\ --bootstrap-admin-url http://controller:5000/v3/ \\ --bootstrap-internal-url http://controller:5000/v3/ \\ --bootstrap-public-url http://controller:5000/v3/ \\ --bootstrap-region-id RegionOne 3.2.6 配置Apache服务器 编辑/etc/httpd/conf/httpd.conf文件，配置ServerName 选项为控制节点 1.96行下入以下一行 ServerName controller #用以下命令修改 sed -i.bak '96cServerName controller' /etc/httpd/conf/httpd.conf MD5值 md5sum /etc/httpd/conf/httpd.conf eaf0e2ae3fea84bac3e5a842f64bdfdb /etc/httpd/conf/httpd.conf 2.创建一个软连接 ln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/ 3.2.7 启动apache并设置为开机自启 systemctl enable httpd && systemctl start httpd 3.2.8 配置管理账户 以下为创建管理员账户admin，密码为ADMIN_PASS export OS_USERNAME=admin export OS_PASSWORD=ADMIN_PASS export OS_PROJECT_NAME=admin export OS_USER_DOMAIN_NAME=Default export OS_PROJECT_DOMAIN_NAME=Default export OS_AUTH_URL=http://controller:5000/v3 export OS_IDENTITY_API_VERSION=3 3.3 创建域、项目、用户和角色 3.3.1 创建一个域 openstack domain create --description \"An Example Domain\" example +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | An Example Domain | | enabled | True | | id | ab6f853144384043a5dd648c154d0efe | | name | example | | tags | [] | +-------------+----------------------------------+ 3.3.2 创建一个服务项目 #service，后期用于关联openstack系统用户glance、nova、neutron openstack project create --domain default \\ --description \"Service Project\" service +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Service Project | | domain_id | default | | enabled | True | | id | f6696bc9511043ae9ec72d1c31a494f3 | | is_domain | False | | name | service | | parent_id | default | | tags | [] | +-------------+----------------------------------+ 3.3.3 常规（非管理员）任务应使用无特权的项目和用户 例如，本指南创建myproject项目和myuser 用户 1.创建myproject项目 openstack project create --domain default \\ --description \"Demo Project\" myproject +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Demo Project | | domain_id | default | | enabled | True | | id | 5b9ccd294c364cc68747df85f9598c89 | | is_domain | False | | name | myproject | | parent_id | default | | tags | [] | +-------------+----------------------------------+ 2.创建myuser用户 //这里交互式和非交互式选择其中一种 #非交互式设置密码 openstack user create --domain default \\ --password MYUSER_PASS myuser +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | domain_id | default | | enabled | True | | id | f7985ae93ad24f7784a5ea3e1f22109a | | name | myuser | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ #交互式设置密码 openstack user create --domain default \\ --password-prompt myuser 3.创建myrole角色 openstack role create myrole +-----------+----------------------------------+ | Field | Value | +-----------+----------------------------------+ | domain_id | None | | id | 9cb289f07a6d4bd6898dd863d616b164 | | name | myrole | +-----------+----------------------------------+ 4.将myrole角色添加到myproject项目和myuser用户 openstack role add --project myproject --user myuser myrole 3.3.4 验证 1.取消设置临时 变量OS_AUTH_URL和OS_PASSWORD环境变量 unset OS_AUTH_URL OS_PASSWORD 2.以admin用户身份请求身份验证令牌 密码是ADMIN_PASS openstack --os-auth-url http://controller:5000/v3 \\ --os-project-domain-name Default --os-user-domain-name Default \\ --os-project-name admin --os-username admin token issue Password: +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | expires | 2020-05-25T09:12:07+0000 | | id | gAAAAABey33Xe4qJjpsA6SSva-ciwawHI6MKrQSn8aP2t1Ja1FOLpBgo31TILIK0hOiC8aP7ql2MrDq6lO-OwwRn91DJGT0KIhfueV-mrEm1zXJfn8a_yL9c01QGi4E5qr6kPatZdsKIN1Q0McDvg5VaCf1S5cj7uB1amz0am2si8YIIpnkYiyU | | project_id | 108d3fecb61840e3818f694c69c3ec4a | | user_id | a0d3db84d1984a24ac6ba213525fe382 | +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ 3.作为myuser上一节中创建的用户，请请求认证令牌 密码是MYUSER_PASS openstack --os-auth-url http://controller:5000/v3 \\ --os-project-domain-name Default --os-user-domain-name Default \\ --os-project-name myproject --os-username myuser token issue +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | expires | 2020-05-25T09:15:01+0000 | | id | gAAAAABey36FhKplKdFCDOIszVcq_eGC-W3Eel33l7wS9-dGfEn4G9F19k9fAClAjiZ9hmQ8BdlglHPDDfxqq8uZkDIdlQK8DctC9kipXLfxuRI9J0lB9MTrsfEMiIMRW9J6DFvAQiVUPEuTmL7vRLyRNH7ORHEgS9ly043SNFzMW-ZZQHSiFUI | | project_id | 5b9ccd294c364cc68747df85f9598c89 | | user_id | be0d4d9c8c56450ea9fcc5c85f3b232b | +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ 3.4 创建OpenStack客户端环境脚本 3.4.1 创建脚本 创建和编辑admin-openrc文件并添加以下内容，这里放在/opt下 cat >/opt/admin-openrc 创建和编辑demo-openrc文件并添加以下内容 cat >/opt/demo-openrc 3.4.2 使用脚本 1.加载admin-openrc文件以使用身份服务的位置以及admin项目和用户凭据填充环境变量 source /opt/admin-openrc 2.请求身份验证令牌（注意expires中是UTC时间，落后中国8个小时，我国是东八区，使用timedatectl查看时间及时区，默认过期时间1小时） openstack token issue +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | expires | 2020-05-25T09:22:49+0000 | | id | gAAAAABey4BZ8Fmp0STtrCrdAMyjJ0lXWDavMSRTBHFmJ6aS5cYMhpMhE4wtJlm3dhUFGeCW7_g7BIu5o0f4z0KlmPi6IAya_eOC96ofqFPeYIDJL2O0qlSgzcALavYt6ZqP0thedY_69q-XMd4X9SC9UcptM4Hnn4RO9rWb9c0wymhsrKdXb7g | | project_id | 108d3fecb61840e3818f694c69c3ec4a | | user_id | a0d3db84d1984a24ac6ba213525fe382 | +------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ 到此，控制节点认证服务keystone安装完成！！！ 四、控制节点镜像服务glance安装 rocky版镜像服务glance安装配置官方文档 OpenStack镜像服务包括以下组件： glance-api 接收镜像API的调用，诸如镜像发现、恢复、存储 glance-registry 存储、处理和恢复镜像的元数据(属性)，元数据包括项诸如大小和类型 glance服务监听两个端口 glance-api 9292 glance-registry 9191 4.1 创建glance数据库并授权 #用以下命令修改 mysql -e \"CREATE DATABASE glance;\" mysql -e \"GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'localhost' \\ IDENTIFIED BY 'GLANCE_DBPASS';\" mysql -e \"GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'%' \\ IDENTIFIED BY 'GLANCE_DBPASS';\" 4.2 获取管理员凭据以获取对仅管理员CLI命令的访问 source /opt/admin-openrc 4.3 创建服务凭据 4.3.1 创建glance用户，密码设置为GLANCE_PASS //这里交互式创建密码和非交互式选择其中一种 #非交互式设置密码 openstack user create --domain default --password GLANCE_PASS glance +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | domain_id | default | | enabled | True | | id | ed462c214a1d4cb485cc4dc5211c4dd4 | | name | glance | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ #交互式设置密码 openstack user create --domain default --password-prompt glance 4.3.2 将admin角色添加到glance用户和 service项目 openstack role add --project service --user glance admin 4.3.3 创建glance服务实体 openstack service create --name glance \\ --description \"OpenStack Image\" image +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Image | | enabled | True | | id | ce5a424428d640c9adec06865d211916 | | name | glance | | type | image | +-------------+----------------------------------+ 4.3.4 创建Image服务API端点 openstack endpoint create --region RegionOne \\ image public http://controller:9292 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | bed29b8924114eee8b427f7a83f2cd64 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | ce5a424428d640c9adec06865d211916 | | service_name | glance | | service_type | image | | url | http://controller:9292 | +--------------+----------------------------------+ openstack endpoint create --region RegionOne \\ image internal http://controller:9292 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 94f84d946e6f4463af82041caf2877b5 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | ce5a424428d640c9adec06865d211916 | | service_name | glance | | service_type | image | | url | http://controller:9292 | +--------------+----------------------------------+ openstack endpoint create --region RegionOne \\ image admin http://controller:9292 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 16e947838d7948e6a0ec7feb7910b415 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | ce5a424428d640c9adec06865d211916 | | service_name | glance | | service_type | image | | url | http://controller:9292 | +--------------+----------------------------------+ 删除API端点使用命令openstack endpoint delete 使用命令openstack endpoint list查看endpoint-id然后根据id删除 4.4 安装和配置组件 4.4.1 安装软件包 yum -y install openstack-glance 4.4.2 编辑/etc/glance/glance-api.conf文件并完成以下操作 1.在该[database]部分中，配置数据库访问 [database] # ... connection = mysql+pymysql://glance:GLANCE_DBPASS@controller/glance 2.在[keystone_authtoken]和[paste_deploy]部分中，配置身份服务访问 [keystone_authtoken] # ... www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = Default user_domain_name = Default project_name = service username = glance password = GLANCE_PASS [paste_deploy] # ... flavor = keystone 3.在该[glance_store]部分中，配置本地文件系统存储和图像文件的位置 [glance_store] # ... stores = file,http default_store = file filesystem_store_datadir = /var/lib/glance/images/ #用以下命令修改 \\cp /etc/glance/glance-api.conf{,.bak} grep '^[a-Z\\[]' /etc/glance/glance-api.conf.bak >/etc/glance/glance-api.conf openstack-config --set /etc/glance/glance-api.conf database connection mysql+pymysql://glance:GLANCE_DBPASS@controller/glance openstack-config --set /etc/glance/glance-api.conf keystone_authtoken www_authenticate_uri http://controller:5000 openstack-config --set /etc/glance/glance-api.conf keystone_authtoken auth_url http://controller:5000 openstack-config --set /etc/glance/glance-api.conf keystone_authtoken memcached_servers controller:11211 openstack-config --set /etc/glance/glance-api.conf keystone_authtoken auth_type password openstack-config --set /etc/glance/glance-api.conf keystone_authtoken project_domain_name Default openstack-config --set /etc/glance/glance-api.conf keystone_authtoken user_domain_name Default openstack-config --set /etc/glance/glance-api.conf keystone_authtoken project_name service openstack-config --set /etc/glance/glance-api.conf keystone_authtoken username glance openstack-config --set /etc/glance/glance-api.conf keystone_authtoken password GLANCE_PASS openstack-config --set /etc/glance/glance-api.conf paste_deploy flavor keystone openstack-config --set /etc/glance/glance-api.conf glance_store stores file,http openstack-config --set /etc/glance/glance-api.conf glance_store default_store file openstack-config --set /etc/glance/glance-api.conf glance_store filesystem_store_datadir /var/lib/glance/images/ MD5值 md5sum /etc/glance/glance-api.conf 53b17f4f4eeb358fbf0bac47a7eed6a6 /etc/glance/glance-api.conf 4.4.3 编辑/etc/glance/glance-registry.conf文件并完成以下操作 1.在该[database]部分中，配置数据库访问 [database] # ... connection = mysql+pymysql://glance:GLANCE_DBPASS@controller/glance 2.在[keystone_authtoken]和[paste_deploy]部分中，配置身份服务访问 [keystone_authtoken] # ... www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = Default user_domain_name = Default project_name = service username = glance password = GLANCE_PASS [paste_deploy] # ... flavor = keystone #用以下命令修改 \\cp /etc/glance/glance-registry.conf{,.bak} grep '^[a-Z\\[]' /etc/glance/glance-registry.conf.bak > /etc/glance/glance-registry.conf openstack-config --set /etc/glance/glance-registry.conf database connection mysql+pymysql://glance:GLANCE_DBPASS@controller/glance openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken www_authenticate_uri http://controller:5000 openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken auth_url http://controller:5000 openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken memcached_servers controller:11211 openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken auth_type password openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken project_domain_name Default openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken user_domain_name Default openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken project_name service openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken username glance openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken password GLANCE_PASS openstack-config --set /etc/glance/glance-registry.conf paste_deploy flavor keystone MD5值 md5sum /etc/glance/glance-registry.conf 888d847475b8c7f6e2c790fed853fb61 /etc/glance/glance-registry.conf 4.4.4 同步数据库 注意：忽略此输出中的任何弃用消息 $ su -s /bin/sh -c \"glance-manage db_sync\" glance /usr/lib/python2.7/site-packages/oslo_db/sqlalchemy/enginefacade.py:1352: OsloDBDeprecationWarning: EngineFacade is deprecated; please use oslo_db.sqlalchemy.enginefacade expire_on_commit=expire_on_commit, _conf=conf) INFO [alembic.runtime.migration] Context impl MySQLImpl. INFO [alembic.runtime.migration] Will assume non-transactional DDL. INFO [alembic.runtime.migration] Running upgrade -> liberty, liberty initial INFO [alembic.runtime.migration] Running upgrade liberty -> mitaka01, add index on created_at and updated_at columns of 'images' table INFO [alembic.runtime.migration] Running upgrade mitaka01 -> mitaka02, update metadef os_nova_server INFO [alembic.runtime.migration] Running upgrade mitaka02 -> ocata_expand01, add visibility to images INFO [alembic.runtime.migration] Running upgrade ocata_expand01 -> pike_expand01, empty expand for symmetry with pike_contract01 INFO [alembic.runtime.migration] Running upgrade pike_expand01 -> queens_expand01 INFO [alembic.runtime.migration] Running upgrade queens_expand01 -> rocky_expand01, add os_hidden column to images table INFO [alembic.runtime.migration] Running upgrade rocky_expand01 -> rocky_expand02, add os_hash_algo and os_hash_value columns to images table INFO [alembic.runtime.migration] Context impl MySQLImpl. INFO [alembic.runtime.migration] Will assume non-transactional DDL. Upgraded database to: rocky_expand02, current revision(s): rocky_expand02 INFO [alembic.runtime.migration] Context impl MySQLImpl. INFO [alembic.runtime.migration] Will assume non-transactional DDL. INFO [alembic.runtime.migration] Context impl MySQLImpl. INFO [alembic.runtime.migration] Will assume non-transactional DDL. Database migration is up to date. No migration needed. INFO [alembic.runtime.migration] Context impl MySQLImpl. INFO [alembic.runtime.migration] Will assume non-transactional DDL. INFO [alembic.runtime.migration] Context impl MySQLImpl. INFO [alembic.runtime.migration] Will assume non-transactional DDL. INFO [alembic.runtime.migration] Running upgrade mitaka02 -> ocata_contract01, remove is_public from images INFO [alembic.runtime.migration] Running upgrade ocata_contract01 -> pike_contract01, drop glare artifacts tables INFO [alembic.runtime.migration] Running upgrade pike_contract01 -> queens_contract01 INFO [alembic.runtime.migration] Running upgrade queens_contract01 -> rocky_contract01 INFO [alembic.runtime.migration] Running upgrade rocky_contract01 -> rocky_contract02 INFO [alembic.runtime.migration] Context impl MySQLImpl. INFO [alembic.runtime.migration] Will assume non-transactional DDL. Upgraded database to: rocky_contract02, current revision(s): rocky_contract02 INFO [alembic.runtime.migration] Context impl MySQLImpl. INFO [alembic.runtime.migration] Will assume non-transactional DDL. Database is synced successfully. #有表即为正确 mysql glance -e \"show tables;\" | wc -l 16 4.4.5 启动glance服务并设置为开机自启（glance-api和glance-registry） systemctl enable openstack-glance-api openstack-glance-registry systemctl start openstack-glance-api openstack-glance-registry 4.4.6 验证操作 1.获取管理员凭据以获取对仅管理员CLI命令的访问权限 source /opt/admin-openrc 2.下载源镜像 wget http://download.cirros-cloud.net/0.4.0/cirros-0.4.0-x86_64-disk.img 3.使用QCOW2磁盘格式，裸容器格式和公共可见性将映像上载到映像服务 ，以便所有项目都可以访问它 注意：这一步一定要看执行后输出结果中size大小，如果为0则说明镜像上载有问题 openstack image create \"cirros\" \\ --file cirros-0.4.0-x86_64-disk.img \\ --disk-format qcow2 --container-format bare \\ --public +------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | checksum | 443b7623e27ecf03dc9e01ee93f67afe | | container_format | bare | | created_at | 2020-05-25T10:49:34Z | | disk_format | qcow2 | | file | /v2/images/94c96aab-d0b3-4340-835c-9a97108d0554/file | | id | 94c96aab-d0b3-4340-835c-9a97108d0554 | | min_disk | 0 | | min_ram | 0 | | name | cirros | | owner | 108d3fecb61840e3818f694c69c3ec4a | | properties | os_hash_algo='sha512', os_hash_value='6513f21e44aa3da349f248188a44bc304a3653a04122d8fb4535423c8e1d14cd6a153f735bb0982e2161b5b5186106570c17a9e58b64dd39390617cd5a350f78', os_hidden='False' | | protected | False | | schema | /v2/schemas/image | | size | 12716032 | | status | active | | tags | | | updated_at | 2020-05-25T10:49:34Z | | virtual_size | None | | visibility | public | +------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ 删除镜像使用命令glance image-delete 镜像id 4.4.7 确认上传图像并验证属性 openstack image list +--------------------------------------+--------+--------+ | ID | Name | Status | +--------------------------------------+--------+--------+ | 94c96aab-d0b3-4340-835c-9a97108d0554 | cirros | active | +--------------------------------------+--------+--------+ 到此，控制节点镜像服务glance安装完成！！！ 五、控制节点和计算节点计算服务nova安装 nova相关服务 服务名称 作用 nova-api 接受并响应最终用户的计算API调用。该服务支持OpenStack Compute API。它执行一些策略并启动大多数编排活动，例如运行实例 nova-api-metadata 接受来自实例的元数据请求。nova-api-metadata当您在nova-network 安装时以多主机模式运行时，通常会使用该服务 nova-compute 通过守护程序API创建和终止虚拟机实例的辅助程序守护程序 nova-placement-api 跟踪每个提供商的库存和使用情况 nova-scheduler 从队列中获取虚拟机实例请求，并确定它在哪台计算服务器主机上运行 nova-conductor 调解nova计算服务和数据库之间的交互。它消除了nova计算服务对云数据库的直接访问。nova导体模块水平伸缩。但是，不要在nova计算服务运行的节点上部署它 nova-consoleauth 为控制台代理提供的用户授权令牌。请参阅 nova-novncproxy和nova-xvpvncproxy。该服务必须正在运行，控制台代理才能起作用。您可以在集群配置中针对单个nova-consoleauth服务运行这两种类型的代理 rocky版不推荐使用，并且以后会删除 nova-novncproxy 提供用于通过VNC连接访问正在运行的实例的代理。支持基于浏览器的novnc客户端。 nova-spicehtml5proxy 提供用于通过SPICE连接访问正在运行的实例的代理。支持基于浏览器的HTML5客户端。 nova-xvpvncproxy 提供用于通过VNC连接访问正在运行的实例的代理。支持特定于OpenStack的Java客户端。 安装和配置控制节点 rocky版控制节点计算服务nova安装配置官方文档 5.1 创建nova、nova_api、nova_cell0、placement数据库并授权 #用以下命令 mysql -e \"CREATE DATABASE nova_api;\" mysql -e \"CREATE DATABASE nova;\" mysql -e \"CREATE DATABASE nova_cell0;\" mysql -e \"CREATE DATABASE placement;\" mysql -e \"GRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'localhost' \\ IDENTIFIED BY 'NOVA_DBPASS';\" mysql -e \"GRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'%' \\ IDENTIFIED BY 'NOVA_DBPASS';\" mysql -e \"GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'localhost' \\ IDENTIFIED BY 'NOVA_DBPASS';\" mysql -e \"GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'%' \\ IDENTIFIED BY 'NOVA_DBPASS';\" mysql -e \"GRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'localhost' \\ IDENTIFIED BY 'NOVA_DBPASS';\" mysql -e \"GRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'%' \\ IDENTIFIED BY 'NOVA_DBPASS';\" mysql -e \"GRANT ALL PRIVILEGES ON placement.* TO 'placement'@'localhost' \\ IDENTIFIED BY 'PLACEMENT_DBPASS';\" mysql -e \"GRANT ALL PRIVILEGES ON placement.* TO 'placement'@'%' \\ IDENTIFIED BY 'PLACEMENT_DBPASS';\" 5.2 获取管理员凭据以获取对仅管理员CLI命令的访问权限 source /opt/admin-openrc 5.3 创建计算服务凭据 5.3.1 创建nova用户，密码设置为NOVA_PASS //这里交互式创建密码和非交互式选择其中一种 #非交互式创建密码 openstack user create --domain default \\ --password NOVA_PASS nova +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | domain_id | default | | enabled | True | | id | ebe9b1934a2e4c8ca9c177af647851b1 | | name | nova | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ #交互式创建密码 openstack user create --domain default --password-prompt nova 5.3.2 将admin角色添加到nova用户 openstack role add --project service --user nova admin 5.3.3 创建nova服务实体 openstack service create --name nova \\ --description \"OpenStack Compute\" compute +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Compute | | enabled | True | | id | 412f485718f44759b6c3cd46b1d624e6 | | name | nova | | type | compute | +-------------+----------------------------------+ 5.3.4 创建Compute API服务端点 openstack endpoint create --region RegionOne \\ compute public http://controller:8774/v2.1 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | cc0a7c21acd0450998760841dd9a11c0 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 412f485718f44759b6c3cd46b1d624e6 | | service_name | nova | | service_type | compute | | url | http://controller:8774/v2.1 | +--------------+----------------------------------+ openstack endpoint create --region RegionOne \\ compute internal http://controller:8774/v2.1 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 69acbdd4f0114a339f8b62d9118ce137 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 412f485718f44759b6c3cd46b1d624e6 | | service_name | nova | | service_type | compute | | url | http://controller:8774/v2.1 | +--------------+----------------------------------+ openstack endpoint create --region RegionOne \\ compute admin http://controller:8774/v2.1 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 5382d617406a4dba8280dc375dd53329 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 412f485718f44759b6c3cd46b1d624e6 | | service_name | nova | | service_type | compute | | url | http://controller:8774/v2.1 | +--------------+----------------------------------+ 5.3.5 创建展示位置服务用户PLACEMENT，密码设置为PLACEMENT_PASS //这里交互式创建密码和非交互式选择其中一种 #非交互式创建密码 openstack user create --domain default --password PLACEMENT_PASS placement +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | domain_id | default | | enabled | True | | id | 5ab24083149e4adf978c43439b87c982 | | name | placement | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ #交互式创建密码 openstack user create --domain default --password-prompt placement 5.3.6 使用管理员角色将Placement用户添加到服务项目中 openstack role add --project service --user placement admin 5.3.7 在服务目录中创建Placement API条目 openstack service create --name placement \\ --description \"Placement API\" placement +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Placement API | | enabled | True | | id | 274104c9a16f4b728bd7f484d3c54d3e | | name | placement | | type | placement | +-------------+----------------------------------+ 5.3.8 创建Placement API服务端点 openstack endpoint create --region RegionOne \\ placement public http://controller:8778 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | c3afd275f71a4406a701d16ad24aa325 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 274104c9a16f4b728bd7f484d3c54d3e | | service_name | placement | | service_type | placement | | url | http://controller:8778 | +--------------+----------------------------------+ openstack endpoint create --region RegionOne \\ placement internal http://controller:8778 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 2ddc86a3b46d45489ebbedbd54fc3c0c | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 274104c9a16f4b728bd7f484d3c54d3e | | service_name | placement | | service_type | placement | | url | http://controller:8778 | +--------------+----------------------------------+ openstack endpoint create --region RegionOne \\ placement admin http://controller:8778 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | d0714a417aa44c0180d59be843e1d40d | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 274104c9a16f4b728bd7f484d3c54d3e | | service_name | placement | | service_type | placement | | url | http://controller:8778 | +--------------+----------------------------------+ 5.4 安装和配置组件 5.4.1 安装软件包 yum -y install openstack-nova-api openstack-nova-conductor \\ openstack-nova-console openstack-nova-novncproxy \\ openstack-nova-scheduler openstack-nova-placement-api 5.4.2 编辑/etc/nova/nova.conf文件并完成以下操作 1.在此[DEFAULT]部分中，仅启用计算和元数据API [DEFAULT] # ... enabled_apis = osapi_compute,metadata 2.在[api_database]，[database]和[placement_database] 部分，配置数据库访问 [api_database] # ... connection = mysql+pymysql://nova:NOVA_DBPASS@controller/nova_api [database] # ... connection = mysql+pymysql://nova:NOVA_DBPASS@controller/nova [placement_database] # ... connection = mysql+pymysql://placement:PLACEMENT_DBPASS@controller/placement 3.在该[DEFAULT]部分中，配置RabbitMQ消息队列访问 [DEFAULT] # ... transport_url = rabbit://openstack:RABBIT_PASS@controller 4.在[api]和[keystone_authtoken]部分中，配置身份服务访问 [api] # ... auth_strategy = keystone [keystone_authtoken] # ... auth_url = http://controller:5000/v3 memcached_servers = controller:11211 auth_type = password project_domain_name = Default user_domain_name = Default project_name = service username = nova password = NOVA_PASS 5.在该[DEFAULT]部分中，配置my_ip选项以使用控制器节点的管理接口IP地址 [DEFAULT] # ... my_ip = 10.0.0.11 6.在本[DEFAULT]节中，启用对网络服务的支持 [DEFAULT] # ... use_neutron = true firewall_driver = nova.virt.firewall.NoopFirewallDriver 默认情况下，Compute使用内部防火墙驱动程序。由于网络服务包含防火墙驱动程序，因此必须使用nova.virt.firewall.NoopFirewallDriver防火墙驱动程序禁用计算防火墙驱动 程序 7.在该[vnc]部分中，将VNC代理配置为使用控制器节点的管理接口IP地址 [vnc] enabled = true # ... server_listen = $my_ip server_proxyclient_address = $my_ip 8.在该[glance]部分中，配置图像服务API的位置 [glance] # ... api_servers = http://controller:9292 9.在该[oslo_concurrency]部分中，配置锁定路径 [oslo_concurrency] # ... lock_path = /var/lib/nova/tmp 10.在该[placement]部分中，配置Placement API [placement] # ... region_name = RegionOne project_domain_name = Default project_name = service auth_type = password user_domain_name = Default auth_url = http://controller:5000/v3 username = placement password = PLACEMENT_PASS #用以下命令修改 \\cp /etc/nova/nova.conf{,.bak} grep '^[a-Z\\[]' /etc/nova/nova.conf.bak >/etc/nova/nova.conf openstack-config --set /etc/nova/nova.conf DEFAULT enabled_apis osapi_compute,metadata openstack-config --set /etc/nova/nova.conf DEFAULT transport_url rabbit://openstack:RABBIT_PASS@controller openstack-config --set /etc/nova/nova.conf DEFAULT my_ip 10.0.0.11 openstack-config --set /etc/nova/nova.conf DEFAULT use_neutron true openstack-config --set /etc/nova/nova.conf DEFAULT firewall_driver nova.virt.firewall.NoopFirewallDriver openstack-config --set /etc/nova/nova.conf api_database connection mysql+pymysql://nova:NOVA_DBPASS@controller/nova_api openstack-config --set /etc/nova/nova.conf database connection mysql+pymysql://nova:NOVA_DBPASS@controller/nova openstack-config --set /etc/nova/nova.conf placement_database connection mysql+pymysql://placement:PLACEMENT_DBPASS@controller/placement openstack-config --set /etc/nova/nova.conf api auth_strategy keystone openstack-config --set /etc/nova/nova.conf keystone_authtoken auth_url http://controller:5000/v3 openstack-config --set /etc/nova/nova.conf keystone_authtoken memcached_servers controller:11211 openstack-config --set /etc/nova/nova.conf keystone_authtoken auth_type password openstack-config --set /etc/nova/nova.conf keystone_authtoken project_domain_name Default openstack-config --set /etc/nova/nova.conf keystone_authtoken user_domain_name Default openstack-config --set /etc/nova/nova.conf keystone_authtoken project_name service openstack-config --set /etc/nova/nova.conf keystone_authtoken username nova openstack-config --set /etc/nova/nova.conf keystone_authtoken password NOVA_PASS openstack-config --set /etc/nova/nova.conf vnc enabled true openstack-config --set /etc/nova/nova.conf vnc server_listen '$my_ip' openstack-config --set /etc/nova/nova.conf vnc server_proxyclient_address '$my_ip' openstack-config --set /etc/nova/nova.conf glance api_servers http://controller:9292 openstack-config --set /etc/nova/nova.conf oslo_concurrency lock_path /var/lib/nova/tmp openstack-config --set /etc/nova/nova.conf placement region_name RegionOne openstack-config --set /etc/nova/nova.conf placement project_domain_name Default openstack-config --set /etc/nova/nova.conf placement project_name service openstack-config --set /etc/nova/nova.conf placement auth_type password openstack-config --set /etc/nova/nova.conf placement user_domain_name Default openstack-config --set /etc/nova/nova.conf placement auth_url http://controller:5000/v3 openstack-config --set /etc/nova/nova.conf placement username placement openstack-config --set /etc/nova/nova.conf placement password PLACEMENT_PASS MD5值 md5sum /etc/nova/nova.conf 6b2990f21ec6a41a4c33f2a25686a44e /etc/nova/nova.conf 5.4.3 由于包装错误，您必须通过将以下配置添加到来启用对Placement API的访问 /etc/httpd/conf.d/00-nova-placement-api.conf 1.备份文件并追加内容 \\cp /etc/httpd/conf.d/00-nova-placement-api.conf{,.bak} 2.注意要添加一行空行，否则格式会有错误(这里添加了两行空行，其中第一行是为了格式正确，第二行是为了格式规范，即标签与标签之间有一行空行) cat >> /etc/httpd/conf.d/00-nova-placement-api.conf = 2.4> Require all granted Order allow,deny Allow from all EOF MD5值 md5sum /etc/httpd/conf.d/00-nova-placement-api.conf 4b31341049e863449951b0c76fe17bde /etc/httpd/conf.d/00-nova-placement-api.conf 3.重启httpd systemctl restart httpd 5.4.3 同步数据库，忽略输出 #同步nova-api和placement数据库 $ su -s /bin/sh -c \"nova-manage api_db sync\" nova #注册cell0数据库 $ su -s /bin/sh -c \"nova-manage cell_v2 map_cell0\" nova #创建cell1单元格 $ su -s /bin/sh -c \"nova-manage cell_v2 create_cell --name=cell1 --verbose\" nova 536383cb-03e4-48bb-bb77-4eeb1bfb9d80 #同步nova数据库 $ su -s /bin/sh -c \"nova-manage db sync\" nova /usr/lib/python2.7/site-packages/pymysql/cursors.py:170: Warning: (1831, u'Duplicate index `block_device_mapping_instance_uuid_virtual_name_device_name_idx`. This is deprecated and will be disallowed in a future release.') result = self._query(query) /usr/lib/python2.7/site-packages/pymysql/cursors.py:170: Warning: (1831, u'Duplicate index `uniq_instances0uuid`. This is deprecated and will be disallowed in a future release.') result = self._query(query) #验证nova cell0和cell1是否正确注册 $ su -s /bin/sh -c \"nova-manage cell_v2 list_cells\" nova +-------+--------------------------------------+------------------------------------+-------------------------------------------------+----------+ | Name | UUID | Transport URL | Database Connection | Disabled | +-------+--------------------------------------+------------------------------------+-------------------------------------------------+----------+ | cell0 | 00000000-0000-0000-0000-000000000000 | none:/ | mysql+pymysql://nova:****@controller/nova_cell0 | False | | cell1 | 536383cb-03e4-48bb-bb77-4eeb1bfb9d80 | rabbit://openstack:****@controller | mysql+pymysql://nova:****@controller/nova | False | +-------+--------------------------------------+------------------------------------+-------------------------------------------------+----------+ 5.4.4 启动Compute服务并将其配置为在系统引导时启动 nova-consoleauth自18.0.0（Rocky）起不推荐使用，并将在以后的版本中删除。每个单元应部署控制台代理。如果执行全新安装（而非升级），则可能不需要安装nova-consoleauth 服务。有关workarounds.enable_consoleauth详细信息，请参见 。 systemctl enable openstack-nova-api.service \\ openstack-nova-consoleauth openstack-nova-scheduler.service \\ openstack-nova-conductor.service openstack-nova-novncproxy.service systemctl start openstack-nova-api.service \\ openstack-nova-consoleauth openstack-nova-scheduler.service \\ openstack-nova-conductor.service openstack-nova-novncproxy.service 安装完成后会有no VNC 10.0.0.11:6080 安装和配置计算节点 rocky版计算节点计算服务nova安装配置官方文档 5.5 安装和配置组件 5.5.1 安装软件包 yum -y install openstack-nova-compute openstack-utils 5.5.2 编辑/etc/nova/nova.conf文件并完成以下操作 1.在此[DEFAULT]部分中，仅启用计算和元数据API [DEFAULT] # ... enabled_apis = osapi_compute,metadata 2.在该[DEFAULT]部分中，配置RabbitMQ消息队列访问： [DEFAULT] # ... transport_url = rabbit://openstack:RABBIT_PASS@controller 3.在[api]和[keystone_authtoken]部分中，配置身份服务访问： [api] # ... auth_strategy = keystone [keystone_authtoken] # ... auth_url = http://controller:5000/v3 memcached_servers = controller:11211 auth_type = password project_domain_name = Default user_domain_name = Default project_name = service username = nova password = NOVA_PASS 4.在该[DEFAULT]部分中，配置my_ip选项：MANAGEMENT_INTERFACE_IP_ADDRESS为计算节点上管理网络接口的IP地址 my_ip = MANAGEMENT_INTERFACE_IP_ADDRESS [DEFAULT] # ... my_ip = 10.0.0.31 5.在本[DEFAULT]节中，启用对网络服务的支持： [DEFAULT] # ... use_neutron = true firewall_driver = nova.virt.firewall.NoopFirewallDriver 6.在本[DEFAULT]节中，启用对网络服务的支持： [DEFAULT] # ... use_neutron = true firewall_driver = nova.virt.firewall.NoopFirewallDriver 7.在该[vnc]部分中，启用和配置远程控制台访问： [vnc] # ... enabled = true server_listen = 0.0.0.0 server_proxyclient_address = $my_ip novncproxy_base_url = http://controller:6080/vnc_auto.html 8.在该[glance]部分中，配置图像服务API的位置： [glance] # ... api_servers = http://controller:9292 9.在该[oslo_concurrency]部分中，配置锁定路径： [oslo_concurrency] # ... lock_path = /var/lib/nova/tmp 10.在该[placement]部分中，配置Placement API： [placement] # ... region_name = RegionOne project_domain_name = Default project_name = service auth_type = password user_domain_name = Default auth_url = http://controller:5000/v3 username = placement password = PLACEMENT_PASS #用以下命令修改 \\cp /etc/nova/nova.conf{,.bak} grep '^[a-Z\\[]' /etc/nova/nova.conf.bak >/etc/nova/nova.conf openstack-config --set /etc/nova/nova.conf DEFAULT enabled_apis osapi_compute,metadata openstack-config --set /etc/nova/nova.conf DEFAULT transport_url rabbit://openstack:RABBIT_PASS@controller openstack-config --set /etc/nova/nova.conf DEFAULT my_ip 10.0.0.31 openstack-config --set /etc/nova/nova.conf DEFAULT use_neutron true openstack-config --set /etc/nova/nova.conf DEFAULT firewall_driver nova.virt.firewall.NoopFirewallDriver openstack-config --set /etc/nova/nova.conf api auth_strategy keystone openstack-config --set /etc/nova/nova.conf keystone_authtoken auth_url http://controller:5000/v3 openstack-config --set /etc/nova/nova.conf keystone_authtoken memcached_servers controller:11211 openstack-config --set /etc/nova/nova.conf keystone_authtoken auth_type password openstack-config --set /etc/nova/nova.conf keystone_authtoken project_domain_name Default openstack-config --set /etc/nova/nova.conf keystone_authtoken user_domain_name Default openstack-config --set /etc/nova/nova.conf keystone_authtoken project_name service openstack-config --set /etc/nova/nova.conf keystone_authtoken username nova openstack-config --set /etc/nova/nova.conf keystone_authtoken password NOVA_PASS openstack-config --set /etc/nova/nova.conf vnc enabled true openstack-config --set /etc/nova/nova.conf vnc server_listen 0.0.0.0 openstack-config --set /etc/nova/nova.conf vnc server_proxyclient_address '$my_ip' openstack-config --set /etc/nova/nova.conf vnc novncproxy_base_url http://controller:6080/vnc_auto.html openstack-config --set /etc/nova/nova.conf glance api_servers http://controller:9292 openstack-config --set /etc/nova/nova.conf oslo_concurrency lock_path /var/lib/nova/tmp openstack-config --set /etc/nova/nova.conf placement region_name RegionOne openstack-config --set /etc/nova/nova.conf placement project_domain_name Default openstack-config --set /etc/nova/nova.conf placement project_name service openstack-config --set /etc/nova/nova.conf placement auth_type password openstack-config --set /etc/nova/nova.conf placement user_domain_name Default openstack-config --set /etc/nova/nova.conf placement auth_url http://controller:5000/v3 openstack-config --set /etc/nova/nova.conf placement username placement openstack-config --set /etc/nova/nova.conf placement password PLACEMENT_PASS MD5值 md5sum /etc/nova/nova.conf ab7abb82433ee2a9f2381aa10018590a /etc/nova/nova.conf 5.5.3 确定您的计算节点是否支持虚拟机的硬件加速 $ egrep -c '(vmx|svm)' /proc/cpuinfo 2 #说明 如果此命令返回值1或更大，则计算节点支持硬件加速，通常不需要其他配置。 如果此命令返回零值，则计算节点不支持硬件加速，您必须将libvirt配置为使用QEMU而不是KVM。 编辑/etc/nova/nova.conf文件中的[libvirt]部分， 如下所示： [libvirt] ...... virt_type = qemu 5.5.4 启动Compute服务及其依赖项，并将它们配置为在系统引导时自动启动 systemctl enable libvirtd.service openstack-nova-compute.service systemctl start libvirtd.service openstack-nova-compute.service 验证操作，在控制节点执行 5.6 验证Compute服务的运行 5.6.1 获取管理员凭据以获取对仅管理员CLI命令的访问权限 source /opt/admin-openrc 5.6.2 列出服务组件以验证每个进程的成功启动和注册 openstack compute service list --service nova-compute +----+--------------+----------+------+---------+-------+----------------------------+ | ID | Binary | Host | Zone | Status | State | Updated At | +----+--------------+----------+------+---------+-------+----------------------------+ | 9 | nova-compute | compute1 | nova | enabled | up | 2020-05-25T23:37:57.000000 | +----+--------------+----------+------+---------+-------+----------------------------+ 5.6.3 发现计算主机 $ su -s /bin/sh -c \"nova-manage cell_v2 discover_hosts --verbose\" nova Found 2 cell mappings. Skipping cell0 since it does not contain hosts. Getting computes from cell 'cell1': 536383cb-03e4-48bb-bb77-4eeb1bfb9d80 Checking host mapping for compute host 'compute1': 83452da0-a693-4860-bcd8-028743169f0f Creating host mapping for compute host 'compute1': 83452da0-a693-4860-bcd8-028743169f0f Found 1 unmapped computes in cell: 536383cb-03e4-48bb-bb77-4eeb1bfb9d80 到此，控制节点和计算节点计算服务nova安装完成！！！ 六、控制节点、计算节点网络服务neutron安装 neutron相关服务 服务名 说明 neutron-server 端口(9696) api 接受和响应外部的网络管理请求 neutron-linuxbridge-agent 负责创建桥接网卡 neutron-dhcp-agent 负责分配IP neutron-metadata-agent 配合nova-metadata-api实现虚拟机的定制化操作 L3-agent 实现三层网络(网络层) 安装和配置控制节点 rocky版控制节点网络服务neutron安装配置官方文档 6.1 创建neutron数据库并授权 #用以下命令 mysql -e \"CREATE DATABASE neutron;\" mysql -e \"GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'localhost' \\ IDENTIFIED BY 'NEUTRON_DBPASS';\" mysql -e \"GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'%' \\ IDENTIFIED BY 'NEUTRON_DBPASS';\" 6.2 获取管理员凭据以获取对仅管理员CLI命令的访问权限 source /opt/admin-openrc 6.3 创建服务凭证 6.3.1 创建neutron用户，密码设置为NEUTRON_PASS //这里交互式创建密码和非交互式选择其中一种 #非交互式创建密码 openstack user create --domain default --password NEUTRON_PASS neutron +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | domain_id | default | | enabled | True | | id | 014a7629fb0548899be31c87494e1156 | | name | neutron | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ #交互式创建密码 openstack user create --domain default --password-prompt neutron 6.3.2 将admin角色添加到neutron用户 openstack role add --project service --user neutron admin 6.3.3 创建neutron服务实体 openstack service create --name neutron \\ --description \"OpenStack Networking\" network +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Networking | | enabled | True | | id | 9e74ccbdaa85421894cf61c97f355dc7 | | name | neutron | | type | network | +-------------+----------------------------------+ 6.4 创建网络服务API端点 openstack endpoint create --region RegionOne \\ network public http://controller:9696 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | abe8c37741934ade89308da46501ea03 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 9e74ccbdaa85421894cf61c97f355dc7 | | service_name | neutron | | service_type | network | | url | http://controller:9696 | +--------------+----------------------------------+ openstack endpoint create --region RegionOne \\ network internal http://controller:9696 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 0c32f6cb44a74ec5b653ba79153e3d68 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 9e74ccbdaa85421894cf61c97f355dc7 | | service_name | neutron | | service_type | network | | url | http://controller:9696 | +--------------+----------------------------------+ openstack endpoint create --region RegionOne \\ network admin http://controller:9696 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | d2c77ff079c94591bc8ea0b4e51be936 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 9e74ccbdaa85421894cf61c97f355dc7 | | service_name | neutron | | service_type | network | | url | http://controller:9696 | +--------------+----------------------------------+ 6.5 配置网络选项，控制节点操作 官网关于两种网络的说明 您可以使用选项1和2表示的两种体系结构之一来部署网络服务。 选项1部署了最简单的架构，该架构仅支持将实例附加到提供程序（外部）网络。没有自助服务（专用）网络，路由器或浮动IP地址。只有admin或其他特权用户可以管理提供商网络。 选项2通过支持将实例附加到自助服务网络的第3层服务增强了选项1。该demo非特权用户或其他非特权用户可以管理自助服务网络，包括在自助服务网络与提供商网络之间提供连接的路由器。此外，浮动IP地址使用自助服务网络从外部网络（例如Internet）提供到实例的连接。 自助服务网络通常使用覆盖网络。诸如VXLAN之类的覆盖网络协议包括其他标头，这些标头增加了开销并减少了可用于有效负载或用户数据的空间。在不了解虚拟网络基础结构的情况下，实例尝试使用默认的1500字节以太网最大传输单元（MTU）发送数据包。网络服务会通过DHCP自动为实例提供正确的MTU值。但是，某些云映像不使用DHCP或忽略DHCP MTU选项，而是需要使用元数据或脚本进行配置。 网络选项1:提供商网络 网络选项2:自助服务网络 以上两种网络任选一种完成后返回这里配置元数据代理 这里选择网路选项1 6.5.1 安装软件包 yum -y install openstack-neutron openstack-neutron-ml2 \\ openstack-neutron-linuxbridge ebtables 6.5.2 配置服务器组件 编辑/etc/neutron/neutron.conf文件并完成以下操作 1.在该[database]部分中，配置数据库访问 [database] # ... connection = mysql+pymysql://neutron:NEUTRON_DBPASS@controller/neutron 2.在该[DEFAULT]部分中，启用模块化第2层（ML2）插件并禁用其他插件： [DEFAULT] # ... core_plugin = ml2 service_plugins = 3.在该[DEFAULT]部分中，配置RabbitMQ 消息队列访问： [DEFAULT] # ... transport_url = rabbit://openstack:RABBIT_PASS@controller 4.在[DEFAULT]和[keystone_authtoken]部分中，配置身份服务访问 [DEFAULT] # ... auth_strategy = keystone [keystone_authtoken] # ... www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = NEUTRON_PASS 5.在[DEFAULT]和[nova]部分中，将网络配置为通知Compute网络拓扑更改 [DEFAULT] # ... notify_nova_on_port_status_changes = true notify_nova_on_port_data_changes = true [nova] # ... auth_url = http://controller:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = nova password = NOVA_PASS 6.在该[oslo_concurrency]部分中，配置锁定路径 [oslo_concurrency] # ... lock_path = /var/lib/neutron/tmp #用以下命令修改 \\cp /etc/neutron/neutron.conf{,.bak} grep '^[a-Z\\[]' /etc/neutron/neutron.conf.bak >/etc/neutron/neutron.conf openstack-config --set /etc/neutron/neutron.conf database connection mysql+pymysql://neutron:NEUTRON_DBPASS@controller/neutron openstack-config --set /etc/neutron/neutron.conf DEFAULT core_plugin ml2 openstack-config --set /etc/neutron/neutron.conf DEFAULT service_plugins openstack-config --set /etc/neutron/neutron.conf DEFAULT transport_url rabbit://openstack:RABBIT_PASS@controller openstack-config --set /etc/neutron/neutron.conf DEFAULT auth_strategy keystone openstack-config --set /etc/neutron/neutron.conf DEFAULT notify_nova_on_port_status_changes true openstack-config --set /etc/neutron/neutron.conf DEFAULT notify_nova_on_port_data_changes true openstack-config --set /etc/neutron/neutron.conf keystone_authtoken www_authenticate_uri http://controller:5000 openstack-config --set /etc/neutron/neutron.conf keystone_authtoken www_authenticate_uri http://controller:5000 openstack-config --set /etc/neutron/neutron.conf keystone_authtoken auth_url http://controller:5000 openstack-config --set /etc/neutron/neutron.conf keystone_authtoken memcached_servers controller:11211 openstack-config --set /etc/neutron/neutron.conf keystone_authtoken auth_type password openstack-config --set /etc/neutron/neutron.conf keystone_authtoken project_domain_name default openstack-config --set /etc/neutron/neutron.conf keystone_authtoken user_domain_name default openstack-config --set /etc/neutron/neutron.conf keystone_authtoken project_name service openstack-config --set /etc/neutron/neutron.conf keystone_authtoken username neutron openstack-config --set /etc/neutron/neutron.conf keystone_authtoken password NEUTRON_PASS openstack-config --set /etc/neutron/neutron.conf nova auth_url http://controller:5000 openstack-config --set /etc/neutron/neutron.conf nova auth_type password openstack-config --set /etc/neutron/neutron.conf nova project_domain_name default openstack-config --set /etc/neutron/neutron.conf nova user_domain_name default openstack-config --set /etc/neutron/neutron.conf nova region_name RegionOne openstack-config --set /etc/neutron/neutron.conf nova project_name service openstack-config --set /etc/neutron/neutron.conf nova username nova openstack-config --set /etc/neutron/neutron.conf nova password NOVA_PASS openstack-config --set /etc/neutron/neutron.conf oslo_concurrency lock_path /var/lib/neutron/tmp MD5值 md5sum /etc/neutron/neutron.conf 1c4b4339f83596fa6bfdbec7a622a35e /etc/neutron/neutron.conf 6.6 配置模块化第2层（ML2）插件 ML2插件使用Linux桥接机制为实例构建第2层（桥接和交换）虚拟网络基础架构 编辑/etc/neutron/plugins/ml2/ml2_conf.ini文件并完成以下操作 1.在本[ml2]节中，启用平面和VLAN网络 [ml2] # ... type_drivers = flat,vlan 2.在该[ml2]部分中，禁用自助服务网络： [ml2] # ... tenant_network_types = 3.在本[ml2]节中，启用Linux桥接机制： [ml2] # ... mechanism_drivers = linuxbridge 4.在此[ml2]部分中，启用端口安全扩展驱动程序： [ml2] # ... extension_drivers = port_security 5.在本[ml2_type_flat]节中，将提供者虚拟网络配置为平面网络： [ml2_type_flat] # ... flat_networks = provider 6.在本[securitygroup]节中，启用ipset以提高安全组规则的效率： [securitygroup] # ... enable_ipset = true #用以下命令修改 \\cp /etc/neutron/plugins/ml2/ml2_conf.ini{,.bak} grep '^[a-Z\\[]' /etc/neutron/plugins/ml2/ml2_conf.ini.bak >/etc/neutron/plugins/ml2/ml2_conf.ini openstack-config --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2 type_drivers flat,vlan openstack-config --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2 tenant_network_types openstack-config --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2 mechanism_drivers linuxbridge openstack-config --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2 extension_drivers port_security openstack-config --set /etc/neutron/plugins/ml2/ml2_conf.ini ml2_type_flat flat_networks provider openstack-config --set /etc/neutron/plugins/ml2/ml2_conf.ini securitygroup enable_ipset true MD5值 md5sum /etc/neutron/plugins/ml2/ml2_conf.ini eb38c10cfd26c1cc308a050c9a5d8aa1 /etc/neutron/plugins/ml2/ml2_conf.ini 6.7 配置linux桥接代理 Linux网桥代理为实例构建第2层（桥接和交换）虚拟网络基础架构并处理安全组 编辑/etc/neutron/plugins/ml2/linuxbridge_agent.ini文件并完成以下操作 1.在本[linux_bridge]节中，将提供者虚拟网络映射到提供者物理网络接口： [linux_bridge] physical_interface_mappings = provider:PROVIDER_INTERFACE_NAME 替换PROVIDER_INTERFACE_NAME为基础提供商物理网络接口的名称。这里是eth0 2.在该[vxlan]部分中，禁用VXLAN覆盖网络： [vxlan] enable_vxlan = false 3.在该[securitygroup]部分中，启用安全组并配置Linux网桥iptables防火墙驱动程序： [securitygroup] # ... enable_security_group = true firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver 通过验证以下所有sysctl值是否设置为确保Linux操作系统内核支持网桥过滤器1： net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables 要启用网络桥接器支持，通常br_netfilter需要加载内核模块。查看操作系统的文档，以获取有关启用此模块的其他详细信息。 #用以下命令修改 \\cp /etc/neutron/plugins/ml2/linuxbridge_agent.ini{,.bak} grep '^[a-Z\\[]' /etc/neutron/plugins/ml2/linuxbridge_agent.ini.bak >/etc/neutron/plugins/ml2/linuxbridge_agent.ini openstack-config --set /etc/neutron/plugins/ml2/linuxbridge_agent.ini linux_bridge physical_interface_mappings provider:eth0 openstack-config --set /etc/neutron/plugins/ml2/linuxbridge_agent.ini vxlan enable_vxlan false openstack-config --set /etc/neutron/plugins/ml2/linuxbridge_agent.ini securitygroup enable_security_group true openstack-config --set /etc/neutron/plugins/ml2/linuxbridge_agent.ini securitygroup firewall_driver neutron.agent.linux.iptables_firewall.IptablesFirewallDriver MD5值 md5sum /etc/neutron/plugins/ml2/linuxbridge_agent.ini 794b19995c83e2fc0c3fd42f506904f1 /etc/neutron/plugins/ml2/linuxbridge_agent.ini 使Linux操作系统内核支持网桥过滤器1 #向/etc/sysctl.d/openstack-rocky-bridge.conf写入以下内容 cat >> /etc/sysctl.d/openstack-rocky-bridge.conf 6.8 配置DHCP代理 DHCP代理为虚拟网络提供DHCP服务 编辑/etc/neutron/dhcp_agent.ini文件并完成以下操作 在本[DEFAULT]节中，配置Linux桥接口驱动程序Dnsmasq DHCP驱动程序，并启用隔离的元数据，以便提供商网络上的实例可以通过网络访问元数据 [DEFAULT] # ... interface_driver = linuxbridge dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq enable_isolated_metadata = true #用以下命令修改 \\cp /etc/neutron/dhcp_agent.ini{,.bak} grep '^[a-Z\\[]' /etc/neutron/dhcp_agent.ini.bak >/etc/neutron/dhcp_agent.ini openstack-config --set /etc/neutron/dhcp_agent.ini DEFAULT interface_driver linuxbridge openstack-config --set /etc/neutron/dhcp_agent.ini DEFAULT dhcp_driver neutron.agent.linux.dhcp.Dnsmasq openstack-config --set /etc/neutron/dhcp_agent.ini DEFAULT enable_isolated_metadata true MD5值 md5sum /etc/neutron/dhcp_agent.ini 33a1e93e1853796070d5da0773496665 /etc/neutron/dhcp_agent.ini 6.9 配置元数据代理 所述元数据代理提供配置信息的诸如凭据实例。 编辑/etc/neutron/metadata_agent.ini文件并完成以下操作 在该[DEFAULT]部分中，配置元数据主机和共享机密： [DEFAULT] # ... nova_metadata_host = controller metadata_proxy_shared_secret = METADATA_SECRET 替换METADATA_SECRET为元数据代理的适当机密 #用以下领命修改 \\cp /etc/neutron/metadata_agent.ini{,.bak} grep '^[a-Z\\[]' /etc/neutron/metadata_agent.ini.bak >/etc/neutron/metadata_agent.ini openstack-config --set /etc/neutron/metadata_agent.ini DEFAULT nova_metadata_host controller openstack-config --set /etc/neutron/metadata_agent.ini DEFAULT metadata_proxy_shared_secret METADATA_SECRET MD5值 md5sum /etc/neutron/metadata_agent.ini e8b90a011b94fece31d33edfd8bc72b6 /etc/neutron/metadata_agent.ini 6.10 配置计算以使用网络 编辑/etc/nova/nova.conf文件并执行以下操作 在该[neutron]部分中，配置访问参数，启用元数据代理，并配置机密： [neutron] # ... url = http://controller:9696 auth_url = http://controller:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = NEUTRON_PASS service_metadata_proxy = true metadata_proxy_shared_secret = METADATA_SECRET #用以下命令修改 openstack-config --set /etc/nova/nova.conf neutron url http://controller:9696 openstack-config --set /etc/nova/nova.conf neutron auth_url http://controller:5000 openstack-config --set /etc/nova/nova.conf neutron auth_type password openstack-config --set /etc/nova/nova.conf neutron project_domain_name default openstack-config --set /etc/nova/nova.conf neutron user_domain_name default openstack-config --set /etc/nova/nova.conf neutron region_name RegionOne openstack-config --set /etc/nova/nova.conf neutron project_name service openstack-config --set /etc/nova/nova.conf neutron username neutron openstack-config --set /etc/nova/nova.conf neutron password NEUTRON_PASS openstack-config --set /etc/nova/nova.conf neutron service_metadata_proxy true openstack-config --set /etc/nova/nova.conf neutron metadata_proxy_shared_secret METADATA_SECRET MD5值 md5sum /etc/nova/nova.conf 81feca9d18ee91397cc973d455bfa271 /etc/nova/nova.conf 6.11 完成安装 6.11.1 网络服务初始化脚本需要/etc/neutron/plugin.ini指向ML2插件配置文件的符号链接 /etc/neutron/plugins/ml2/ml2_conf.ini。如果此符号链接不存在，请使用以下命令创建它 ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini 6.11.2 同步数据库，最后提示OK即为正确 su -s /bin/sh -c \"neutron-db-manage --config-file /etc/neutron/neutron.conf \\ --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head\" neutron 6.11.3 重新启动Compute API服务 systemctl restart openstack-nova-api.service 6.11.4 启动网络服务并将其配置为在系统引导时启动 对于官网中的两种网络，这里选择的是第一种网络 #启动网络服务并设置开机自启 systemctl enable neutron-server.service \\ neutron-linuxbridge-agent.service neutron-dhcp-agent.service \\ neutron-metadata-agent.service systemctl start neutron-server.service \\ neutron-linuxbridge-agent.service neutron-dhcp-agent.service \\ neutron-metadata-agent.service 6.11.5 验证 #启动服务后提示如下即为正确，alive处都为笑脸 $ neutron agent-list neutron CLI is deprecated and will be removed in the future. Use openstack CLI instead. +--------------------------------------+--------------------+------------+-------------------+-------+----------------+---------------------------+ | id | agent_type | host | availability_zone | alive | admin_state_up | binary | +--------------------------------------+--------------------+------------+-------------------+-------+----------------+---------------------------+ | beffcac6-745e-449f-bad8-7f2e4fa973f2 | Linux bridge agent | controller | | :-) | True | neutron-linuxbridge-agent | +--------------------------------------+--------------------+------------+-------------------+-------+----------------+---------------------------+ 安装和配置计算节点 rocky版计算节点网络服务neutron安装配置官方文档 6.12 安装包 yum -y install openstack-neutron-linuxbridge ebtables ipset openstack-utils 6.13 配置公共组件 编辑/etc/neutron/neutron.conf文件并完成以下操作 1.在该[DEFAULT]部分中，配置RabbitMQ 消息队列访问： [DEFAULT] # ... transport_url = rabbit://openstack:RABBIT_PASS@controller 2.在[DEFAULT]和[keystone_authtoken]部分中，配置身份服务访问： [DEFAULT] # ... auth_strategy = keystone [keystone_authtoken] # ... www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = NEUTRON_PASS 3.在该[oslo_concurrency]部分中，配置锁定路径： [oslo_concurrency] # ... lock_path = /var/lib/neutron/tmp #用以下命令修改 \\cp /etc/neutron/neutron.conf{,.bak} grep '^[a-Z\\[]' /etc/neutron/neutron.conf.bak >/etc/neutron/neutron.conf openstack-config --set /etc/neutron/neutron.conf DEFAULT transport_url rabbit://openstack:RABBIT_PASS@controller openstack-config --set /etc/neutron/neutron.conf DEFAULT auth_strategy keystone openstack-config --set /etc/neutron/neutron.conf keystone_authtoken www_authenticate_uri http://controller:5000 openstack-config --set /etc/neutron/neutron.conf keystone_authtoken auth_url http://controller:5000 openstack-config --set /etc/neutron/neutron.conf keystone_authtoken memcached_servers controller:11211 openstack-config --set /etc/neutron/neutron.conf keystone_authtoken auth_type password openstack-config --set /etc/neutron/neutron.conf keystone_authtoken project_domain_name default openstack-config --set /etc/neutron/neutron.conf keystone_authtoken user_domain_name default openstack-config --set /etc/neutron/neutron.conf keystone_authtoken project_name service openstack-config --set /etc/neutron/neutron.conf keystone_authtoken username neutron openstack-config --set /etc/neutron/neutron.conf keystone_authtoken password NEUTRON_PASS openstack-config --set /etc/neutron/neutron.conf oslo_concurrency lock_path /var/lib/neutron/tmp MD5值 md5sum /etc/neutron/neutron.conf 9c47ffb59b23516b59e7de84a39bcbe8 /etc/neutron/neutron.conf 6.14 配置网络选项 6.14.1 配置桥接代理 Linux网桥代理为实例构建第2层（桥接和交换）虚拟网络基础结构并处理安全组 编辑/etc/neutron/plugins/ml2/linuxbridge_agent.ini文件并完成以下操作 1.在本[linux_bridge]节中，将提供者虚拟网络映射到提供者物理网络接口： [linux_bridge] physical_interface_mappings = provider:PROVIDER_INTERFACE_NAME 替换PROVIDER_INTERFACE_NAME为基础提供商物理网络接口的名称。这里为eth0 2.在该[vxlan]部分中，禁用VXLAN覆盖网络： [vxlan] enable_vxlan = false 3.在该[securitygroup]部分中，启用安全组并配置Linux网桥iptables防火墙驱动程序： [securitygroup] # ... enable_security_group = true firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver #用以下命令修改 \\cp /etc/neutron/plugins/ml2/linuxbridge_agent.ini{,.bak} grep '^[a-Z\\[]' /etc/neutron/plugins/ml2/linuxbridge_agent.ini.bak >/etc/neutron/plugins/ml2/linuxbridge_agent.ini openstack-config --set /etc/neutron/plugins/ml2/linuxbridge_agent.ini linux_bridge physical_interface_mappings provider:eth0 openstack-config --set /etc/neutron/plugins/ml2/linuxbridge_agent.ini vxlan enable_vxlan false openstack-config --set /etc/neutron/plugins/ml2/linuxbridge_agent.ini securitygroup enable_security_group true openstack-config --set /etc/neutron/plugins/ml2/linuxbridge_agent.ini securitygroup firewall_driver neutron.agent.linux.iptables_firewall.IptablesFirewallDriver MD5值 md5sum /etc/neutron/plugins/ml2/linuxbridge_agent.ini 794b19995c83e2fc0c3fd42f506904f1 /etc/neutron/plugins/ml2/linuxbridge_agent.ini 使Linux操作系统内核支持网桥过滤器1 #向/etc/sysctl.d/openstack-rocky-bridge.conf写入以下内容 cat >> /etc/sysctl.d/openstack-rocky-bridge.conf 6.14.2 配置计算以使用网络 编辑/etc/nova/nova.conf文件并完成以下操作 在该[neutron]部分中，配置访问参数： [neutron] # ... url = http://controller:9696 auth_url = http://controller:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = NEUTRON_PASS #用以下命令修改 openstack-config --set /etc/nova/nova.conf neutron url http://controller:9696 openstack-config --set /etc/nova/nova.conf neutron auth_url http://controller:5000 openstack-config --set /etc/nova/nova.conf neutron auth_type password openstack-config --set /etc/nova/nova.conf neutron project_domain_name default openstack-config --set /etc/nova/nova.conf neutron user_domain_name default openstack-config --set /etc/nova/nova.conf neutron region_name RegionOne openstack-config --set /etc/nova/nova.conf neutron project_name service openstack-config --set /etc/nova/nova.conf neutron username neutron openstack-config --set /etc/nova/nova.conf neutron password NEUTRON_PASS MD5值 md5sum /etc/nova/nova.conf 9b96b21ae709f89c96cc559018ba7058 /etc/nova/nova.conf 6.15 完成安装 6.15.1 重新启动Compute服务 systemctl restart openstack-nova-compute.service 6.15.2 启动Linux网桥代理并将其配置为在系统引导时启动 systemctl enable neutron-linuxbridge-agent.service systemctl start neutron-linuxbridge-agent.service 6.16 验证 控制节点执行 输出应指示控制器节点上的三个代理，每个计算节点上的一个代理 openstack network agent list +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | ID | Agent Type | Host | Availability Zone | Alive | State | Binary | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | 42cfe05b-0a9c-40ce-8f99-06ba76938c50 | Linux bridge agent | controller | None | :-) | UP | neutron-linuxbridge-agent | | 749cb43f-a5db-4918-a3f5-8765e92e851c | DHCP agent | controller | nova | :-) | UP | neutron-dhcp-agent | | 856ecf5f-6018-4ac4-a66b-f6f88784db0e | Metadata agent | controller | None | :-) | UP | neutron-metadata-agent | | b5c2309c-fefc-46d0-b98e-37b05861095c | Linux bridge agent | compute1 | None | :-) | UP | neutron-linuxbridge-agent | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ 到此，控制节点、计算节点网络服务neutron安装完成！！！ 七、控制节点horizon web界面Dashboard安装 rocky版控制节点horizon web节点dashboard安装配置官方文档 horizon插件注册表官方文档 7.1 安装包 yum -y install openstack-dashboard 7.2 编辑/etc/openstack-dashboard/local_settings文件并完成以下操作 ⚠️因为有一些内容是删除之后粘贴的，所以一些行数并不是很准确，但是行数误差不超过3行 1.配置仪表板以在controller节点上使用OpenStack服务 ： 184行 OPENSTACK_HOST = \"127.0.0.1\" 修改为 OPENSTACK_HOST = \"controller\" 2.允许主机访问仪表板： ALLOWED_HOSTS也可以是['*']以接受所有主机。这对于开发工作可能有用，但是可能不安全，因此不应在生产中使用。有关 更多信息，请参见 https://docs.djangoproject.com/en/dev/ref/settings/#allowed-hosts。 38行 ALLOWED_HOSTS = ['one.example.com', 'two.example.com'] 修改为 ALLOWED_HOSTS = ['*', ] 3.配置memcached会话存储服务： 161行，CACHES上加一行 SESSION_ENGINE，并且修改为如下内容 SESSION_ENGINE = 'django.contrib.sessions.backends.cache' CACHES = { 'default': { 'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache', 'LOCATION': 'controller:11211', } } 4.启用身份API版本3： 187行，不用修改 OPENSTACK_KEYSTONE_URL = \"http://%s:5000/v3\" % OPENSTACK_HOST 5.启用对域的支持： 75行 #OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = False 修改为 OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = True 6.配置API版本： 64行，原先为注释， #OPENSTACK_API_VERSIONS = { # \"data-processing\": 1.1, # \"identity\": 3, # \"image\": 2, # \"volume\": 2, # \"compute\": 2, #} 修改为如下 OPENSTACK_API_VERSIONS = { \"identity\": 3, \"image\": 2, \"volume\": 2, } 7.配置Default为通过仪表板创建的用户的默认域： 95行 #OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = 'Default' 修改为 OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = \"Default\" 8.配置user为通过仪表板创建的用户的默认角色： 186行 OPENSTACK_KEYSTONE_DEFAULT_ROLE = \"_member_\" 修改为 OPENSTACK_KEYSTONE_DEFAULT_ROLE = \"user\" 9.如果选择网络选项1，请禁用对第3层网络服务的支持： 324行 OPENSTACK_NEUTRON_NETWORK = { 'enable_router': True, 'enable_quotas': True, 'enable_ipv6': True, 'enable_distributed_router': False, 'enable_ha_router': False, 'enable_fip_topology_check': True, 修改为如下 OPENSTACK_NEUTRON_NETWORK = { 'enable_router': False, 'enable_quotas': False, 'enable_distributed_router': False, 'enable_ha_router': False, 'enable_lb': False, 'enable_firewall': False, 'enable_vpn': False, 'enable_fip_topology_check': False, 10.配置时区： 467行 TIME_ZONE = \"TIME_ZONE\" 修改为 TIME_ZONE = \"Asia/Shanghai\" 备份一下文件 \\cp /etc/openstack-dashboard/local_settings{,.bak} 采用cat EOF方式可能会有格式问题，因为文件内容太多了，这里必须使用vi打开文件然后复制粘贴内容，不能使用vim会有格式错误 /etc/openstack-dashboard/local_settings文件内容 # -*- coding: utf-8 -*- import os from django.utils.translation import ugettext_lazy as _ from openstack_dashboard.settings import HORIZON_CONFIG DEBUG = False # This setting controls whether or not compression is enabled. Disabling # compression makes Horizon considerably slower, but makes it much easier # to debug JS and CSS changes #COMPRESS_ENABLED = not DEBUG # This setting controls whether compression happens on the fly, or offline # with `python manage.py compress` # See https://django-compressor.readthedocs.io/en/latest/usage/#offline-compression # for more information #COMPRESS_OFFLINE = not DEBUG # WEBROOT is the location relative to Webserver root # should end with a slash. WEBROOT = '/dashboard/' #LOGIN_URL = WEBROOT + 'auth/login/' #LOGOUT_URL = WEBROOT + 'auth/logout/' # # LOGIN_REDIRECT_URL can be used as an alternative for # HORIZON_CONFIG.user_home, if user_home is not set. # Do not set it to '/home/', as this will cause circular redirect loop #LOGIN_REDIRECT_URL = WEBROOT # If horizon is running in production (DEBUG is False), set this # with the list of host/domain names that the application can serve. # For more information see: # https://docs.djangoproject.com/en/dev/ref/settings/#allowed-hosts ALLOWED_HOSTS = ['*', ] # Set SSL proxy settings: # Pass this header from the proxy after terminating the SSL, # and don't forget to strip it from the client's request. # For more information see: # https://docs.djangoproject.com/en/dev/ref/settings/#secure-proxy-ssl-header #SECURE_PROXY_SSL_HEADER = ('HTTP_X_FORWARDED_PROTO', 'https') # If Horizon is being served through SSL, then uncomment the following two # settings to better secure the cookies from security exploits #CSRF_COOKIE_SECURE = True #SESSION_COOKIE_SECURE = True # The absolute path to the directory where message files are collected. # The message file must have a .json file extension. When the user logins to # horizon, the message files collected are processed and displayed to the user. #MESSAGES_PATH=None # Overrides for OpenStack API versions. Use this setting to force the # OpenStack dashboard to use a specific API version for a given service API. # Versions specified here should be integers or floats, not strings. # NOTE: The version should be formatted as it appears in the URL for the # service API. For example, The identity service APIs have inconsistent # use of the decimal point, so valid options would be 2.0 or 3. # Minimum compute version to get the instance locked status is 2.9. OPENSTACK_API_VERSIONS = { \"identity\": 3, \"image\": 2, \"volume\": 2, } # Set this to True if running on a multi-domain model. When this is enabled, it # will require the user to enter the Domain name in addition to the username # for login. OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = True # Set this to True if you want available domains displayed as a dropdown menu # on the login screen. It is strongly advised NOT to enable this for public # clouds, as advertising enabled domains to unauthenticated customers # irresponsibly exposes private information. This should only be used for # private clouds where the dashboard sits behind a corporate firewall. #OPENSTACK_KEYSTONE_DOMAIN_DROPDOWN = False # If OPENSTACK_KEYSTONE_DOMAIN_DROPDOWN is enabled, this option can be used to # set the available domains to choose from. This is a list of pairs whose first # value is the domain name and the second is the display name. #OPENSTACK_KEYSTONE_DOMAIN_CHOICES = ( # ('Default', 'Default'), #) # Overrides the default domain used when running on single-domain model # with Keystone V3. All entities will be created in the default domain. # NOTE: This value must be the name of the default domain, NOT the ID. # Also, you will most likely have a value in the keystone policy file like this # \"cloud_admin\": \"rule:admin_required and domain_id:\" # This value must be the name of the domain whose ID is specified there. OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = 'Default' # Set this to True to enable panels that provide the ability for users to # manage Identity Providers (IdPs) and establish a set of rules to map # federation protocol attributes to Identity API attributes. # This extension requires v3.0+ of the Identity API. #OPENSTACK_KEYSTONE_FEDERATION_MANAGEMENT = False # Set Console type: # valid options are \"AUTO\"(default), \"VNC\", \"SPICE\", \"RDP\", \"SERIAL\", \"MKS\" # or None. Set to None explicitly if you want to deactivate the console. #CONSOLE_TYPE = \"AUTO\" # Toggle showing the openrc file for Keystone V2. # If set to false the link will be removed from the user dropdown menu # and the API Access page #SHOW_KEYSTONE_V2_RC = True # If provided, a \"Report Bug\" link will be displayed in the site header # which links to the value of this setting (ideally a URL containing # information on how to report issues). #HORIZON_CONFIG[\"bug_url\"] = \"http://bug-report.example.com\" # Show backdrop element outside the modal, do not close the modal # after clicking on backdrop. #HORIZON_CONFIG[\"modal_backdrop\"] = \"static\" # Specify a regular expression to validate user passwords. #HORIZON_CONFIG[\"password_validator\"] = { # \"regex\": '.*', # \"help_text\": _(\"Your password does not meet the requirements.\"), #} # Turn off browser autocompletion for forms including the login form and # the database creation workflow if so desired. #HORIZON_CONFIG[\"password_autocomplete\"] = \"off\" # Setting this to True will disable the reveal button for password fields, # including on the login form. #HORIZON_CONFIG[\"disable_password_reveal\"] = False LOCAL_PATH = '/tmp' # Set custom secret key: # You can either set it to a specific value or you can let horizon generate a # default secret key that is unique on this machine, e.i. regardless of the # amount of Python WSGI workers (if used behind Apache+mod_wsgi): However, # there may be situations where you would want to set this explicitly, e.g. # when multiple dashboard instances are distributed on different machines # (usually behind a load-balancer). Either you have to make sure that a session # gets all requests routed to the same dashboard instance or you set the same # SECRET_KEY for all of them. SECRET_KEY='f9ed41e34c2b04178998' # We recommend you use memcached for development; otherwise after every reload # of the django development server, you will have to login again. To use # memcached set CACHES to something like #CACHES = { # 'default': { # 'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache', # 'LOCATION': '127.0.0.1:11211', # }, #} SESSION_ENGINE = 'django.contrib.sessions.backends.cache' CACHES = { 'default': { 'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache', 'LOCATION': 'controller:11211', } } # Send email to the console by default EMAIL_BACKEND = 'django.core.mail.backends.console.EmailBackend' # Or send them to /dev/null #EMAIL_BACKEND = 'django.core.mail.backends.dummy.EmailBackend' # Configure these for your outgoing email host #EMAIL_HOST = 'smtp.my-company.com' #EMAIL_PORT = 25 #EMAIL_HOST_USER = 'djangomail' #EMAIL_HOST_PASSWORD = 'top-secret!' # For multiple regions uncomment this configuration, and add (endpoint, title). #AVAILABLE_REGIONS = [ # ('http://cluster1.example.com:5000/v3', 'cluster1'), # ('http://cluster2.example.com:5000/v3', 'cluster2'), #] OPENSTACK_HOST = \"controller\" OPENSTACK_KEYSTONE_URL = \"http://%s:5000/v3\" % OPENSTACK_HOST OPENSTACK_KEYSTONE_DEFAULT_ROLE = \"user\" # For setting the default service region on a per-endpoint basis. Note that the # default value for this setting is {}, and below is just an example of how it # should be specified. # A key of '*' is an optional global default if no other key matches. #DEFAULT_SERVICE_REGIONS = { # '*': 'RegionOne' # OPENSTACK_KEYSTONE_URL: 'RegionTwo' #} # Enables keystone web single-sign-on if set to True. #WEBSSO_ENABLED = False # Authentication mechanism to be selected as default. # The value must be a key from WEBSSO_CHOICES. #WEBSSO_INITIAL_CHOICE = \"credentials\" # The list of authentication mechanisms which include keystone # federation protocols and identity provider/federation protocol # mapping keys (WEBSSO_IDP_MAPPING). Current supported protocol # IDs are 'saml2' and 'oidc' which represent SAML 2.0, OpenID # Connect respectively. # Do not remove the mandatory credentials mechanism. # Note: The last two tuples are sample mapping keys to a identity provider # and federation protocol combination (WEBSSO_IDP_MAPPING). #WEBSSO_CHOICES = ( # (\"credentials\", _(\"Keystone Credentials\")), # (\"oidc\", _(\"OpenID Connect\")), # (\"saml2\", _(\"Security Assertion Markup Language\")), # (\"acme_oidc\", \"ACME - OpenID Connect\"), # (\"acme_saml2\", \"ACME - SAML2\"), #) # A dictionary of specific identity provider and federation protocol # combinations. From the selected authentication mechanism, the value # will be looked up as keys in the dictionary. If a match is found, # it will redirect the user to a identity provider and federation protocol # specific WebSSO endpoint in keystone, otherwise it will use the value # as the protocol_id when redirecting to the WebSSO by protocol endpoint. # NOTE: The value is expected to be a tuple formatted as: (, ). #WEBSSO_IDP_MAPPING = { # \"acme_oidc\": (\"acme\", \"oidc\"), # \"acme_saml2\": (\"acme\", \"saml2\"), #} # If set this URL will be used for web single-sign-on authentication # instead of OPENSTACK_KEYSTONE_URL. This is needed in the deployment # scenarios where network segmentation is used per security requirement. # In this case, the controllers are not reachable from public network. # Therefore, user's browser will not be able to access OPENSTACK_KEYSTONE_URL # if it is set to the internal endpoint. #WEBSSO_KEYSTONE_URL = \"http://keystone-public.example.com/v3\" # The Keystone Provider drop down uses Keystone to Keystone federation # to switch between Keystone service providers. # Set display name for Identity Provider (dropdown display name) #KEYSTONE_PROVIDER_IDP_NAME = \"Local Keystone\" # This id is used for only for comparison with the service provider IDs. This ID # should not match any service provider IDs. #KEYSTONE_PROVIDER_IDP_ID = \"localkeystone\" # Disable SSL certificate checks (useful for self-signed certificates): #OPENSTACK_SSL_NO_VERIFY = True # The CA certificate to use to verify SSL connections #OPENSTACK_SSL_CACERT = '/path/to/cacert.pem' # The OPENSTACK_KEYSTONE_BACKEND settings can be used to identify the # capabilities of the auth backend for Keystone. # If Keystone has been configured to use LDAP as the auth backend then set # can_edit_user to False and name to 'ldap'. # # TODO(tres): Remove these once Keystone has an API to identify auth backend. OPENSTACK_KEYSTONE_BACKEND = { 'name': 'native', 'can_edit_user': True, 'can_edit_group': True, 'can_edit_project': True, 'can_edit_domain': True, 'can_edit_role': True, } # Setting this to True, will add a new \"Retrieve Password\" action on instance, # allowing Admin session password retrieval/decryption. #OPENSTACK_ENABLE_PASSWORD_RETRIEVE = False # The Launch Instance user experience has been significantly enhanced. # You can choose whether to enable the new launch instance experience, # the legacy experience, or both. The legacy experience will be removed # in a future release, but is available as a temporary backup setting to ensure # compatibility with existing deployments. Further development will not be # done on the legacy experience. Please report any problems with the new # experience via the Launchpad tracking system. # # Toggle LAUNCH_INSTANCE_LEGACY_ENABLED and LAUNCH_INSTANCE_NG_ENABLED to # determine the experience to enable. Set them both to true to enable # both. #LAUNCH_INSTANCE_LEGACY_ENABLED = True #LAUNCH_INSTANCE_NG_ENABLED = False # A dictionary of settings which can be used to provide the default values for # properties found in the Launch Instance modal. #LAUNCH_INSTANCE_DEFAULTS = { # 'config_drive': False, # 'enable_scheduler_hints': True, # 'disable_image': False, # 'disable_instance_snapshot': False, # 'disable_volume': False, # 'disable_volume_snapshot': False, # 'create_volume': True, #} # The Xen Hypervisor has the ability to set the mount point for volumes # attached to instances (other Hypervisors currently do not). Setting # can_set_mount_point to True will add the option to set the mount point # from the UI. OPENSTACK_HYPERVISOR_FEATURES = { 'can_set_mount_point': False, 'can_set_password': False, 'requires_keypair': False, 'enable_quotas': True } # This settings controls whether IP addresses of servers are retrieved from # neutron in the project instance table. Setting this to ``False`` may mitigate # a performance issue in the project instance table in large deployments. #OPENSTACK_INSTANCE_RETRIEVE_IP_ADDRESSES = True # The OPENSTACK_CINDER_FEATURES settings can be used to enable optional # services provided by cinder that is not exposed by its extension API. OPENSTACK_CINDER_FEATURES = { 'enable_backup': False, } # The OPENSTACK_NEUTRON_NETWORK settings can be used to enable optional # services provided by neutron. Options currently available are load # balancer service, security groups, quotas, VPN service. OPENSTACK_NEUTRON_NETWORK = { 'enable_router': False, 'enable_quotas': False, 'enable_distributed_router': False, 'enable_ha_router': False, 'enable_lb': False, 'enable_firewall': False, 'enable_vpn': False, 'enable_fip_topology_check': False, # Default dns servers you would like to use when a subnet is # created. This is only a default, users can still choose a different # list of dns servers when creating a new subnet. # The entries below are examples only, and are not appropriate for # real deployments # 'default_dns_nameservers': [\"8.8.8.8\", \"8.8.4.4\", \"208.67.222.222\"], # Set which provider network types are supported. Only the network types # in this list will be available to choose from when creating a network. # Network types include local, flat, vlan, gre, vxlan and geneve. # 'supported_provider_types': ['*'], # You can configure available segmentation ID range per network type # in your deployment. # 'segmentation_id_range': { # 'vlan': [1024, 2048], # 'vxlan': [4094, 65536], # }, # You can define additional provider network types here. # 'extra_provider_types': { # 'awesome_type': { # 'display_name': 'Awesome New Type', # 'require_physical_network': False, # 'require_segmentation_id': True, # } # }, # Set which VNIC types are supported for port binding. Only the VNIC # types in this list will be available to choose from when creating a # port. # VNIC types include 'normal', 'direct', 'direct-physical', 'macvtap', # 'baremetal' and 'virtio-forwarder' # Set to empty list or None to disable VNIC type selection. 'supported_vnic_types': ['*'], # Set list of available physical networks to be selected in the physical # network field on the admin create network modal. If it's set to an empty # list, the field will be a regular input field. # e.g. ['default', 'test'] 'physical_networks': [], } # The OPENSTACK_HEAT_STACK settings can be used to disable password # field required while launching the stack. OPENSTACK_HEAT_STACK = { 'enable_user_pass': True, } # The OPENSTACK_IMAGE_BACKEND settings can be used to customize features # in the OpenStack Dashboard related to the Image service, such as the list # of supported image formats. #OPENSTACK_IMAGE_BACKEND = { # 'image_formats': [ # ('', _('Select format')), # ('aki', _('AKI - Amazon Kernel Image')), # ('ami', _('AMI - Amazon Machine Image')), # ('ari', _('ARI - Amazon Ramdisk Image')), # ('docker', _('Docker')), # ('iso', _('ISO - Optical Disk Image')), # ('ova', _('OVA - Open Virtual Appliance')), # ('qcow2', _('QCOW2 - QEMU Emulator')), # ('raw', _('Raw')), # ('vdi', _('VDI - Virtual Disk Image')), # ('vhd', _('VHD - Virtual Hard Disk')), # ('vhdx', _('VHDX - Large Virtual Hard Disk')), # ('vmdk', _('VMDK - Virtual Machine Disk')), # ], #} # The IMAGE_CUSTOM_PROPERTY_TITLES settings is used to customize the titles for # image custom property attributes that appear on image detail pages. IMAGE_CUSTOM_PROPERTY_TITLES = { \"architecture\": _(\"Architecture\"), \"kernel_id\": _(\"Kernel ID\"), \"ramdisk_id\": _(\"Ramdisk ID\"), \"image_state\": _(\"Euca2ools state\"), \"project_id\": _(\"Project ID\"), \"image_type\": _(\"Image Type\"), } # The IMAGE_RESERVED_CUSTOM_PROPERTIES setting is used to specify which image # custom properties should not be displayed in the Image Custom Properties # table. IMAGE_RESERVED_CUSTOM_PROPERTIES = [] # Set to 'legacy' or 'direct' to allow users to upload images to glance via # Horizon server. When enabled, a file form field will appear on the create # image form. If set to 'off', there will be no file form field on the create # image form. See documentation for deployment considerations. #HORIZON_IMAGES_UPLOAD_MODE = 'legacy' # Allow a location to be set when creating or updating Glance images. # If using Glance V2, this value should be False unless the Glance # configuration and policies allow setting locations. #IMAGES_ALLOW_LOCATION = False # A dictionary of default settings for create image modal. #CREATE_IMAGE_DEFAULTS = { # 'image_visibility': \"public\", #} # OPENSTACK_ENDPOINT_TYPE specifies the endpoint type to use for the endpoints # in the Keystone service catalog. Use this setting when Horizon is running # external to the OpenStack environment. The default is 'publicURL'. #OPENSTACK_ENDPOINT_TYPE = \"publicURL\" # SECONDARY_ENDPOINT_TYPE specifies the fallback endpoint type to use in the # case that OPENSTACK_ENDPOINT_TYPE is not present in the endpoints # in the Keystone service catalog. Use this setting when Horizon is running # external to the OpenStack environment. The default is None. This # value should differ from OPENSTACK_ENDPOINT_TYPE if used. #SECONDARY_ENDPOINT_TYPE = None # The number of objects (Swift containers/objects or images) to display # on a single page before providing a paging element (a \"more\" link) # to paginate results. API_RESULT_LIMIT = 1000 API_RESULT_PAGE_SIZE = 20 # The size of chunk in bytes for downloading objects from Swift SWIFT_FILE_TRANSFER_CHUNK_SIZE = 512 * 1024 # The default number of lines displayed for instance console log. INSTANCE_LOG_LENGTH = 35 # Specify a maximum number of items to display in a dropdown. DROPDOWN_MAX_ITEMS = 30 # The timezone of the server. This should correspond with the timezone # of your entire OpenStack installation, and hopefully be in UTC. TIME_ZONE = \"Asia/Shanghai\" # When launching an instance, the menu of available flavors is # sorted by RAM usage, ascending. If you would like a different sort order, # you can provide another flavor attribute as sorting key. Alternatively, you # can provide a custom callback method to use for sorting. You can also provide # a flag for reverse sort. For more info, see # http://docs.python.org/2/library/functions.html#sorted #CREATE_INSTANCE_FLAVOR_SORT = { # 'key': 'name', # # or # 'key': my_awesome_callback_method, # 'reverse': False, #} # Set this to True to display an 'Admin Password' field on the Change Password # form to verify that it is indeed the admin logged-in who wants to change # the password. #ENFORCE_PASSWORD_CHECK = False # Modules that provide /auth routes that can be used to handle different types # of user authentication. Add auth plugins that require extra route handling to # this list. #AUTHENTICATION_URLS = [ # 'openstack_auth.urls', #] # The Horizon Policy Enforcement engine uses these values to load per service # policy rule files. The content of these files should match the files the # OpenStack services are using to determine role based access control in the # target installation. # Path to directory containing policy.json files POLICY_FILES_PATH = '/etc/openstack-dashboard' # Map of local copy of service policy files. # Please insure that your identity policy file matches the one being used on # your keystone servers. There is an alternate policy file that may be used # in the Keystone v3 multi-domain case, policy.v3cloudsample.json. # This file is not included in the Horizon repository by default but can be # found at # http://git.openstack.org/cgit/openstack/keystone/tree/etc/ \\ # policy.v3cloudsample.json # Having matching policy files on the Horizon and Keystone servers is essential # for normal operation. This holds true for all services and their policy files. #POLICY_FILES = { # 'identity': 'keystone_policy.json', # 'compute': 'nova_policy.json', # 'volume': 'cinder_policy.json', # 'image': 'glance_policy.json', # 'network': 'neutron_policy.json', #} # Change this patch to the appropriate list of tuples containing # a key, label and static directory containing two files: # _variables.scss and _styles.scss #AVAILABLE_THEMES = [ # ('default', 'Default', 'themes/default'), # ('material', 'Material', 'themes/material'), #] LOGGING = { 'version': 1, # When set to True this will disable all logging except # for loggers specified in this configuration dictionary. Note that # if nothing is specified here and disable_existing_loggers is True, # django.db.backends will still log unless it is disabled explicitly. 'disable_existing_loggers': False, # If apache2 mod_wsgi is used to deploy OpenStack dashboard # timestamp is output by mod_wsgi. If WSGI framework you use does not # output timestamp for logging, add %(asctime)s in the following # format definitions. 'formatters': { 'console': { 'format': '%(levelname)s %(name)s %(message)s' }, 'operation': { # The format of \"%(message)s\" is defined by # OPERATION_LOG_OPTIONS['format'] 'format': '%(message)s' }, }, 'handlers': { 'null': { 'level': 'DEBUG', 'class': 'logging.NullHandler', }, 'console': { # Set the level to \"DEBUG\" for verbose output logging. 'level': 'INFO', 'class': 'logging.StreamHandler', 'formatter': 'console', }, 'operation': { 'level': 'INFO', 'class': 'logging.StreamHandler', 'formatter': 'operation', }, }, 'loggers': { 'horizon': { 'handlers': ['console'], 'level': 'DEBUG', 'propagate': False, }, 'horizon.operation_log': { 'handlers': ['operation'], 'level': 'INFO', 'propagate': False, }, 'openstack_dashboard': { 'handlers': ['console'], 'level': 'DEBUG', 'propagate': False, }, 'novaclient': { 'handlers': ['console'], 'level': 'DEBUG', 'propagate': False, }, 'cinderclient': { 'handlers': ['console'], 'level': 'DEBUG', 'propagate': False, }, 'keystoneauth': { 'handlers': ['console'], 'level': 'DEBUG', 'propagate': False, }, 'keystoneclient': { 'handlers': ['console'], 'level': 'DEBUG', 'propagate': False, }, 'glanceclient': { 'handlers': ['console'], 'level': 'DEBUG', 'propagate': False, }, 'neutronclient': { 'handlers': ['console'], 'level': 'DEBUG', 'propagate': False, }, 'swiftclient': { 'handlers': ['console'], 'level': 'DEBUG', 'propagate': False, }, 'oslo_policy': { 'handlers': ['console'], 'level': 'DEBUG', 'propagate': False, }, 'openstack_auth': { 'handlers': ['console'], 'level': 'DEBUG', 'propagate': False, }, 'django': { 'handlers': ['console'], 'level': 'DEBUG', 'propagate': False, }, # Logging from django.db.backends is VERY verbose, send to null # by default. 'django.db.backends': { 'handlers': ['null'], 'propagate': False, }, 'requests': { 'handlers': ['null'], 'propagate': False, }, 'urllib3': { 'handlers': ['null'], 'propagate': False, }, 'chardet.charsetprober': { 'handlers': ['null'], 'propagate': False, }, 'iso8601': { 'handlers': ['null'], 'propagate': False, }, 'scss': { 'handlers': ['null'], 'propagate': False, }, }, } # 'direction' should not be specified for all_tcp/udp/icmp. # It is specified in the form. SECURITY_GROUP_RULES = { 'all_tcp': { 'name': _('All TCP'), 'ip_protocol': 'tcp', 'from_port': '1', 'to_port': '65535', }, 'all_udp': { 'name': _('All UDP'), 'ip_protocol': 'udp', 'from_port': '1', 'to_port': '65535', }, 'all_icmp': { 'name': _('All ICMP'), 'ip_protocol': 'icmp', 'from_port': '-1', 'to_port': '-1', }, 'ssh': { 'name': 'SSH', 'ip_protocol': 'tcp', 'from_port': '22', 'to_port': '22', }, 'smtp': { 'name': 'SMTP', 'ip_protocol': 'tcp', 'from_port': '25', 'to_port': '25', }, 'dns': { 'name': 'DNS', 'ip_protocol': 'tcp', 'from_port': '53', 'to_port': '53', }, 'http': { 'name': 'HTTP', 'ip_protocol': 'tcp', 'from_port': '80', 'to_port': '80', }, 'pop3': { 'name': 'POP3', 'ip_protocol': 'tcp', 'from_port': '110', 'to_port': '110', }, 'imap': { 'name': 'IMAP', 'ip_protocol': 'tcp', 'from_port': '143', 'to_port': '143', }, 'ldap': { 'name': 'LDAP', 'ip_protocol': 'tcp', 'from_port': '389', 'to_port': '389', }, 'https': { 'name': 'HTTPS', 'ip_protocol': 'tcp', 'from_port': '443', 'to_port': '443', }, 'smtps': { 'name': 'SMTPS', 'ip_protocol': 'tcp', 'from_port': '465', 'to_port': '465', }, 'imaps': { 'name': 'IMAPS', 'ip_protocol': 'tcp', 'from_port': '993', 'to_port': '993', }, 'pop3s': { 'name': 'POP3S', 'ip_protocol': 'tcp', 'from_port': '995', 'to_port': '995', }, 'ms_sql': { 'name': 'MS SQL', 'ip_protocol': 'tcp', 'from_port': '1433', 'to_port': '1433', }, 'mysql': { 'name': 'MYSQL', 'ip_protocol': 'tcp', 'from_port': '3306', 'to_port': '3306', }, 'rdp': { 'name': 'RDP', 'ip_protocol': 'tcp', 'from_port': '3389', 'to_port': '3389', }, } # Deprecation Notice: # # The setting FLAVOR_EXTRA_KEYS has been deprecated. # Please load extra spec metadata into the Glance Metadata Definition Catalog. # # The sample quota definitions can be found in: # /etc/metadefs/compute-quota.json # # The metadata definition catalog supports CLI and API: # $glance --os-image-api-version 2 help md-namespace-import # $glance-manage db_load_metadefs # # See Metadata Definitions on: # https://docs.openstack.org/glance/latest/user/glancemetadefcatalogapi.html # The hash algorithm to use for authentication tokens. This must # match the hash algorithm that the identity server and the # auth_token middleware are using. Allowed values are the # algorithms supported by Python's hashlib library. #OPENSTACK_TOKEN_HASH_ALGORITHM = 'md5' # AngularJS requires some settings to be made available to # the client side. Some settings are required by in-tree / built-in horizon # features. These settings must be added to REST_API_REQUIRED_SETTINGS in the # form of ['SETTING_1','SETTING_2'], etc. # # You may remove settings from this list for security purposes, but do so at # the risk of breaking a built-in horizon feature. These settings are required # for horizon to function properly. Only remove them if you know what you # are doing. These settings may in the future be moved to be defined within # the enabled panel configuration. # You should not add settings to this list for out of tree extensions. # See: https://wiki.openstack.org/wiki/Horizon/RESTAPI REST_API_REQUIRED_SETTINGS = ['OPENSTACK_HYPERVISOR_FEATURES', 'LAUNCH_INSTANCE_DEFAULTS', 'OPENSTACK_IMAGE_FORMATS', 'OPENSTACK_KEYSTONE_BACKEND', 'OPENSTACK_KEYSTONE_DEFAULT_DOMAIN', 'CREATE_IMAGE_DEFAULTS', 'ENFORCE_PASSWORD_CHECK'] # Additional settings can be made available to the client side for # extensibility by specifying them in REST_API_ADDITIONAL_SETTINGS # !! Please use extreme caution as the settings are transferred via HTTP/S # and are not encrypted on the browser. This is an experimental API and # may be deprecated in the future without notice. #REST_API_ADDITIONAL_SETTINGS = [] # DISALLOW_IFRAME_EMBED can be used to prevent Horizon from being embedded # within an iframe. Legacy browsers are still vulnerable to a Cross-Frame # Scripting (XFS) vulnerability, so this option allows extra security hardening # where iframes are not used in deployment. Default setting is True. # For more information see: # http://tinyurl.com/anticlickjack #DISALLOW_IFRAME_EMBED = True # Help URL can be made available for the client. To provide a help URL, edit the # following attribute to the URL of your choice. #HORIZON_CONFIG[\"help_url\"] = \"http://openstack.mycompany.org\" # Settings for OperationLogMiddleware # OPERATION_LOG_ENABLED is flag to use the function to log an operation on # Horizon. # mask_targets is arrangement for appointing a target to mask. # method_targets is arrangement of HTTP method to output log. # format is the log contents. #OPERATION_LOG_ENABLED = False #OPERATION_LOG_OPTIONS = { # 'mask_fields': ['password'], # 'target_methods': ['POST'], # 'ignored_urls': ['/js/', '/static/', '^/api/'], # 'format': (\"[%(client_ip)s] [%(domain_name)s]\" # \" [%(domain_id)s] [%(project_name)s]\" # \" [%(project_id)s] [%(user_name)s] [%(user_id)s] [%(request_scheme)s]\" # \" [%(referer_url)s] [%(request_url)s] [%(message)s] [%(method)s]\" # \" [%(http_status)s] [%(param)s]\"), #} # The default date range in the Overview panel meters - either minus N # days (if the value is integer N), or from the beginning of the current month # until today (if set to None). This setting should be used to limit the amount # of data fetched by default when rendering the Overview panel. #OVERVIEW_DAYS_RANGE = 1 # To allow operators to require users provide a search criteria first # before loading any data into the views, set the following dict # attributes to True in each one of the panels you want to enable this feature. # Follow the convention . #FILTER_DATA_FIRST = { # 'admin.instances': False, # 'admin.images': False, # 'admin.networks': False, # 'admin.routers': False, # 'admin.volumes': False, # 'identity.users': False, # 'identity.projects': False, # 'identity.groups': False, # 'identity.roles': False #} # Dict used to restrict user private subnet cidr range. # An empty list means that user input will not be restricted # for a corresponding IP version. By default, there is # no restriction for IPv4 or IPv6. To restrict # user private subnet cidr range set ALLOWED_PRIVATE_SUBNET_CIDR # to something like #ALLOWED_PRIVATE_SUBNET_CIDR = { # 'ipv4': ['10.0.0.0/8', '192.168.0.0/16'], # 'ipv6': ['fc00::/7'] #} ALLOWED_PRIVATE_SUBNET_CIDR = {'ipv4': [], 'ipv6': []} # Projects and users can have extra attributes as defined by keystone v3. # Horizon has the ability to display these extra attributes via this setting. # If you'd like to display extra data in the project or user tables, set the # corresponding dict key to the attribute name, followed by the display name. # For more information, see horizon's customization # (https://docs.openstack.org/horizon/latest/configuration/customizing.html#horizon-customization-module-overrides) #PROJECT_TABLE_EXTRA_INFO = { # 'phone_num': _('Phone Number'), #} #USER_TABLE_EXTRA_INFO = { # 'phone_num': _('Phone Number'), #} # Password will have an expiration date when using keystone v3 and enabling the # feature. # This setting allows you to set the number of days that the user will be alerted # prior to the password expiration. # Once the password expires keystone will deny the access and users must # contact an admin to change their password. #PASSWORD_EXPIRES_WARNING_THRESHOLD_DAYS = 0 md5sum /etc/openstack-dashboard/local_settings 0e53f197affdd94c9e25a4f6f7fdf14b /etc/openstack-dashboard/local_settings 7.3 修改配置文件，否则后续访问dashboard会报500错误 /etc/httpd/conf.d/openstack-dashboard.conf如果不包含以下内容，请添加以下行 sed -i.bak '3aWSGIApplicationGroup %{GLOBAL}' \\ /etc/httpd/conf.d/openstack-dashboard.conf #重启httpd和memcache systemctl restart httpd.service memcached.service 7.4 登陆dashboard 10.0.0.11/dashboard 域：default 用户名：admin 密码：ADMIN_PASS 登陆后首界面 八、控制节点和存储节点块存储服务cinder安装 rocky版块存储cinder安装配置官方文档 官方对cidner服务的说明 本节介绍如何为块存储服务安装和配置存储节点。为简单起见，此配置引用一个具有空本地块存储设备的存储节点。指令使用/dev/sdb，但是您可以将特定节点替换为其他值。 该服务使用LVM驱动程序在该设备上置备逻辑卷， 并通过iSCSI传输将其提供给实例。您可以对这些说明进行少量修改，以通过其他存储节点水平扩展您的环境。 cinder相关服务 服务名 说明 cinder-volume 提供存储空间，包括lvm、nfs、glusterfs、ceph等等存储 cinder-api 接收外部的api请求 cinder-scheduler 调度器，决定由哪一个cinder-volume提供存储空间 cinder-backup 备份创建的卷 安装和配置控制节点 rocky版控制节点块存储服务cinder安装配置官方文档 8.1 创建cinder数据库并授权 #用以下命令修改 mysql -e \"CREATE DATABASE cinder;\" mysql -e \"GRANT ALL PRIVILEGES ON cinder.* TO 'cinder'@'localhost' \\ IDENTIFIED BY 'CINDER_DBPASS';\" mysql -e \"GRANT ALL PRIVILEGES ON cinder.* TO 'cinder'@'%' \\ IDENTIFIED BY 'CINDER_DBPASS';\" 8.2 获取管理员凭据以获取对仅管理员CLI命令的访问 source /opt/admin-openrc 8.3 创建服务凭证 8.3.1 创建cinder用户，密码设置为CIDNER_PASS //这里交互式创建密码和非交互式选择其中一种 #非交互式设置密码 openstack user create --domain default --password CINDER_PASS cinder +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | domain_id | default | | enabled | True | | id | 65b5343859e6409994d007f2de30570b | | name | cinder | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ #交互式设置密码 openstack user create --domain default --password-prompt cinder 8.3.2 将admin角色添加到cinder用户 openstack role add --project service --user cinder admin 8.3.3 创建cinderv2和cinderv3服务实体 ⚠️块存储服务需要两个服务实体 openstack service create --name cinderv2 \\ --description \"OpenStack Block Storage\" volumev2 +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Block Storage | | enabled | True | | id | efcdff53520142d2ac6b0953cf532340 | | name | cinderv2 | | type | volumev2 | +-------------+----------------------------------+ openstack service create --name cinderv3 \\ --description \"OpenStack Block Storage\" volumev3 +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Block Storage | | enabled | True | | id | 910b223e07244359ae0480d579a0231a | | name | cinderv3 | | type | volumev3 | +-------------+----------------------------------+ 8.4 创建块存储服务API端点 cinderv2 openstack endpoint create --region RegionOne \\ volumev2 public http://controller:8776/v2/%\\(project_id\\)s +--------------+------------------------------------------+ | Field | Value | +--------------+------------------------------------------+ | enabled | True | | id | dcd7a491205f4c8a8a1af94fbd95d452 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | efcdff53520142d2ac6b0953cf532340 | | service_name | cinderv2 | | service_type | volumev2 | | url | http://controller:8776/v2/%(project_id)s | +--------------+------------------------------------------+ openstack endpoint create --region RegionOne \\ volumev2 internal http://controller:8776/v2/%\\(project_id\\)s +--------------+------------------------------------------+ | Field | Value | +--------------+------------------------------------------+ | enabled | True | | id | e044f276dd624336b5c4bb51aa343a55 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | efcdff53520142d2ac6b0953cf532340 | | service_name | cinderv2 | | service_type | volumev2 | | url | http://controller:8776/v2/%(project_id)s | +--------------+------------------------------------------+ openstack endpoint create --region RegionOne \\ volumev2 admin http://controller:8776/v2/%\\(project_id\\)s +--------------+------------------------------------------+ | Field | Value | +--------------+------------------------------------------+ | enabled | True | | id | e9c888a00e354a2cab3035b70b9e6c30 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | efcdff53520142d2ac6b0953cf532340 | | service_name | cinderv2 | | service_type | volumev2 | | url | http://controller:8776/v2/%(project_id)s | +--------------+------------------------------------------+ cinderv3 openstack endpoint create --region RegionOne \\ volumev3 public http://controller:8776/v3/%\\(project_id\\)s +--------------+------------------------------------------+ | Field | Value | +--------------+------------------------------------------+ | enabled | True | | id | 4f818560bac745dfa493dc53b3106cc3 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 910b223e07244359ae0480d579a0231a | | service_name | cinderv3 | | service_type | volumev3 | | url | http://controller:8776/v3/%(project_id)s | +--------------+------------------------------------------+ openstack endpoint create --region RegionOne \\ volumev3 internal http://controller:8776/v3/%\\(project_id\\)s +--------------+------------------------------------------+ | Field | Value | +--------------+------------------------------------------+ | enabled | True | | id | e102e7b28f5f47409e4e231af0af4776 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 910b223e07244359ae0480d579a0231a | | service_name | cinderv3 | | service_type | volumev3 | | url | http://controller:8776/v3/%(project_id)s | +--------------+------------------------------------------+ openstack endpoint create --region RegionOne \\ volumev3 admin http://controller:8776/v3/%\\(project_id\\)s +--------------+------------------------------------------+ | Field | Value | +--------------+------------------------------------------+ | enabled | True | | id | 4585dc9397b041b7a1a45d063d515dcb | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 910b223e07244359ae0480d579a0231a | | service_name | cinderv3 | | service_type | volumev3 | | url | http://controller:8776/v3/%(project_id)s | +--------------+------------------------------------------+ 8.5 安装和配置组件 8.5.1 安装软件包 yum -y install openstack-cinder 8.5.2 编辑/etc/cinder/cinder.conf文件并完成以下操作 1.在该[database]部分中，配置数据库访问： [database] # ... connection = mysql+pymysql://cinder:CINDER_DBPASS@controller/cinder 2.在该[DEFAULT]部分中，配置RabbitMQ 消息队列访问： [DEFAULT] # ... transport_url = rabbit://openstack:RABBIT_PASS@controller 3.在[DEFAULT]和[keystone_authtoken]部分中，配置身份服务访问： [DEFAULT] # ... auth_strategy = keystone [keystone_authtoken] # ... www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_id = default user_domain_id = default project_name = service username = cinder password = CINDER_PASS 4.在该[DEFAULT]部分中，配置my_ip选项以使用控制器节点的管理接口IP地址： [DEFAULT] # ... my_ip = 10.0.0.11 5.在该[oslo_concurrency]部分中，配置锁定路径： [oslo_concurrency] # ... lock_path = /var/lib/cinder/tmp #用以下命令修改 \\cp /etc/cinder/cinder.conf{,.bak} grep '^[a-Z\\[]' /etc/cinder/cinder.conf.bak > /etc/cinder/cinder.conf openstack-config --set /etc/cinder/cinder.conf database connection mysql+pymysql://cinder:CINDER_DBPASS@controller/cinder openstack-config --set /etc/cinder/cinder.conf DEFAULT transport_url rabbit://openstack:RABBIT_PASS@controller openstack-config --set /etc/cinder/cinder.conf DEFAULT auth_strategy keystone openstack-config --set /etc/cinder/cinder.conf DEFAULT my_ip 10.0.0.11 openstack-config --set /etc/cinder/cinder.conf keystone_authtoken www_authenticate_uri http://controller:5000 openstack-config --set /etc/cinder/cinder.conf keystone_authtoken auth_url http://controller:5000 openstack-config --set /etc/cinder/cinder.conf keystone_authtoken memcached_servers controller:11211 openstack-config --set /etc/cinder/cinder.conf keystone_authtoken auth_type password openstack-config --set /etc/cinder/cinder.conf keystone_authtoken project_domain_id default openstack-config --set /etc/cinder/cinder.conf keystone_authtoken user_domain_id default openstack-config --set /etc/cinder/cinder.conf keystone_authtoken project_name service openstack-config --set /etc/cinder/cinder.conf keystone_authtoken username cinder openstack-config --set /etc/cinder/cinder.conf keystone_authtoken password CINDER_PASS openstack-config --set /etc/cinder/cinder.conf oslo_concurrency lock_path /var/lib/cinder/tmp MD5值 md5sum /etc/cinder/cinder.conf 7fd4cf1f205df40cb8f01a280110988e /etc/cinder/cinder.conf 8.5.3 同步数据库 $ su -s /bin/sh -c \"cinder-manage db sync\" cinder Deprecated: Option \"logdir\" from group \"DEFAULT\" is deprecated. Use option \"log-dir\" from group \"DEFAULT\" #有表即为正确 mysql cinder -e \"show tables\"|wc -l 36 8.6 配置计算已使用块存储 编辑/etc/nova/nova.conf文件并向其中添加以下内容 openstack-config --set /etc/nova/nova.conf cinder os_region_name RegionOne MD5值 md5sum /etc/nova/nova.conf a8f15dce52b4c6a2ae8f4768a20f66a5 /etc/nova/nova.conf 8.7 完成安装 8.7.1 重启Compute API服务 systemctl restart openstack-nova-api.service 8.7.2 启动块存储服务，并将其配置为在系统启动时启动 systemctl enable openstack-cinder-api.service openstack-cinder-scheduler.service systemctl start openstack-cinder-api.service openstack-cinder-scheduler.service 8.8 验证 返回的结果是cinder-api提供的，并且cinder-scheduler的状态是up cinder service-list +------------------+------------+------+---------+-------+----------------------------+-----------------+ | Binary | Host | Zone | Status | State | Updated_at | Disabled Reason | +------------------+------------+------+---------+-------+----------------------------+-----------------+ | cinder-scheduler | controller | nova | enabled | up | 2020-05-29T10:58:08.000000 | - | +------------------+------------+------+---------+-------+----------------------------+-----------------+ 安装和配置块存储节点 rocky版块存储节点块存储服务cinder安装配置官方文档 8.8 前提条件 8.8.1 安装包 yum -y install lvm2 device-mapper-persistent-data openstack-utils.noarch 8.8.2 启动LVM元数据服务，并将其配置为在系统引导时启动 systemctl enable lvm2-lvmetad.service systemctl start lvm2-lvmetad.service 8.8.3 创建LVM物理卷/dev/sdb ⚠️如果是在虚拟机中，需要添加一块数据盘，使用命令echo \"- - -\" >/sys/class/scsi_host/host0/scan实现热加载（不一定为host0，也可能是其他数字，比如1、2、3等） 查看添加的磁盘 $ fdisk -l /dev/sdb Disk /dev/sdb: 5368 MB, 5368709120 bytes, 10485760 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 4096 bytes I/O size (minimum/optimal): 4096 bytes / 4096 bytes 创建物理卷pv $ pvcreate /dev/sdb Physical volume \"/dev/sdb\" successfully created 8.8.4 创建LVM卷组cinder-volumes $ vgcreate cinder-volumes /dev/sdb Volume group \"cinder-volumes\" successfully created 8.8.5 关于lvm的问题 只有实例可以访问块存储卷。但是，底层操作系统管理与卷关联的设备。默认情况下，LVM卷扫描工具会在/dev目录中扫描包含卷的块存储设备。如果项目在其卷上使用LVM，则扫描工具会检测到这些卷并尝试对其进行缓存，这可能导致基础操作系统卷和项目卷出现各种问题。您必须将LVM重新配置为仅扫描包含cinder-volumes卷组的设备 ⚠️⚠️⚠️ 如果存储节点在操作系统磁盘上使用LVM，则还必须将关联的设备添加到过滤器中。例如，如果/dev/sda设备包含操作系统： filter = [ \"a/sda/\", \"a/sdb/\", \"r/.*/\"] 同样，如果您的计算节点在操作系统磁盘上使用LVM，则还必须/etc/lvm/lvm.conf在这些节点上的文件中修改过滤器， 使其仅包括操作系统磁盘。例如，如果/dev/sda 设备包含操作系统： filter = [ \"a/sda/\", \"r/.*/\"] 因为使用的虚拟机在安装的时候是采用的lvm，所以配置文件中应当把系统盘/dev/sda也添加 编辑 /etc/lvm/lvm.conf文件并完成以下操作 在该devices部分中，添加一个接受/dev/sdb设备并拒绝所有其他设备的过滤 器： devices { ... filter = [ \"a/sdb/\", \"r/.*/\"] #用以下命令修改 \\cp /etc/lvm/lvm.conf{,.bak} egrep -v '^$|#' /etc/lvm/lvm.conf.bak > /etc/lvm/lvm.conf sed -i '/^devices/a\\\\tfilter = [ \"a/sda/\", \"a/sdb/\", \"r/.*/\"]' /etc/lvm/lvm.conf MD5值 md5sum /etc/lvm/lvm.conf f14b4b4075998bf20d1186089cfcdc40 /etc/lvm/lvm.conf 滤波器阵列中的每个项目开始于a用于接受或 r用于拒绝，并且包括用于所述装置名称的正则表达式。该阵列必须r/.*/以拒绝任何剩余的设备结尾。您可以使用vgs -vvvv命令测试过滤器 8.9 安装和配置组件 8.9.1 安装软件包 targetcli是iscsi的包 yum -y install openstack-cinder targetcli python-keystone 8.9.2 编辑/etc/cinder/cinder.conf文件并完成以下操作 ⚠️在配置文件中的[DEFAULT]区域，默认官方定义的后端lvm卷名称就是lvm，这个名称是任意的，并且DEFAULT区域的enabled_backends定义的名称是有单独的一个区域，例如 #default区域内容如下 [DEFAULT] enabled_backends = lvm #则如下区域内容和DEFAULT区域定义的名称一一对应的 [lvm] volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver #驱动 volume_group = cinder-volumes #卷组名 iscsi_protocol = iscsi iscsi_helper = lioadm 如果有多个lvm卷，则DEFAULT区域可以写成如下，并且最后要写上一一对应的内容 [DEFAULT] enabled_backends = lvm,lvm2,lvm3 #后段名称任意，这里我们定义为普通磁盘sata，固态硬盘ssd [DEFAULT] enabled_backends = sata,ssd [sata] volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver volume_group = cinder-volumes iscsi_protocol = iscsi iscsi_helper = lioadm volume_backend_name = sata [ssd] volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver volume_group = cinder-ssd iscsi_protocol = iscsi iscsi_helper = lioadm volume_backend_name = ssd 1.在该[database]部分中，配置数据库访问： [database] # ... connection = mysql+pymysql://cinder:CINDER_DBPASS@controller/cinder 2.在该[DEFAULT]部分中，配置RabbitMQ 消息队列访问： [DEFAULT] # ... transport_url = rabbit://openstack:RABBIT_PASS@controller 3.在[DEFAULT]和[keystone_authtoken]部分中，配置身份服务访问： [DEFAULT] # ... auth_strategy = keystone [keystone_authtoken] # ... www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_id = default user_domain_id = default project_name = service username = cinder password = CINDER_PASS 4.在该[DEFAULT]部分中，配置my_ip选项：替换MANAGEMENT_INTERFACE_IP_ADDRESS为存储节点上管理网络接口的IP地址，对于示例体系结构中的第一个节点，通常为10.0.0.41 [DEFAULT] # ... my_ip = MANAGEMENT_INTERFACE_IP_ADDRESS 5.在该[lvm]部分中，为LVM后端配置LVM驱动程序，cinder-volumes卷组，iSCSI协议和适当的iSCSI服务。如果该[lvm]部分不存在，请创建它： [lvm] volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver volume_group = cinder-volumes iscsi_protocol = iscsi iscsi_helper = lioadm 6.在该[DEFAULT]部分中，启用LVM后端： 后端名称是任意的。例如，本指南使用驱动程序的名称作为后端的名称。 [DEFAULT] # ... enabled_backends = lvm 7.在该[DEFAULT]部分中，配置图像服务API的位置： [DEFAULT] # ... glance_api_servers = http://controller:9292 8.在该[oslo_concurrency]部分中，配置锁定路径： [oslo_concurrency] # ... lock_path = /var/lib/cinder/tmp #用以下命令修改 \\cp /etc/cinder/cinder.conf{,.bak} grep '^[a-Z\\[]' /etc/cinder/cinder.conf.bak > /etc/cinder/cinder.conf openstack-config --set /etc/cinder/cinder.conf database connection mysql+pymysql://cinder:CINDER_DBPASS@controller/cinder openstack-config --set /etc/cinder/cinder.conf DEFAULT transport_url rabbit://openstack:RABBIT_PASS@controller openstack-config --set /etc/cinder/cinder.conf DEFAULT auth_strategy keystone openstack-config --set /etc/cinder/cinder.conf DEFAULT my_ip 10.0.0.41 openstack-config --set /etc/cinder/cinder.conf DEFAULT enabled_backends lvm openstack-config --set /etc/cinder/cinder.conf DEFAULT glance_api_servers http://controller:9292 openstack-config --set /etc/cinder/cinder.conf keystone_authtoken www_authenticate_uri http://controller:5000 openstack-config --set /etc/cinder/cinder.conf keystone_authtoken auth_url http://controller:5000 openstack-config --set /etc/cinder/cinder.conf keystone_authtoken memcached_servers controller:11211 openstack-config --set /etc/cinder/cinder.conf keystone_authtoken auth_type password openstack-config --set /etc/cinder/cinder.conf keystone_authtoken project_domain_id default openstack-config --set /etc/cinder/cinder.conf keystone_authtoken user_domain_id default openstack-config --set /etc/cinder/cinder.conf keystone_authtoken project_name service openstack-config --set /etc/cinder/cinder.conf keystone_authtoken username cinder openstack-config --set /etc/cinder/cinder.conf keystone_authtoken password CINDER_PASS openstack-config --set /etc/cinder/cinder.conf lvm volume_driver cinder.volume.drivers.lvm.LVMVolumeDriver openstack-config --set /etc/cinder/cinder.conf lvm volume_group cinder-volumes openstack-config --set /etc/cinder/cinder.conf lvm iscsi_protocol iscsi openstack-config --set /etc/cinder/cinder.conf lvm iscsi_helper lioadm openstack-config --set /etc/cinder/cinder.conf oslo_concurrency lock_path /var/lib/cinder/tmp MD5值 md5sum /etc/cinder/cinder.conf 07cc203c56289c1ed19d6f3daba7ec32 /etc/cinder/cinder.conf 8.9.3 启动块存储卷服务及其相关性，并将其配置为在系统启动时启动 systemctl enable openstack-cinder-volume.service target.service systemctl start openstack-cinder-volume.service target.service 到此，控制节点和块存储节点块存储服务cinder安装完成！！！ 九、控制节点和对象节点对象存储服务swift安装 OpenStack对象存储是一个多租户对象存储系统。它具有高度的可扩展性，并且可以通过RESTful HTTP API以低成本管理大量非结构化数据。 swift相关组件 名称 说明 代理服务器（swift-proxy-server） 接受OpenStack对象存储API和原始HTTP请求，以上传文件，修改元数据和创建容器。它还向网络浏览器提供文件或容器列表。为了提高性能，代理服务器可以使用通常与memcache一起部署的可选缓存。 帐户服务器（swift-account-server） 管理使用对象存储定义的帐户 容器服务器（swift容器服务器） 在对象存储中管理容器或文件夹的映射 对象服务器（swift-object-server） 管理存储节点上的实际对象，例如文件 各种周期性过程 在大型数据存储上执行内务处理任务。复制服务可确保整个群集的一致性和可用性。其他定期过程包括审核员，更新者和收割者 WSGI中间件 处理身份验证，通常是OpenStack身份 swift client 使用户能够通过授权为管理员用户，代理商用户或快速用户的命令行客户端将命令提交到REST API swift-init 脚本初始化环文件的构建，以守护程序名称作为参数并提供命令。记录在 https://docs.openstack.org/swift/latest/admin_guide.html#managing-services中 swift-recon cli工具，用于检索swift-recon中间件已收集的有关群集的各种度量和遥测信息 swift-ring-builder 存储环构建和重新平衡实用程序。在 https://docs.openstack.org/swift/latest/admin_guide.html#managing-the-rings中记录 安装和配置控制节点 rocky版控制节点对象存储服务swift安装配置官方文档 9.1 创建身份服务凭据 9.1.1 获取管理员凭据以获取对仅管理员CLI命令的访问 source /opt/admin-openrc 9.1.2 创建swift用户，密码设置为SWIFT_PASS //这里交互式创建密码和非交互式选择其中一种 #非交互式设置密码 openstack user create --domain default --password SWIFT_PASS swift +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | domain_id | default | | enabled | True | | id | 312ab4f320434d30b76c9486463e2dea | | name | swift | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ #交互式设置密码 openstack user create --domain default --password-prompt swift 9.1.3 将admin角色添加到swift用户 openstack role add --project service --user swift admin 9.1.4 创建swift服务实体 openstack service create --name swift \\ --description \"OpenStack Object Storage\" object-store +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Object Storage | | enabled | True | | id | a41ace8ca3bb42ec92e27a29503828e7 | | name | swift | | type | object-store | +-------------+----------------------------------+ 9.2 创建对象存储服务API端点 openstack endpoint create --region RegionOne \\ object-store public http://controller:8080/v1/AUTH_%\\(project_id\\)s +--------------+-----------------------------------------------+ | Field | Value | +--------------+-----------------------------------------------+ | enabled | True | | id | 25063822e1c947f38189af370d97a0c2 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | a41ace8ca3bb42ec92e27a29503828e7 | | service_name | swift | | service_type | object-store | | url | http://controller:8080/v1/AUTH_%(project_id)s | +--------------+-----------------------------------------------+ openstack endpoint create --region RegionOne \\ object-store internal http://controller:8080/v1/AUTH_%\\(project_id\\)s +--------------+-----------------------------------------------+ | Field | Value | +--------------+-----------------------------------------------+ | enabled | True | | id | 6f36da03e9344d84906f98a31a09ebe9 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | a41ace8ca3bb42ec92e27a29503828e7 | | service_name | swift | | service_type | object-store | | url | http://controller:8080/v1/AUTH_%(project_id)s | +--------------+-----------------------------------------------+ openstack endpoint create --region RegionOne \\ object-store admin http://controller:8080/v1 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | ffe6a96aeb224d8abe3e0c3de6c9e072 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | a41ace8ca3bb42ec92e27a29503828e7 | | service_name | swift | | service_type | object-store | | url | http://controller:8080/v1 | +--------------+----------------------------------+ 9.3 安装和配置组件 9.3.1 安装软件包 yum -y install openstack-swift-proxy python-swiftclient \\ python-keystoneclient python-keystonemiddleware memcached openstack-utils.noarch 9.3.2 从对象存储源存储库获取代理服务配置文件 curl -o /etc/swift/proxy-server.conf https://opendev.org/openstack/swift/raw/branch/stable/rocky/etc/proxy-server.conf-sample 9.3.3 编辑/etc/swift/proxy-server.conf文件并完成以下操作 ⚠️⚠️⚠️这里官方文档有坑，q版之后就不用35357端口了，但是文档中还是写着auth_url = http://controller:35357，这里应该改成5000端口，否则后续验证swift会报错500 1.在该[DEFAULT]部分中，配置绑定端口，用户和配置目录： [DEFAULT] ... bind_port = 8080 user = swift swift_dir = /etc/swift 2.在该[pipeline:main]部分中，删除tempurl和 tempauth模块，然后添加authtoken和keystoneauth 模块 请勿更改模块的顺序！！！ 有关启用其他功能的其他模块的更多信息，请参考如下地址 https://docs.openstack.org/swift/latest/deployment_guide.html [pipeline:main] pipeline = catch_errors gatekeeper healthcheck proxy-logging cache container_sync bulk ratelimit authtoken keystoneauth container-quotas account-quotas slo dlo versioned_writes proxy-logging proxy-server 3.在该[app:proxy-server]部分中，启用自动帐户创建： [app:proxy-server] use = egg:swift#proxy ... account_autocreate = True 4.在该[filter:keystoneauth]部分中，配置操作员角色： [filter:keystoneauth] use = egg:swift#keystoneauth ... operator_roles = admin,user 5.在该[filter:authtoken]部分中，配置身份服务访问： [filter:authtoken] paste.filter_factory = keystonemiddleware.auth_token:filter_factory ... www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_id = default user_domain_id = default project_name = service username = swift password = SWIFT_PASS delay_auth_decision = True 6.在该[filter:cache]部分中，配置memcached位置： [filter:cache] use = egg:swift#memcache ... memcache_servers = controller:11211 #用以下命令修改 \\cp /etc/swift/proxy-server.conf{,.bak} grep '^[a-Z\\[]' /etc/swift/proxy-server.conf.bak > /etc/swift/proxy-server.conf openstack-config --set /etc/swift/proxy-server.conf DEFAULT bind_port 8080 openstack-config --set /etc/swift/proxy-server.conf DEFAULT user swift openstack-config --set /etc/swift/proxy-server.conf DEFAULT swift_dir /etc/swift openstack-config --set /etc/swift/proxy-server.conf app:proxy-server use egg:swift#proxy openstack-config --set /etc/swift/proxy-server.conf app:proxy-server account_autocreate True openstack-config --set /etc/swift/proxy-server.conf filter:keystoneauth use egg:swift#keystoneauth openstack-config --set /etc/swift/proxy-server.conf filter:keystoneauth operator_roles admin,user openstack-config --set /etc/swift/proxy-server.conf filter:authtoken paste.filter_factory keystonemiddleware.auth_token:filter_factory openstack-config --set /etc/swift/proxy-server.conf filter:authtoken www_authenticate_uri http://controller:5000 openstack-config --set /etc/swift/proxy-server.conf filter:authtoken auth_url http://controller:5000 openstack-config --set /etc/swift/proxy-server.conf filter:authtoken memcached_servers controller:11211 openstack-config --set /etc/swift/proxy-server.conf filter:authtoken auth_type password openstack-config --set /etc/swift/proxy-server.conf filter:authtoken project_domain_id default openstack-config --set /etc/swift/proxy-server.conf filter:authtoken user_domain_id default openstack-config --set /etc/swift/proxy-server.conf filter:authtoken project_name service openstack-config --set /etc/swift/proxy-server.conf filter:authtoken username swift openstack-config --set /etc/swift/proxy-server.conf filter:authtoken password SWIFT_PASS openstack-config --set /etc/swift/proxy-server.conf filter:authtoken delay_auth_decision True openstack-config --set /etc/swift/proxy-server.conf filter:cache use egg:swift#memcache openstack-config --set /etc/swift/proxy-server.conf filter:cache memcache_servers controller:11211 sed -i '/^pipeline/c pipeline = catch_errors gatekeeper healthcheck proxy-logging cache container_sync bulk ratelimit authtoken keystoneauth container-quotas account-quotas slo dlo versioned_writes proxy-logging proxy-server' /etc/swift/proxy-server.conf MD5值 md5sum /etc/swift/proxy-server.conf 007b21d8dbe36156ff7fffff53e88f5a /etc/swift/proxy-server.conf 安装和配置对象节点(51,52) rocky版存储节点对象存储服务swift安装配置官方文档 本节介绍如何安装和配置用于操作帐户，容器和对象服务的存储节点。为简单起见，此配置引用两个存储节点，每个存储节点包含两个空的本地块存储设备。指令使用/dev/sdb和/dev/sdc，但是您可以为特定节点替换不同的值。 尽管对象存储支持具有扩展属性（xattr）的任何文件系统，但是测试和基准测试表明XFS具有最佳性能和可靠性。有关水平扩展环境的更多信息，请参阅《 部署指南》。 本部分适用于Red Hat Enterprise Linux 7和CentOS 7 9.4 前提条件 9.4.1 安装软件包 yum -y install xfsprogs rsync 9.4.2 将/dev/sdb和/dev/sdc设备格式化为XFS mkfs.xfs /dev/sdb mkfs.xfs /dev/sdc 9.4.3 创建安装点目录结构 mkdir -p /srv/node/sdb mkdir -p /srv/node/sdc 9.4.4 编辑/etc/fstab文件并向其中添加以下内容 cp /etc/fstab{,.bak} cat >> /etc/fstab 9.4.5 挂载目录 mount /srv/node/sdb mount /srv/node/sdc 9.4.6 创建或编辑/etc/rsyncd.conf文件以包含以下内容 该rsync服务不需要身份验证，因此请考虑在生产环境中的专用网络上运行它。 替换MANAGEMENT_INTERFACE_IP_ADDRESS为存储节点上管理网络的IP地址 #10.0.0.51 \\cp /etc/rsyncd{,.bak} cat > /etc/rsyncd.conf /etc/rsyncd.conf 9.5 安装和配置组件 ⚠️在每个对象节点(51,52)上执行以下步骤 9.5.1 安装软件包 yum -y install openstack-swift-account openstack-swift-container \\ openstack-swift-object openstack-utils.noarch 9.5.2 从对象存储源存储库中获取计费，容器和对象服务配置文件 curl -o /etc/swift/account-server.conf https://opendev.org/openstack/swift/raw/branch/stable/rocky/etc/account-server.conf-sample curl -o /etc/swift/container-server.conf https://opendev.org/openstack/swift/raw/branch/stable/rocky/etc/container-server.conf-sample curl -o /etc/swift/object-server.conf https://opendev.org/openstack/swift/raw/branch/stable/rocky/etc/object-server.conf-sample 9.5.3 编辑/etc/swift/account-server.conf文件并完成以下操作 1.在此[DEFAULT]部分中，配置绑定IP地址，绑定端口，用户，配置目录和安装点目录：替换MANAGEMENT_INTERFACE_IP_ADDRESS为存储节点上管理网络的IP地址。 [DEFAULT] ... bind_ip = MANAGEMENT_INTERFACE_IP_ADDRESS bind_port = 6202 user = swift swift_dir = /etc/swift devices = /srv/node mount_check = True 2.在该[pipeline:main]部分中，启用适当的模块： 有关启用其他功能的其他模块的更多信息，参考如下地址 https://docs.openstack.org/swift/latest/deployment_guide.html [pipeline:main] pipeline = healthcheck recon account-server 3.在该[filter:recon]部分中，配置侦察（计量）缓存目录： [filter:recon] use = egg:swift#recon ... recon_cache_path = /var/cache/swift #用以下命令修改 #10.0.0.51 \\cp /etc/swift/account-server.conf{,.bak} grep '^[a-Z\\[]' /etc/swift/account-server.conf.bak > /etc/swift/account-server.conf openstack-config --set /etc/swift/account-server.conf DEFAULT bind_ip 10.0.0.51 openstack-config --set /etc/swift/account-server.conf DEFAULT bind_port 6202 openstack-config --set /etc/swift/account-server.conf DEFAULT user swift openstack-config --set /etc/swift/account-server.conf DEFAULT swift_dir /etc/swift openstack-config --set /etc/swift/account-server.conf DEFAULT devices /srv/node openstack-config --set /etc/swift/account-server.conf DEFAULT mount_check True openstack-config --set /etc/swift/account-server.conf filter:recon use egg:swift#recon openstack-config --set /etc/swift/account-server.conf filter:recon recon_cache_path /var/cache/swift MD5值 md5sum /etc/swift/account-server.conf 201ae87b1a85fb5d27a493b08bad6aab /etc/swift/account-server.conf #10.0.0.52 \\cp /etc/swift/account-server.conf{,.bak} grep '^[a-Z\\[]' /etc/swift/account-server.conf.bak > /etc/swift/account-server.conf openstack-config --set /etc/swift/account-server.conf DEFAULT bind_ip 10.0.0.52 openstack-config --set /etc/swift/account-server.conf DEFAULT bind_port 6202 openstack-config --set /etc/swift/account-server.conf DEFAULT user swift openstack-config --set /etc/swift/account-server.conf DEFAULT swift_dir /etc/swift openstack-config --set /etc/swift/account-server.conf DEFAULT devices /srv/node openstack-config --set /etc/swift/account-server.conf DEFAULT mount_check True openstack-config --set /etc/swift/account-server.conf filter:recon use egg:swift#recon openstack-config --set /etc/swift/account-server.conf filter:recon recon_cache_path /var/cache/swift MD5值 md5sum /etc/swift/account-server.conf 4896e265fa7f08cc0b3f71e9c0255647 /etc/swift/account-server.conf 9.5.4 编辑/etc/swift/container-server.conf文件并完成以下操作 1.在此[DEFAULT]部分中，配置绑定IP地址，绑定端口，用户，配置目录和安装点目录： 替换MANAGEMENT_INTERFACE_IP_ADDRESS为存储节点上管理网络的IP地址。 [DEFAULT] ... bind_ip = MANAGEMENT_INTERFACE_IP_ADDRESS bind_port = 6201 user = swift swift_dir = /etc/swift devices = /srv/node mount_check = True 2.在该[pipeline:main]部分中，启用适当的模块： 有关启用其他功能的其他模块的更多信息，请参考如下地址 https://docs.openstack.org/swift/latest/deployment_guide.html [pipeline:main] pipeline = healthcheck recon container-server 3.在该[filter:recon]部分中，配置侦察（计量）缓存目录： [filter:recon] use = egg:swift#recon ... recon_cache_path = /var/cache/swift #用以下命令修改 #10.0.0.51 \\cp /etc/swift/container-server.conf{,.bak} grep '^[a-Z\\[]' /etc/swift/container-server.conf.bak > /etc/swift/container-server.conf openstack-config --set /etc/swift/container-server.conf DEFAULT bind_ip 10.0.0.51 openstack-config --set /etc/swift/container-server.conf DEFAULT bind_port 6201 openstack-config --set /etc/swift/container-server.conf DEFAULT user swift openstack-config --set /etc/swift/container-server.conf DEFAULT swift_dir /etc/swift openstack-config --set /etc/swift/container-server.conf DEFAULT devices /srv/node openstack-config --set /etc/swift/container-server.conf DEFAULT mount_check True openstack-config --set /etc/swift/container-server.conf filter:recon use egg:swift#recon openstack-config --set /etc/swift/container-server.conf filter:recon recon_cache_path /var/cache/swift MD5值 md5sum /etc/swift/container-server.conf 8da5dc93bb2b4dcaf34dddf6244c5a50 /etc/swift/container-server.conf #10.0.0.52 \\cp /etc/swift/container-server.conf{,.bak} grep '^[a-Z\\[]' /etc/swift/container-server.conf.bak > /etc/swift/container-server.conf openstack-config --set /etc/swift/container-server.conf DEFAULT bind_ip 10.0.0.52 openstack-config --set /etc/swift/container-server.conf DEFAULT bind_port 6201 openstack-config --set /etc/swift/container-server.conf DEFAULT user swift openstack-config --set /etc/swift/container-server.conf DEFAULT swift_dir /etc/swift openstack-config --set /etc/swift/container-server.conf DEFAULT devices /srv/node openstack-config --set /etc/swift/container-server.conf DEFAULT mount_check True openstack-config --set /etc/swift/container-server.conf filter:recon use egg:swift#recon openstack-config --set /etc/swift/container-server.conf filter:recon recon_cache_path /var/cache/swift MD5值 md5sum /etc/swift/container-server.conf 027623ff6b9d87b218703efbdffe73ca /etc/swift/container-server.conf 9.5.5 编辑/etc/swift/object-server.conf文件并完成以下操作 1.在此[DEFAULT]部分中，配置绑定IP地址，绑定端口，用户，配置目录和安装点目录： 替换MANAGEMENT_INTERFACE_IP_ADDRESS为存储节点上管理网络的IP地址。 [DEFAULT] ... bind_ip = MANAGEMENT_INTERFACE_IP_ADDRESS bind_port = 6200 user = swift swift_dir = /etc/swift devices = /srv/node mount_check = True 2.在该[pipeline:main]部分中，启用适当的模块： 有关启用其他功能的其他模块的更多信息，请参考如下地址 https://docs.openstack.org/swift/latest/deployment_guide.html [pipeline:main] pipeline = healthcheck recon object-server 3.在此[filter:recon]部分中，配置侦察（仪表）缓存和锁定目录： [filter:recon] use = egg:swift#recon ... recon_cache_path = /var/cache/swift recon_lock_path = /var/lock #用以下命令修改 #10.0.0.51 \\cp /etc/swift/object-server.conf{,.bak} grep '^[a-Z\\[]' /etc/swift/object-server.conf.bak > /etc/swift/object-server.conf openstack-config --set /etc/swift/object-server.conf DEFAULT bind_ip 10.0.0.51 openstack-config --set /etc/swift/object-server.conf DEFAULT bind_port 6200 openstack-config --set /etc/swift/object-server.conf DEFAULT user swift openstack-config --set /etc/swift/object-server.conf DEFAULT swift_dir /etc/swift openstack-config --set /etc/swift/object-server.conf DEFAULT devices /srv/node openstack-config --set /etc/swift/object-server.conf DEFAULT mount_check True openstack-config --set /etc/swift/object-server.conf filter:recon use egg:swift#recon openstack-config --set /etc/swift/object-server.conf filter:recon recon_cache_path /var/cache/swift openstack-config --set /etc/swift/object-server.conf filter:recon recon_lock_path /var/lock MD5值 md5sum /etc/swift/object-server.conf a3decd3b7143c7255f732d5b8872f449 /etc/swift/object-server.conf #10.0.0.52 \\cp /etc/swift/object-server.conf{,.bak} grep '^[a-Z\\[]' /etc/swift/object-server.conf.bak > /etc/swift/object-server.conf openstack-config --set /etc/swift/object-server.conf DEFAULT bind_ip 10.0.0.52 openstack-config --set /etc/swift/object-server.conf DEFAULT bind_port 6200 openstack-config --set /etc/swift/object-server.conf DEFAULT user swift openstack-config --set /etc/swift/object-server.conf DEFAULT swift_dir /etc/swift openstack-config --set /etc/swift/object-server.conf DEFAULT devices /srv/node openstack-config --set /etc/swift/object-server.conf DEFAULT mount_check True openstack-config --set /etc/swift/object-server.conf filter:recon use egg:swift#recon openstack-config --set /etc/swift/object-server.conf filter:recon recon_cache_path /var/cache/swift openstack-config --set /etc/swift/object-server.conf filter:recon recon_lock_path /var/lock MD5值 md5sum /etc/swift/object-server.conf a8c6c63f0d34ea0b9edc1207f7326aa7 /etc/swift/object-server.conf 9.5.6 确保对安装点目录结构拥有适当的所有权 chown -R swift:swift /srv/node 9.5.7 创建recon目录并确保对其拥有适当的所有权 mkdir -p /var/cache/swift chown -R root:swift /var/cache/swift chmod -R 775 /var/cache/swift 9.6 创建和分发初始环 ⚠️在控制节点执行以下步骤 在启动对象存储服务之前，必须创建初始帐户，容器和对象环。环形构建器创建配置文件，每个节点都使用该配置文件来确定和部署存储体系结构。为简单起见，本指南使用一个区域和两个区域，最大分区为2 ^ 10（1024）个，每个对象3个副本，两次移动一个分区之间的最少间隔时间为1小时。对于对象存储，分区表示存储设备上的目录，而不是常规分区表。有关更多信息，请参见《 部署指南》。 9.7 创建帐户环 帐户服务器使用帐户环维护容器列表 9.7.1 ⚠️要切换到/etc/swift目录 cd /etc/swift 9.7.2 创建基础account.builder文件 swift-ring-builder account.builder create 10 3 1 9.7.3 将每个存储节点添加到环 官网示例 swift-ring-builder account.builder \\ add --region 1 --zone 1 --ip STORAGE_NODE_MANAGEMENT_INTERFACE_IP_ADDRESS --port 6202 \\ --device DEVICE_NAME --weight DEVICE_WEIGHT 替换STORAGE_NODE_MANAGEMENT_INTERFACE_IP_ADDRESS为存储节点上管理网络的IP地址。用DEVICE_NAME同一存储节点上的存储设备名称替换。例如，使用“ 安装”中的第一个存储节点并使用/dev/sdb存储设备和权重100 配置存储节点： 对每个存储节点上的每个存储设备重复此命令。在示例体系结构中，使用以下四个变体中的命令 $ swift-ring-builder account.builder add \\ --region 1 --zone 1 --ip 10.0.0.51 --port 6202 --device sdb --weight 100 Device d0r1z1-10.0.0.51:6202R10.0.0.51:6202/sdb_\"\" with 100.0 weight got id 0 $ swift-ring-builder account.builder add \\ --region 1 --zone 1 --ip 10.0.0.51 --port 6202 --device sdc --weight 100 Device d1r1z2-10.0.0.51:6202R10.0.0.51:6202/sdc_\"\" with 100.0 weight got id 1 $ swift-ring-builder account.builder add \\ --region 1 --zone 2 --ip 10.0.0.52 --port 6202 --device sdb --weight 100 Device d2r1z3-10.0.0.52:6202R10.0.0.52:6202/sdb_\"\" with 100.0 weight got id 2 $ swift-ring-builder account.builder add \\ --region 1 --zone 2 --ip 10.0.0.52 --port 6202 --device sdc --weight 100 Device d3r1z4-10.0.0.52:6202R10.0.0.52:6202/sdc_\"\" with 100.0 weight got id 3 9.7.4 验证 $ swift-ring-builder account.builder account.builder, build version 4, id 7fcd3aae59374c538cc6c368804c5102 1024 partitions, 3.000000 replicas, 1 regions, 2 zones, 4 devices, 100.00 balance, 0.00 dispersion The minimum number of hours before a partition can be reassigned is 1 (0:00:00 remaining) The overload factor is 0.00% (0.000000) Ring file account.ring.gz not found, probably it hasn't been written yet Devices: id region zone ip address:port replication ip:port name weight partitions balance flags meta 0 1 1 10.0.0.51:6202 10.0.0.51:6202 sdb 100.00 0 -100.00 1 1 1 10.0.0.51:6202 10.0.0.51:6202 sdc 100.00 0 -100.00 2 1 2 10.0.0.52:6202 10.0.0.52:6202 sdb 100.00 0 -100.00 3 1 2 10.0.0.52:6202 10.0.0.52:6202 sdc 100.00 0 -100.00 9.7.5 重新平衡权重 $ swift-ring-builder account.builder rebalance Reassigned 3072 (300.00%) partitions. Balance is now 0.00. Dispersion is now 0.00 9.8 创建容器环 容器服务器使用容器环维护对象列表。但是，它不跟踪对象位置 9.8.1 转到/etc/swift目录 cd /etc/swift 9.8.2 创建基础container.builder文件 swift-ring-builder container.builder create 10 3 1 9.8.3 将每个存储节点添加到环 官网示例 swift-ring-builder container.builder \\ add --region 1 --zone 1 --ip STORAGE_NODE_MANAGEMENT_INTERFACE_IP_ADDRESS --port 6201 --device DEVICE_NAME --weight DEVICE_WEIGHT 替换STORAGE_NODE_MANAGEMENT_INTERFACE_IP_ADDRESS为存储节点上管理网络的IP地址。用DEVICE_NAME同一存储节点上的存储设备名称替换。例如，使用“ 安装”中的第一个存储节点并使用/dev/sdb 存储设备和权重100 配置存储节点 对每个存储节点上的每个存储设备重复此命令。在示例体系结构中，使用以下四个变体中的命令 $ swift-ring-builder container.builder add \\ --region 1 --zone 1 --ip 10.0.0.51 --port 6201 --device sdb --weight 100 Device d0r1z1-10.0.0.51:6201R10.0.0.51:6201/sdb_\"\" with 100.0 weight got id 0 $ swift-ring-builder container.builder add \\ --region 1 --zone 1 --ip 10.0.0.51 --port 6201 --device sdc --weight 100 Device d1r1z2-10.0.0.51:6201R10.0.0.51:6201/sdc_\"\" with 100.0 weight got id 1 $ swift-ring-builder container.builder add \\ --region 1 --zone 2 --ip 10.0.0.52 --port 6201 --device sdb --weight 100 Device d2r1z3-10.0.0.52:6201R10.0.0.52:6201/sdb_\"\" with 100.0 weight got id 2 $ swift-ring-builder container.builder add \\ --region 1 --zone 2 --ip 10.0.0.52 --port 6201 --device sdc --weight 100 Device d3r1z4-10.0.0.52:6201R10.0.0.52:6201/sdc_\"\" with 100.0 weight got id 3 9.8.4 验证 $ swift-ring-builder container.builder container.builder, build version 4, id 72f47fcf245841f19ba211e19f3752f4 1024 partitions, 3.000000 replicas, 1 regions, 2 zones, 4 devices, 100.00 balance, 0.00 dispersion The minimum number of hours before a partition can be reassigned is 1 (0:00:00 remaining) The overload factor is 0.00% (0.000000) Ring file container.ring.gz not found, probably it hasn't been written yet Devices: id region zone ip address:port replication ip:port name weight partitions balance flags meta 0 1 1 10.0.0.51:6201 10.0.0.51:6201 sdb 100.00 0 -100.00 1 1 1 10.0.0.51:6201 10.0.0.51:6201 sdc 100.00 0 -100.00 2 1 2 10.0.0.52:6201 10.0.0.52:6201 sdb 100.00 0 -100.00 3 1 2 10.0.0.52:6201 10.0.0.52:6201 sdc 100.00 0 -100.00 9.8.5 重新平衡权重 $ swift-ring-builder container.builder rebalance Reassigned 3072 (300.00%) partitions. Balance is now 0.00. Dispersion is now 0.00 9.9 创建对象环 对象服务器使用对象环维护本地设备上对象位置的列表 9.9.1 转到/etc/swift目录 cd /etc/dwift 9.9.2 创建基础object.builder文件 swift-ring-builder object.builder create 10 3 1 9.9.3 将每个存储节点添加到环 官方示例 swift-ring-builder object.builder \\ add --region 1 --zone 1 --ip STORAGE_NODE_MANAGEMENT_INTERFACE_IP_ADDRESS --port 6200 --device DEVICE_NAME --weight DEVICE_WEIGHT 替换STORAGE_NODE_MANAGEMENT_INTERFACE_IP_ADDRESS为存储节点上管理网络的IP地址。用DEVICE_NAME同一存储节点上的存储设备名称替换。例如，使用“ 安装”中的第一个存储节点并使用/dev/sdb存储设备和权重100 配置存储节点 对每个存储节点上的每个存储设备重复此命令。在示例体系结构中，使用以下四个变体中的命令 $ swift-ring-builder object.builder add \\ --region 1 --zone 1 --ip 10.0.0.51 --port 6200 --device sdb --weight 100 Device d0r1z1-10.0.0.51:6200R10.0.0.51:6200/sdb_\"\" with 100.0 weight got id 0 $ swift-ring-builder object.builder add \\ --region 1 --zone 1 --ip 10.0.0.51 --port 6200 --device sdc --weight 100 Device d1r1z2-10.0.0.51:6200R10.0.0.51:6200/sdc_\"\" with 100.0 weight got id 1 $ swift-ring-builder object.builder add \\ --region 1 --zone 2 --ip 10.0.0.52 --port 6200 --device sdb --weight 100 Device d2r1z3-10.0.0.52:6200R10.0.0.52:6200/sdb_\"\" with 100.0 weight got id 2 $ swift-ring-builder object.builder add \\ --region 1 --zone 2 --ip 10.0.0.52 --port 6200 --device sdc --weight 100 Device d3r1z4-10.0.0.52:6200R10.0.0.52:6200/sdc_\"\" with 100.0 weight got id 3 9.9.4 验证 $ swift-ring-builder object.builder object.builder, build version 4, id 58129d88cd59455ea3c53172d05a5399 1024 partitions, 3.000000 replicas, 1 regions, 2 zones, 4 devices, 100.00 balance, 0.00 dispersion The minimum number of hours before a partition can be reassigned is 1 (0:00:00 remaining) The overload factor is 0.00% (0.000000) Ring file object.ring.gz not found, probably it hasn't been written yet Devices: id region zone ip address:port replication ip:port name weight partitions balance flags meta 0 1 1 10.0.0.51:6200 10.0.0.51:6200 sdb 100.00 0 -100.00 1 1 1 10.0.0.51:6200 10.0.0.51:6200 sdc 100.00 0 -100.00 2 1 2 10.0.0.52:6200 10.0.0.52:6200 sdb 100.00 0 -100.00 3 1 2 10.0.0.52:6200 10.0.0.52:6200 sdc 100.00 0 -100.00 9.9.5 重新平衡权重 $ swift-ring-builder object.builder rebalance Reassigned 3072 (300.00%) partitions. Balance is now 0.00. Dispersion is now 0.00 9.10 分发环网配置文件 拷贝account.ring.gz，container.ring.gz以及 object.ring.gz文件复制到/etc/swift每个存储节点和运行代理服务的任何其他节点上目录 scp /etc/swift/{account.ring.gz,container.ring.gz,object.ring.gz} object1:/etc/swift scp /etc/swift/{account.ring.gz,container.ring.gz,object.ring.gz} object2:/etc/swift 9.11 完成安装 rocky版对象存储服务swift完成安装官方文档 9.11.1 /etc/swift/swift.conf从对象存储源存储库中获取文件 ⚠️这一步在控制节点执行 #swift文件原先内容 $ cat /etc/swift/swift.conf [swift-hash] swift_hash_path_suffix = %SWIFT_HASH_PATH_SUFFIX% curl -o /etc/swift/swift.conf \\ https://opendev.org/openstack/swift/raw/branch/stable/rocky/etc/swift.conf-sample 9.11.2 编辑/etc/swift/swift.conf文件并完成以下操作 ⚠️这一步在控制节点执行 1.在该[swift-hash]部分中，为您的环境配置哈希路径前缀和后缀。用唯一值替换HASH_PATH_PREFIX和HASH_PATH_SUFFIX，请将这些值保密，不要更改或丢失它们 [swift-hash] ... swift_hash_path_suffix = HASH_PATH_SUFFIX swift_hash_path_prefix = HASH_PATH_PREFIX 2.在该[storage-policy:0]部分中，配置默认存储策略： [storage-policy:0] ... name = Policy-0 default = yes #用以下命令修改 \\cp /etc/swift/swift.conf{,.bak} grep '^[a-Z\\[]' /etc/swift/swift.conf.bak > /etc/swift/swift.conf openstack-config --set /etc/swift/swift.conf swift-hash swift_hash_path_suffix HASH_PATH_SUFFIX openstack-config --set /etc/swift/swift.conf swift-hash swift_hash_path_prefix HASH_PATH_PREFIX openstack-config --set /etc/swift/swift.conf storage-policy:0 name Policy-0 openstack-config --set /etc/swift/swift.conf storage-policy:0 default yes MD5值 md5sum /etc/swift/swift.conf 7fdc00e448c50b77fc703debf654d906 /etc/swift/swift.conf 9.11.3 将swift.conf文件复制到/etc/swift每个存储节点以及运行代理服务的所有其他节点上的目录中 ⚠️这一步在控制节点执行 scp /etc/swift/swift.conf object1:/etc/swift scp /etc/swift/swift.conf object2:/etc/swift 9.11.4 在所有节点上，确保对配置目录拥有适当的所有权 在控制节点和两个对象存储节点(51、52)执行 chown -R root:swift /etc/swift 9.11.5 在控制器节点和运行代理服务的任何其他节点上，启动对象存储代理服务及其相关性，并将它们配置为在系统启动时启动 ⚠️这一步在控制节点执行 systemctl enable openstack-swift-proxy.service memcached.service systemctl start openstack-swift-proxy.service memcached.service 9.11.6 在存储节点上，启动对象存储服务并将其配置为在系统引导时启动 两个对象存储节点(51、52)执行 systemctl enable openstack-swift-account \\ openstack-swift-account-auditor \\ openstack-swift-account-reaper \\ openstack-swift-account-replicator \\ openstack-swift-container \\ openstack-swift-container-auditor \\ openstack-swift-container-replicator \\ openstack-swift-container-updater \\ openstack-swift-object \\ openstack-swift-object-auditor \\ openstack-swift-object-replicator \\ openstack-swift-object-updater systemctl start openstack-swift-account \\ openstack-swift-account-auditor \\ openstack-swift-account-reaper \\ openstack-swift-account-replicator \\ openstack-swift-container \\ openstack-swift-container-auditor \\ openstack-swift-container-replicator \\ openstack-swift-container-updater \\ openstack-swift-object \\ openstack-swift-object-auditor \\ openstack-swift-object-replicator \\ openstack-swift-object-updater 9.12 验证操作 rocky版对象存储服务swift验证操作官方文档 在控制器上执行以下步骤 ⚠️⚠️⚠️ 如果您使用的是Red Hat Enterprise Linux 7或CentOS 7，并且其中一个或多个步骤不起作用，请检查该/var/log/audit/audit.log文件中是否有SELinux消息，表明该swift进程拒绝采取措施。如果存在，请将/srv/node目录的安全上下文更改为swift_data_t类型，object_r 角色和system_u用户的最低安全级别（s0）： chcon -R system_u:object_r:swift_data_t:s0 /srv/node 9.12.1 获取demo凭证 ⚠️⚠️⚠️这里不知道是什么原因(也肯能是我自己哪里出错了)，如果按照官方文档中加载demo凭证，那么在执行swift stat命令时会报错403权限拒绝，所以这里加载了admin凭证 source /opt/demo-openrc 9.12.2 显示服务状态 $ swift stat Account: AUTH_a8cb8e52e5a44288b2ac1a216195ee10 Containers: 0 Objects: 0 Bytes: 0 X-Put-Timestamp: 1590683616.82847 X-Timestamp: 1590683616.82847 X-Trans-Id: tx85844a798ed34d998b692-005ecfe7e0 Content-Type: text/plain; charset=utf-8 X-Openstack-Request-Id: tx85844a798ed34d998b692-005ecfe7e0 9.12.3 创建container1容器 openstack container create container1 +---------------------------------------+------------+------------------------------------+ | account | container | x-trans-id | +---------------------------------------+------------+------------------------------------+ | AUTH_a8cb8e52e5a44288b2ac1a216195ee10 | container1 | tx3e166ae00ded4264a0dbe-005ecfea29 | +---------------------------------------+------------+------------------------------------+ 9.12.4 将测试文件上传到container1容器 #需要创建一个测试文件 echo test >/tmp/test.txt $ openstack object create container1 /tmp/test.txt +---------------+------------+----------------------------------+ | object | container | etag | +---------------+------------+----------------------------------+ | /tmp/test.txt | container1 | d8e8fca2dc0f896fd7cb4cb0031ba249 | +---------------+------------+----------------------------------+ 9.12.5 列出container1容器中的文件 openstack object list container1 +---------------+ | Name | +---------------+ | /tmp/test.txt | +---------------+ 9.12.6 从container1容器下载测试文件 #先把本地的测试文件/tmp/test.txt删除 rm /tmp/test.txt #然后下载测试文件，能下载并且文件内容不变即为正确 openstack object save container1 /tmp/test.txt 到此，对象存储服务swift安装完成 rocky版更多服务参考这个官方文档 十、安装和配置备份服务(可选) 安装和配置备份服务。为简单起见，此配置使用“块存储”节点和“对象存储”（驱动程序）驱动程序，因此取决于“ 对象存储”服务。 在安装和配置备份服务之前，必须先安装和配置存储节点。 在块存储节点上执行以下步骤 10.1 安装软件包 yum -y install openstack-cinder 10.2 编辑/etc/cinder/cinder.conf文件并完成以下操作 在该[DEFAULT]部分中，配置备份选项： [DEFAULT] # ... backup_driver = cinder.backup.drivers.swift backup_swift_url = SWIFT_URL #用以下命令修改 openstack-config --set /etc/cinder/cinder.conf DEFAULT backup_driver cinder.backup.drivers.swift openstack-config --set /etc/cinder/cinder.conf DEFAULT backup_swift_url http://controller:8080/v1/AUTH_ee435c972a7a476cadbd2c9ad782c6f0 public的url每次都是不一样的 替换SWIFT_URL为对象存储服务的URL。可以通过显示对象库API端点来找到URL，在控制节点上执行命令openstack catalog show object-store openstack catalog show object-store +-----------+-----------------------------------------------------------------------------+ | Field | Value | +-----------+-----------------------------------------------------------------------------+ | endpoints | RegionOne | | | admin: http://controller:8080/v1 | | | RegionOne | | | public: http://controller:8080/v1/AUTH_a8cb8e52e5a44288b2ac1a216195ee10 | | | RegionOne | | | internal: http://controller:8080/v1/AUTH_a8cb8e52e5a44288b2ac1a216195ee10 | | | | | id | b5169189845a4fb1b80fe1ab06584ffc | | name | swift | | type | object-store | +-----------+-----------------------------------------------------------------------------+ 10.3 启动块存储备份服务，并将其配置为在系统启动时启动 systemctl enable openstack-cinder-backup.service systemctl start openstack-cinder-backup.service 到此块存储节点块存储备份服务安装完成！！！ 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/openstack/rocky/2.rocky版使用命令启动一个实例.html":{"url":"linux/openstack/rocky/2.rocky版使用命令启动一个实例.html","title":"rocky版使用命令启动一个实例","keywords":"","body":"rocky版使用命令启动一个实例 rocky版启动实例官方文档 因为选择的是提供商网络，即网络1，所以参考这个官方文档 1.创建网络 openstack network create 创建网络 --shared 创建共享网络 --provider-physical-network 指定物理网卡名称 provider网络标签 --provider-network-type 指定网络类型 flat是桥接网络 pptfz是网络名称 openstack network create --share --external \\ --provider-physical-network provider \\ --provider-network-type flat pptfz +---------------------------+--------------------------------------+ | Field | Value | +---------------------------+--------------------------------------+ | admin_state_up | UP | | availability_zone_hints | | | availability_zones | | | created_at | 2020-05-26T12:41:05Z | | description | | | dns_domain | None | | id | 26fa223a-231f-419a-a387-750d6eabf3fe | | ipv4_address_scope | None | | ipv6_address_scope | None | | is_default | None | | is_vlan_transparent | None | | mtu | 1500 | | name | pptfz | | port_security_enabled | True | | project_id | 108d3fecb61840e3818f694c69c3ec4a | | provider:network_type | flat | | provider:physical_network | provider | | provider:segmentation_id | None | | qos_policy_id | None | | revision_number | 1 | | router:external | External | | segments | None | | shared | True | | status | ACTIVE | | subnets | | | tags | | | updated_at | 2020-05-26T12:41:05Z | +---------------------------+--------------------------------------+ 2.创建一个子网 创建一个名为pptfz的子网，依据的网络是第一步中创建的网络pptfz openstack subnet create --network pptfz \\ --allocation-pool start=10.0.0.101,end=10.0.0.250 \\ --dns-nameserver 223.5.5.5 --gateway 10.0.0.1 \\ --subnet-range 10.0.0.0/24 pptfz +-------------------+--------------------------------------+ | Field | Value | +-------------------+--------------------------------------+ | allocation_pools | 10.0.0.101-10.0.0.250 | | cidr | 10.0.0.0/24 | | created_at | 2020-05-26T12:45:13Z | | description | | | dns_nameservers | 223.5.5.5 | | enable_dhcp | True | | gateway_ip | 10.0.0.1 | | host_routes | | | id | ad3d939a-866f-4b2b-9321-29e98fe64f26 | | ip_version | 4 | | ipv6_address_mode | None | | ipv6_ra_mode | None | | name | pptfz | | network_id | 26fa223a-231f-419a-a387-750d6eabf3fe | | project_id | 108d3fecb61840e3818f694c69c3ec4a | | revision_number | 0 | | segment_id | None | | service_types | | | subnetpool_id | None | | tags | | | updated_at | 2020-05-26T12:45:13Z | +-------------------+--------------------------------------+ 3.创建云主机的硬件配置方案 openstack flavor create --id 0 --vcpus 1 --ram 64 --disk 1 m1.nano +----------------------------+---------+ | Field | Value | +----------------------------+---------+ | OS-FLV-DISABLED:disabled | False | | OS-FLV-EXT-DATA:ephemeral | 0 | | disk | 1 | | id | 0 | | name | m1.nano | | os-flavor-access:is_public | True | | properties | | | ram | 64 | | rxtx_factor | 1.0 | | swap | | | vcpus | 1 | +----------------------------+---------+ #参数说明 flavor 硬件配置方案 --id 指定编号 --vcpus cpu个数 --ram 内存（单位：M） --disk 磁盘（单位：G） m1.nano 方案名称 #创建其余配置 openstack flavor create --id 1 --vcpus 1 --ram 512 --disk 5 m1.tiny1 openstack flavor create --id 2 --vcpus 1 --ram 1024 --disk 5 m1.tiny2 openstack flavor create --id 3 --vcpus 1 --ram 2048 --disk 10 m1.small openstack flavor create --id 4 --vcpus 2 --ram 4096 --disk 20 m1.medium 4.创建密钥对 ssh-keygen -q -N \"\" -f ~/.ssh/id_rsa && \\ openstack keypair create --public-key ~/.ssh/id_rsa.pub mykey +-------------+-------------------------------------------------+ | Field | Value | +-------------+-------------------------------------------------+ | fingerprint | 38:66:ea:65:c2:4d:50:3c:ee:b1:86:a2:2a:af:70:03 | | name | mykey | | user_id | a0d3db84d1984a24ac6ba213525fe382 | +-------------+-------------------------------------------------+ //参数说明 ssh-keygen -q -N \"\" -f ~/.ssh/id_rsa 非交互式生成密钥对 -q 安静模式 -N 指定加密密码 -f 密钥对存放位置 openstack keypair create --public-key ~/.ssh/id_rsa.pub mykey 上传密钥对 #验证密钥对的添加 openstack keypair list +-------+-------------------------------------------------+ | Name | Fingerprint | +-------+-------------------------------------------------+ | mykey | 38:66:ea:65:c2:4d:50:3c:ee:b1:86:a2:2a:af:70:03 | +-------+-------------------------------------------------+ 5.创建安全组规则 **默认情况下，default安全组适用于所有实例，并包括拒绝对实例进行远程访问的防火墙规则。 许可ICMP（ping） openstack security group rule create --proto icmp default +-------------------+--------------------------------------+ | Field | Value | +-------------------+--------------------------------------+ | created_at | 2020-05-26T12:53:35Z | | description | | | direction | ingress | | ether_type | IPv4 | | id | 838f15e5-7b23-42e3-aadc-a16887830efc | | name | None | | port_range_max | None | | port_range_min | None | | project_id | 108d3fecb61840e3818f694c69c3ec4a | | protocol | icmp | | remote_group_id | None | | remote_ip_prefix | 0.0.0.0/0 | | revision_number | 0 | | security_group_id | 04ea403e-40c7-4881-a8d7-e62825e6509c | | updated_at | 2020-05-26T12:53:35Z | +-------------------+--------------------------------------+ 允许安全外壳（SSH）访问 openstack security group rule create --proto tcp --dst-port 22 default +-------------------+--------------------------------------+ | Field | Value | +-------------------+--------------------------------------+ | created_at | 2020-05-26T12:53:49Z | | description | | | direction | ingress | | ether_type | IPv4 | | id | 5e7a6e16-14c7-4204-9651-52e0559a2a92 | | name | None | | port_range_max | 22 | | port_range_min | 22 | | project_id | 108d3fecb61840e3818f694c69c3ec4a | | protocol | tcp | | remote_group_id | None | | remote_ip_prefix | 0.0.0.0/0 | | revision_number | 0 | | security_group_id | 04ea403e-40c7-4881-a8d7-e62825e6509c | | updated_at | 2020-05-26T12:53:49Z | +-------------------+--------------------------------------+ 6.启动一个实例 6.1 确定实例的选项 6.1.1 在控制器节点上，demo获取凭据以访问仅用户的CLI命令 source /opt/demo-openrc 6.1.2 指定虚拟资源分配配置文件，其中包括处理器，内存和存储，列出可用的规格 openstack flavor list +----+-----------+------+------+-----------+-------+-----------+ | ID | Name | RAM | Disk | Ephemeral | VCPUs | Is Public | +----+-----------+------+------+-----------+-------+-----------+ | 0 | m1.nano | 64 | 1 | 0 | 1 | True | | 1 | m1.tiny1 | 512 | 5 | 0 | 1 | True | | 2 | m1.tiny2 | 1024 | 5 | 0 | 1 | True | | 3 | m1.small | 2048 | 10 | 0 | 1 | True | | 4 | m1.medium | 4096 | 20 | 0 | 2 | True | +----+-----------+------+------+-----------+-------+-----------+ 6.1.3 列出可用的镜像 openstack image list +--------------------------------------+--------+--------+ | ID | Name | Status | +--------------------------------------+--------+--------+ | 94c96aab-d0b3-4340-835c-9a97108d0554 | cirros | active | +--------------------------------------+--------+--------+ 6.1.4 列出可用的网络 openstack network list +--------------------------------------+-------+--------------------------------------+ | ID | Name | Subnets | +--------------------------------------+-------+--------------------------------------+ | 26fa223a-231f-419a-a387-750d6eabf3fe | pptfz | ad3d939a-866f-4b2b-9321-29e98fe64f26 | +--------------------------------------+-------+--------------------------------------+ 6.1.5 列出可用的安全组 openstack security group list +--------------------------------------+---------+------------------------+----------------------------------+------+ | ID | Name | Description | Project | Tags | +--------------------------------------+---------+------------------------+----------------------------------+------+ | e65b8ec1-3544-414c-94d0-2c87dd6eadbf | default | Default security group | 5b9ccd294c364cc68747df85f9598c89 | [] | +--------------------------------------+---------+------------------------+----------------------------------+------+ 6.2 启动一个实例 官网启动示例 openstack server create --flavor m1.nano --image cirros \\ --nic net-id=PROVIDER_NET_ID --security-group default \\ --key-name mykey provider-instance 启动实例过程中需要用到net-id，因此使用neutron net-list|awk 'NR==4{print $2}'获取 openstack server create --flavor m1.nano --image cirros \\ --nic net-id=`neutron net-list|awk 'NR==4{print $2}'` --security-group default \\ --key-name mykey pptfz neutron CLI is deprecated and will be removed in the future. Use openstack CLI instead. +-----------------------------+-----------------------------------------------+ | Field | Value | +-----------------------------+-----------------------------------------------+ | OS-DCF:diskConfig | MANUAL | | OS-EXT-AZ:availability_zone | | | OS-EXT-STS:power_state | NOSTATE | | OS-EXT-STS:task_state | scheduling | | OS-EXT-STS:vm_state | building | | OS-SRV-USG:launched_at | None | | OS-SRV-USG:terminated_at | None | | accessIPv4 | | | accessIPv6 | | | addresses | | | adminPass | jVR6on2EN7AX | | config_drive | | | created | 2020-05-26T13:08:14Z | | flavor | m1.nano (0) | | hostId | | | id | da4a32c7-e51e-4de0-b8a9-c0533db7e6fd | | image | cirros (94c96aab-d0b3-4340-835c-9a97108d0554) | | key_name | mykey | | name | pptfz | | progress | 0 | | project_id | 5b9ccd294c364cc68747df85f9598c89 | | properties | | | security_groups | name='e65b8ec1-3544-414c-94d0-2c87dd6eadbf' | | status | BUILD | | updated | 2020-05-26T13:08:14Z | | user_id | 82d945a092b44988af8d6e02ba2cc15c | | volumes_attached | | +-----------------------------+-----------------------------------------------+ 查看示例启动状态 openstack server list +--------------------------------------+-------+--------+------------------+--------+---------+ | ID | Name | Status | Networks | Image | Flavor | +--------------------------------------+-------+--------+------------------+--------+---------+ | 3191793e-055d-4417-bab5-df6c6574aaed | pptfz | ACTIVE | pptfz=10.0.0.113 | cirros | m1.nano | +--------------------------------------+-------+--------+------------------+--------+---------+ 创建成功后会在web界面展示 点击控制台登陆虚拟机 ⚠️点击控制台后提示找不到controller地址，因为没有做hosts解析，需要先做hosts解析 windows C:\\Windows\\System32\\drivers\\etc\\hosts 10.0.0.11 controller mac /etc/hosts 10.0.0.11 controller 解析完后刷新浏览器，会看到默认用户是cirros，密码是gocubsgo 查看主机名、IP地址、检查是否能联网 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/openstack/rocky/3.openstack rocky版手动增加一个计算节点.html":{"url":"linux/openstack/rocky/3.openstack rocky版手动增加一个计算节点.html","title":"openstack rocky版手动增加一个计算节点","keywords":"","body":"openstack rocky版手动增加一个计算节点 1.配置host解析 cat /etc/hosts 2.配置yum源 yum -y install centos-release-openstack-rocky yum -y install python-openstackclient 3.时间同步 1.安装chrony yum -y install chrony 2.编辑chrony配置文件/etc/chrony.conf /删除以下4行，指定控制节点为NTP服务器 server 0.centos.pool.ntp.org iburst server 1.centos.pool.ntp.org iburst server 2.centos.pool.ntp.org iburst server 3.centos.pool.ntp.org iburst 修改为 server controller iburst #用以下命令修改 sed -i '3,6d' /etc/chrony.conf && sed -i '3cserver controller iburst' /etc/chrony.conf 3.启动NTP服务并设置开机自启 systemctl enable chronyd && systemctl start chronyd 4.检查端口，监听udp323端口 $ netstat -nupl|grep chronyd udp 0 0 127.0.0.1:323 0.0.0.0:* 1327/chronyd udp6 0 0 ::1:323 :::* 1327/chronyd 5.验证，计算节点显示的是控制节点 $ chronyc sources 210 Number of sources = 1 MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^? controller 3 6 200 50 +1319ms[+1319ms] +/- 14.4s 4.安装软件包 yum -y install openstack-nova-compute openstack-utils 5.配置计算服务nova 5.1 编辑/etc/nova/nova.conf文件并完成以下操作 ⚠️compute2的IP地址为10.0.0.32 1.在此[DEFAULT]部分中，仅启用计算和元数据API [DEFAULT] # ... enabled_apis = osapi_compute,metadata 2.在该[DEFAULT]部分中，配置RabbitMQ消息队列访问： [DEFAULT] # ... transport_url = rabbit://openstack:RABBIT_PASS@controller 3.在[api]和[keystone_authtoken]部分中，配置身份服务访问： [api] # ... auth_strategy = keystone [keystone_authtoken] # ... auth_url = http://controller:5000/v3 memcached_servers = controller:11211 auth_type = password project_domain_name = Default user_domain_name = Default project_name = service username = nova password = NOVA_PASS 4.在该[DEFAULT]部分中，配置my_ip选项：MANAGEMENT_INTERFACE_IP_ADDRESS为计算节点上管理网络接口的IP地址 my_ip = MANAGEMENT_INTERFACE_IP_ADDRESS [DEFAULT] # ... my_ip = 10.0.0.32 5.在本[DEFAULT]节中，启用对网络服务的支持： [DEFAULT] # ... use_neutron = true firewall_driver = nova.virt.firewall.NoopFirewallDriver 6.在本[DEFAULT]节中，启用对网络服务的支持： [DEFAULT] # ... use_neutron = true firewall_driver = nova.virt.firewall.NoopFirewallDriver 7.在该[vnc]部分中，启用和配置远程控制台访问： [vnc] # ... enabled = true server_listen = 0.0.0.0 server_proxyclient_address = $my_ip novncproxy_base_url = http://controller:6080/vnc_auto.html 8.在该[glance]部分中，配置图像服务API的位置： [glance] # ... api_servers = http://controller:9292 9.在该[oslo_concurrency]部分中，配置锁定路径： [oslo_concurrency] # ... lock_path = /var/lib/nova/tmp 10.在该[placement]部分中，配置Placement API： [placement] # ... region_name = RegionOne project_domain_name = Default project_name = service auth_type = password user_domain_name = Default auth_url = http://controller:5000/v3 username = placement password = PLACEMENT_PASS #用以下命令修改 \\cp /etc/nova/nova.conf{,.bak} grep '^[a-Z\\[]' /etc/nova/nova.conf.bak >/etc/nova/nova.conf openstack-config --set /etc/nova/nova.conf DEFAULT enabled_apis osapi_compute,metadata openstack-config --set /etc/nova/nova.conf DEFAULT transport_url rabbit://openstack:RABBIT_PASS@controller openstack-config --set /etc/nova/nova.conf DEFAULT my_ip 10.0.0.32 openstack-config --set /etc/nova/nova.conf DEFAULT use_neutron true openstack-config --set /etc/nova/nova.conf DEFAULT firewall_driver nova.virt.firewall.NoopFirewallDriver openstack-config --set /etc/nova/nova.conf api auth_strategy keystone openstack-config --set /etc/nova/nova.conf keystone_authtoken auth_url http://controller:5000/v3 openstack-config --set /etc/nova/nova.conf keystone_authtoken memcached_servers controller:11211 openstack-config --set /etc/nova/nova.conf keystone_authtoken auth_type password openstack-config --set /etc/nova/nova.conf keystone_authtoken project_domain_name Default openstack-config --set /etc/nova/nova.conf keystone_authtoken user_domain_name Default openstack-config --set /etc/nova/nova.conf keystone_authtoken project_name service openstack-config --set /etc/nova/nova.conf keystone_authtoken username nova openstack-config --set /etc/nova/nova.conf keystone_authtoken password NOVA_PASS openstack-config --set /etc/nova/nova.conf vnc enabled true openstack-config --set /etc/nova/nova.conf vnc server_listen 0.0.0.0 openstack-config --set /etc/nova/nova.conf vnc server_proxyclient_address '$my_ip' openstack-config --set /etc/nova/nova.conf vnc novncproxy_base_url http://controller:6080/vnc_auto.html openstack-config --set /etc/nova/nova.conf glance api_servers http://controller:9292 openstack-config --set /etc/nova/nova.conf oslo_concurrency lock_path /var/lib/nova/tmp openstack-config --set /etc/nova/nova.conf placement region_name RegionOne openstack-config --set /etc/nova/nova.conf placement project_domain_name Default openstack-config --set /etc/nova/nova.conf placement project_name service openstack-config --set /etc/nova/nova.conf placement auth_type password openstack-config --set /etc/nova/nova.conf placement user_domain_name Default openstack-config --set /etc/nova/nova.conf placement auth_url http://controller:5000/v3 openstack-config --set /etc/nova/nova.conf placement username placement openstack-config --set /etc/nova/nova.conf placement password PLACEMENT_PASS MD5值 md5sum /etc/nova/nova.conf c348d4b98cb5dc08fb329050ef592d86 /etc/nova/nova.conf 5.2 启动Compute服务及其依赖项，并将它们配置为在系统引导时自动启动 systemctl enable libvirtd.service openstack-nova-compute.service && \\ systemctl start libvirtd.service openstack-nova-compute.service 6.配置网络服务neutron 6.1 安装包 yum -y install openstack-neutron-linuxbridge ebtables ipset openstack-utils 6.2 配置公共组件 编辑/etc/neutron/neutron.conf文件并完成以下操作 1.在该[DEFAULT]部分中，配置RabbitMQ 消息队列访问： [DEFAULT] # ... transport_url = rabbit://openstack:RABBIT_PASS@controller 2.在[DEFAULT]和[keystone_authtoken]部分中，配置身份服务访问： [DEFAULT] # ... auth_strategy = keystone [keystone_authtoken] # ... www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = NEUTRON_PASS 3.在该[oslo_concurrency]部分中，配置锁定路径： [oslo_concurrency] # ... lock_path = /var/lib/neutron/tmp #用以下命令修改 \\cp /etc/neutron/neutron.conf{,.bak} grep '^[a-Z\\[]' /etc/neutron/neutron.conf.bak >/etc/neutron/neutron.conf openstack-config --set /etc/neutron/neutron.conf DEFAULT transport_url rabbit://openstack:RABBIT_PASS@controller openstack-config --set /etc/neutron/neutron.conf DEFAULT auth_strategy keystone openstack-config --set /etc/neutron/neutron.conf keystone_authtoken www_authenticate_uri http://controller:5000 openstack-config --set /etc/neutron/neutron.conf keystone_authtoken auth_url http://controller:5000 openstack-config --set /etc/neutron/neutron.conf keystone_authtoken memcached_servers controller:11211 openstack-config --set /etc/neutron/neutron.conf keystone_authtoken auth_type password openstack-config --set /etc/neutron/neutron.conf keystone_authtoken project_domain_name default openstack-config --set /etc/neutron/neutron.conf keystone_authtoken user_domain_name default openstack-config --set /etc/neutron/neutron.conf keystone_authtoken project_name service openstack-config --set /etc/neutron/neutron.conf keystone_authtoken username neutron openstack-config --set /etc/neutron/neutron.conf keystone_authtoken password NEUTRON_PASS openstack-config --set /etc/neutron/neutron.conf oslo_concurrency lock_path /var/lib/neutron/tmp MD5值 md5sum /etc/neutron/neutron.conf 9c47ffb59b23516b59e7de84a39bcbe8 /etc/neutron/neutron.conf 6.3 配置网络选项 6.3.1 配置桥接代理 Linux网桥代理为实例构建第2层（桥接和交换）虚拟网络基础结构并处理安全组 编辑/etc/neutron/plugins/ml2/linuxbridge_agent.ini文件并完成以下操作 1.在本[linux_bridge]节中，将提供者虚拟网络映射到提供者物理网络接口： [linux_bridge] physical_interface_mappings = provider:PROVIDER_INTERFACE_NAME 替换PROVIDER_INTERFACE_NAME为基础提供商物理网络接口的名称。这里为eth0 2.在该[vxlan]部分中，禁用VXLAN覆盖网络： [vxlan] enable_vxlan = false 3.在该[securitygroup]部分中，启用安全组并配置Linux网桥iptables防火墙驱动程序： [securitygroup] # ... enable_security_group = true firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver #用以下命令修改 \\cp /etc/neutron/plugins/ml2/linuxbridge_agent.ini{,.bak} grep '^[a-Z\\[]' /etc/neutron/plugins/ml2/linuxbridge_agent.ini.bak >/etc/neutron/plugins/ml2/linuxbridge_agent.ini openstack-config --set /etc/neutron/plugins/ml2/linuxbridge_agent.ini linux_bridge physical_interface_mappings provider:eth0 openstack-config --set /etc/neutron/plugins/ml2/linuxbridge_agent.ini vxlan enable_vxlan false openstack-config --set /etc/neutron/plugins/ml2/linuxbridge_agent.ini securitygroup enable_security_group true openstack-config --set /etc/neutron/plugins/ml2/linuxbridge_agent.ini securitygroup firewall_driver neutron.agent.linux.iptables_firewall.IptablesFirewallDriver MD5值 md5sum /etc/neutron/plugins/ml2/linuxbridge_agent.ini 794b19995c83e2fc0c3fd42f506904f1 /etc/neutron/plugins/ml2/linuxbridge_agent.ini 使Linux操作系统内核支持网桥过滤器1 #向/etc/sysctl.d/openstack-rocky-bridge.conf写入以下内容 cat >> /etc/sysctl.d/openstack-rocky-bridge.conf 6.4 配置计算以使用网络 编辑/etc/nova/nova.conf文件并完成以下操作 在该[neutron]部分中，配置访问参数： [neutron] # ... url = http://controller:9696 auth_url = http://controller:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = NEUTRON_PASS #用以下命令修改 openstack-config --set /etc/nova/nova.conf neutron url http://controller:9696 openstack-config --set /etc/nova/nova.conf neutron auth_url http://controller:5000 openstack-config --set /etc/nova/nova.conf neutron auth_type password openstack-config --set /etc/nova/nova.conf neutron project_domain_name default openstack-config --set /etc/nova/nova.conf neutron user_domain_name default openstack-config --set /etc/nova/nova.conf neutron region_name RegionOne openstack-config --set /etc/nova/nova.conf neutron project_name service openstack-config --set /etc/nova/nova.conf neutron username neutron openstack-config --set /etc/nova/nova.conf neutron password NEUTRON_PASS MD5值 md5sum /etc/nova/nova.conf 6ba9c6b28eb8145e4bbec4d9942d1774 /etc/nova/nova.conf 6.5 完成安装 6.5.1 重新启动Compute服务 systemctl restart openstack-nova-compute.service 6.5.2 启动Linux网桥代理并将其配置为在系统引导时启动 systemctl enable neutron-linuxbridge-agent.service && \\ systemctl start neutron-linuxbridge-agent.service 6.6 验证 控制节点执行 有compute2输出并且状态为up即为正确 openstack network agent list +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | ID | Agent Type | Host | Availability Zone | Alive | State | Binary | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | 6f3e4e38-0d60-4fd7-b545-b6accccc728e | Linux bridge agent | compute2 | None | :-) | UP | neutron-linuxbridge-agent | | b627a998-e6d2-4cea-b6f1-773f0a294823 | DHCP agent | controller | nova | :-) | UP | neutron-dhcp-agent | | d2999370-36db-43c1-9fa8-dbdf9afcd118 | Linux bridge agent | compute1 | None | :-) | UP | neutron-linuxbridge-agent | | f6e6488d-2be8-425d-99ea-97974450cedf | Linux bridge agent | controller | None | :-) | UP | neutron-linuxbridge-agent | | fc7271f1-f214-4a17-bda7-ba340a61e0f9 | Metadata agent | controller | None | :-) | UP | neutron-metadata-agent | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ 7.验证计算节点是否可用 手动创建虚拟机并且指定调度到compute2 需要先创建分组，分组在dashboard中叫主机聚合 查看主机聚合 管理员-->计算-->主机聚合 创建主机聚合 创建一个名称为compute2的主机聚合，可用域也定义为compute2 点击管理聚合内的主机，选择compute2，然后创建主机聚合 创建完成之后可用域中就会多出一个compute2域 然后web界面创建虚拟机 项目-->计算-->实例-->创建实例 实例名称为compute2，可用域选择compute2 选择测试镜像ciiros 选择实例规格，然后点击创建实例 成功创建后的实例 进入实例控制台，使用用户cirros、密码gocubsgo登陆，然后sudo su -切换到root用户，设置root用户密码 接下来就可以使用远程连接工具连接虚拟机了 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/openstack/rocky/4.openstack 域、用户、项目、角色之间的关系.html":{"url":"linux/openstack/rocky/4.openstack 域、用户、项目、角色之间的关系.html","title":"openstack 域、用户、项目、角色之间的关系","keywords":"","body":"openstack 域、用户、项目、角色之间的关系 创建默认域 openstack domain create --description \"Default Domain\" default 创建管理项目 openstack project create --domain default \\ --description \"Admin Project\" admin 创建管理员用户 openstack user create --domain default \\ --password ADMIN_PASS admin 创建管理员角色 openstack role create admin 将admin角色添加到admin项目和用户 openstack role add --project admin --user admin admin 示意图 项目、用户、角色关联关系 在xx项目中给xx用户授予xx角色 openstack中会有一个default默认域，也可以创建其他的域 default域中会有admin项目、service项目，也可以创建自定义项目 default域中会有admin用户、服务用户，也可以创建自定义用户 默认的角色是管理员admin角色和普通角色`user角色` 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/openstack/rocky/5.glance镜像服务迁移.html":{"url":"linux/openstack/rocky/5.glance镜像服务迁移.html","title":"glance镜像服务迁移","keywords":"","body":"glance镜像服务迁移 1.迁移步骤 1、glance数据库迁移 2、在新机器上安装glance服务 3、迁移之前已有的镜像 4、在keystone上，修改glance服务的api地址 5、修改控制节点和计算节点nova配置文件中glance的api地址以及块存储节点中cinder配置文件中glance的api地址 6、上传新的镜像测试glance服务是否正常 7、启动一台新的虚拟机完成测试 2.迁移过程 2.1 控制节点导出glance数据库并拷贝到新机器 新机器的IP地址是10.0.0.10 #备份glance数据库 mysqldump -B glance >glance-db.sql #拷贝备份文件到新机器 scp -p glance-db.sql 10.0.0.10:~ 2.2 新机器配置hosts解析 cat >> /etc/hosts 2.3 新机器安装mariadb并设置开启自启 yum -y install mariadb mariadb-server python2-PyMySQL systemctl enable mariadb && systemctl start mariadb 2.4 新机器导入数据库glance-db.sql mysql 2.5 新机器给glance数据库授权 #用以下命令修改 mysql -e \"GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'localhost' \\ IDENTIFIED BY 'GLANCE_DBPASS';\" mysql -e \"GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'%' \\ IDENTIFIED BY 'GLANCE_DBPASS';\" 2.6 控制节点停止glance服务 systemctl stop openstack-glance-api openstack-glance-registry systemctl disable openstack-glance-api openstack-glance-registry 2.7 新机器安装glance yum -y install openstack-glance openstack-utils 2.8 新机器拷贝控制节点glance配置文件 scp -rp 10.0.0.11:/etc/glance/glance-api.conf /etc/glance scp -rp 10.0.0.11:/etc/glance/glance-registry.conf /etc/glance 2.9 新机器编辑glance配置文件/etc/glance/glance-api.conf，修改数据库连接 openstack-config --set /etc/glance/glance-api.conf database connection mysql+pymysql://glance:GLANCE_DBPASS@localhost/glance MD5值 md5sum /etc/glance/glance-api.conf 76d2be813471725c008245a9d135ea92 /etc/glance/glance-api.conf 2.10 新机器编辑glance配置文件/etc/glance/glance-registry.conf openstack-config --set /etc/glance/glance-registry.conf database connection mysql+pymysql://glance:GLANCE_DBPASS@localhost/glance md5sum /etc/glance/glance-registry.conf 7fefe761789d2d4d2afa3409b0e22bb0 /etc/glance/glance-registry.conf 2.11 新机器启动glance服务 glance-api 监听tcp/9292 glance-registry 监听tcp/9191 systemctl start openstack-glance-api openstack-glance-registry systemctl enable openstack-glance-api openstack-glance-registry 2.12 新机器拷贝控制节点/var/lib/glance/images下的镜像到本地的/var/lib/glance/images目录下 #如果使用scp的话，拷贝过来的镜像还需要手动修改镜像文件所有者为glance，拷贝过来的文件默认所有者是root rsync -avz 10.0.0.11:/var/lib/glance/images/* /var/lib/glance/images/ 2.13 控制节点上修改keystone中glance api的地址 keystone数据库中的endpoint表记录了各个api地址 2.13.1 备份keystone数据库中的endpoint表 mysqldump keystone endpoint > keystone-endpoint.sql 2.13.2 keystone数据库中的endpoint表记录了各api的地址，可以先查询一下endpoint表中有9292端口的记录 mysql keystone -e \"select * from endpoint where url like '%9292'\" +----------------------------------+--------------------+-----------+----------------------------------+------------------------+-------+---------+-----------+ | id | legacy_endpoint_id | interface | service_id | url | extra | enabled | region_id | +----------------------------------+--------------------+-----------+----------------------------------+------------------------+-------+---------+-----------+ | 0db3f8b44aff4501a3c866ba01bd546d | NULL | public | eb33b46815ba43a982fc39a9737efa7f | http://controller:9292 | {} | 1 | RegionOne | | 3119eb7c9e6e4bf98cf9b9738d53703d | NULL | admin | eb33b46815ba43a982fc39a9737efa7f | http://controller:9292 | {} | 1 | RegionOne | | 6382b60ec0a94472b6e68f8ecc1d13fe | NULL | internal | eb33b46815ba43a982fc39a9737efa7f | http://controller:9292 | {} | 1 | RegionOne | +----------------------------------+--------------------+-----------+----------------------------------+------------------------+-------+---------+-----------+ 2.13.3 然后修改这3条记录中的url mysql keystone -e \"update endpoint set url='http://10.0.0.10:9292' where url like '%9292'\" 2.13.4 再次查看9292相关记录 url中的地址修改为了10.0.0.10 mysql keystone -e \"select * from endpoint where url like '%9292'\" +----------------------------------+--------------------+-----------+----------------------------------+-----------------------+-------+---------+-----------+ | id | legacy_endpoint_id | interface | service_id | url | extra | enabled | region_id | +----------------------------------+--------------------+-----------+----------------------------------+-----------------------+-------+---------+-----------+ | 0db3f8b44aff4501a3c866ba01bd546d | NULL | public | eb33b46815ba43a982fc39a9737efa7f | http://10.0.0.10:9292 | {} | 1 | RegionOne | | 3119eb7c9e6e4bf98cf9b9738d53703d | NULL | admin | eb33b46815ba43a982fc39a9737efa7f | http://10.0.0.10:9292 | {} | 1 | RegionOne | | 6382b60ec0a94472b6e68f8ecc1d13fe | NULL | internal | eb33b46815ba43a982fc39a9737efa7f | http://10.0.0.10:9292 | {} | 1 | RegionOne | +----------------------------------+--------------------+-----------+----------------------------------+-----------------------+-------+---------+-----------+ 2.14 控制节点验证修改是否成功 openstack endpoint list|grep glance | 0db3f8b44aff4501a3c866ba01bd546d | RegionOne | glance | image | True | public | http://10.0.0.10:9292 | | 3119eb7c9e6e4bf98cf9b9738d53703d | RegionOne | glance | image | True | admin | http://10.0.0.10:9292 | | 6382b60ec0a94472b6e68f8ecc1d13fe | RegionOne | glance | image | True | internal | http://10.0.0.10:9292 2.15 控制节点、计算节点修改/etc/nova/nova.conf中glance的地址 1.修改nova配置文件 openstack-config --set /etc/nova/nova.conf glance api_servers http://10.0.0.10:9292 2.控制节点重启nova-api systemctl restart openstack-nova-api 3.计算节点重启nova-compute systemctl restart openstack-nova-compute 2.16 块存储节点修改配置文件/etc/cinder/cinder.conf中的glance api的地址 1.修改cinder配置文件中glance api地址 openstack-config --set /etc/cinder/cinder.conf DEFAULT glance_api_servers http://10.0.0.10:9292 2.重启cinder服务 systemctl restart openstack-cinder-volume.service target.service 2.17 最后web界面上传镜像并启动虚拟机测试 能成功上传镜像并能成功启动虚拟机即为成功 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/openstack/rocky/6.openstack中的卷.html":{"url":"linux/openstack/rocky/6.openstack中的卷.html","title":"openstack中的卷","keywords":"","body":"openstack中的卷 openstack中卷可以转换成镜像，镜像也可以转换成卷 在块存储节点上的配置文件/etc/lvm/lvm.conf中定义了使用lvm作为后端存储 a/sdb/代表一个lvm，a/sdc/代表另一个lvm，可以有多个磁盘做成lvm 在该devices部分中，添加一个接受/dev/sdb设备并拒绝所有其他设备的过滤 器： devices { ... filter = [ \"a/sdb/\", \"a/sdc/\", \"r/.*/\"] /etc/cinder/cinder.conf文件中关于后端存储的定义 enabled_backends = sata,ssd表示的是后端存储的名称，名称任意，这里使用/dev/sdb和/dev/sdc做了两个lvm，分别模拟普通的sata盘和较快速的固态硬盘(ssd) enabled_backends后边的任意名称会在配置文件中作为单独的一个区域存在，这个区域中的volume_backend_name会在后续创建卷的时候指定磁盘的类型，其中volume_backend_name是键，后边的sata和ssd是值，这样的话就能把普通磁盘和ssd磁盘区分开来并且给实例挂载不同的磁盘 #后段名称任意，这里我们定义为普通磁盘sata，固态硬盘ssd [DEFAULT] enabled_backends = sata,ssd [sata] volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver volume_group = cinder-volumes iscsi_protocol = iscsi iscsi_helper = lioadm volume_backend_name = sata [ssd] volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver volume_group = cinder-ssd iscsi_protocol = iscsi iscsi_helper = lioadm volume_backend_name = ssd 创建卷(没有卷) 项目-->卷-->卷-->创建卷 创建一个名为sata的卷 创建一个名为ssd的卷 创建后的卷 创建卷 管理员-->卷-->卷-->创建卷 创建sata和ssd卷 创建后的卷 创建卷扩展规格 点击创建后的卷-->查看扩展规格 点击已创建 创建卷扩展规格，写入配置文件中的键和值，这里示例了ssd，sata是同样的操作 键就是/etc/cinder/cinder.conf中enabled_backends对应的后端存储名称单独区域中的volume_backend_name #后段名称任意，这里我们定义为普通磁盘sata，固态硬盘ssd [DEFAULT] enabled_backends = sata,ssd [sata] volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver volume_group = cinder-volumes iscsi_protocol = iscsi iscsi_helper = lioadm volume_backend_name = sata [ssd] volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver volume_group = cinder-ssd iscsi_protocol = iscsi iscsi_helper = lioadm volume_backend_name = ssd 创建后的卷扩展规格 ssd sata 创建卷(有卷) 删除之前创建的没有卷的卷 创建sata类型的卷和ssd类型的卷 创建后的卷 给虚拟机关联卷 虚拟机中的初始磁盘，默认是1G大小 选择要连接卷的虚拟机，点击连接卷 选择一个卷连接 虚拟机中查看磁盘，发现会多了一个10G的磁盘 格式化后挂载 关于卷的安全性问题 上一步中把新关联的卷挂载到了/mnt，现在向新关联的卷写入一些内容 $ echo 'test ssd' > /mnt/test.txt $ cat /mnt/test.txt test ssd 然后在web界面查看卷的ID 项目-->卷-->卷-->点击ssd 在块存储节点上查看lv，可以看到volume-c1b20eb9-4e05-4fd6-816b-87d93c7cdcfb是对应的ssd卷 这个ssd的具体路径是/dev/mapper/cinder--ssd-volume--c1b20eb9--4e05--4fd6--816b--87d93c7cdcfb 当尝试挂载这个ssd时是不被允许的 [root@block1 ~]# mount /dev/mapper/cinder--ssd-volume--c1b20eb9--4e05--4fd6--816b--87d93c7cdcfb /opt mount: /dev/mapper/cinder--ssd-volume--c1b20eb9--4e05--4fd6--816b--87d93c7cdcfb is already mounted or /opt busy 可以采用先拷贝这个文件然后再挂载(cp、dd都可以) #拷贝目录 cp /dev/mapper/cinder--ssd-volume--c1b20eb9--4e05--4fd6--816b--87d93c7cdcfb /root #查看大小 [root@block1 ~]# ll -h total 10G -rw-r----- 1 root root 10G Jun 2 08:18 cinder--ssd-volume--c1b20eb9--4e05--4fd6--816b--87d93c7cdcfb #挂载 loop的意思是用来把一个文件当成硬盘分区mount到目录 mount -o loop cinder--ssd-volume--c1b20eb9--4e05--4fd6--816b--87d93c7cdcfb /mnt #进入/mnt目录，查看文件内容，此时是可以看见的 [root@block1 ~]# cd /mnt [root@block1 mnt]# ls lost+found test.txt [root@block1 mnt]# cat test.txt test ssd 计算节点上虚拟机中的磁盘是可以被拷贝到计算节点的，并且内容可见 把虚拟机启动在卷上 openstack中的虚拟机默认是启动在计算节点上的 点击实例名称，查看示例id 虚拟机的存放位置默认是计算节点中的/var/lib/nova/instances 选择创建新卷、删除实例时删除卷，并且指定卷大小 源中指定了卷大小为5G，所以这里要选择和卷大小相同规格的根磁盘 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/openstack/rocky/7.增加一个flat网络.html":{"url":"linux/openstack/rocky/7.增加一个flat网络.html","title":"增加flat网络","keywords":"","body":"增加一个flat网络 控制节点和计算节点增加一块网卡，配置另外一个网段 控制节点 编辑/etc/neutron/plugins/ml2/ml2_conf.ini #官方文档中默认只配置一个网段 [ml2_type_flat] flat_networks = provider #现在再增加一个网段，名称为net_172_16_1 [ml2_type_flat] flat_networks = provider,net_172_16_1 编辑/etc/neutron/plugins/ml2/linuxbridge_agent.ini #原先配置 [linux_bridge] physical_interface_mappings = provider:eth0 #现在再增加一个网段 [linux_bridge] physical_interface_mappings = provider:eth0,net_172_16_1:eth1 重启服务 systemctl restart neutron-server.service neutron-linuxbridge-agent.service neutron-dhcp-agent.service 计算节点 编辑/etc/neutron/plugins/ml2/linuxbridge_agent.ini #原先配置 [linux_bridge] physical_interface_mappings = provider:eth0 #改为如下 [linux_bridge] physical_interface_mappings = provider:eth0,net_172_16_1:eth1 重启服务 systemctl restart neutron-linuxbridge-agent.service 控制节点检查neutron服务是否正常 neutron agent-list neutron CLI is deprecated and will be removed in the future. Use openstack CLI instead. +--------------------------------------+--------------------+------------+-------------------+-------+----------------+---------------------------+ | id | agent_type | host | availability_zone | alive | admin_state_up | binary | +--------------------------------------+--------------------+------------+-------------------+-------+----------------+---------------------------+ | b627a998-e6d2-4cea-b6f1-773f0a294823 | DHCP agent | controller | nova | :-) | True | neutron-dhcp-agent | | d2999370-36db-43c1-9fa8-dbdf9afcd118 | Linux bridge agent | compute1 | | :-) | True | neutron-linuxbridge-agent | | f6e6488d-2be8-425d-99ea-97974450cedf | Linux bridge agent | controller | | :-) | True | neutron-linuxbridge-agent | | fc7271f1-f214-4a17-bda7-ba340a61e0f9 | Metadata agent | controller | | :-) | True | neutron-metadata-agent | +--------------------------------------+--------------------+------------+-------------------+-------+----------------+---------------------------+ 创建网络 openstack network create --share --external \\ --provider-physical-network net_172_16_1 \\ --provider-network-type flat net_172_16_1 创建子网 一个网络可以对应多个子网 openstack subnet create --network net_172_16_1 \\ --allocation-pool start=172.16.1.10,end=172.16.1.250 \\ --dns-nameserver 223.5.5.5 --gateway 172.16.1.1 \\ --subnet-range 172.16.1.0/24 net_172_16_1 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/nginx/1.centos7安装nginx.html":{"url":"linux/linux服务/nginx/1.centos7安装nginx.html","title":"nginx安装","keywords":"","body":"centos7安装nginx nginx官网 nginx github地址 一、源码编译安装 nginx官网总下载地址 nginx官方源码下载地址 nginx github下载地址 nginx官方源码安装文档 1.1 下载nginx源码包 wget https://nginx.org/download/nginx-1.17.9.tar.gz 1.2 编译安装nginx //创建nginx用户 useradd nginx -s /sbin/nologin -M //安装依赖包 yum -y install gcc gcc-c++ zlib zlib-devel openssl openssl-devel pcre-devel //解压缩源码包 tar xf nginx-1.17.9.tar.gz && cd nginx-1.17.9 //编译安装 ./configure \\ --prefix=/etc/nginx \\ --user=nginx \\ --group=nginx \\ --sbin-path=/usr/sbin/nginx \\ --conf-path=/etc/nginx/nginx.conf \\ --pid-path=/var/run/nginx.pid \\ --lock-path=/var/run/nginx.lock \\ --error-log-path=/var/log/nginx/error.log \\ --http-log-path=/var/log/nginx/access.log \\ --with-http_gzip_static_module \\ --with-http_stub_status_module \\ --with-http_ssl_module \\ --with-pcre \\ --with-file-aio \\ --with-http_realip_module \\ --without-http_scgi_module \\ --without-http_uwsgi_module \\ --without-http_fastcgi_module make && make install 编译参数说明 更多参数请使用./configure --help查看或者查看官方编译安装说明文档 参数 说明 --prefix nginx安装路径 --user nginx运行用户 --group nginx运行用户组 --sbin-path nginx可执行文件路径 --conf-path nginx配置文件路径 --pid-path nginx pid文件路径 --lock-path nginx锁文件路径 --error-log-path nginx错误日志路径 --http-log-path nginx访问日志路径 --with-http_gzip_static_module 支持.gz压缩文件 --with-http_stub_status_module 支持nginx基本状态信息访问 --with-http_ssl_module 支持nginx https --with-pcre 强制使用pcre库 --with-file-aio 支持异步IO --with-http_realip_module 将客户端地址更改为在指定的头字段中发送的地址 --without-http_scgi_module 禁止将请求传递到SCGI服务器 --without-http_uwsgi_module 禁止将请求传递到uwsgi服务器 --without-http_fastcgi_module 禁止将请求传递到FastCGI服务器 二、通过yum源安装 nginx yum源官方地址 nginx centos yum源官方地址 2.1 添加nginx官方yum源 cat > /etc/yum.repos.d/nginx.repo 2.2 安装nginx 2.3.1 安装最新版 yum -y install nginx 2.3.2 安装指定版本 查看可用版本 yum list nginx --showduplicates|sort -r 安装指定版本 yum -y install nginx-1.12.2 三、rpm包安装 3.1 下载rpm包 nginx rpm包官方下载地址 nginx centos rpm包官方下载地址 wget https://nginx.org/packages/rhel/7/x86_64/RPMS/nginx-1.18.0-1.el7.ngx.x86_64.rpm 3.2 安装 yum -y localinstall nginx-1.18.0-1.el7.ngx.x86_64.rpm 四、nginx配置文件主要模块 nginx主配置文件/etc/nginx/nginx.conf是一个纯文本类型的文件，整个配置文件是以区块的形式组织的。一般，每个区块以一对大括号{}来表示开始与结束。 模块分类 1.CoreModule 核心模块 2.EventModule 事件驱动模块 3.HttpCoreModule http内核模块 CoreModule层下可以有Event、HTTP HTTP模块层允许有多个Server层, Server主要用于配置多个网站 Server层又允许有多个Location, Location主要用于定义网站访问路径 CoreModule核心模块 user www; #Nginx进程所使用的用户 worker_processes 1; #启动的work进程数(CPU数量一致或auto) error_log /log/nginx/error.log #错误日志 pid /var/run/nginx.pid #Nginx服务启动后产生的pid进程号 events事件模块 events { worker_connections #每个worker进程支持的最大连接数 use #事件驱动模型, epoll默认 } http内核模块 #公共的配置定义在http{} http { #使用Server配置网站, 每个Server{}代表一个网站(简称虚拟主机) server { listen 80; #监听端口, 默认80 server_name localhost; #提供服务的域名或主机名 access_log host.access.log; #访问日志 #控制网站访问路径 location / { root /usr/share/nginx/html; #存放网站代码路径 index index.html index.htm; #服务器返回的默认页面文件 } #指定错误代码, 统一定义错误页面, 错误代码重定向到新的Locaiton error_page 500 502 503 504 /50x.html; } #第二个虚拟主机配置 server { } include /etc/nginx/conf.d/*.conf; #包含/etc/nginx/conf.d/目录下所有以.conf结尾的文件 } 五、nginx工作原理简介 Nginx WEB服务器最主要就是各种模块的工作，模块从结构上分为核心模块、基础模块和第三方模块，其中三类模块分别如下： 核心模块：HTTP模块、EVENT模块和MAIL模块等； 基础模块：HTTP Access模块、HTTP FastCGI模块、HTTP Proxy模块和HTTP Rewrite模块； 第三方模块：HTTP Upstream Request Hash模块、Notice模块和HTTP Access Key模块、Limit_req模块等； Nginx的模块从功能上分为如下三类。 Handlers（处理器模块）：此类模块直接处理请求，并进行输出内容和修改headers信息等操作，Handlers处理器模块一般只能有一个； Filters （过滤器模块）：此类模块主要对其他处理器模块输出的内容进行修改操作，最后由Nginx输出； Proxies （代理类模块）：此类模块是Nginx的HTTP Upstream之类的模块，这些模块主要与后端一些服务比如FastCGI等进行交互，实现服务代理和负载均衡等功能。 Nginx由内核和模块组成，其中内核的设计非常微小和简洁，完成的工作也非常简单，仅仅通过查找配置文件将客户端的请求映射到一个location block，而location是Nginx配置中的一个指令，用于访问的URL匹配，而在这个location中所配置的每个指令将会启动不同的模块去完成相应的工作，如图所示： Nginx的高并发得益于其采用了epoll模型，与传统的服务器程序架构不同，epoll是Linux内核2.6以后才出现的，Nginx采用epoll模型，异步非阻塞，而apache采用的是select模型： Select特点：select 选择句柄的时候，是遍历所有句柄，也就是说句柄有事件响应时，select需要遍历所有句柄才能获取到哪些句柄有事件通知，因此效率是非常低。 epoll的特点：epoll对于句柄事件的选择不是遍历的，是事件响应的，就是句柄上事件来就马上选择出来，不需要遍历整个句柄链表，因此效率非常高。 Nginx默认以80端口监听在服务器上，并且启动一个master进程，同时有master进程生成多个工作进程，当浏览器发起一个HTTP连接请求，每个进程都有可能处理这个连接，怎么做到的呢？怎么保证同一时刻一个HTTP请求被一个工作进程处理呢。 首先每个worker进程都是从Master进程fork出来，在Master进程里面，建立好需要listen的socket（listenfd）之后，会fork出多个worker进程。 所有worker进程的listenfd会在新连接到来时变得可读，为保证只有一个进程处理该连接，所有worker进程在注册listenfd读事件前抢accept_mutex，抢到互斥锁的那个进程注册listenfd读事件，在读事件里调用accept接受该连接。 当一个worker进程在accept这个连接之后，就开始读取请求、解析请求、处理请求，产生数据后，再返回给客户端，最后才断开连接，这样形成一个完整的请求流程。 管理员---->发送信号--->master进程---->worker进程客户端 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/nginx/2.http简要记录.html":{"url":"linux/linux服务/nginx/2.http简要记录.html","title":"http简要记录","keywords":"","body":"http简要记录 一、http（超文本传输协议） 由html文件 ->包含各种各样的元素（URL链接）->web页面 二、URL结构 http:// www.qq.com:80 /news/index.html 协议 域名: 端口 具体的文件名下面的某个页面 三、http的工作原理 1.客户端发起dns请求 2.获取到域名对应的IP地址 3.浏览器发起TCP的连接 4.基于TCP的连接，传输http的请求（一次TCP的连接，可以建立多次的http请求） 5.浏览器请求/index.html 6.服务器响应/index.html至浏览器 7.浏览器翻译index.html中的内容为人类可读 8.断开TCP连接-->四次挥手 http的短连接：建立一次tcp的连接，发起一次http的请求，结束，tcp断开 http的长连接：建立一次tcp的连接，发起多次http的请求，结束，tcp断开 四、http的请求方法 方法 描述 请求 响应 GET 用来请求访问已被URI识别的资源 指定的资源经服务器端解析后返回响应内容 GET /index.html HTTP/1.1 Host: www.baidu.com 返回index.html的页面资源 POST 用来传输实体的主体 虽然用GET方法也可以传输实体的主体，但一般不用GET方法进行传输，而是用POST方法 虽说POST的功能与GET相似，但POST的主要目的并不是获取响应的主体内容 POST /submit.cgi HTTP/1.1 Host: www.baidu.com Content-Length: 1500(1500字节的数据) 返回submit.cgi接收数据的处理结果 PUT 用来传输文件 就像FTP协议的文件上传一样，要求在请求报文的主体中包含文件的内容，然后保存到请求URI指定的位置 PUT /example.html HTTP/1.1 Host: www.baidu.com Content-Type: text/html Content-Length: 1560(1560字节的数据) 响应返回状态吗 204 No Content(比如：该html已存在于服务器上) HEAD 用于确认URI的有效性及资源更新的日期时间等，和GET方法一样，只是不返回报文主体部分 HEAD /index.html HTTP/1.1 Host: www.baidu.com 返回index.html有关的响应头部 DELETE 用来删除文件，是与PUT 相反的方法 按请求URI删除指定的资源 DELETE /example.html HTTP/1.1 Host: www.baidu.com 响应返回状态吗 204 No Content(比如：该html已存在于服务器上) OPTIONS 用来查询针对请求URI指定的资源支持的方法 OPTIONS * HTTP/1.1 Host: www.baidu.com HTTP/1.1 200 OK Allow: GET,POST,HEAD,OPTIONS(返回服务器支持的方法) TRACE 让web服务器端将之前的请求通信环回给客户端的方法 发送请求时，在Max-Forwards首部字段中填入数值，每经过一个服务端就将该数字减1，当数值刚好剑到0时就停止持续传输，最后接收到请求的服务端则返回状态码 200 OK 的响应 TRACE /HTTP/1.1 Host: www.baidu.com Max-Forwards: 2 HTTP/1.1 200 Ok Content-Type: message/http Content-Length: 1024 TRACE / HTTP/1.1 Host: www.baidu.com Max-Forwards: 2(返回响应包含请求内容) CONNECT 要求在与代理服务器通信时建立隧道，实现用隧道协议进行TCP通信，主要使用SSL和TLS协议把通信内容加密后经网络隧道传输 CONNECT proxy.sample.com:8000 HTTP/1.1 Host: proxy.sample.com HTTP/1.1 200 OK(之后进入网络隧道) 五、常见http的响应状态码（以3位数字组成） 状态码 说明 200 成功 301 永久重定向 302 临时重定向 304 浏览器缓存 401 权限认证失败 403 请求不到首页，权限被拒绝 404 资源找不到 500 服务器内部错误 502 错误的网关，找不到后端资源 504 请求超时 六、用户访问网站携带的参数，以及服务端返回的参数 概况 字段 说明 Request URL: http://www.abc.com/index.html 请求的URL地址 Request Method: GET 请求的方法（获取） Status Code: 304 Not Modified 返回的状态 Remote Address: www.abc.com:80 请求的地址 客户端请求的头部信息 字段 说明 Accept: text/html 请求的类型 Accept-Encoding: gzip, deflate 是否进行压缩 Accept-Language: zh-CN,zh;q=0.9 请求的语言 Cache-Control: max-age=0 缓存 Connection: keep-alive TCP长连接 Host: www.abc.com 请求的域名 If-Modified-Since: Fri, 05 May 2019 09:33:22 GMT 修改的时间 If-None-Match: \"a49-56b5ce607fe00\" 标记 Upgrade-Insecure-Requests:1 在http和https之间起的一个过渡作用 User-Agent: Mozilla/5.0 用户的浏览器 请求一个空行 服务端响应的头部信息 字段 说明 HTTP/1.1 304 Not Modified 返回服务器的http协议，状态码 Date: Fri, 15 Sep 2018 09:15:28 GMT 返回服务器的时间 Server: Apache/2.4.6 (CentOS) PHP/5.4.16 返回服务器使用的软件（Apache php） Connection: Keep-Alive TCP长连接 Keep-Alive: timeout=5, max=100 长连接的超时时间 ETag: \"a49-56b5ce607fe00\" 验证客户端标记 返回一个空行 xxx 返回页面内容 七、PV、UV、IP PV：页面浏览量 UV：独立的客户 IP：独立IP 示例说明 公司有100人，每个人有一台电脑一个手机，上网都是通过nat转换出口，每个人点击网站2次(假设点击一次返回的pv是1) PV：400 UV：200 IP：1个 八、用户访问网站的大体流程 1.客户端输入域名以及请求的页面 2.解析域名对应的dns 3.最终客户端浏览器获取到dns的IP地址 4.客户端会与服务端发起TCP的三次握手（长连接） 5.客户端发起http请求，请求会先抵达前端的防火墙 6.防火墙识别用户身份，正常的请求通过内部交换机通过TCP连接前端的负载均衡，然后传递用户的http请求 7.负载接收到请求，会根据请求的内容进行下发任务，通过TCP连接后端的web，然后下发用户的http请求 8.web接收到用户的http请求后，会根据用户请求的内容进行解析，解析分为如下两步： ​ 静态请求:由web服务器向nfs建立TCP连接，获取对应的图片，最后返回给负载均衡（负载均衡->防火墙->用户） ​ 动态请求:由web向后端的动态程序建立TCP连接，将用户的动态http请求传递给动态程序->由动态程序进行解析 9.动态程序在解析的过程中，如果碰到查询数据库的请求，则优先和缓存建立TCP的连接，然后缓存服务发起http的查询 10.如果缓存没有对应的数据，动态程序再次向数据库建立TCP的连接，然后发起查询操作 11.由数据库返回->动态程序->缓存->web服务->负载均衡->防火墙->用户 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/nginx/3.nginx基础应用.html":{"url":"linux/linux服务/nginx/3.nginx基础应用.html","title":"nginx基础应用","keywords":"","body":"nginx基础应用 一、nginx目录索引 加参数charset utf-8,gbk;解决中文乱码问题 autoindex 是否列出网站根目录(nginx默认是不允许列出整个目录浏览下载的，即autoindex off) 默认为off，禁止列出网站根目录内容 修改为on，列出网站根目录内容 编辑nginx配置文件 cat > /etc/nginx/conf.d/www.abc.com 检测nginx语法并重载nginx nginx -t nginx -s reload 创建网站根目录并创建文件 mkdir /website && cd /website touch {1..3}.txt 本机hosts解析，然后浏览器访问域名www.abc.com windows c:\\windows\\system32\\drivers\\etc mac /etc/hosts 当autoindex为off的时候是拒绝访问网站根目录的 当autoindex为on的时候是可以访问网站根目录的 autoindex_exact_size 是否显示文件的确切大小 默认为on， 显示出文件的确切大小，单位是bytes。 修改为off，显示出文件的大概大小，单位是kB或者MB或者GB 当autoindex_exact_size为on的时候，显示文件确切大小，单位是字节，显示如下 当autoindex_exact_size为off的时候，吸纳是文件的大概带下，单位是KB/MB/GB，显示如下 autoindex_localtime 显示文件修改时间或文件服务器时间 默认为off，显示的文件时间为GMT时间。 修改为on， 显示的文件时间为文件的服务器时间。 北京时间=GMT时间+8小时 当autoindex_localtime为off的时候，显示如下 当autoindex_localtime为on的时候，显示如下 ⚠️上传的文件显示的时间是文件的修改时间，与服务器时间没有关系，在服务器中创建的文件才是服务器的时间 配置站点目录浏览功能 在nginx配置文件中开启以下参数即可 location / { root /xxx; autoindex on; #列出根目录，默认off autoindex_localtime on; #显示文件时间为当前服务器时间，默认off autoindex_exact_size off; #显示文件确切大小，以人类易读的方式显示，默认on } 二、nginx状态监控 nginx中ngx_http_stub_status_module用于展示nginx连接状态信息, 需要--with-http_stub_status_module模块支持 2.1 检测nginx是否支持stub_status模块 使用命令nginx -V &>nginx.txt把nginx支持的模块信息放入到文件中，然后在文件中过滤--with-http_stub_status模块(rpm包或者yum安装的nginx都支持)，注意一定要写成&>，只写>不会有内容 nginx -V &> nginx.txt 2.2 配置nginx status location /nginx_status { stub_status; access_log off; } 2.3 浏览器访问域名/nginx_status 返回结果如下 各参数含义 Active connections:1 #当前活动的连接数 server accepts handled requests 21 21 27 21 #总的tcp连接数connection 21 #成功tcp连接数connection(失败连接=(总连接数-成功连接数)) 27 #总共处理的http请求数requests #keepalive_timeout 0; 每次连接都会产生一次请求(短连接) #keepalive_timeout 60; 在60s以内的请求建立在一个连接基础之上(长连接) Reading:0 Writing:1 Waiting: 0 Reading #请求 Writing #响应 Waiting #等待的请求数，开启了keepalive 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/nginx/4.nginx访问控制.html":{"url":"linux/linux服务/nginx/4.nginx访问控制.html","title":"nginx访问控制","keywords":"","body":"nginx访问控制 访问控制类别 基于IP的访问控制 http_access_module 基于用户登陆认证的访问控制 http_auth_basic_module 1.1 基于IP的访问控制 语法： allow|deny address 1.1.1 访问控制配置示例1， 拒绝指定的IP，其他全部允许 location /nginx_status { stub_status; access_log off; deny 10.0.0.51; allow all; } 10.0.0.51访问，权限拒绝 $ curl www.abc.com/nginx_status 403 Forbidden 403 Forbidden nginx/1.18.0 10.0.0.52访问，可以访问 $ curl www.abc.com/nginx_status Active connections: 1 server accepts handled requests 26 26 31 Reading: 0 Writing: 1 Waiting: 0 1.1.2 访问控制配置示例2，只允许谁能访问，其它全部拒绝 location / { root /website; index index.php index.html index.htm; allow 192.168.9.0/24; allow 10.0.0.51; deny all; } 10.0.0.51访问，可以访问 $ curl www.abc.com www.abc.com 的网站根目录 10.0.0.52访问，权限拒绝 $ curl www.abc.com 403 Forbidden 403 Forbidden nginx/1.18.0 http_access_module局限性 当客户端通过代理服务器访问真实的后端服务器时，通过remote_addr能获取到代理服务器的IP地址，但是无法获取客户端的IP地址 在nginx主配置文件/etc/nginx/nginx.conf中访问日志格式有如下定义 log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; nginx访问日志/var/log/nginx/access.log中如下，可以看到使用$remote_addr可以获取直接访问后端真实web的代理服务器的IP，但是最后边的\"-\"表明无法获取真实客户端的IP 10.0.0.51 - - [16/Jun/2020:00:27:30 +0800] \"GET / HTTP/1.0\" 200 10 \"-\" \"curl/7.29.0\" \"-\" 现在在代理服务器和后端真实web中的nginx头文件proxy_params中加上参数X-Forwarded-For以获取客户端真实IP，然后模拟访问过程如下 客户端10.0.0.10-->通过代理服务器10.0.0.51-->访问后端真实web 10.0.0.52 代理服务器10.0.0.51 nginx配置 #编辑nginx反向代理配置文件 cat > /etc/nginx/conf.d/www.abc.com.conf /etc/nginx/proxy_params 后端真实web 10.0.0.52操作 #编辑nginx配置文件 cat > /etc/nginx/conf.d/www.abc.com.conf /etc/nginx/proxy_params /website/index.html 加上X-Forwarded-For参数后，nginx的访问日志中就可以获取到客户端的真实IP地址了 10.0.0.51 - - [16/Jun/2020:10:35:12 +0800] \"GET / HTTP/1.0\" 200 10 \"-\" \"curl/7.29.0\" \"10.0.0.10\" 1.2 基于用户登陆认证的访问控制 可在http、server、location下添加如下内容即可 auth_basic \"Auth access down Input your Passwd!\"; auth_basic_user_file /etc/nginx/auth_file; 配置示例 #安装包 yum -y install httpd-tools #创建一个用户名为test密码为123的登陆认证用户，同时将密码存放于/etc/nginx/auth_conf htpasswd -b -c /etc/nginx/auth_file test 123 #编辑nginx配置文件 location / { root /website; auth_basic \"Auth access down Input your Passwd!\"; auth_basic_user_file /etc/nginx/auth_file; autoindex on; autoindex_exact_size off; autoindex_localtime on; charset utf-8,gbk; index index.php index.html index.htm; } 浏览器访问提示需要输入用户名和密码 1.3 基于配置参数的访问控制 限制对http资源访问的官方文档 ngx_http_limit_conn_module模块可以根据定义的key来限制每个键值的连接数 因为一次tcp连接可以建立多次http请求连接，因此http请求连接要比tcp连接限制更准确 limit_conn_module 连接频率限制，TCP连接 limit_req_module 请求频率限制，http请求连接 http协议的连接与请求 HTTP是建立在TCP连接之上, 在完成HTTP请求需要先建立TCP三次握手（称为TCP连接）,在连接的基础上再发起HTTP请求。 HTTP请求建立在一次TCP连接基础上，一次TCP请求至少产生一次HTTP请求 1.3.1 nginx连接限制配置 limit_conn_module 配置示例 #在nginx主配置文件/etc/nginx/nginx.con中http模块下加入limit_conn_zone http { #http段配置连接限制, 同一时刻只允许一个客户端IP连接 limit_conn_zone $binary_remote_addr zone=conn_zone:10m; } #在/etc/nginx.conf.d/xxx.conf中加入limit_conn server { location / { #同一时刻只允许一个客户端IP连接 limit_conn conn_zone 1; } } 1.3.2 nginx请求限制配置 limit_req_module 配置示例 #在nginx主配置文件/etc/nginx/nginx.con中http模块下加入limit_req_module http { #http段配置连接限制, 1r/s只接收一个请求,其余请求拒绝处理并返回错误码给客户端 limit_req_zone $binary_remote_addr zone=req_zone:10m rate=1r/s; } #在/etc/nginx.conf.d/xxx.conf中加入limit_req server { location / { #1r/s只接收一个请求，其余请求拒绝处理并返回错误码给客户端 #limit_req zone=req_zone; #请求超过1r/s，剩下的将被延迟处理，请求数超过burst定义的数量，多余的请求返回503 limit_req zone=req_zone burst=3 nodelay; } } 在终端中快速重复访问，就可以看到有503的报错 [root@test1 ~]# curl www.abc.com www.abc.com 的网站根目录 [root@test1 ~]# curl www.abc.com www.abc.com 的网站根目录 [root@test1 ~]# curl www.abc.com 503 Service Temporarily Unavailable 503 Service Temporarily Unavailable nginx/1.18.0 www.abc.com 的网站根目录 也可以用ab简单压测一下 -n 指定数量 -c 指定并发数 可以看到请求数是50，失败的数量是46，因为配置文件中请求限制为1r/s，burst=3，因此成功数量是4 $ ab -n 50 -c 10 www.abc.com/index.html This is ApacheBench, Version 2.3 Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking www.abc.com (be patient).....done Server Software: nginx/1.18.0 Server Hostname: www.abc.com Server Port: 80 Document Path: /index.html Document Length: 31 bytes Concurrency Level: 10 Time taken for tests: 0.005 seconds Complete requests: 50 Failed requests: 46 (Connect: 0, Receive: 0, Length: 46, Exceptions: 0) Write errors: 0 Non-2xx responses: 46 Total transferred: 18972 bytes HTML transferred: 9186 bytes Requests per second: 10066.44 [#/sec] (mean) Time per request: 0.993 [ms] (mean) Time per request: 0.099 [ms] (mean, across all concurrent requests) Transfer rate: 3730.09 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 0.1 0 0 Processing: 0 1 0.1 1 1 Waiting: 0 0 0.1 0 1 Total: 1 1 0.1 1 1 Percentage of the requests served within a certain time (ms) 50% 1 66% 1 75% 1 80% 1 90% 1 95% 1 98% 1 99% 1 100% 1 (longest request) 连接限制没有请求限制有效? http多个请求可以建立在一次TCP连接之上, 那么我们对请求的精度限制，要比对一个连接的限制会更加的有效。 因为同一时刻只允许一个连接请求进入。 但是同一时刻多个请求可以通过一个连接进入。 所以请求限制才是比较优的解决方案。 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/nginx/5.nginx日志.html":{"url":"linux/linux服务/nginx/5.nginx日志.html","title":"nginx日志","keywords":"","body":"nginx日志 nginx日志官方文档 access_log指令 Syntax: access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]];access_log off; Default: access_log logs/access.log combined; Context: http, server, location, if in location, limit_except 设置缓冲日志写入的路径、格式和配置。可以在同一级别指定多个日志。可以通过在第一个参数中指定“syslog:”前缀来配置登录到syslog。特殊值off取消当前级别上的所有access_log指令。如果未指定格式，则使用预定义的“组合”格式。 如果使用buffer或gzip(1.3.10, 1.2.7)参数，写入日志将被缓冲。 缓冲区的大小不能超过对磁盘文件的原子写入的大小。对于FreeBSD，这个大小是无限制的。 当启用缓冲时，数据将写入文件: 如果缓冲区无法容纳下一个日志行; 如果缓冲数据比刷新参数(1.3.10,1.2.7)指定的早; 工作进程重新打开日志文件或关闭日志文件时。 如果使用了gzip参数，那么缓冲数据将在写入文件之前被压缩。压缩级别可以设置在1(最快，较少压缩)和9(最慢，最好压缩)之间。默认情况下，缓冲区大小为64K字节，压缩级别设置为1。由于数据是在原子块中压缩的，所以“zcat”可以在任何时候解压或读取日志文件。 示例: access_log /path/to/log.gz combined gzip flush=5m; 为了使gzip压缩正常工作，必须使用zlib库构建nginx。 文件路径可以包含变量(0.7.6+)，但是这样的日志有一些约束: 工作进程使用其凭证的用户应该有权限在具有此类日志的目录中创建文件; 缓冲写不工作; 每次写日志时，都会打开和关闭该文件。但是，由于常用文件的描述符可以存储在缓存中，所以可以在open_log_file_cache指令的有效参数指定的时间内继续写入旧文件 在每个日志写期间，会检查请求的根目录是否存在，如果它不存在，就不会创建日志。因此，在同一个级别上同时指定 root 和access_log是一个好主意: server { root /spool/vhost/data/$host; access_log /spool/vhost/logs/$host; ... } if参数(1.7.0)支持条件日志记录。如果条件的计算结果为“0”或空字符串，则不会记录请求。在下面的示例中，响应码为2xx和3xx的请求将不被记录: map $status $loggable { ~^[23] 0; default 1; } access_log /path/to/access.log combined if=$loggable; log_format指令 Syntax: log_format name [escape=default Default: log_format combined \"...\"; Context: http 指定日志格式。 转义参数(1.11.8)允许在变量中设置json或默认转义字符，默认情况下，使用默认转义。none值(1.13.10)禁止转义。 对于默认转义，字符\" \" \" \"，\" \\ \"和值小于32(0.7.0)或大于126(1.1.6)的字符被转义为\" \\xXX \"。如果没有找到变量值，将记录一个连字符(\" - \")。 对于json转义，json字符串中不允许的所有字符都将进行转义:字符“”和“\\”将转义为“\\”和“\\”，值小于32的字符将转义为“\\n”、“\\r”、“\\t”、“\\b”、“\\f”或“\\u00XX”。 日志格式可以包含常见的变量，以及只在写日志时存在的变量: #相关字段含义 $bytes_sent #发送给客户端的字节数 $connection #连接序列号 $connection_requests #当前通过连接发出的请求数（1.1.18） $mse #日志写入时的时间（以毫秒为单位），以毫秒为单位 $pipe #“ p”（如果请求已传递），.否则为“ ” $request_length #请求长度（包括请求行，标头和请求正文） $request_time #以毫秒为单位请求处理时间，以毫秒为单位；从客户端读取第一个字节到将最后一个字节发送到客户端后的日志写入之间经过的时间 $status #反应状态 $time_iso8601 #ISO 8601标准格式的当地时间 $time_local #通用日志格式的本地时间 发送给客户端的头行具有“senthttp”前缀，例如$sent_http_content_range。 配置总是包括预定义的“组合”格式: log_format combined '$remote_addr - $remote_user [$time_local] ' '\"$request\" $status $body_bytes_sent ' '\"$http_referer\" \"$http_user_agent\"'; open_log_file_cache指令 Syntax: open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time];open_log_file_cache off; Default: open_log_file_cache off; Context: http, server, location 定义一个缓存，用于存储名称中包含变量的常用日志的文件描述符。指令有以下参数: max #设置缓存中描述符的最大数量；如果缓存已满，则关闭最近最少使用（LRU）描述符 inactive #设置在此期间如果没有访问权限则关闭缓存的描述符的时间；默认情况下为10秒 min_uses #设置在inactive参数定义的时间内文件的最小使用量，以使描述符在缓存中保持打开状态；默认情况下，1 valid #设置时间，在该时间后应检查文件是否仍然具有相同名称；默认情况下为60秒 off #禁用缓存 用法示例 open_log_file_cache max=1000 inactive=20s valid=1m min_uses=2; nginx默认日志格式 log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log /var/log/nginx/access.log main; 各字段含义 字段 说明 对应真实日志内容 $remote_addr 记录客户端IP地址 10.0.0.51 $remote_user 记录客户端用户名称 - - $time_local 通用日志格式下的本地时间 [16/Jun/2020:10:35:12 +0800] $request 记录请求的URL和HTTP协议 \"GET / HTTP/1.0\" $status 记录请求状态码 200 $body_bytes_sent 发送给客户端的字节数，不包括响应头的大小 10 $http_referer 记录从哪个页面链接访问过来的 \"-\" $http_user_agent 记录客户端浏览器相关信息 \"curl/7.29.0\" $http_x_forwarded_for 记录客户端真实IP地址 \"10.0.0.10\" 真实日志内容 10.0.0.51 - - [16/Jun/2020:10:35:12 +0800] \"GET / HTTP/1.0\" 200 10 \"-\" \"curl/7.29.0\" \"10.0.0.10\" 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/nginx/6.nginx代理.html":{"url":"linux/linux服务/nginx/6.nginx代理.html","title":"nginx代理","keywords":"","body":"nginx代理 nginx反向代理官方文档 一、代理分类 nginx代理分为正向代理和反向代理 正向代理代理的对象是客户端 反向代理代理的对象是服务端 正向代理 概念 在如今的网络环境下，我们如果由于技术需要要去访问国外的某些网站，此时你会发现位于国外的某网站我们通过浏览器是没有办法访问的，此时大家可能都会用一个操作FQ进行访问，FQ的方式主要是找到一个可以访问国外网站的代理服务器，我们将请求发送给代理服务器，代理服务器去访问国外的网站，然后将访问到的数据传递给我们！ 上述这样的代理模式称为正向代理，正向代理最大的特点是客户端非常明确要访问的服务器地址；服务器只清楚请求来自哪个代理服务器，而不清楚来自哪个具体的客户端；正向代理模式屏蔽或者隐藏了真实客户端信息。 示意图 反向代理 概念 多个客户端给nginx服务器发送请求，nginx服务器接收到请求之后，按照一定的规则分发给了后端的业务处理服务器进行处理。此时请求的来源也就是客户端是明确的，但是请求具体由哪台服务器处理的就不明确了，nginx扮演的就是一个反向代理角色 反向代理，主要用于服务器集群分布式部署的情况下，反向代理隐藏了服务器的信息！ 示意图 项目场景 通常情况下，我们在实际项目操作时，正向代理和反向代理很有可能会存在在一个应用场景中，正向代理代理客户端的请求去访问目标服务器，目标服务器是一个反向代理服务器，反向代理了多台真实的业务处理服务器。公司的生产环境就是如下图所示，公司的核心业务SASS平台是这样的流程 域名解析到了阿里云的SLB，通过SLB把请求分发到公司公共nginx(两台ECS)，然后又在公共nginx上配置了具体的转发规则(location的匹配，upstream等)，最后把请求的流量转发到ECS中，下图中的正向代理就相当于我们的SLB，反向代理就相当于我们的公共nginx，业务服务器就相当于后端的真实web服务ECS 具体的拓扑图如下 二、nginx代理配置相关 语法 Syntax: proxy_pass URL; Default: — Context: location, if in location, limit_except 2.1 将请求传递到代理服务器 当NGINX代理请求时，它将请求发送到指定的代理服务器，获取响应，然后将其发送回客户端。可以使用指定协议将请求代理到HTTP服务器（另一个NGINX服务器或任何其他服务器）或非HTTP服务器（可以运行使用特定框架开发的应用程序，例如PHP或Python）。支持的协议包括FastCGI，uwsgi，SCGI和memcached。 要将请求传递到HTTP代理服务器，请在proxy_pass中指定指令location。例如： location /some/path/ { proxy_pass http://www.example.com/link/; } 此示例配置结果将在此位置处理的所有请求传递到指定地址的代理服务器。此地址可以指定为域名或IP地址。地址还可以包括一个端口: location ~ \\.php { proxy_pass http://127.0.0.1:8000; } 注意，在上面的第一个示例中，代理服务器的地址后跟URI /link/。如果URI与地址一起指定，它将替换与位置参数匹配的请求URI部分。例如，这里带有/some/path/page.html URI的请求将被代理到http://www.example.com/link/page.html。如果指定的地址没有URI，或者无法确定要替换的URI部分，则传递(可能是修改)完整的请求URI。 要将请求传递到非HTTP代理服务器，**_pass应使用适当的指令 fastcgi_pass 将请求传递给FastCGI服务器 uwsgi_pass 将请求传递给uwsgi服务器 scgi_pass 将请求传递给SCGI服务器 memcached_pass 将请求传递到内存缓存服务器 请注意，在这些情况下，用于指定地址的规则可能会有所不同。您可能还需要将其他参数传递给服务器（有关更多详细信息，请参见参考文档）。 该proxy_pass指令还可以指向服务器的命名组。在这种情况下，将根据指定的方法在组中的服务器之间分配请求。 代理到后端的TCP连接、响应、返回等超时时间 #nginx代理与后端服务器连接超时时间(代理连接超时) Syntax: proxy_connect_timeout time; Default: proxy_connect_timeout 60s; Context: http, server, location #nginx代理等待后端服务器的响应时间 Syntax: proxy_read_timeout time; Default: proxy_read_timeout 60s; Context: http, server, location #后端服务器数据回传给nginx代理超时时间 Syntax: proxy_send_timeout time; Default: proxy_send_timeout 60s; Context: http, server, location 2.2 传递请求头 默认情况下，NGINX在代理请求中重新定义两个头字段“ Host”和“ Connection”，并消除其值为空字符串的标头字段。“主机”设置为$proxy_host变量，“连接”设置为close。 要更改这些设置以及修改其他标题字段，请使用proxy_set_header伪指令。可以在location或更高版本中指定此指令。也可以在特定server上下文或http块中指定。例如： location /some/path/ { proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_pass http://localhost:8000; } 在此配置中，“主机”字段设置为$host变量。 为了防止将头字段传递给代理服务器，请按以下步骤将其设置为空字符串： location /some/path/ { proxy_set_header Accept-Encoding \"\"; proxy_pass http://localhost:8000; } 添加发往后端服务器的请求头信息 #用户请求的时候HOST的值是www.abc.com, 那么代理服务会像后端传递请求的还是www.abc.com proxy_set_header Host $http_host; #将$remote_addr的值放进变量X-Real-IP中，$remote_addr的值为客户端的ip proxy_set_header X-Real-IP $remote_addr; #客户端通过代理服务访问后端服务, 后端服务通过该变量会记录真实客户端地址 proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 2.3 配置缓冲区 默认情况下，NGINX缓冲来自代理服务器的响应。响应存储在内部缓冲区中，直到接收到整个响应后才发送给客户端。缓冲有助于优化慢速客户端的性能，如果响应从NGINX同步传递到客户端，则这可能会浪费代理服务器的时间。但是，启用缓冲后，NGINX允许代理服务器快速处理响应，而NGINX将响应存储的时间与客户端下载响应所需的时间一样长。 负责启用和禁用缓冲的指令是proxy_buffering。默认情况下将其设置为on并启用缓冲。 该proxy_buffers指令控制规模和分配的请求缓冲区的数目。来自代理服务器的响应的第一部分存储在单独的缓冲区中，缓冲区的大小由proxy_buffer_size伪指令设置。这部分通常包含一个相对较小的响应头，并且可以使其小于其余响应的缓冲区。 在以下示例中，增加了默认缓冲区数，并使响应第一部分的缓冲区大小小于默认值。 location /some/path/ { proxy_buffers 16 4k; proxy_buffer_size 2k; proxy_pass http://localhost:8000; } 如果禁用了缓冲，则响应将从客户端服务器接收到的响应同步发送到客户端。对于需要尽快开始接收响应的快速交互客户端，此行为可能是理想的。 要在特定位置禁用缓冲，请将proxy_buffering伪指令location与off参数一起放置在中，如下所示： location /some/path/ { proxy_buffering off; proxy_pass http://localhost:8000; } 在这种情况下，NGINX仅使用配置的缓冲区proxy_buffer_size来存储响应的当前部分。 反向代理的常见用法是提供负载平衡。在免费的《选择软件负载平衡器的五个理由》电子书中，了解如何提高性能，性能并通过快速部署专注于您的应用程序。 proxy_buffer代理缓冲区 #nignx会把后端返回的内容先放到缓冲区当中，然后再返回给客户端,边收边传, 不是全部接收完再传给客户端 Syntax: proxy_buffering on | off; Default: proxy_buffering on; Context: http, server, location #设置nginx代理保存用户头信息的缓冲区大小 Syntax: proxy_buffer_size size; Default: proxy_buffer_size 4k|8k; Context: http, server, location #proxy_buffers 缓冲区 Syntax: proxy_buffers number size; Default: proxy_buffers 8 4k|8k; Context: http, server, location 2.4 选择转发IP地址 如果代理服务器具有多个网络接口，有时您可能需要选择特定的源IP地址以连接到代理服务器或上游服务器。如果将NGINX之后的代理服务器配置为接受来自特定IP网络或IP地址范围的连接，这可能很有用。 指定proxy_bind指令和必要的网络接口的IP地址： location /app1/ { proxy_bind 127.0.0.1; proxy_pass http://example.com/app1/; } location /app2/ { proxy_bind 127.0.0.2; proxy_pass http://example.com/app2/; } IP地址也可以用变量指定。例如，$server_addr变量传递接受请求的网络接口的IP地址： location /app3/ { proxy_bind $server_addr; proxy_pass http://example.com/app3/; } 三、配置nginx反向代理 在代理服务器和后端真实web中的nginx头文件proxy_params中加上参数X-Forwarded-For以获取客户端真实IP，然后模拟访问过程如下 客户端10.0.0.10-->通过代理服务器10.0.0.51-->访问后端真实web 10.0.0.52 代理服务器10.0.0.51 nginx配置 #编辑nginx反向代理配置文件 cat > /etc/nginx/conf.d/www.abc.com.conf /etc/nginx/proxy_params 后端真实web 10.0.0.52操作 #编辑nginx配置文件 cat > /etc/nginx/conf.d/www.abc.com.conf /etc/nginx/proxy_params /website/index.html 客户端10.0.0.10做本地hosts解析 10.0.0.51 www.abc.com 客户端10.0.0.10访问www.abc.com，经过nginx代理服务器10.0.0.51将请求转发至后端真实web 10.0.0.52，最终访问到的内容如下 $ curl www.abc.com 10.0.0.52 加上X-Forwarded-For参数后，nginx的访问日志(真实web服务器10.0.0.52查看)中就可以获取到客户端的真实IP地址了 10.0.0.51 - - [16/Jun/2020:10:35:12 +0800] \"GET / HTTP/1.0\" 200 10 \"-\" \"curl/7.29.0\" \"10.0.0.10\" 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/nginx/7.nginx location.html":{"url":"linux/linux服务/nginx/7.nginx location.html","title":"nginx location","keywords":"","body":"nginx location nginx location官方文档 匹配语法 location [ = | ~ | ~* | ^~ ] uri { ... } location @name { ... } location [匹配模式] uri { ... } location匹配规则 匹配规则总览 匹配模式 匹配符 优先级 精确匹配 = 1 前缀匹配 ^~ 2 正则匹配 ~ 3 正常匹配 uri 4 全匹配(通用匹配) / 5 匹配规则细分 匹配符 匹配规则 优先级 = 精确匹配 1 ^~ 以某个字符串开头 2 ~ 区分大小写的正则匹配 3 ~* 不区分大小写的正则匹配 4 !~ 区分大小写不匹配的正则 5 !~* 不区分大小写不匹配的正则 6 / 通用匹配，任何请求都会匹配到 7 location匹配优先级 路径匹配优先级 精确匹配 > 前缀匹配 > 正则匹配 > 正常匹配 > 全匹配 匹配示例 精确匹配 ⚠️server_name _ 中的_只是一个无效域名的表示方法 编辑nginx配置文件 server { listen 80; server_name _; # 第1段 location /nginx { #return 200 \"aaa\"; root /data/nginx/html4/; index index.html; } # 第2段 location = /nginx { #return 200 \"bbb\"; root /data/nginx/html3/; index index.html; } } 创建网站根目录 mkdir -p /data/nginx/html{3,4}/nginx echo 'html3' >/data/nginx/html3/nginx/index.html echo 'html4' >/data/nginx/html4/nginx/index.html 访问测试 $ curl 127.0.0.1/nginx 301 Moved Permanently 301 Moved Permanently nginx/1.18.0 $ curl 127.0.0.1/nginx/ html4 精确匹配中 '/nginx/'中优先匹配到第2段，再访问'/nginx/index.html'，此次内部跳转uri已经是/nginx/index.html，而非=的；最终访问结果是第1段中的index.html。 结论：精确匹配区分大小写，不能使用正则，访问的URI必须完全与=后面的一致，多一个\"/\"或者少一个\"/\"，都是不可以的。 前缀匹配 编辑nginx配置文件 server { listen 80; server_name _; location ^~ /nginx/ { rewrite ^ https://www.163.com break; } location ^~ /nginx/bcd/ { rewrite ^ https://www.qq.com break; } location ^~ /Abc/ { rewrite ^ https://www.sina.com.cn break; } } 访问测试 访问127.0.0.1/nginx/，在终端中会返回302，在浏览器中会跳转到www.163.com $ curl 127.0.0.1/nginx/ 302 Found 302 Found nginx/1.18.0 访问127.0.0.1/nginx/bcd/，在终端中会返回302，在浏览器中会跳转到www.qq.com ⚠️如果bcd后边不加/，跳转页面是www.163.com，即只匹配前缀/nginx $ curl 127.0.0.1/nginx/bcd/ 302 Found 302 Found nginx/1.18.0 访问一个不存在的页面127.0.0.1/nginx/abcd/，在终端中会返回302，在浏览器中会跳转到www.163.com $ curl 127.0.0.1/nginx/abcd/ 302 Found 302 Found nginx/1.18.0 访问127.0.0.1/Abc/，在终端中会返回302，在浏览器中会跳转到www.sina.com.cn $ curl 127.0.0.1/nginx/abc/ 302 Found 302 Found nginx/1.18.0 结论：前缀匹配不能使用正则，区分大小写，只要前缀相同，都可以匹配成功，不管后面有没有字符，保证前缀相同即可。 正则匹配 编辑nginx配置文件 server { listen 80; server_name _; location ~ /[a-z]nginx/ { rewrite ^ https://www.baidu.com break; } location ~* /[a-z]nginx/ { rewrite ^ https://www.163.com break; } } 访问测试 访问127.0.0.1/anginx/，在终端中会返回302，在浏览器中会跳转到www.baidu.com $ curl 127.0.0.1/anginx/ 302 Found 302 Found nginx/1.18.0 访问127.0.0.1/anginx/abc在终端中会返回302，在浏览器中会跳转到www.baidu.com $ curl 127.0.0.1/anginx/abc/ 302 Found 302 Found nginx/1.18.0 访问127.0.0.1/Anginx/，在终端中会返回302，在浏览器中会跳转到www.163.com $ curl 127.0.0.1/Anginx/ 302 Found 302 Found nginx/1.18.0 结论：正则匹配 ~ 区分大小写，~* 不区分大小写, 并且与前缀匹配比较类似，只需要匹配模式开头部分，这两种同时存在时，优先匹配区分大小写的。 正常匹配 正常匹配就是匹配模式为空的匹配规则 编辑 nginx配置文件 server { listen 80; server_name _; # 第1段 location /nginx/ { rewrite ^ https://www.baidu.com break; } # 第2段 location /[0-9]nginx/ { rewrite ^ https://www.qq.com break; } } 访问测试 访问127.0.0.1/nginx/，在终端中会返回302，在浏览器中会跳转到www.baidu.com $ curl 127.0.0.1/nginx/ 302 Found 302 Found nginx/1.18.0 上述配置文件中第2段访问不生效，404 ⚠️location ^~ /nginx/与location /nginx/不能同时出现 结论：正常匹配与前缀匹配的差别，只在于优先级。 全匹配(通用匹配) 编辑nginx配置文件 server { listen 80; server_name _; location / { root /data/nginx/html; index index.html index.htm; } } 全匹配没有匹配模式，并且匹配的uri仅是一个斜杠/，通常用在一个默认页面的地方 命名匹配 命名匹配一般用于静态页面或者错误页面(404，500等)，并且这个命名匹配中，不允许有alias。 error_page 404 = @notfound; location @notfound { rewrite ^ https://www.baidu.com break; } 优先级验证综合实验 编辑nginx配置文件 ⚠️前缀匹配和正常匹配不能同时存在 server { listen 80; server_name _; # 全匹配，这里/data/nginx/html/下面有一个nginx文件夹，里面有index.html，内容是nginx location test location / { root /data/nginx/html; index index.html; } # 正常匹配 location /nginx/ { rewrite ^/nginx/$ https://www.sina.com.cn/ break; } # 正则匹配 location ~ /[a-z]ginx/ { rewrite ^/nginx/$ https://www.163.com/ break; } # 前缀匹配 location ^~ /nginx/ { rewrite ^/nginx/$ https://www.baidu.com/ break; } # 精确匹配 location = /nginx/ { rewrite ^/nginx/$ https://www.qq.com/ break; } } 创建网站根目录 mkdir -p /data/nginx/html/nginx echo 'nginx location test' > /data/nginx/html/nginx/index.html 第一步、把正常匹配注释掉，留下前缀匹配，然后浏览器访问IP/nginx/，第一次返回的结果是跳转到了www.qq.com，证明了=精确匹配优先级是最大的 第二步、把精确匹配注释掉，然后浏览器访问IP/nginx/，结果是跳转到了www.baidu.com，证明了^~前缀匹配优先级是仅次于精确匹配 第三步、因为前缀匹配和正常匹配不能同时存在，所以这一步比较第一步和第二步，还是把精确匹配注释掉，这次把前缀匹配注释掉，把正常匹配注释打开，结果是跳转到了www.163.com，说明正则匹配的优先级是大于正常匹配的，同时也验证了前缀匹配优先级第2，正则匹配优先级第3，正常匹配优先级第4 第四步、现在只剩下全匹配了，所以全匹配的优先级最低 结论：各匹配优先级如下 精确匹配 > 前缀匹配 > 正则匹配 > 正常匹配 > 全匹配 匹配原则除了这个优先级外，还有一个就是在相同指令模式匹配中，匹配度最大的URI优先 root与alias nginx配置 location规则中的 uri 往往都是匹配一个目录。 root 编辑nginx配置文件 server { listen 80; server_name _; location /nginx/ { root /data/nginx/html/; index index.html index.htm; } } 使用root关键字指定网站根目录 当访问127.0.0.1/nginx/index.html时，如果/data/nginx/html/这个目录下没有nginx/index.html或者没有nginx目录，则会报错404 原因是使用root指定目录时，目录下边要包括location后面的uri，否则就会报错 使用root指定目录时，不会将location uri配置的路径去掉，即访问的路径是/data/nginx/html/nginx 访问测试 #不创建目录nginx mkdir -p /data/nginx/html/ echo 'abc' >/data/nginx.html/index.html #访问报错404 $ curl 127.0.0.1/nginx/ 404 Not Found 404 Not Found nginx/1.18.0 alias 编辑nginx配置文件 server { listen 80; server_name _; location /nginx/ { alias /data/nginx/html/; index index.html index.htm; } } 使用alias关键字指定网站根目录 当访问127.0.0.1/nginx/index.html时，只要保证alias指定的目录中有index.html即可，即使没有目录nginx，它会将location uri配置的路径去掉，实际访问的就是/data/nginx/html/index.html 访问测试 #不创建目录nginx mkdir -p /data/nginx/html/ echo 'abc' >/data/nginx.html/index.html $ curl 127.0.0.1/nginx/ abc 结论：root 指定的目录中，需要location中的 uri 路径目录确实存在，alias 指定的目录中不需要 location中的uri 路径目录存在。 代理服务器 proxy_pass 中有无 / 实验环境 角色 主机名 IP 真实web web01 10.0.0.10 nginx代理 nginx-proxy 10.0.0.51 后端真实web服务配置 后端真实web服务nginx 10.0.0.10配置 server { listen 80; server_name _; location /nginx/ { root /data/nginx/html/; index index.html index.htm; } location /ng/ { root /data/nginx/html/; index index.html index.htm; } location /k8s/ { root /data/nginx/html/; index index.html index.htm; } } 创建网站根目录 mkdir -p /data/nginx/html/{nginx,ng,k8s} echo 'nginx' >/data/nginx/html/nginx/index.html echo 'ng' >/data/nginx/html/ng/index.html echo 'k8s' >/data/nginx/html/k8s/index.html 访问测试 $ curl 127.0.0.1/nginx/ nginx $ curl 127.0.0.1/ng/ ng $ curl 127.0.0.1/k8s/ k8s proxy_pass无目录无/ 代理服务器nginx 10.0.0.51配置中 proxy_pass 无'/'验证 server { listen 80; server_name _; location /nginx { #没有/指的是proxy_pass后边的url没有/后缀 proxy_pass http://10.0.0.10; } } 访问测试 $ curl 10.0.0.51/nginx/ nginx $ curl -L 10.0.0.51/nginx nginx 真实web服务10.0.0.10nginx访问日志如下 10.0.0.51 - - [18/Jun/2020:17:46:53 +0800] \"GET /nginx/ HTTP/1.0\" 200 6 \"-\" \"curl/7.29.0\" \"-\" 结论：如果proxy_pass 反向代理中，在server后面没有 \"/\" 反斜杠的话，访问的是 http://10.0.0.10/nginx/index.html，它会去上游真实服务器去匹配代理服务器上面location URI。 proxy_pass无目录有/ 代理服务器nginx 10.0.0.51配置中 proxy_pass '/'验证 server { listen 80; server_name _; location /nginx { #有/指的是proxy_pass后边的url有/后缀 proxy_pass http://10.0.0.10/; } } 访问测试 因为访问的是真实服务器的/，但是并没有在真实服务器根中写入访问页面 $ curl 10.0.0.51/nginx/ 404 Not Found 404 Not Found nginx/1.18.0 真实web服务10.0.0.10nginx访问日志如下 10.0.0.51 - - [18/Jun/2020:17:51:32 +0800] \"GET / HTTP/1.0\" 404 153 \"-\" \"curl/7.29.0\" \"-\" 结论：如果proxy_pass 反向代理中，在server后面有 \"/\" 反斜杠的话，访问的是 http://10.0.0.10/index.html，它会忽略掉代理服务器上面location中的URI，直接访问代理服务器上面的\"/\"。 proxy_pass有目录无/ 代理服务器10.0.0.51proxy_pass后面增加目录，但不加\"/\" server { listen 80; server_name _; location /nginx/ { proxy_pass http://10.0.0.10/nginx; } } 访问测试 因为访问的是真实服务器的/，但是并没有在真实服务器根中写入访问页面 $ curl 10.0.0.51/nginx/ 404 Not Found 404 Not Found nginx/1.18.0 真实web服务10.0.0.10nginx访问日志如下 10.0.0.51 - - [18/Jun/2020:18:04:40 +0800] \"GET /nginx HTTP/1.0\" 404 153 \"-\" \"curl/7.29.0\" \"-\" 结论：如果proxy_pass 反向代理中，在server后面有URI， 但没有 \"/\" 反斜杠的话，访问的是 http://10.0.0.10/nginx，它会去上游真实服务器去匹配代理服务器上面的URI。 proxy_pass有目录有/ 代理服务器10.0.0.51proxy_pass后面增加目录并且加\"/\" server { listen 80; server_name _; location /nginx/ { proxy_pass http://10.0.0.10/nginx/; } } 访问测试 $ curl 10.0.0.51/nginx/ nginx 真实web服务10.0.0.10nginx访问日志如下 10.0.0.51 - - [18/Jun/2020:17:58:47 +0800] \"GET /nginx/ HTTP/1.0\" 200 6 \"-\" \"curl/7.29.0\" \"-\" 结论：如果proxy_pass反向代理中有目录，并且有\"/\"反斜杠的话，访问的是http://10.0.0.10/nginx/index.html，它会忽略掉代理服务器上面location中的URI，直接访问代理服务器上面的目录+\"/\"的形式。 测试结果最终对比 情况 proxy_pass配置 访问结果 日志中的访问路径 proxy_pass中无目录无/ location /nginx { proxy_pass http://10.0.0.10; } 访问的是 http://10.0.0.10/nginx/index.html，它会去上游真实服务器去匹配代理服务器上面location URI。 /nginx/ proxy_pass中无目录有/ location /nginx { proxy_pass http://10.0.0.10/; } 访问的是 http://10.0.0.10/index.html，它会忽略掉代理服务器上面location中的URI，直接访问代理服务器上面的\"/\"。 / proxy_pass中有目录无/ location /nginx/ { proxy_pass http://10.0.0.10/nginx; } 访问的是 http://10.0.0.10/nginx，它会去上游真实服务器去匹配代理服务器上面的URI。 /nginx proxy_pass中有目录有/ location /nginx/ { proxy_pass http://10.0.0.10/nginx/; } 访问的是 http://10.0.0.10/nginx/index.html，它会忽略掉代理服务器上面location中的URI，直接访问代理服务器上面的目录+\"/\"的形式。 /nginx/ 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/nginx/8.nginx虚拟主机.html":{"url":"linux/linux服务/nginx/8.nginx虚拟主机.html","title":"nginx虚拟主机","keywords":"","body":"nginx虚拟主机 虚拟机主机概念 虚拟主机就是在一台服务器上配置多个网站 虚拟主机分类 基于IP的虚拟主机(浪费IP，没用) 基于端口的虚拟主机 基于域名的虚拟主机 配置nginx虚拟主机 基于域名的虚拟主机 编辑aaa.com.conf文件 cat > /etc/nginx/conf.d/aaa.com.conf 编辑bbb.com.conf文件 cat > /etc/nginx/conf.d/bbb.com.conf 检测nginx语法并重载nginx $ nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful $ nginx -s reload 创建网站根目录 mkdir /website/{aaa,bbb} echo \"aaa.com\" > /website/aaa/index.html echo \"bbb.com\" > /website/bbb/index.html 绑定hosts cat >> /etc/hosts 测试访问 $ curl aaa.com aaa.com $ curl bbb.com bbb.com 基于端口的虚拟主机 虚拟主机监听不同端口，不与系统端口冲突即可 编辑aaa.com.conf文件 cat > /etc/nginx/conf.d/aaa.com.conf 检测nginx语法并重载nginx $ nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful $ nginx -s reload 测试访问 $ curl aaa.com:8001 aaa.com $ curl aaa.com:8002 bbb.com 配置虚拟主机别名 虚拟主机别名，就是虚拟主机设置除了主域名以外的一个域名，实现用户访问的多个域名对应同一个虚拟主机网站的功能。 编辑aaa.com.conf文件 cat > /etc/nginx/conf.d/aaa.com.conf 测试访问，aaa.com、bbb.com、ccc.com访问到的是同一个网站的同一资源 $ curl aaa.com aaa.com $ curl bbb.com aaa.com $ curl ccc.com aaa.com 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/nginx/9.1nginx七层负载均衡.html":{"url":"linux/linux服务/nginx/9.1nginx七层负载均衡.html","title":"nginx七层负载均衡","keywords":"","body":"nginx七层负载均衡概述 nginx七层负载均衡官方文档简介版 nginx七层负载均衡官方文档详细版 一、nginx负载均衡概念 后端web服务往往要承载大量并发请求，单台服务器难以负荷，后端使用多台web服务器组成集群，前端使用nginx作为负载均衡，将请求分散的打到后端服务器集群中，实现负载的分发。这样会大大提升系统的吞吐率、请求性能、高容灾等等。 示意图 二、nginx负载均衡upstream 2.1 语法 Syntax: upstream name { ... } Default: - Context: http 2.2 负载均衡方法 总揽 开源nginx调度算法 调度算法 概述 Round Robin 轮询(rr)，按时间顺序逐一分配到不同的后端服务器(默认) Weight Round Robin 加权轮询(wrr)，weight值越大，分配到的访问几率越高 IP Hash 每个请求按访问IP的hash结果分配，这样来自同一IP的请求固定访问同一个后端服务器 Generic Hash(url_hash) 按照访问URL的hash结果来分配请求，每个URL定向到同一个后端 Least Connections 最少链接数，哪个机器链接数少就分发 2.2.1 Round Robin 轮询 请求在服务器之间平均分配，同时考虑了服务器权重。默认情况下使用此方法（没有启用它的指令） upstream backend { # 没有配置就是Round Robin 轮询 server backend1.example.com; server backend2.example.com; } 2.2.2 Weight Round Robin 加权轮询 在此示例中，backend1.example.com具有weight 5；其他两台服务器的默认权重（1），但是具有IP地址的192.0.0.1一台backup服务器被标记为服务器，除非其他两台服务器均不可用，否则不会接收请求。随着权重的这种配置，每的6请求，5发送到backend1.example.com和1对backend2.example.com upstream backend { server backend1.example.com weight=5; server backend2.example.com; server 192.0.0.1 backup; } 2.2.3 Least Connections 最少连接 将活动连接最少的请求发送到服务器，再次考虑服务器权重 upstream backend { least_conn; server backend1.example.com; server backend2.example.com; } 2.2.4 IP Hash 从客户端IP地址确定向其发送请求的服务器。在这种情况下，可以使用IPv4地址的前三个八位位组或整个IPv6地址来计算哈希值。该方法保证了来自同一地址的请求将到达同一服务器，除非该请求不可用 upstream backend { ip_hash; server backend1.example.com; server backend2.example.com; } 如果其中一台服务器需要暂时从负载平衡循环中删除，则可以使用down参数对其进行标记，以保留客户端IP地址的当前哈希值。该服务器要处理的请求将自动发送到组中的下一个服务器 upstream backend { server backend1.example.com; server backend2.example.com; server backend3.example.com down; } 2.2.5 Generic Hash (url_hash) 发送请求到的服务器由用户定义的键决定，该键可以是文本字符串、变量或组合。例如，键可以是成对的源IP地址和端口，或者是一个URI，如本例所示 upstream backend { hash $request_uri consistent; server backend1.example.com; server backend2.example.com; } 哈希指令的可选consistent参数支持ketama一致哈希负载平衡。请求根据用户定义的散列键值均匀地分布在所有上游服务器上。如果上游服务器被添加到或从上游组移除，只有几个键被重新映射，在负载平衡的缓存服务器或其他积累状态的应用程序的情况下最小化缓存丢失。 应用场景 有一个服务器集群A，需要对外提供文件下载，由于文件上传量巨大，没法存储到服务器磁盘中，所以用到了第三方云存储来做文件存储。服务器集群A收到客户端请求之后，需要从云存储中下载文件然后返回，为了省去不必要的网络带宽和下载耗时，在服务器集群A上做了一层临时缓存（缓存一个月）。由于是服务器集群，所以同一个资源多次请求，可能会到达不同的服务器上，导致不必要的多次下载，缓存命中率不高，以及一些资源时间的浪费。在此类场景下，为了使得缓存命中率提高，很适合使用url_hash策略，同一个url（也就是同一个资源请求）会到达同一台机器，一旦缓存住了资源，再此收到请求，就可以从缓存中读取，既减少了带宽，也减少的下载时间。 upstream somestream { hash $request_uri; server 192.168.1.1:8080; server 192.168.1.2:8080; server 192.168.1.3:8080; } server { listen 80 default; server_name test.cdn.com; charset utf-8; location /get { proxy_pass http://somestream; } } 2.2.6 random 每个请求将传递到随机选择的服务器，如果two指定了参数，首先，NGINX考虑服务器权重随机选择两个服务器，然后使用指定的方法选择这些服务器之一 least_conn –活动连接最少 least_time=header（NGINX Plus）–从服务器接收响应标头的最短平均时间（$upstream_header_time） least_time=last_byte（NGINX Plus）–从服务器接收完整响应的最短平均时间（$upstream_response_time） upstream backend { random two least_time=last_byte; server backend1.example.com; server backend2.example.com; server backend3.example.com; server backend4.example.com; } 随机负载平衡方法应该用于分布式环境，其中多个负载平衡器将请求传递给同一组后端。对于负载平衡器对所有请求都有完整视图的环境，可以使用其他负载平衡方法，比如轮询、最少连接和最少时间。 nginx plus增加的调度算法 调度算法 概述 Least Time 选择具有最低平均延迟和最低数量的活动连接 第三方调度算法 调度算法 概述 fair 按照服务器端的响应时间来分配请求，响应时间短的优先分配 2.2.7 fair 按照服务器端的响应时间来分配请求，响应时间短的优先分配。 upstream dynamic_zuoyu { fair; #实现响应时间短的优先分配 server localhost:8080; #tomcat 7.0 server localhost:8081; #tomcat 8.0 server localhost:8082; #tomcat 8.5 server localhost:8083; #tomcat 9.0 } 2.3 后端web服务器在前端nginx负载均衡调度中的状态 ⚠️ip_hash和bakcup不能一起写，否则语法检测会有报错 状态 概述 down 当前的server暂时不参与负载均衡 backup 预留的备份服务器 max_fails 允许请求失败的次数 fail_timeout 经过max_fails失败后, 服务暂停时间 max_conns 限制最大的接收连接数 配置示例 upstream www { server 10.0.0.50:80 down; server 10.0.0.51:80 backup; server 10.0.0.52:80 max_fails=1 fail_timeout=10s; } location / { proxy_pass http://www; include proxy_params; } 2.4 配置示例 #upstream例子 upstream backend { server backend1.example.com weight=5; server backend2.example.com:8080; server unix:/tmp/backend3; server backup1.example.com:8080 backup; } server { location / { proxy_pass http://backend; } } 三、配置健康检查 http健康检查官方文档 3.1 被动健康检查 对于被动运行状况检查，NGINX会监视发生的事务，并尝试恢复失败的连接。如果仍然无法恢复交易，则NGINX会将服务器标记为不可用，并暂时停止向服务器发送请求，直到再次将其标记为活动。 使用块中server指令的参数为每个上游服务器定义了将上游服务器标记为不可用的条件upstream： fail_timeout –设置必须多次尝试失败才能将服务器标记为不可用的时间，以及将服务器标记为不可用的时间（默认为10秒）。 max_fails –设置在fail_timeout服务器标记为不可用的时间段内必须发生的失败尝试次数（默认为1次尝试）。 在以下示例中，如果NGINX无法在30秒内向服务器发送请求或没有收到3次响应，则它将服务器标记为30秒钟不可用： upstream backend { server backend1.example.com; server backend2.example.com max_fails=3 fail_timeout=30s; } 四、nginx负载均衡配置示例 实验环境 服务器角色 ip 主机名 lb 10.0.0.10 lb01 web01 10.0.0.51 web01 web02 10.0.0.52 web02 4.1 负载均衡lb配置 编辑nginx配置文件 upstream www { server 10.0.0.51; server 10.0.0.52; } server { listen 80; server_name _; location / { proxy_pass http://www; } } 4.2 web01配置 编辑nginx配置文件 server { listen 80; root /code; index index.html; } 创建网站根目录 mkdir /code cat > /code/index.html Code1 Code1 EOF 4.3 web02配置 编辑nginx配置文件 server { listen 80; root /code; index index.html; } 创建网站根目录 mkdir /code cat > /code/index.html Code1 Code2 EOF 4.4 浏览器访问lb IP地址 第一次访问 第二次访问 因为是使用默认的rr轮询算法，因此请求会依次转发到web01和web02 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/nginx/9.2nginx四层负载均衡.html":{"url":"linux/linux服务/nginx/9.2nginx四层负载均衡.html","title":"nginx四层负载均衡","keywords":"","body":"nginx四层负载均衡 nginx四层负载均衡官方文档 一、nginx四层负载均衡简介 nginx官网对于--with-stream模块的简介 nginx从1.9.0版本开始，新增了ngx_stream_core_module 模块，使nginx支持四层负载均衡。默认编译的时候该模块并未编译进去，需要编译的时候添加 --with-stream，使其支持stream代理。 负载平衡是指在多个后端服务器之间有效地分配网络流量。 nginx可以代理和负载平衡传输控制协议（TCP）通信。TCP是许多流行的应用程序和服务的协议，例如LDAP，MySQL和RTMP。 nginx可以代理和负载均衡UDP流量。UDP（用户数据报协议）是许多流行的非事务性应用程序的协议，例如DNS，syslog和RADIUS。 二、先决条件 需要模块--with-stream的支持 通过TCP或UDP进行通信的应用程序，数据库或服务 上游服务器，每个服务器运行应用程序，数据库或服务的相同实例 三、官方配置示例 3.1 配置反向代理 首先，需要配置反向代理，以便NGINX可以将TCP连接或UDP数据报从客户端转发到上游组或代理服务器。 3.1.1 创建一个顶级stream{}块： stream { # ... } server {}在顶级stream {}上下文中为每个虚拟服务器定义一个或多个配置块。 3.1.2 在server {}每个服务器的配置块中，包括listen用于定义服务器侦听的IP地址或端口的指令。 对于UDP通信，还包括udp参数。由于TCP是stream上下文的默认协议，因此tcp该listen指令没有参数： stream { server { listen 12345; # ... } server { listen 53 udp; # ... } # ... } 3.1.3 配置proxy_pass指令以定义代理服务器或服务器将流量转发到的上游组 stream { server { listen 12345; #TCP流量将转发到\"stream_backend\"上游组 proxy_pass stream_backend; } server { listen 12346; #TCP流量将被转发到指定的服务器 proxy_pass backend.example.com:12346; } server { listen 53 udp; #UDP流量将转发到\"dns_servers\"上游组 proxy_pass dns_servers; } # ... } 3.1.4 配置代理绑定 如果代理服务器具有多个网络接口，则可以选择将NGINX配置为在连接到上游服务器时使用特定的源IP地址。如果将NGINX之后的代理服务器配置为接受来自特定IP网络或IP地址范围的连接，这可能很有用 包括proxy_bind指令和相应网络接口的IP地址 stream { # ... server { listen 127.0.0.1:12345; proxy_pass backend.example.com:12345; proxy_bind 127.0.0.1:12345; } } 3.1.5 配置缓冲 可以调整两个内存缓冲区的大小，NGINX可以在其中放置来自客户端和上游连接的数据。如果数据量很小，则可以减少缓冲区，这可以节省内存资源。如果有大量数据，则可以增加缓冲区大小以减少套接字读/写操作的数量。在一个连接上接收到数据后，NGINX将读取该数据并通过另一连接转发该数据。缓冲区由proxy_buffer_size伪指令控制： stream { # ... server { listen 127.0.0.1:12345; proxy_pass backend.example.com:12345; proxy_buffer_size 16k; } } 3.2 配置TCP或UDP负载平衡 3.2.1 创建一组服务器 upstream{}在顶级stream {}上下文中定义一个或多个配置块，并为上游组（例如，stream_backendTCP服务器和dns_serversUDP服务器）设置名称： 确保上游组的名称由proxy_pass指令引用，就像上面为反向代理配置的指令一样。 stream { upstream stream_backend { # ... } upstream dns_servers { # ... } # ... } 3.2.2 在服务器组中添加后端真实服务器(上游服务器) 在该upstream {}块内，server为每个上游服务器添加一个指令，指定其IP地址或主机名（可以解析为多个IP地址）和一个必需的端口号。请注意，并未为每个服务器定义协议，因为该协议是由在前面创建listen的server块中的指令中包含的参数为整个上游组定义的。 stream { upstream stream_backend { server backend1.example.com:12345; server backend2.example.com:12345; server backend3.example.com:12346; # ... } upstream dns_servers { server 192.168.136.130:53; server 192.168.136.131:53; # ... } # ... } 3.2.3 配置上游服务器组的负载均衡算法 3.2.3.1 轮询 Round Robin 默认情况下，NGINX使用Round Robin算法来负载均衡流量，将其顺序地定向到已配置的上游组中的服务器。因为它是默认方法，所以没有round‑robin指令。只需在顶级上下文中创建配置块并添加上一步中所述的指令。upstream {} stream {} server 3.2.3.2 最少连接 NGINX选择当前活动连接数量较少的服务器。 3.2.3.3 哈希 hash NGINX根据用户定义的密钥（例如，源IP地址（$remote_addr））选择服务器： upstream stream_backend { hash $remote_addr; server backend1.example.com:12345; server backend2.example.com:12345; server backend3.example.com:12346; } 该Hash负载平衡方法也可以用来配置会话持久性。由于哈希函数基于客户端IP地址，因此除非服务器关闭或不可用，否则来自给定客户端的连接将始终传递到同一服务器。指定一个可选consistent参数以应用ketama一致性哈希方法： hash $remote_addr consistent; 3.2.4 为每个上游服务器指定服务器特定的参数，包括最大连接数，服务器权重等(可选) upstream stream_backend { hash $remote_addr consistent; server backend1.example.com:12345 weight=5; server backend2.example.com:12345; server backend3.example.com:12346 max_conns=3; } upstream dns_servers { least_conn; server 192.168.136.130:53; server 192.168.136.131:53; # ... } 另一种方法是将流量代理到单个服务器而不是上游组。如果您通过主机名标识服务器，并配置主机名以解析为多个IP地址，则NGINX使用该Round Robin算法对IP地址之间的流量进行负载平衡。在这种情况下，您必须在proxy_pass指令中指定服务器的端口号，并且不得在IP地址或主机名之前指定协议 stream { # ... server { listen 12345; proxy_pass backend.example.com:12345; } } 3.3 配置TCP健康检查 nginx TCP健康检查官方文档 3.3.1 简介 nginx TCP健康检查可以持续测试TCP上游服务器，避免出现故障的服务器，并可以将恢复的服务器正常地添加到负载平衡组中 3.3.2 前提条件 已在stream上下文中配置了TCP服务器的上游组** stream { #... upstream stream_backend { server backend1.example.com:12345; server backend2.example.com:12345; server backend3.example.com:12345; } #... } 已经配置了将TCP连接传递到服务器组的服务器 stream { #... server { listen 12345; proxy_pass stream_backend; } #... } 3.3.3 被动TCP运行状况检查 如果连接上游服务器的尝试超时或导致错误，NGINX可以将服务器标记为不可用，并在指定的时间内停止向其发送请求。要定义NGINX认为上游服务器不可用的条件，请在server指令中包含以下参数 fail_timeout –在指定的连接尝试次数内必须失败的时间，才能将服务器视为不可用。同样，NGINX将服务器标记为不可用后的时间。 max_fails –在指定时间内NGINX认为服务器不可用的失败尝试次数。 默认值为10秒数和1尝试次数。因此，如果连接尝试超时或在10秒钟内至少失败一次，NGINX会将服务器标记为10秒钟不可用。该示例显示了如何在30秒内将这些参数设置为2个失败 upstream stream_backend { server backend1.example.com:12345 weight=5; server backend2.example.com:12345 max_fails=2 fail_timeout=30s; server backend3.example.com:12346 max_conns=3; } 3.3.3.1 服务器缓慢启动(只有nginx plus可以使用) 最近恢复的上游服务器很容易被连接淹没，这可能导致服务器再次标记为不可用。慢速启动允许上游服务器在恢复或可用后将其权重从零逐渐恢复到其标称值。这可以通过slow_start上游server指令的参数来完成 upstream backend { server backend1.example.com:12345 slow_start=30s; server backend2.example.com; server 192.0.0.1 backup; } ⚠️请注意，如果组中只有一台服务器，则将slow_start忽略该参数，并且永远不会将服务器标记为不可用。慢速启动是NGINX Plus独有的 3.4 配置UDP健康检查 nginx UDP健康检查官方文档 3.4.1 前提条件 已配置上下文中的上游服务器组来处理UDP网络流量（DNS，RADIUS，系统日志），例如：stream {} stream { #... upstream dns_upstream { server 192.168.136.130:53; server 192.168.136.131:53; server 192.168.136.132:53; } #... } 已经配置了将UDP数据报传递到上游服务器组的服务器 stream { #... server { listen 53 udp; proxy_pass dns_upstream; proxy_timeout 1s; proxy_responses 1; error_log logs/dns.log; } #... } 3.4.2 被动UDP健康检查 如果服务器回复错误或超时，则NGINX可以将服务器标记为不可用，并在一段时间内停止向其发送UDP数据报。 max_fails使用上游服务器的参数设置在特定时间段内连续失败的连接尝试次数（默认值为1）。 时间段由fail_timeout参数设置（默认值为10秒）。该参数还设置了NGINX标记服务器后认为服务器不可用的时间。 因此，如果连接尝试超时或在10秒内至少失败一次，NGINX会将服务器标记为10秒钟不可用。该示例显示了如何在60秒内将这些参数设置为2个失败： upstream dns_upstream { server 192.168.136.130:53 fail_timeout=60s; server 192.168.136.131:53 fail_timeout=60s; } 四、TCP和UDP负载平衡配置官方总示例 在此示例中，所有与TCP和UDP代理相关的功能都在stream块内进行配置，就像在http块中配置了HTTP请求的设置一样。 有两个命名的upstream块，每个块包含三个托管彼此相同内容的服务器。在serverfor eadch服务器中，服务器名称后跟必需的端口号。根据“ 最少连接”负载平衡方法，连接在服务器之间分配：连接到活动连接最少的服务器。 这三个server块定义了三个虚拟服务器： 第一台服务器侦听端口12345，并将所有TCP连接代理到上游服务器的stream_backend组。请注意，在模块proxy_pass上下文中定义的指令stream不得包含协议。 指定了两个可选的超时参数：proxy_connect_timeout伪指令设置与stream_backend组中的服务器建立连接所需的超时。该proxy_timeout指令设置在代理到stream_backend组中的一台服务器已启动之后使用的超时。 第二台服务器侦听端口53，并将所有UDP数据报（指令的udp参数listen）代理到称为dns_servers的上游组。如果udp未指定该参数，则套接字监听TCP连接。 第三台虚拟服务器侦听端口12346，并代理到backend4.example.com的 TCP连接，后者可以解析为使用Round Robin方法实现负载平衡的多个IP地址。 stream { upstream stream_backend { least_conn; server backend1.example.com:12345 weight=5; server backend2.example.com:12345 max_fails=2 fail_timeout=30s; server backend3.example.com:12345 max_conns=3; } upstream dns_servers { least_conn; server 192.168.136.130:53; server 192.168.136.131:53; server 192.168.136.132:53; } server { listen 12345; proxy_pass stream_backend; proxy_timeout 3s; proxy_connect_timeout 1s; } server { listen 53 udp; proxy_pass dns_servers; } server { listen 12346; proxy_pass backend4.example.com:12346; } } 五、实际配置示例 5.1 实验说明 官方对于TCP负载均衡的说明，应该选择使用TCP协议的服务去验证 nginx可以代理和负载平衡传输控制协议（TCP）通信。TCP是许多流行的应用程序和服务的协议，例如LDAP，MySQL和RTMP。 这里选择使用TCP协议的mysql和ssh服务作为实验对象，便于验证 1.访问负载均衡的12345端口，连接至后端web的22端口 2.访问负载均衡的12346端口，连接至后端mysql的3306端口 实验环境 服务器角色 外网ip** 主机名 lb 10.0.0.10 lb web01 10.0.0.51 web mysql 10.0.0.52 mysql 5.2 负载均衡lb操作 ⚠️stream {} 必须与 http {}在同一级，而nginx主配置文件/etc/nginx/nginx.conf中include /etc/nginx/conf.d/*.conf;是在http中的，因此在/etc/nginx/conf.d/下编辑含有stream {}的配置文件是会报错的 编辑nginx主配置文件/etc/nginx/nginx.conf #在events下方 http上方加入以下内容，以解决stream必须与http同级的问题 include /etc/nginx/conf.e/*.conf; 创建目录 mkdir /etc/nginx/conf.e 编辑nginx配置文件 cat > /etc/nginx/conf.e/tcp.conf 检测nginx语法并重载nginx $ nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful $ nginx -s reload 5.3 测试 5.3.1 ssh连接测试 连接lb的12345端口，因为默认算法是rr，因此会轮流连接到web和mysql机器 5.3.2 mysql连接测试 测试前在mysql机器上进行一个授权 mysql> grant all on *.* to test@'%' identified by 'test'; Query OK, 0 rows affected, 1 warning (0.00 sec) 创建一个数据库，便于确认 mysql> create database tcp_test; Query OK, 1 row affected (0.00 sec) 连接成功，通过lb的四层负载均衡进行的端口转发连接到了mysql机器上的3306端口 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/nginx/9.3nginx负载均衡之基于不同客户端.html":{"url":"linux/linux服务/nginx/9.3nginx负载均衡之基于不同客户端.html","title":"nginx负载均衡之基于不同客户端","keywords":"","body":"nginx负载均衡之基于不同客户端 负载均衡还可以根据不同客户端进行相应的转发 以下示例为基于不同手机端及浏览器进行转发 实验环境 角色 IP地址 主机名 负载均衡 lb 10.0.0.10 lb 真实后端服务 web01 10.0.0.51 web01 真实后端服务 web02 10.0.0.52 web02 让手机端的访问转发到web01，让浏览器的访问和默认访问转发到web02 负载均衡操作 upstream iphone { server 10.0.0.51; } upstream android { server 10.0.0.51:8080; } upstream chrom { server 10.0.0.52; } upstream firefox { server 10.0.0.52:8080; } upstream defaults { server 10.0.0.52; } server { listen 80; server_name _; location / { #匹配iPhone手机访问 if ($http_user_agent ~* \"iphone\") { proxy_pass http://iphone; } #匹配Android手机访问 if ($http_user_agent ~* \"android\") { proxy_pass http://android; } #匹配谷歌浏览器访问 if ($http_user_agent ~* \"chrom\") { proxy_pass http://chrom; } #匹配firefox浏览器访问 if ($http_user_agent ~* \"firefox\") { proxy_pass http://Firefox; } #其他浏览器访问默认规则 proxy_pass http://defaults; } } web01操作 编辑nginx配置文件 server { listen 80; server_name _; root /data/iphone; index index.html; } server { listen 8080; server_name _; root /data/android; index index.html; } 创建网站根目录 mkdir -p /data/{iphone,android} echo 'iphone' >/data/iphone/index.html echo 'android' >/data/android/index.html web02操作 编辑nginx配置文件 server { listen 80; server_name _; root /data/chrom; index index.html; } server { listen 8080; server_name _; root /data/firefox; index index.html; } 创建网站根目录 mkdir -p /data/{chrom,firefox} echo 'chrom' >/data/chrom/index.html echo 'firefox' >/data/firefox/index.html 浏览器访问验证 模拟iphone nginx访问日志 10.0.0.2 - - [20/Jun/2020:19:22:50 +0800] \"GET / HTTP/1.1\" 200 7 \"-\" \"Mozilla/5.0 (iPhone; CPU iPhone OS 13_2_3 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.0.3 Mobile/15E148 Safari/604.1\" \"-\" 模拟安卓手机 nginx访问日志 10.0.0.2 - - [20/Jun/2020:19:21:29 +0800] \"GET / HTTP/1.1\" 304 0 \"-\" \"Mozilla/5.0 (Linux; Android 5.0; SM-G900P Build/LRX21T) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Mobile Safari/537.36\" \"-\" 谷歌浏览器访问 nginx访问日志 10.0.0.2 - - [20/Jun/2020:19:26:17 +0800] \"GET / HTTP/1.1\" 304 0 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\" \"-\" 火狐浏览器访问 nginx访问日志 10.0.0.2 - - [20/Jun/2020:19:22:05 +0800] \"GET / HTTP/1.1\" 304 0 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:77.0) Gecko/20100101 Firefox/77.0\" \"-\" 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/nginx/10.lnmp平台.html":{"url":"linux/linux服务/nginx/10.lnmp平台.html","title":"lnmp平台","keywords":"","body":"lnmp平台 一、lnmp简介 LNMP就是Linux+Nginx+MySQL+PHP，Linux作为服务器的操作系统，Nginx作为Web服务器、PHP作为解析动态脚本语言、MySQL即为数据库。 Linux作为服务器的操作系统。 Nginx作为WebServer服务器。 PHP 作为动态解析服务(php)。 MySQL作为后端存储数据库服务。 二、fastcgi协议 Nginx服务本身不能处理PHP的请求，用户发起PHP动态请求, Nginx处理过程如下 用户-->http协议-->Nginx-->fastcgi协议-->php-fpm fastcgi是nginx连接php-fpm之间的协议 nginx结合PHP FastCGI运行原理图 1.用户发起的所有请求会先抵达LNMP架构中的Nginx 2.如果用户请求的是静态内容，则Nginx直接响应并处理 3.如果用户请求的是动态内容，则通过fastcgi协议发送至php-fpm管理进程 4.php-fpm接收到请求后，会派生对应的wrapper线程，来解析用户请求的动态内容 5.如果涉及到查询数据库操作，则需要php先连接数据库，然后进行查询操作(php-mysql) 6.最终由mysql-->php-fpm->fastcgi->nginx->client 三、搭建lnmp平台 3.1 安装nginx nginx centos rpm包官方下载地址 3.1.1 下载安装包并安装 wget https://nginx.org/packages/rhel/7/x86_64/RPMS/nginx-1.18.0-1.el7.ngx.x86_64.rpm yum -y localinstall nginx-1.18.0-1.el7.ngx.x86_64.rpm 3.1.2 创建www用户并把nginx运行用户修改为www useradd -u www -M -s /sbin/nologin sed -i.bak '/user nginx;/cuser www;' /etc/nginx/nginx.conf 3.1.3 启动nginx并设置开机自启 systemctl enable nginx && systemctl start nginx 3.2 安装mysql mysql官方下载地址 3.2.1 下载安装包并安装 wget https://cdn.mysql.com//Downloads/MySQL-8.0/mysql-8.0.20-1.el7.x86_64.rpm-bundle.tar yum -y localinstall *.rpm 3.2.2 启动mysql并设置开机自启 systemctl enable mysqld && systemctl start mysqld 3.2.3 从/var/log/mysqld.log中找到mysql8的默认roo密码 $ grep 'root@localhost' /var/log/mysqld.log 2020-06-21T00:46:49.942011Z 6 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: jB6wzV 3.2.4 修改root密码 mysql8中密码要求为要包含大写字母，小写字母，数字，特殊符号 在MySQL 8.04前，执行：SET PASSWORD=PASSWORD('[新密码]');修改密码 但是MySQL8.0.4开始，这样默认是不行的。因为之前，MySQL的密码认证插件是mysql_native_password，而现在使用的是caching_sha2_password。 ⚠️mysql8.0.20初次修改root密码需要用如下命令 mysql> alter user user() identified by 'Bxb123.com'; Query OK, 0 rows affected (0.00 sec) 查看mysql8.0.20密码策略 mysql> show variables like 'validate_password%'; +--------------------------------------+--------+ | Variable_name | Value | +--------------------------------------+--------+ | validate_password.check_user_name | ON | | validate_password.dictionary_file | | | validate_password.length | 8 | | validate_password.mixed_case_count | 1 | | validate_password.number_count | 1 | | validate_password.policy | MEDIUM | | validate_password.special_char_count | 1 | +--------------------------------------+--------+ validate_password.length 固定密码的总长度； validate_password.dictionary_file 指定密码验证的文件路径； validate_password.mixed_case_count 整个密码中至少要包含大/小写字母的总个数； validate_password.number_count 整个密码中至少要包含阿拉伯数字的个数； validate_password.policy 指定密码的强度验证等级，默认为 MEDIUM； 关于 validate_password.policy 的取值： 0/LOW：只验证长度； 1/MEDIUM：验证长度、数字、大小写、特殊字符； 2/STRONG：验证长度、数字、大小写、特殊字符、字典文件； 如果需要设置空密码或者简单密码 设置空密码 mysql> UNINSTALL COMPONENT \"file://component_validate_password\"; Query OK, 0 rows affected (0.00 sec) mysql> set password=''; Query OK, 0 rows affected (0.00 sec) 设置简单密码 #设置密码的验证强度等级，LOW表示只验证密码长 set global validate_password.policy=LOW; #设置密码固定密码总长度 set global validate_password.length=4; 3.3 安装php 3.3.1 添加第三方yum源 安装epel源并添加第三方yum源 yum -y install epel-release && \\ yum -y install https://rpms.remirepo.net/enterprise/remi-release-7.rpm 选择要安装的php版本 export phpversion=php73 yum -y install $phpversion-php-fpm $phpversion-php-cli $phpversion-php-bcmath $phpversion-php-gd $phpversion-php-json $phpversion-php-mbstring $phpversion-php-mcrypt $phpversion-php-mysqlnd $phpversion-php-opcache $phpversion-php-pdo $phpversion-php-pecl-crypto $phpversion-php-pecl-mcrypt $phpversion-php-pecl-geoip $phpversion-php-recode $phpversion-php-snmp $phpversion-php-soap $phpversion-php-xml 通过以下命令来获取更多安装信息 yum search php73 安装后的php配置文件路径 /etc/opt/remi/php73 3.3.2 修改php配置文件 编辑文件/etc/opt/remi/php73/php-fpm.d/www.conf修改php运行用户和组为www sed -i.bak '/^user/c user = www' /etc/opt/remi/php73/php-fpm.d/www.conf && \\ sed -i '/^group/c group = www' /etc/opt/remi/php73/php-fpm.d/www.conf 3.3.3 启动php并设置开机自启 systemctl enable php73-php-fpm && systemctl start php73-php-fpm 四、基于lnmp平台搭建wordpress wordpress中文官网 wordpress下载地址 4.1 nginx配置 编辑wordpress的nginx配置文件/etc/nginx.conf.d/blog.conf ⚠️server_name下的index后边必须是index.php，否则会报错403 cat > /etc/nginx/conf.d/blog.conf wordpress https配置文件 server { listen 80; server_name blog.nginx.com; rewrite (.*) https://$server_name$request_uri redirect; } server { server_name _; listen 443; client_max_body_size 20m; ssl on; ssl_certificate ssl_key/server.crt; ssl_certificate_key ssl_key/server.key; location / { root /website/wordpress; index index.php index.html; } location ~ \\.php$ { root /website/wordpress; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } } 文件fastcgi_params fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;#脚本文件请求的路径 #以下为默认内容 fastcgi_param QUERY_STRING $query_string; #请求的参数;如?app=123 fastcgi_param REQUEST_METHOD $request_method; #请求的动作(GET,POST) fastcgi_param CONTENT_TYPE $content_type; #请求头中的Content-Type字段 fastcgi_param CONTENT_LENGTH $content_length; #请求头中的Content-length字段。 fastcgi_param SCRIPT_NAME $fastcgi_script_name; #脚本名称 fastcgi_param REQUEST_URI $request_uri; #请求的地址不带参数 fastcgi_param DOCUMENT_URI document_uri; #与document_uri; #与uri相同。 fastcgi_param DOCUMENT_ROOT $document_root; #网站的根目录。在server配置中root指令中指定的值 fastcgi_param SERVER_PROTOCOL $server_protocol; #请求使用的协议，通常是HTTP/1.0或HTTP/1.1。 fastcgi_param GATEWAY_INTERFACE CGI/1.1;#cgi 版本 fastcgi_param SERVER_SOFTWARE nginx/$nginx_version;#nginx 版本号，可修改、隐藏 fastcgi_param REMOTE_ADDR $remote_addr; #客户端IP fastcgi_param REMOTE_PORT $remote_port; #客户端端口 fastcgi_param SERVER_ADDR $server_addr; #服务器IP地址 fastcgi_param SERVER_PORT $server_port; #服务器端口 fastcgi_param SERVER_NAME $server_name; #服务器名，域名在server配置中指定的server_name #fastcgi_param PATH_INFO $path_info;#可自定义变量 # PHP only, required if PHP was built with --enable-force-cgi-redirect #fastcgi_param REDIRECT_STATUS 200; 在php可打印出上面的服务环境变量 如：echo $_SERVER['REMOTE_ADDR'] 创建网站根目录 mkdir /website 编辑php测试配置文件 cat > /etc/nginx/conf.d/test.conf 创建info.php测试php是否正常解析 cat > /tmp/info.php EOF 注意端口是88 创建mysql.php测试php是否能连接mysql数据库服务 cat > /tmp/mysql.php EOF 本机测试即可 $ curl 127.0.0.1:88/mysql.php Connection successful 4.2 下载wordpress安装包并解压至nginx网站根目录 wget https://cn.wordpress.org/latest-zh_CN.tar.gz tar xf latest-zh_CN.tar.gz -C /website cd /website && chown -R www.www wordpress/ 4.3 创建数据库并授权 mysql> create database wordpress; Query OK, 1 row affected (0.00 sec) #mysql8不能直接创建用户授权，需要先创建用户，然后授权 mysql> create user wordpress@'localhost' identified by 'wordpress'; Query OK, 0 rows affected (0.01 sec) mysql> grant all on wordpress.* to wordpress@'localhost'; Query OK, 0 rows affected (0.00 sec) 4.4 浏览器访问IP开始安装 第一步、浏览器访问IP开始安装 点击现在就开始 第二步、填写数据库信息 第三步、开始安装 第四步、配置站点标题、用户名密码、邮箱 第五步、完成安装 第六步、登陆wordpress 登陆后首界面 五、文件上传限制问题 修改php配置文件php.ini upload_max_filesize = 20M post_max_size = 20M 修改nginx配置文件 client_max_body_size 300M; php.ini 配置对php上传文件大小的影响参数有： 配置项 值 功能 file_uploads ON 确定服务器上的PHP脚本是否可以接受HTTP文件上传 memory_limit 8M 设置脚本可以分配的最大内存量，防止失控的脚本独占服务器内存 post_max_size 8M 限制通过POST方法可以接受的信息最大量 upload_max_filesize 2M 限制PHP处理上传文件最大值，此值必须小于post_max_size值 ⚠️当post_max_size值小于upload_max_filesize的值，以post_max_size的值为准 而对应的$_FILES 中error对应的错误提示有： 文件上传时产生的错误 0：表示没有发生任何错误，文件上传成功 1：表示上传文件的大小超出了再PHP配置文件中upload_max_filesize选项限制的值 2：表示上传文件大小超出了HTML表单中MAX_FILE_SIZE选项所指定的值 3：表示文件只被部分上传 4：表示没有上传任何文件 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/nginx/11.nginx https.html":{"url":"linux/linux服务/nginx/11.nginx https.html","title":"nginx https","keywords":"","body":"nginx https openssl官网 一、检查环境并创建存放证书目录 1.1 openssl版本1.0.2以上 $ openssl version OpenSSL 1.0.2k-fips 26 Jan 2017 1.2 nginx必须支持--with-http_ssl_module模块 #先把输出放到一个文件中，然后从文件中过滤 nginx -V &> nginx.txt 1.3 创建存放nginx证书的目录 mkdir /etc/nginx/ssl_key && cd /etc/nginx/ssl_key 二、生成证书 2.1 生成私钥 使用openssl充当CA权威机构创建私钥(生产不可能使用此方式生成证书，不被互联网CA权威承认的黑户证书) 加-idea参数就会提示输入密码，最少4位 openssl genrsa -out ca.key 2048 2.2 生成自签证书 交互式 openssl req -x509 -new -nodes -sha256 -days 36500 -key ca.key -out ca.crt 参数说明 参数 说明 req 请求子命令 -x509 证书格式 -new 生成证书请求 -nodes 私钥不加密 -days 证书有效期 -key 指定私钥文件 -out 输入证书文件 免交互式 openssl req -x509 -new -nodes -sha256 -days 36500 \\ -subj \"/C=CN/ST=Beijing/L=Beijing/O=dev/OU=devops/CN=www.yzbpdcnm.com\" \\ -key ca.key \\ -out ca.crt 免交互式-subj参数 简写 完整单词 含义 C Country Name 国家 ST State or Province Name 省 L Locality Name 城市 O Organization Name 组织名称 OU Organization Unit Name 组织单位名称 CN Common Name 域名 三、配置nginx以https方式访问 3.1 编辑nginx配置文件 cat > /etc/nginx/conf.d/https-test.conf 3.2 创建网站根目录 mkdir /code && echo 'https test' >/code/index.html 3.3 本地绑定hosts浏览器访问 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/nginx/12.nginx rewrite.html":{"url":"linux/linux服务/nginx/12.nginx rewrite.html","title":"nginx rewrite","keywords":"","body":"nginx rewrite 本文部分抄袭于此 nginx rewrite官方文档 一、rewrite基本概述 1.1 什么是rewrite rewrite即URL重写， 主要实现url地址重写以及重定向, 就是把传入Web的请求重定向到其他URL的过程。 1.2 rewrite使用场景 1.URL地址跳转，例如用户访问aaa.com将其跳转到bbb.com , 或者当用户通过http的方式访问aaa.com时，将其跳转至https的方式访问bbb.com 2.URL伪静态, 将动态页面显示为静态页面方式的一种技术, 便于搜索引擎的录入, 同时减少动态URL地址对外暴露过多的参数, 提升更高的安全性。 3.搜索引擎SEO优化依赖于url路径, 以便支持搜索引擎录入 二、rewrite配置语法 Syntax: rewrite regex replacement [flag]; Default: — Context: server, location, if 在匹配过程中可以引用一些Nginx的全局变量 变量 说明 $document_root 针对当前请求的根路径设置值 $host 请求信息中的\"Host\"，如果请求中没有Host行，则等于设置的服务器名 $request_filename 当前请求的文件路径名（带网站的主目录/code/images/test.jpg） $request_uri 当前请求的文件路径名（不带网站的主目录/images/test.jpg） $scheme 请求用的协议，比如http或者https rewrite匹配优先级 1.执行server块的rewrite指令 2.执行location匹配 3.执行选定的location中的rewrite 三、flag rewrite指令根据表达式来重定向URI, 或者修改字符串。 可以应用于server、location、if环境下，每行rewrite指令最后跟一个flag标记，支持的flag标记有如下表格所示 flag 说明 last 本条规则匹配完成后，停止匹配，不在匹配后面的规则 break 本条规则匹配完成后，停止匹配，不在匹配后面的规则 redirect 返回302临时重定向， 地址栏会显示跳转后的地址 permanent 返回301永久重定向，地址栏会显示跳转后的地址 last 官方解释 停止处理当前ngx_http_rewrite_module指令集， 并开始搜索与更改后的URI相匹配的新位置 如果匹配的URI，rewrite在server块中，并且last做为flag，匹配到此rewrite URI时，不再向下匹配server块中的rewrite，进而继续下面location URI的查找匹配； 如果匹配的URI，rewrite在location块中，last做为flag，匹配到此rewrite URI时，会跳出此location块，继续从上到下查找其它的location块URI，但不会再匹配server块中的rewrite中的URI break 官方解释 ngx_http_rewrite_module与break指令一样， 停止处理当前的指令集 如果匹配的URI，rewrite在server块中，并且break做为flag，匹配到此rewrite URI时，不再向下匹配server块中的rewrite，进而继续下面location URI的查找匹配； 如果匹配的URI，rewrite在location块中，break做为flag，匹配到此rewrite时，不会跳出此location块，而是继续对location块下面的语句继续运行，不会跳出此location块，并且也不会匹配location 块下面的其它rewrite规则； 完成该rewrite规则的执行后，停止处理后续rewrite指令集，并不再重新查找；但是当前location内剩余非rewrite语句和location外的的非rewrite语句可以执行 redirect 官方解释 返回带有302代码的临时重定向；如果替换字符串不是以 \"http://\"，\" https://\"或\" $scheme\" 开头，则使用该字符串 permanent 官方解释 返回301永久重定向，地址栏会显示跳转后的地址，即表示如果客户端不清理浏览器缓存，那么返回的结果将永久保存在客户端浏览器中了 四、nginx处理http请求的11个阶段 ngx_http_post_read_phase 读取请求头，接收到http头部后处理阶段 ngx_http_server_rewrite_phase 执行server块中rewrite，独立http阶段 ngx_http_find_config_phase 根据uri查找替换location，uri寻找匹配的location阶段 ngx_http_rewrite_phase 根据替换结果，继续执行rewrite，寻找到匹配的location之后再修改请求的uri ngx_http_post_rewrite_phase 执行rewrite后处理，在rewrite重写url后，防止错误的nginx.conf配置导致死循环(递归的修改uri) ngx_http_preaccess_phase 认证预处理，请求限制，连接限制，表示在处理ngx_http_access_phase阶段请求访问限制前，http模块可以介入处理的阶段 ngx_http_access_phase 认证处理，用于让http模块判断是否允许这个请求访问nginx服务 ngx_http_post_access_phase 认证后处理，认证不通过，丢包，在ngx_http_access_phase阶段中，当http模块的handler处理函数返回不允许访问的错误码时(ngx_htp_forbidden或者ngx_http_unauhorized)，这里将负责向用户发送拒绝服务的错误相应 ngx_http_try_files_phase 尝试try标签，此阶段专门为try_files配置预设立，当http请求访问静态资源时，try_files配置项可以使这个配置顺序的访问多个静态资源 ngx_http_content_phase 内容处理，用于处理http请求内容的阶段，这是大部分http模块最愿意介入的阶段 ngx_http_log_phase 日志处理，处理完请求后记录日志的阶段 五、rewrite配置实例 5.1 无flag测试 在nginx中引入echo、sleep、time等功能 github地址 无flag测试用例1 server { listen 80; rewrite ^/(.*)$ /nginx_one/$1; rewrite ^/nginx_one/(.*)$ /nginx_two/$1; location / { echo \"This is default location\"; echo \"uri: ${uri}\"; } location /nginx_one/ { echo \"This is nginx_one location\"; echo \"uri: ${uri}\"; } location /nginx_two/ { echo \"This is nginx_two location\"; echo \"uri: ${uri}\"; } } 测试结果 $ curl 127.0.0.1/abc This is nginx_two location uri: /nginx_two/abc 无 flag 时，rewrite 会依次向下匹配，根据nginx在http请求处理的阶段中，我们 会先匹配server块中的rewrite规则； 第一次匹配rewrite ^/(.*)$ /nginx_one/$1; URI变成:/nginx_one/abc，无flag继续向下匹配； 第二次匹配rewrite ^/nginx_one/(.*)$ /nginx_two/$1; URI变成/nginx_two/abc； 再向下FIND_CONFIG阶段，查找location进行匹配，正好找到location /nginx_two/ 所以 response 如上； 无flag测试用例2 server { listen 80; rewrite ^/(.*)$ /nginx_one/$1; location / { echo \"This is default location\"; echo \"uri: ${uri}\"; } location /nginx_one/ { rewrite ^/nginx_one/(.*)$ /nginx_two/$1; echo \"This is nginx_one location\"; echo \"uri: ${uri}\"; } location /nginx_two/ { echo \"This is nginx_two location\"; echo \"uri: ${uri}\"; } } 测试结果 $ curl 127.0.0.1/abc This is nginx_two location uri: /nginx_two/abc 无flag，处理server块阶段，匹配rewrite ^/(.*)$ /nginx_one/$1 ，URI为：/nginx_one/abc; 到FIND_CONFIG阶段，匹配location, location /nginx_one/ ,这个location块中有rewrite再次匹配^/nginx_one/(.*)$ /nginx_two/$1; URI变为：/nginx_two/abc，这里没有flag，会跳出继续FIND_CONFIG阶段，而不会到 SERVER_REWRITE 阶段；而是匹配location /nginx_two/ ，所以response如上。 5.2 有flag测试 redirect和permanent的区别就是redirect是临时重定向302，而permanent是永久重定向301 5.2.1 flag redirect测试用例1 server { listen 80; #rewrite ^/(.*)$ /nginx_one/$1 redirect; rewrite ^/(.*)$ https://www.baidu.com/ redirect; rewrite ^/nginx_one/(.*)$ /nginx_two/$1; rewrite ^/nginx_two/(.*)$ /nginx_three/$1; location / { echo \"This is default location\"; echo \"uri: ${uri}\"; } location /nginx_one/ { echo \"This is nginx_one location\"; echo \"uri: ${uri}\"; } location /nginx_two/ { echo \"This is nginx_two location\"; echo \"uri: ${uri}\"; } location /nginx_three/ { echo \"This is nginx_three location\"; echo \"uri: ${uri}\"; } } 测试结果 浏览器访问 虚拟机IP地址/abc 会跳转到百度首页 状态码为临时重定向302 这里的flag是redirect，说明需要重定向到replacement，正好这里的replacement有\"https://\"，此时会直接跳转并返回给客户端； 如果打开#rewrite ^/(.*)$ /nginx_one/$1 redirect;的注释，浏览器中访问会提示重定向次数过多 5.2.2 flag redirect测试用例2 server { listen 80; rewrite_log on; rewrite ^/nginx_one/(.*)$ /nginx_two/$1; rewrite ^/nginx_two/(.*)$ /nginx_three/$1 redirect; rewrite ^/(.*)$ /nginx_one/$1; location / { echo \"This is default location\"; echo \"uri: ${uri}\"; } location /nginx_one/ { echo \"This is nginx_one location\"; echo \"uri: ${uri}\"; } location /nginx_two/ { echo \"This is nginx_two location\"; echo \"uri: ${uri}\"; } location /nginx_three/ { echo \"This is nginx_three location\"; echo \"uri: ${uri}\"; } } 测试结果 $ curl -I 127.0.0.1/nginx_one/abc HTTP/1.1 302 Moved Temporarily Server: nginx/1.16.1 Date: Mon, 22 Jun 2020 12:05:16 GMT Content-Type: text/html Content-Length: 145 Location: http://127.0.0.1/nginx_three/abc Connection: keep-alive 1.匹配rewrite ^/nginx_one/(.*)$ /nginx_two/$1; 后，URI变为：/nginx_two/abc ; 无flag，继续向下； 2.继续匹配 rewrite ^/nginx_two/(.*)$ /nginx_three/$1 redirect; 302临时 重定向，URI: http://127.0.0.1/nginx_three/abc, 3.再次访问，此时会从SERVER_REWRITE这个阶段开始，此时匹配的是 rewrite ^/(.*)$ /nginx_one/$1; URI变为：/nginx_one/nginx_three/abc ，无flag，向 > 下FIND_CONFIG阶段； 4.最后查看location 匹配location /nginx_one/ ,所以回显如上； 5.2.3 flag last测试用例1 server { listen 80; rewrite_log on; rewrite ^/nginx_one/(.*)$ /nginx_two/$1 last; rewrite ^/nginx_two/(.*)$ /nginx_three/$1; location / { echo \"This is default location\"; echo \"uri: ${uri}\"; } location /nginx_one/ { echo \"This is nginx_one location\"; echo \"uri: ${uri}\"; } location /nginx_two/ { echo \"This is nginx_two location\"; echo \"uri: ${uri}\"; } location /nginx_three/ { echo \"This is nginx_three location\"; echo \"uri: ${uri}\"; } } 测试结果 $ curl 127.0.0.1/nginx_one/abc This is nginx_two location uri: /nginx_two/abc 1.匹配 rewrite ^/k8svip_one/(.*)$ /k8svip_two/$1 last;遇到last，停止同级段的匹配，这里的意思是，中止server段向下的匹配，进行FIND_CONFIG阶段，URI变为：/k8svip_two/abc; 这里可以看出，如果last没有中止server段向下的匹配，会匹配rewrite ^/k8svip_two/(.*)$ /k8svip_three/$1，实际结果是没有匹配的； 2.由上面步骤之后，匹配location /k8svip_two/， 所以会出现上面的response结果; 5.2.4 flag last测试用例2 server { listen 80; rewrite_log on; rewrite ^/(.*)$ /nginx_one/$1; rewrite ^/nginx_three/(.*)$ /nginx_four/$1; location / { echo \"This is default location\"; echo \"uri: ${uri}\"; } location /nginx_one/ { rewrite ^/(.*)$ /nginx_three/$1 last; rewrite ^/nginx_three/(.*)$ /; echo \"This is nginx_one location\"; echo \"uri: ${uri}\"; } location /nginx_two/ { echo \"This is nginx_two location\"; echo \"uri: ${uri}\"; } location /nginx_three/ { echo \"This is nginx_three location\"; echo \"uri: ${uri}\"; } location /nginx_four/ { echo \"This is nginx_four location\"; echo \"uri: ${uri}\"; } } 测试结果 $ curl 127.0.0.1/abc This is nginx_three location uri: /nginx_three/nginx_one/abc 1.匹配rewrite ^/(.*)$ /k8svip_one/$1; URI变为：/nginx_one/abc; 2.匹配location /nginx_one/ 进而匹配location块中的rewrite ^/(.*)$ /nginx_three/$1 last; 因为是last，会跳出location继续FIND_CONFIG阶段 3.URI为：/nginx_three/nginx_one/abc；而不会到SERVER_WRITE阶段； 匹配 location /nginx_three/ ,所以看到上面的response； 5.2.5 flag break测试用例1 server { listen 80; rewrite_log on; rewrite ^/nginx_one/(.*)$ /nginx_two/$1 break; rewrite ^/nginx_two/(.*)$ /nginx_three/$1; location / { echo \"This is default location\"; echo \"uri: ${uri}\"; } location /nginx_one/ { echo \"This is nginx_one location\"; echo \"uri: ${uri}\"; } location /nginx_two/ { echo \"This is nginx_two location\"; echo \"uri: ${uri}\"; } location /nginx_three/ { echo \"This is nginx_three location\"; echo \"uri: ${uri}\"; } } 测试结果 $ curl 127.0.0.1/nginx_one/abc This is nginx_two location uri: /nginx_two/abc 1.匹配rewrite ^/nginx_one/(.*)$ /nginx_two/$1 break; flag为break，结束本层级的rewirte匹配，URI变为：/nginx_two/abc 2.继续FIND_CONFIG阶段，匹配location /nginx_two/; 所以response 如上； 5.2.6 flag break测试用例2 server { listen 80; rewrite_log on; rewrite ^/(.*)$ /nginx_one/$1; location / { echo \"This is default location\"; echo \"uri: ${uri}\"; } location /nginx_one/ { rewrite ^/(.*)$ /nginx_three/$1 break; rewrite ^/nginx_two/(.*)$ /; echo \"This is nginx_one location\"; echo \"uri: ${uri}\"; } location /nginx_two/ { echo \"This is nginx_two location\"; echo \"uri: ${uri}\"; } location /nginx_three/ { echo \"This is nginx_three location\"; echo \"uri: ${uri}\"; } } 测试结果 $ curl 127.0.0.1/abc This is nginx_one location uri: /nginx_three/nginx_one/abc 1.匹配rewrite ^/(.*)$ /nginx_one/$1; URI变为：/nginx_one/abc 2.匹配location /nginx_one/，然后继续 rewrite ^/(.)$ /nginx_three/$1 break; flag为break，结束本层级的rewrite ^/(.)$ /nginx_three/$1 break;，并且继续进行本层级的其它操作； 3.此时的URI：/nginx_three/nginx_one/abc,所以response如上； 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/nginx/13.nginx动静分离.html":{"url":"linux/linux服务/nginx/13.nginx动静分离.html","title":"nginx动静分离","keywords":"","body":"nginx动静分离 一、动静分离简介 动静分离，通过中间件将动态请求和静态请求进行分离, 分离资源, 减少不必要的请求消耗, 减少请求延时。 好处 动静分离后, 即使动态服务不可用, 但静态资源不会受到影响 实验环境 角色 服务 IP地址 主机名 负载均衡 Nginx Proxy 10.0.0.10 lb01 静态资源 Nginx Static 10.0.0.51 web01 动态资源 Tomcat Server 10.0.0.52 tomcat 二、配置过程 2.1 负载均衡配置 编辑nginx配置文件 upstream static { server 10.0.0.51:80; } upstream tomcat { server 10.0.0.52:8080; } server { listen 80; server_name _; location / { root /website; index index.html; } location ~* .*\\.(png|jpg|gif)$ { proxy_pass http://static; } location ~* .*\\.jsp$ { proxy_pass http://tomcat; } } 2.2 web01配置静态资源 编辑nginx配置文件 server { listen 80; server_name _; location ~* .*\\.(png|jpg|gif)$ { root /website/images; } } 创建网站根目录 #创建网站根目录 mkdir -p /website/images && cd /website/images #下载一个图片 wget -O /website/images/nginx.png https://nginx.org/nginx.png 2.3 tomcat配置动态资源 编辑jsp测试文件 ⚠️这里已经二进制安装tomcat8.5 cat > /usr/local/tomcat-8.5.56/webapps/ROOT/tomcat_test.jsp JSP Test Page Random number:\"); out.println(rand.nextInt(99)+100); %> EOF 三、访问测试 访问静态资源 访问动态资源 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/nginx/nginx增加新模块.html":{"url":"linux/linux服务/nginx/nginx增加新模块.html","title":"nginx增加新模块","keywords":"","body":"nginx增加新模块 场景：编译安装的nginx后续可能会增加一些第三方模块或者未编译的nginx模块 一、编译安装的nginx增加新模块 1.1 查看nginx编译安装参数 $ nginx -V nginx version: nginx/1.16.1 built by gcc 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) built with OpenSSL 1.0.2k-fips 26 Jan 2017 TLS SNI support enabled configure arguments: --prefix=/etc/nginx --user=nginx --group=nginx --sbin-path=/usr/sbin/nginx --conf-path=/etc/nginx/nginx.conf --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --with-http_gzip_static_module --with-http_stub_status_module --with-http_ssl_module --with-pcre --with-file-aio --with-http_realip_module --without-http_scgi_module --without-http_uwsgi_module --without-http_fastcgi_module 1.2 下载第三方模块 echo-nginx-module github地址 ngx_echo 为Nginx配置文件带来\"echo\"，\"sleep\"，\"time\"，\"exec\"和更多shell样式的东西 wget https://github.com/openresty/echo-nginx-module/archive/v0.61.tar.gz 解压缩至/usr/local tar xf v0.61.tar.gz -C /usr/local 使用选项--add-module=/path/to/echo-nginx-module添加模块 1.3 重新编译nginx ⚠️make之后不要执行make install ！！！ #进入nginx源码目录 cd nginx-1.16.1 #重新./configure ./configure --prefix=/etc/nginx --user=nginx --group=nginx --sbin-path=/usr/sbin/nginx --conf-path=/etc/nginx/nginx.conf --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --with-http_gzip_static_module --with-http_stub_status_module --with-http_ssl_module --with-pcre --with-file-aio --with-http_realip_module --without-http_scgi_module --without-http_uwsgi_module --without-http_fastcgi_module --add-module=/usr/local/echo-nginx-module-0.61 #编译，不能执行make install make 安装完成后查看，最后就是添加的第三方模块 $ nginx -V nginx version: nginx/1.16.1 built by gcc 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) built with OpenSSL 1.0.2k-fips 26 Jan 2017 TLS SNI support enabled configure arguments: --prefix=/etc/nginx --user=nginx --group=nginx --sbin-path=/usr/sbin/nginx --conf-path=/etc/nginx/nginx.conf --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --with-http_gzip_static_module --with-http_stub_status_module --with-http_ssl_module --with-pcre --with-file-aio --with-http_realip_module --without-http_scgi_module --without-http_uwsgi_module --without-http_fastcgi_module --add-module=/usr/local/echo-nginx-module-0.61 1.4 nginx二进制文件操作 备份原有文件 mv /usr/sbin/nginx{,.bak} 拷贝新文件 cp nginx-1.16.1/objs/nginx /usr/sbin 1.5 编译nginx配置文件以测试模块安装是否成功 server { listen 88; server_name _; location /test { echo \"This is default location\"; echo \"uri: ${uri}\"; } } 检测nginx语法并重载nginx 这里语法不报错就证明第三方模块echo安装成功了 $ nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful $ nginx -s reload 本机访问测试 $ curl 127.0.0.1:88/test This is default location uri: /test 二、rpm包安装的nginx增加新模块 nginx是使用rpm包安装的，如果想要安装第三方模块的解决方法 2.1 查看nginx安装的模块 $ nginx -V nginx version: nginx/1.16.1 built by gcc 4.8.5 20150623 (Red Hat 4.8.5-36) (GCC) built with OpenSSL 1.0.2k-fips 26 Jan 2017 TLS SNI support enabled configure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib64/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt='-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -fPIC' --with-ld-opt='-Wl,-z,relro -Wl,-z,now -pie' 安装完成后查看，最后就是添加的第三方模块 $ nginx -V nginx version: nginx/1.16.1 built by gcc 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) built with OpenSSL 1.0.2k-fips 26 Jan 2017 TLS SNI support enabled configure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib64/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt='-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -fPIC' --with-ld-opt='-Wl,-z,relro -Wl,-z,now -pie' --add-module=/usr/local/echo-nginx-module-0.61 2.2 下载一个相同版本的nginx源码包 nginx官方源码下载地址 wget https://nginx.org/download/nginx-1.16.1.tar.gz 2.3 重新编译nginx 解压缩源码包并进入目录 tar xf nginx-1.16.1.tar.gz cd cd nginx-1.16.1/ ⚠️make之后不要执行make install ！！！ #重新./configure ./configure --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib64/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt='-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -fPIC' --with-ld-opt='-Wl,-z,relro -Wl,-z,now -pie' --add-module=/usr/local/echo-nginx-module-0.61 #编译 make 2.4 nginx二进制文件操作 备份原有文件 mv /usr/sbin/nginx{,.bak} 拷贝新文件 cp nginx-1.16.1/objs/nginx /usr/sbin 2.5 编译nginx配置文件以测试模块安装是否成功 server { listen 88; server_name _; location /test { echo \"This is default location\"; echo \"uri: ${uri}\"; } } ⚠️因为是rpm包安装的nginx，因此需要使用systemctl命名重启一下nginx systemctl restart nginx 检测nginx语法并重载nginx 这里语法不报错就证明第三方模块echo安装成功了 $ nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful $ nginx -s reload 本机访问测试 $ curl 127.0.0.1:88/test This is default location uri: /test 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/nginx/nginx解决非80端口https问题.html":{"url":"linux/linux服务/nginx/nginx解决非80端口https问题.html","title":"nginx解决非80端口https问题","keywords":"","body":"nginx解决非80端口https问题 解决思路： 监听80端口，80重定向到https443端口，443端口代理别的端口 server { listen 80; server_name pan.pptfz.top; return 301 https://$server_name$request_uri; } server { listen 443 ssl; server_name pan.pptfz.top; if ($host != 'pan.pptfz.top') { rewrite ^(.*)$ https://pan.pptfz.top/$1 permanent; } if ($request_uri ~ \"^[^?]*//\") { rewrite \"(.*)\" $scheme://$host$1 permanent; } location / { try_files /_not_exists_ @backend; } location @backend { proxy_set_header X-Forwarded-For $remote_addr; proxy_set_header Host $http_host; proxy_set_header X-Forwarded-Proto $scheme; proxy_pass http://127.0.0.1:5212; } access_log /var/log/nginx/pan.pptfz.top.access.log main; error_log /var/log/nginx/pan.pptfz.top.error.log; ssl_certificate /etc/nginx/ssl_key/pan/3356127_pan.pptfz.top.pem; ssl_certificate_key /etc/nginx/ssl_key/pan/3356127_pan.pptfz.top.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; } 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/nginx/14.nginx+keepalived实现负载均衡高可用.html":{"url":"linux/linux服务/nginx/14.nginx+keepalived实现负载均衡高可用.html","title":"nginx+keepalived实现负载均衡高可用","keywords":"","body":"nginx+keepalived实现负载均衡高可用 keepalived官网 keepalived github地址 keepalived官方文档 keepalived源码包官方下载地址 一、keepalived简介 Keepalived是用C语言编写的路由软件。该项目的主要目标是为Linux系统和基于Linux的基础架构提供负载均衡和高可用性的简单而强大的功能。 负载平衡框架依赖于提供第4层负载平衡的著名且广泛使用的Linux虚拟服务器（IPVS）内核模块。Keepalived实现了一组检查器，以根据其运行状况动态，自适应地维护和管理负载平衡的服务器池。另一方面，VRRP实现了高可用性协议。VRRP是路由器故障转移的基础。此外，Keepalived还实现了一组VRRP有限状态机的钩，从而提供了低级和高速协议交互。为了提供最快的网络故障检测，Keepalived实施BFD协议。VRRP状态转换可以考虑BFD提示来驱动快速状态转换。Keepalived框架可以独立使用，也可以一起使用以提供弹性基础架构。 二、keepalived负载均衡高可用配置过程 实验环境 角色 IP 主机名 keepalived-master 10.0.0.10 keepalived01 keepalived-slave 10.0.0.11 keepalived02 web01 10.0.0.51 nginx01 web02 10.0.0.52 nginx02 2.1 负载均衡端配置 2.1.1 安装keepalived yum -y install keepalived centos7.7中默认的keepalive版本是1.3.5，如果需要高版本请到keepalived github地址或者keepalived官网下载，这里仅做实验直接yum安装 $ keepalived -version Keepalived v1.3.5 (03/19,2017), git commit v1.3.5-6-g6fa32f2 2.1.2 lb01(keepalived master)编辑配置文件 lb01编辑keepalived配置文件/etc/keepalived/keepalived.conf #备份原有文件 mv /etc/keepalived/keepalived.conf{,.bak} #重新编辑文件 cat > /etc/keepalived/keepalived.conf 配置文件参数含义 #配置含义 global_defs { router_id lb01 #表示id身份，名称随意 } vrrp_instance VI_1 { state MASTER #状态，角色为master interface eth0 #VIP绑定的网卡 virtual_router_id 50 #主和备的虚拟id号要相同，表明在一个组当中，名称随意，不要超过255 priority 150 #优先级，越大优先级越高 advert_int 1 #心跳检测，单位秒，备机每隔1秒检测一次主的存活状态 authentication { #认证信息 auth_type PASS auth_pass 123456 } virtual_ipaddress { 10.0.0.100 #虚拟IP } } 2.1.3 lb02(keepalived backup)编辑配置文件 #备份原有文件 mv /etc/keepalived/keepalived.conf{,.bak} #重新编辑文件 cat > /etc/keepalived/keepalived.conf 配置文件参数含义 global_defs { router_id lb02 #表示id身份，名称随意 } vrrp_instance VI_1 { state BACKUP #状态，因为是slave，所以是BACKUP interface eth0 #VIP绑定的网卡 virtual_router_id 50 #主和备的虚拟id号要相同，表明在一个组当中，名称随意，不要 超过255 priority 100 #优先级，越大优先级越高 advert_int 1 #心跳检测，单位秒，备机每隔1秒检测一次主的存活状态 authentication { #认证信息 auth_type PASS auth_pass 123456 } virtual_ipaddress { 10.0.0.100 #虚拟IP } } 对比keepalived的master与backup配置的区别 Keepalived配置区别 Master配置 Backup节配置 route_id(唯一标识) route_id lb01 route_id lb02 state(角色状态) state Master state Backup priority(竞选优先级) priority 150 priority 100 2.1.4 启动keepalived lb01和lb02相同操作 systemctl start keepalived && systemctl enable keepalived 2.1.5 检测lb01是否有vip 可以看到，启动keepalived后，lb01 eth0网卡就有了VIP 10.0.0.100 $ ip a s eth0 2: eth0: mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:1c:42:f3:3c:78 brd ff:ff:ff:ff:ff:ff inet 10.0.0.10/24 brd 10.0.0.255 scope global eth0 valid_lft forever preferred_lft forever inet 10.0.0.100/32 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::21c:42ff:fef3:3c78/64 scope link valid_lft forever preferred_lft forever 2.1.6 验证VIP是否能够正常漂移 VIP首先在master上，当master宕机后，VIP会漂移至backup，当master恢复时VIP会自动漂移回来！！！ 先停止lb01上的keepalived systemctl stop keepalived 查看lb01上是否有VIP 可以看到，VIP此时已经没有了 $ ip a s eth0 2: eth0: mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:1c:42:f3:3c:78 brd ff:ff:ff:ff:ff:ff inet 10.0.0.10/24 brd 10.0.0.255 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::21c:42ff:fef3:3c78/64 scope link valid_lft forever preferred_lft forever 查看lb02上是否有VIP 当keepalived master宕机后，VIP就会漂移到lb02 $ ip a s eth0 2: eth0: mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:1c:42:c1:0b:16 brd ff:ff:ff:ff:ff:ff inet 10.0.0.11/24 brd 10.0.0.255 scope global eth0 valid_lft forever preferred_lft forever inet 10.0.0.100/32 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::21c:42ff:fec1:b16/64 scope link valid_lft forever preferred_lft forever 重新启动lb01上的keepalived systemctl start keepalived #查看VIP $ ip a s eth0 2: eth0: mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:1c:42:f3:3c:78 brd ff:ff:ff:ff:ff:ff inet 10.0.0.10/24 brd 10.0.0.255 scope global eth0 valid_lft forever preferred_lft forever inet 10.0.0.100/32 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::21c:42ff:fef3:3c78/64 scope link valid_lft forever preferred_lft forever 2.1.7 编辑nginx配置文件 lb01和lb02编辑nginx配置文件 cat > /etc/nginx/conf.d/kd.test.conf 检测nginx语法并重载nginx $ nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful $ nginx -s reload 2.2 后端真实服务web配置 web01操作 2.2.1 编辑nginx配置文件 cat >> /etc/nginx/conf.d/kd.test.conf 2.2.2 创建网站根目录 mkdir /code && echo \"web01 web01 web01\" > /code/index.html 2.2.3 检测nginx语法并重载nginx $ nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful $ nginx -s reload web02操作 2.2.4 编辑nginx配置文件 cat >> /etc/nginx/conf.d/kd.test.conf 2.2.5 创建网站根目录 mkdir /code && echo \"web02 web02 web02\" > /code/index.html 2.2.6 检测nginx语法并重载nginx $ nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful $ nginx -s reload 2.3 浏览器验证负载均衡是否正常工作 浏览器访问VIP 10.0.0.100 三、nginx宕机问题 如果Nginx宕机，会导致用户请求失败， 但Keepalived并不会进行切换，所以编写nginx检测脚本，检测nginx存活状态，不存活则kill掉nginx和keepalived，然后VIP进行漂移 3.1 编辑脚本 lb01操作 #创建存放脚本的目录 mkdir -p /server/scripts #编辑脚本内容 cat >> /server/scripts/check_web.sh 3.2 验证脚本是否生效 故意把nginx配置文件修改错误(比如删除一个括号或者分号)，然后停止lb01上的nginx，因为上边的脚本中会判断nginx如果不存活就启动nginx，把nginx配置文件改错了nginx就无法正常启动过了 systemctl stop nginx 后台脚本检测到nginx不存活会kill掉keepalived，此时浏览器访问会报错，隔几秒就恢复了，因为VIP已经漂移至lb02上 3.3 在keepalived中调用检测脚本 ⚠️nohup sh /server/scripts/check_web.sh &执行脚本属于手动执行，还可以在keepalived配置文件中配置调用监控脚本 lb01、lb02都需要操作 编辑keepalived配置文件/etc/keepalived/keepalived.conf #在global_defs标签下增加如下内容 vrrp_script check_web { script \"/server/scripts/check_web.sh\" interval 10 weight 50 } #track_script标签要写在vrrp_instance VI_1{}中 track_script { check_web } ⚠️⚠️⚠️vrrp_script{}中的interval时间需大于脚本中的sleep时间 否则会报错Keepalived_vrrp[2612]: /server/scripts/check_web.sh exited due to signal 15 这样就能够使keepalived自动调用监控脚本了，keepalived会根据配置文件中vrrp_script {}中的interval参数来决定每隔几秒执行脚本，interval后面的数字就表明执行脚本的间隔时间 在脚本中我们定义了，keepalived master上检测nginx是否存活，不存活尝试启动nginx，当无法成功启动nginx的时候停止master上的keepalived，然后让VIP漂移，这样的话就实现了当nginx服务挂掉时keepalived VIP能够漂移从而不影响客户端访问 四、keepalived高可用脑裂 概念 脑裂就是由于某些原因，导致两台keepalived高可用服务器在指定时间内，无法检测到对方的心跳消息，各自取得资源及服务的所有权，而此时的两台高可用服务器又都还活着，产生裂脑的情况下，master和backup上都会有VIP 产生脑裂的原因 1.服务器网络故障 2.服务器硬件故障发生损坏现象而崩溃 3.主备都开启firewalld防火墙 4.1 模拟脑裂 lb01和lb02开启firewalld防火墙 systemctl start firewalld 开启防火墙后产生裂脑原因 lb01和lb02都开启防火墙后，因为没有允许vrrp，当backup去检测master的时候无法检测到，此时backup认为master已经宕机，所以将VIP抢占；而master实际上并没有宕机，所以VIP不会漂移，这样就造成了master和backup都在抢占VIP。此时就出现了裂脑的情况 4.2 测试脑裂问题 在keepalived备上编写检测脚本, 测试如果能ping通主keepalived并且备节点还有VIP的话则认为产生了脑裂 lb02操作 #创建存放脚本的目录 mkdir -p /server/scripts #编辑脚本内容 cat >/server/scripts/check_split_brain.sh /dev/null if [ $? -eq 0 -a `ip add|grep \"$lb01_vip\"|wc -l` -eq 1 ];then echo \"keepalived出现了脑裂！！！\" else echo \"keepalived完全objk\" fi sleep 5 done EOF 运行脚本，因为此时是脑裂的，keepalived主备上都有VIP，因为前期会报出现脑裂，当把主备上的firewalld关掉时就没有问题了 #脚本会一直运行，ctrl+c停止 $ sh /server/scripts/check_split_brain.sh keepalived出现了脑裂！！！ keepalived出现了脑裂！！！ keepalived出现了脑裂！！！ keepalived出现了脑裂！！！ keepalived出现了脑裂！！！ keepalived出现了脑裂！！！ keepalived出现了脑裂！！！ keepalived完全objk keepalived完全objk 五、源码安装keepalived keepalived源码包官方下载地址 5.1 下载包 wget https://www.keepalived.org/software/keepalived-2.1.2.tar.gz 5.2 编译安装 安装依赖包 yum -y install openssl openssl-devel libnl3-devel pcre-devel 解压缩包 tar xf keepalived-2.1.2.tar.gz && cd keepalived-2.1.2 编译安装 ./configure --prefix=/usr/local/keepalived make && make install 5.3 配置keepalived 5.3.1 软连接keepalived命令 ln -s /usr/local/keepalived/sbin/keepalived /usr/sbin 验证 $ keepalived -v Keepalived v2.1.2 (06/14,2020) Copyright(C) 2001-2020 Alexandre Cassen, Built with kernel headers for Linux 3.10.0 Running on Linux 3.10.0-1127.el7.x86_64 #1 SMP Tue Mar 31 23:36:51 UTC 2020 configure options: --prefix=/etc/keepalived --sysconfdir=/etc/keepalived Config options: LVS VRRP VRRP_AUTH OLD_CHKSUM_COMPAT FIB_ROUTING System options: PIPE2 SIGNALFD INOTIFY_INIT1 VSYSLOG EPOLL_CREATE1 IPV6_ADVANCED_API RTA_ENCAP RTA_EXPIRES RTA_PREF FRA_SUPPRESS_PREFIXLEN FRA_TUN_ID RTAX_CC_ALGO RTAX_QUICKACK RTA_VIA FRA_OIFNAME IFA_FLAGS IP_MULTICAST_ALL NET_LINUX_IF_H_COLLISION LIBIPTC_LINUX_NET_IF_H_COLLISION VRRP_VMAC IFLA_LINK_NETNSID CN_PROC SOCK_NONBLOCK SOCK_CLOEXEC O_PATH GLOB_BRACE INET6_ADDR_GEN_MODE SO_MARK SCHED_RESET_ON_FORK 5.3.2 keepalived.service文件 ⚠️keepalived编译安装完成后会自动生成文件/usr/lib/systemd/system/keepalived.service 5.3.3 拷贝安装目录下keepalived配置文件 否则会报错Unable to find configuration file /etc/keepalived/keepalived.conf (glob returned 3) mkdir /etc/keepalived cp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/ 5.3.4 拷贝启动文件(可选) cp /root/keepalived-2.1.2/keepalived/etc/init.d/keepalived /etc/init.d 5.3.5 启动keepalived并设置开机自启 systemctl daemon-reload && systemctl enable keepalived && systemctl start keepalived 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/ssh/1.ssh服务.html":{"url":"linux/linux服务/ssh/1.ssh服务.html","title":"禁止root远程登陆","keywords":"","body":"一、ssh禁止root远程登陆 1.编辑文件/etc/ssh/sshd_config #禁止root远程登陆 PermitRootLogin no #禁用密码验证 PasswordAuthentication no #启用密钥验证 RSAAuthentication yes //centos7没有这一项 PubkeyAuthentication yes 2.sudo免密配置等root权限用户 visudo或者编辑文件/etc/sudoers //创建一个用户 useradd lcc //visudo编辑,101行写入以下内容 lcc ALL=NOPASSWD :ALL 3.配置ssh密钥 //切换到lcc用户 su - lcc //生成密钥 $ ssh-keygen Generating public/private rsa key pair. Enter file in which to save the key (/home/lcc/.ssh/id_rsa): Created directory '/home/lcc/.ssh'. Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /home/lcc/.ssh/id_rsa. Your public key has been saved in /home/lcc/.ssh/id_rsa.pub. The key fingerprint is: SHA256:nSW5jEvQwr8zPZok5CfK+fnrhPJfk2motWOgx1/eNZ4 lcc@experiment The key's randomart image is: +---[RSA 2048]----+ | | | . . . | | + . o . | | + + = | | . S = | | o.o = o | | .o=.@ X o | | ..=oXo@ + o o | | +o=*Xo. . E | +----[SHA256]-----+ //向authorized_keys文件写入公钥 cd .ssh && cat id_rsa.pub >authorized_keys //修改authorized_keys文件权限至少为644，默认为664，无法使用密钥登陆 chmod 644 authorized_keys ⚠️ssh服务配置文件/etc/ssh/sshd_config中有一项配置是AuthorizedKeysFile .ssh/authorized_keys，如果想要使用私钥免密登陆，则公钥必须写入到文件.ssh/authorized_keys中，即注册私钥，否则免密会失败！！！ 4.配置完后验证 //root无法远程登陆 baixuebingdeMacBook-Pro:~ baixuebing$ ssh root@10.0.0.13 root@10.0.0.13: Permission denied (publickey,gssapi-keyex,gssapi-with-mic). //无法使用密码登陆，只能使用密钥登陆 baixuebingdeMacBook-Pro:~ baixuebing$ ssh lcc@10.0.0.13 lcc@10.0.0.13: Permission denied (publickey,gssapi-keyex,gssapi-with-mic). 二、ssh免交互配置 ssh-keygen免交互生成密钥 #免交互生成密钥 ssh-keygen -t rsa -f /root/.ssh/id_dsa -P \"\" -q -f filename #指定密钥文件的文件名 -P passphrase #提供旧密钥口令 -q Silence ssh-keygen #静默输出 -t key type #密钥类型 dsa ecdsa ed25519 rsa(默认) rsa1 ⚠️ssh服务配置文件/etc/ssh/sshd_config中有一项配置是AuthorizedKeysFile .ssh/authorized_keys，如果想要使用私钥免密登陆，则公钥必须写入到文件.ssh/authorized_keys中，即注册私钥，否则免密会失败！！！ ssh-copy免交互推送密钥 sshpass -p1 ssh-copy-id -i ~/.ssh/id_rsa.pub -o StrictHostKeyChecking=no root@IP 批量分发密钥脚本 #!/bin/bash #生成密钥 \\rm -f /root/.ssh/id_* ssh-keygen -t rsa -f /root/.ssh/id_rsa -P \"\" -q #分发密钥 for ip in IP do echo \"=== 分发主机 10.0.0.$ip ===\" sshpass -p1 ssh-copy-id -i ~/.ssh/id_rsa.pub -o StrictHostKeyChecking=no root@10.0.0.$ip echo \"=== 分发ojbk ===\" echo \"\" done 三、ssh自动断开远程服务器问题 编辑ssh服务配置文件/etc/ssh/sshd_config修改以下两项 #向客户端每30秒发一次保持连接的信号 ClientAliveInterval 30 #如果客户端30次未响应就断开连接 ClientAliveCountMax 30 重启服务 systemctl restart sshd 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/nfs/centos7.7搭建NFS.html":{"url":"linux/linux服务/nfs/centos7.7搭建NFS.html","title":"nfs","keywords":"","body":"centos7.7搭建NFS 一、NFS基本概述 基本概念 NFS是Network File System的缩写及网络文件系统。 主要功能 通过局域网络让不同的主机系统之间可以共享文件或目录。 用处 NFS系统和Windows网络共享、网络驱动器类似, 只不过windows用于局域网, NFS用于企业集群架构中, 如果是大型网站, 会用到更复杂的分布式文件系统 小文件存储系统：(Moosefs,FastDFS) 大文件存储系统：(glusterfs,HDFS) 为什么要用NFS服务进行数据存储 1.实现数据信息共享 2.实现数据信息一致 二、NFS实现原理 相关进程 rpc.nfsd 基本的nfs守护进程，主要功能是管理客户端是否能够登陆服务器 rpc.mount 管理nfs的文件系统，当客户端顺利通过nfsd登陆nfs服务器后，在使用nfs 服务所提供的文件前，还必须通过文件使用权限的验证，它会读取nfs的配置文件/etc/exports来对比客户端权限 portmap 进行端口映射 本地文件操作方式 当用户进程发起本地文件访问或修改，该用户请求传递至内核，由内核驱动硬件完成操作 NFS访问方式 1.用户进程访问NFS客户端，使用不同的函数对数据进行处理 2.请求会通过TCP/IP的方式传递给NFS服务端 3.NFS服务端接收到请求后，会调用portmap进程进行端口映射 4.nfsd进程用于判断NFS客户端是否拥有权限连接NFS服务端 5.Rpc.mount用于判断客户端是否有对应的权限进行验证 6.idmap进程实现用户映射和压缩 7.最后NFS服务端会将对应请求的函数转换为本地能识别的命令，传递至内核，由内核驱动硬件 三、NFS服务搭建过程 实验环境 角色 IP 主机名 nfs服务端 10.0.0.10 nfs-server nfs客户端 10.0.0.11 nfs-client nfs服务端操作 1.安装nfs-utils yum -y install nfs-utils 2.编辑nfs配置文件/etc/exports，文件默认没有内容 nfs配置文件格式 NFS共享目录 NFS客户端地址1(参数1,参数2,...) 客户端地址2(参数1,参数2,...) NFS共享目录 NFS客户端地址(参数1,参数2,...) 执行man exports命令可以查看帮助，如下为nfs参数 nfs共享参数 参数作用 rw 读写权限 ro 只读权限 root_squash 当NFS客户端以root管理员访问时，映射为NFS服务器的匿名用户 no_root_squash 当NFS客户端以root管理员访问时，映射为NFS服务器的root管理员 all_squash 无论NFS客户端使用什么账户访问，均映射为NFS服务器的匿名用户 no_all_squash 无论NFS客户端使用什么账户访问，都不进行压缩 sync 同时将数据写入到内存与硬盘中，保证不丢失数据 async 优先将数据保存到内存，然后再写入硬盘；这样效率更高，但可能会丢失数据 anonuid 配置all_squash使用,指定NFS的用户UID,必须存在系统 anongid 配置all_squash使用,指定NFS的用户UID,必须存在系统 编辑nfs配置文件 cat >/etc/exports 3.创建共享目录并修改目录所有者为nfsnobody mkdir /data chown -R nfsnobody.nfsnobody /data 4.启动nfs并设置开机自启 systemctl start rpcbind nfs-server && systemctl enable rpcbind nfs-server 5.验证配置是否生效 $ exportfs /data 10.0.0.0/24 6.检查nfs共享记录 nfs启动后会在/var/lib/nfs/etab文件中记录共享内容 $ cat /var/lib/nfs/etab /data 10.0.0.0/24(rw,sync,wdelay,hide,nocrossmnt,secure,root_squash,all_squash,no_subtree_check,secure_locks,acl,no_pnfs,anonuid=65534,anongid=65534,sec=sys,rw,secure,root_squash,all_squash) nfs客户端操作 1.安装nfs-utils yum -y install nfs-utils 2.启动rpcbind并设置开机自启 systemctl start rpcbind && systemctl enable rpcbind 3.创建挂载点并修改挂载点所有者为nfsnobody mkdir /data && chown -R nfsnobody.nfsnobody /data 4.查询nfs服务端共享信息 $ showmount -e 10.0.0.10 Export list for 10.0.0.10: /data 10.0.0.0/24 showmount命令 参数 作用 -e 显示NFS服务器的共享列表 -a 显示本机挂载的文件资源的情况NFS资源的情况 -v 显示版本号 5.客户端挂载nfs mount -t 文件系统 服务器IP:共享目录 挂载点 mount -t nfs 10.0.0.10:/data /data ⚠️在企业工作场景，通常情况NFS服务器共享的只是普通静态数据（图片、附件、视频），不需要执行suid、exec等权限，挂载的这个文件系统只能作为数据存取之用，无法执行程序，对于客户端来讲增加了安全性。例如: 很多木马篡改站点文件都是由上传入口上传的程序到存储目录然后执行的 通过mount -o指定挂载参数，禁止使用suid、exec，增加安全性能 mount -t nfs -o nosuid,noexec,nodev 10.0.0.10:/data /mnt 6.查看挂载信息 df -h 10.0.0.10:/data 17G 4.4G 13G 26% /data 7.设置开机自动挂载 cat >> /etc/fstab 8.如果不需要使用nfs共享，可以卸载 umount /data 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/同步服务/centos7.7搭建rsync.html":{"url":"linux/linux服务/同步服务/centos7.7搭建rsync.html","title":"rsync","keywords":"","body":"centos7.7搭建rsync rsync基本概述 rsync是一款开源的备份工具，可以在不同主机之间进行同步，可实现全量备份与增量备份，保持链接和权限，且采用优化的同步算法，传输前执行压缩，因此非常适合用于架构集中式备份或异地备份等应用。 rsync官网 rsync监听端口：tcp/873 rsync运行模式：C/S rsync备份方式 1.完全备份(效率低、占用空间) 2.增量备份(提高备份效率,节省空间, 适合异地备份) 3.差异备份 rsync关于数据同步的两种方式 推：一台主机负责把数据推送至其他主机，服务器开销大(适合推送少量主机) 拉：所有主机定时去找一主机拉数据。可能会导致数据同步缓慢 rsync传输模式 本地方式 远程方式 守护进程方式 rsync命令选项 -a 归档模式传输, 等于-tropgDl -v 详细模式输出, 打印速率, 文件数量等 -z 传输时进行压缩以提高效率 -r 递归传输目录及子目录，即目录下的所有目录都同样传输 -t 保持文件时间信息 -o 保持文件属主信息 -p 保持文件权限 -g 保持文件属组信息 -l 保留软连接 -P 显示同步的过程及传输时的进度等信息 -D 保持设备文件信息 -L 保留软连接指向的目标文件 -e 使用的信道协议,指定替代rsh的shell程序 --exclude=PATTERN 指定排除不需要传输的文件模式 --exclude-from=file 文件名所在的目录文件 --bwlimit=100 限速传输 --partial 断点续传 --delete 让目标目录和源目录数据保持一致 rsync传输示例 本地传输 rsync 选项 源文件或目录 目标路径 例：将/etc/passwd文件同步到/opt rsync -avz /etc/passwd /opt 远程传输 ```python 推传输 rsync 选项 源文件或目录 远程主机目标路径 例：将本机/etc/passwd同步到另一台主机的/opt rsync -zav /etc/passwd root@10.0.0.10:/opt 拉传输 rsync 选项 远程主机源文件或目录 本地路径 例：将远程主机的/etc/passwd同步到本地/opt rsync -avz root@10.0.0.10:/etc/passwd /opt --- **试验环境** | 角色 | IP | 主机名 | | ------------ | --------- | ------------ | | rsync server | 10.0.0.10 | rsync-server | | rsync client | 10.0.0.11 | rsync-client | **实验过程** # rsync服务端操作 ## 1.安装rsync ```python yum -y install rsync 2.编辑rsync配置文件 #备份原有文件 cp /etc/rsyncd.conf{,.bak} #编辑rsync配置文件 cat >/etc/rsyncd.conf 3.建立rsync用户及相关目录 #创建rsync用户 useradd -M -s /sbin/nologin rsync #创建真正的共享目录并修改目录所有者为rsync mkdir /backup && chown rsync.rsync /backup 4.创建用户密码文件 ⚠️用户密码文件权限必须为600！！！ #创建密码文件，密码文件要与/etc/rsyncd.conf中\"secrets file = /etc/rsync.passwor\"相同 echo \"rsync_backup:1\" > /etc/rsync.password #修改密码文件权限，必须为600！！！ chmod 600 /etc/rsync.password 5.启动rsync并加入开机自启 systemctl start rsyncd && systemctl enable rsyncd rsync客户端操作 安装rsync、启动 yum -y install rsync systemctl start rsyncd && systemctl enable rsyncd 测试一、客户端推送及拉取不需要输入密码 ⚠️客户端使用--password-file=选项时，密码文件的权限必须为600！！！ #拉取语法 rsync -avz 用户@IP::共享名称 本机文件|目录 #推送语法 rsync -avz 本机文件|目录 用户@IP::共享名称 方法一： 在客户端/etc/rsync.password(文件随意)中写入服务端密码文件/etc/rsync.password中的密码 rsync拉取或推送时加选项--password-file= ⚠️这里的密码文件权限必须为600！！！ $ echo 1 > /etc/rsync.password && chmod 600 /etc/rsync.password $ rsync -avz rsync_backup@10.0.0.10::backup . --password-file=/etc/rsync.password receiving incremental file list ./ 1.txt 2.txt 3.txt 4.txt 5.txt sent 126 bytes received 317 bytes 295.33 bytes/sec total size is 0 speedup is 0.00 ############################################################### 方法二： 在客户端中导出变量，变量名必须为RSYNC_PASSWORD $ export RSYNC_PASSWORD=1 $ rsync -avz rsync_backup@10.0.0.10::backup . receiving incremental file list ./ 1.txt 2.txt 3.txt 4.txt 5.txt sent 126 bytes received 317 bytes 80.55 bytes/sec total size is 0 speedup is 0.00 测试二、实现数据无差异同步 --delete选项 此选项非常危险，生产环境不要使用！！！ ⚠️生产环境千万不要使用--delete选项 服务端 10.0.0.10 客户端 10.0.0.11 1.查看文件 服务端文件 [root@rsync-server backup]# ls 1.txt 2.txt 3.txt 4.txt 5.txt 客户端文件 [root@rsync-client backup]# ls 1.txt 2.txt 3.txt 4.txt 5.txt 2.删除服务端1.txt [root@rsync-server backup]# rm -rf 1.txt [root@rsync-server backup]# ls 2.txt 3.txt 4.txt 5.txt 3.不加--delete参数再次同步，可以看到客户端文件没有变化，但是服务端没有1.txt [root@rsync-client backup]# rsync -avz rsync_backup@10.0.0.10::backup . receiving incremental file list ./ sent 27 bytes received 127 bytes 308.00 bytes/sec total size is 0 speedup is 0.00 [root@rsync-client backup]# ls 1.txt 2.txt 3.txt 4.txt 5.txt 4.加--delete参数再次同步，可以看到，客户端同步服务端全部文件，删除1.txt [root@rsync-client backup]# rsync -avz --delete rsync_backup@10.0.0.10::backup . receiving incremental file list deleting 1.txt sent 24 bytes received 120 bytes 96.00 bytes/sec total size is 0 speedup is 0.00 [root@test1 backup]# ls 2.txt 3.txt 4.txt 5.txt 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/同步服务/centos7.7搭建sersync.html":{"url":"linux/linux服务/同步服务/centos7.7搭建sersync.html","title":"sersync","keywords":"","body":"centos7.7搭建sersync sersync已于2015年8月停止更新，作者推荐使用lsyncd lsyncd github地址 sersync官网 sersync github地址 一、sersync简介 sersync主要用于服务器同步，web镜像等功能。基于boost1.41.0,inotify api,rsync command.开发。目前使用的比较多的同步解决方案是inotify-tools+rsync ，另外一个是google开源项目Openduckbill（依赖于inotify- tools），这两个都是基于脚本语言编写的。相比较上面两个项目，本项目优点是： 1.sersync是使用c++编写，而且对linux系统文件系统产生的临时文件和重复的文件操作进行过滤（详细见附录，这个过滤脚本程序没有实现），所以在结合rsync同步的时候，节省了运行时耗和网络资源。 因此更快。 2.相比较上面两个项目，sersync配置起来很简单，其中bin目录下 已经有基本上静态编译的2进制文件，配合bin目录下的xml配置文件直接使用即可。 3.另外本项目相比较其他脚本开源项目，使用多线程进行同步，尤其在同步较大文件时，能够保证多个服务器实时保持同步状态。 4.本项目有出错处理机制，通过失败队列对出错的文件重新同步，如果仍旧失败，则 每10个小时对同步失败的文件重新同步。 5.本项目自带crontab功能，只需在xml配置文件中开启，即可按您的要求，隔一段时间整体同步一次。无需再额外配置crontab功能。 6.本项目socket与http插件扩展，满足您二次开发的需要。 同步原理图 二、sersync搭建过程 sersync流程 安装sersync的服务器角色为客户端，实时检测在sersync中配置的共享目录文件变化，采用客户端主动推送的方式将发生变化的文件传输到服务端 sersync负责检测文件变化，真正同步文件还是rsync 试验环境 角色 IP 主机名 安装服务 rsync server 10.0.0.10 rsync-server rsync rsync client 10.0.0.11 rsync-client sersync、rsync、inotify-tools 服务端操作 1.安装rsync yum -y install rsync 2.编辑rsync配置文件 #备份原有文件 cp /etc/rsyncd.conf{,.bak} #编辑rsync配置文件 cat >/etc/rsyncd.conf 3.建立rsync用户及共享目录 #创建rsync用户 useradd -M -s /sbin/nologin rsync #创建真正的共享目录并修改目录所有者为rsync mkdir /backup && chown rsync.rsync /backup 4.创建用户密码文件 ⚠️用户密码文件权限必须为600！！！ #创建密码文件，密码文件要与/etc/rsyncd.conf中\"secrets file = /etc/rsync.password\"相同 echo \"rsync_backup:1\" > /etc/rsync.password #修改密码文件权限，必须为600！！！ chmod 600 /etc/rsync.password 5.启动rsync并加入开机自启 systemctl start rsyncd && systemctl enable rsyncd 客户端操作 1.安装inotify-tools yum -y install inotify-tools 2.下载sersync #下载sersync git clone https://github.com.cnpmjs.org/wsgzao/sersync.git #解压缩包并重命名 tar xf sersync/sersync2.5.4_64bit_binary_stable_final.tar.gz mv GNU-Linux-x86/ /usr/local/sersync 3.配置sersync ⚠️13行这个选项是否开启完全同步，比较危险，一般设置为false #查看sersync目录内容，包含配置文件confxml.xml和启动文件sersync2 $ cd /usr/local/sersync $ pwd /usr/local/sersync $ ls confxml.xml sersync2 #配置confxml，精简版修改 13行，是否开启完全同步，比较危险，一般为false 24行，配置本机共享目录 25行，远程主机IP及rsync共享名称 30行，rsync同步时命令的选项，一般默认即可 31行，指定服务端rsync配置中的认证用户及密码文件 #参数说明 -a //归档模式传输, 等于-tropgDl -v //详细模式输出, 打印速率, 文件数量等 -z //传输时进行压缩以提高效率 -r //递归传输目录及子目录，即目录下的所有目录都同样传输 -t //保持文件时间信息 -o //保持文件属主信息 -p //保持文件权限 -g //保持文件属组信息 -l //保留软连接 -P //显示同步的过程及传输时的进度等信息 -D //保持设备文件信息 -L //保留软连接指向的目标文件 -e //使用的信道协议,指定替代rsh的shell程序 --exclude=PATTERN //指定排除不需要传输的文件模式 --exclude-from=file //文件名所在的目录文件 --bwlimit=100 //限速传输 --partial //断点续传 --delete //让目标目录和源目录数据保持一致 31行，开启用户认证，用户名，密码文件 4.创建用户认证密码文件及共享目录 ⚠️密码文件权限必须为600！！！ #创建用户认证密码文件 echo 1 > /etc/rsync.password #修改文件权限，必须为600！！！ chmod 600 /etc/rsync.password #创建rsync用户 useradd -M -s /sbin/nologin rsync #创建共享目录 mkdir /backup && chown rsync.rsync /backup 5.启动sersync #启动sersync /usr/local/sersync/sersync2 -dro /usr/local/sersync/confxml.xml set the system param execute：echo 50000000 > /proc/sys/fs/inotify/max_user_watches execute：echo 327679 > /proc/sys/fs/inotify/max_queued_events parse the command param option: -d run as a daemon option: -r rsync all the local files to the remote servers before the sersync work option: -o config xml name： /usr/local/sersync/confxml.xml daemon thread num: 10 parse xml config file host ip : localhost host port: 8008 daemon start，sersync run behind the console config xml parse success please set /etc/rsyncd.conf max connections=0 Manually sersync working thread 12 = 1(primary thread) + 1(fail retry thread) + 10(daemon sub threads) Max threads numbers is: 22 = 12(Thread pool nums) + 10(Sub threads) please according your cpu ，use -n param to adjust the cpu rate ------------------------------------------ rsync the directory recursivly to the remote servers once working please wait... execute command: cd /backup && rsync -artuz -R --delete ./ 10.0.0.12::backup >/dev/null 2>&1 #查看sersync进程 $ ps aux|grep sersyn[c] root 2213 0.0 0.1 92324 704 ? Ssl 15:05 0:00 /usr/local/sersync/sersync2 -dro /usr/local/sersync/confxml.xml #启动参数说明 -d 启用守护进程模式 -r 在监控前，将监控目录与远程主机用rsync命令推送一遍 -n 指定开启守护线程的数量，默认为10个 -o 指定配置文件，默认使用confxml.xml文件 -m 单独启用其他模块，使用 -m refreshCDN 开启刷新CDN模块 -m 单独启用其他模块，使用 -m socket 开启socket模块 -m 单独启用其他模块，使用 -m http 开启http模块 不加-m参数，则默认执行同步程序 6.验证同步 #文件、目录同步验证 1.进入客户端10.0.0.10 /backup目录创建文件、目录 $ touch {1..5}.txt && mkdir dir{1..3} $ ls 1.txt 2.txt 3.txt 4.txt 5.txt dir1 dir2 dir3 2.服务端10.0.0.11验证，可以看到文件已经同步 $ cd /backup $ ls 1.txt 2.txt 3.txt 4.txt 5.txt dir1 dir2 dir3 #文件内容同步验证 1.客户端10.0.0.10 /backup中向1.txt写入内容 $ cd /backup && echo 'test sersync' >1.txt 2.服务端10.0.0.11 /backup中查看1.txt文件内容 $ cd /backup && cat 1.txt test sersync 7.同步过程总结 sersync同步过程中需要注意的点 sersync端需要用到rsyncd服务端配置文件中指定的认证用户的密码，并且密码文件权限必须为600 sersync的作用其实就是实时检测本地文件，一旦有变化就把文件推送到配置文件中指定的主机 sersync端推送文件实际上还是利用了rsync 有关密码文件的说明 rsync认证用户:密码 一定是写在rsyncd服务端的 只有单纯的密码 一定是写在推送端的 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/同步服务/centos7.7搭建lsyncd.html":{"url":"linux/linux服务/同步服务/centos7.7搭建lsyncd.html","title":"lsyncd","keywords":"","body":"centos7.7搭建lsyncd lsyncd官网 lsyncd github地址 lsyncd简介 Lsyncd使用文件系统事件接口（inotify或fsevents）来监视本地文件和目录的更改。Lsyncd整理这些事件几秒钟，然后生成一个或多个进程以将更改同步到远程文件系统。默认的同步方法是rsync。因此，Lsyncd是一种轻型的实时镜像解决方案。Lsyncd相对易于安装，并且不需要新的文件系统或块设备。Lysncd不会妨碍本地文件系统的性能。 作为rsync的替代方法，Lsyncd还可以通过rsync + ssh推送更改。当文件或目录被重命名或移动到本地树中的新位置时，Rsync + ssh允许更高效的同步。（相反，普通rsync通过删除旧文件然后重新传输整个文件来执行移动。） 细粒度的定制可以通过配置文件来实现。自定义操作配置甚至可以从头开始写在层叠的层次上，从外壳脚本到用Lua语言编写的代码。因此，简单，强大和灵活的配置是可能的。 Lsyncd 2.2.1在所有源计算机和目标计算机上都要求rsync> = 3.1。 lsyncd同步流程 服务器A中部署rsync客户端+lsyncd，lsyncd通过内核的inotify触发机制监控文件的动向，并将改动发送给rsync，由rsync同步到服务器B；服务器B以守护进程的方式部署rsync服务端，接收A发来的文件同步请求，并将文件同步！ 部署lsyncd端的服务器的角色为客户端 试验环境 角色 IP 主机名 安装服务 lsyncd server 10.0.0.10 lsyncd-server rsync lsyncd client 10.0.0.11 lsyncd-client rsync、lsyncd 服务端操作 1.安装rsync yum -y install rsync 2.编辑rsync配置文件 #备份原有文件 cp /etc/rsyncd.conf{,.bak} #编辑rsync配置文件 cat >/etc/rsyncd.conf 3.建立rsync用户及共享目录 #创建rsync用户 useradd -M -s /sbin/nologin rsync #创建真正的共享目录并修改目录所有者为rsync mkdir /backup && chown rsync.rsync /backup 4.创建用户密码文件 ⚠️用户密码文件权限必须为600！！！ #创建密码文件，密码文件要与/etc/rsyncd.conf中\"secrets file = /etc/rsync.password\"相同 echo \"rsync_backup:1\" > /etc/rsync.password #修改密码文件权限，必须为600！！！ chmod 600 /etc/rsync.password 5.启动rsync并加入开机自启 systemctl start rsyncd && systemctl enable rsyncd 客户端操作 1.安装lsyncd、rsync #安装lsyncd需要epel仓库 yum install -y epel-release #安装lsyncd、rsync yum -y install lsyncd rsync #查看版本 $ rpm -qa lsyncd lsyncd-2.2.2-1.el7.x86_64 $ rpm -qa rsync rsync-3.1.2-6.el7_6.1.x86_64 2.配置lsyncd lsyncd配置文件/etc/lsyncd.conf原先内容如下，--标示注释 ---- -- User configuration file for lsyncd. -- -- Simple example for default rsync, but executing moves through on the target. -- -- For more examples, see /usr/share/doc/lsyncd*/examples/ -- sync{default.rsyncssh, source=\"/var/www/html\", host=\"localhost\", targetdir=\"/tmp/htmlcopy/\"} 同步一台机器(密码文件方式) 编辑/etc/lsyncd.conf ⚠️--delete = true这个选项千万不要在生产环境中使用！！！ #备份文件 cp /etc/lsyncd.conf{,.bak} #编辑文件 cat >/etc/lsyncd.conf 同步多台机器(密码文件方式) 以上为仅同步一台机器，如果需要同步到多台机器，只需要在加几个sync{xxx}配置即可，同时需要注意的是如果采用密码文件的方式，则每一个sync标签中都必须包含rsync标签，用来指定密码文件 官方说明 #在/etc/lsyncd.conf配置文件中多加几个sync标签即为同步到多台机器，需要注意的是，如果采用密码文件的方式，则每一个sync标签中都必须包含一个rsync标签，用来指定密码文件 sync { default.rsync, source = \"/backup\", --监控目录 target = \"rsync_backup@10.0.0.134::backup\", rsync = { binary = \"/usr/bin/rsync\", --rsync可执行文件路径， 必须为绝对路径 password_file = \"/etc/rsync.password\",--密码认证文件 archive = true, compress = false, verbose = false, _extra = { \"--bwlimit=200\", \"--omit-link-times\" } } } sync { default.rsync, source = \"/backup\", --监控目录 target = \"rsync_backup@10.0.0.130::backup\", --rsync的认证用户名、IP、模块 --delete = true, exclude = { '.**', '.git/**', '*.bak', '*.tmp', 'runtime/**', 'cache/**' }, rsync = { binary = \"/usr/bin/rsync\", --rsync可执行文件路径， 必须为绝对路径 password_file = \"/etc/rsync.password\",--密码认证文件 archive = true, compress = false, verbose = false, _extra = { \"--bwlimit=200\", \"--omit-link-times\" } } } 官方说明文档(同步到多台机器) 使用ssh免密方式同步(非密码文件方式) 官方配置文件示意图 主机之间先做ssh免密登陆 #生成密钥，默认rsa加密类型，长度2048 -b指定长度 -t指定加密类型 $ ssh-keygen Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa. Your public key has been saved in /root/.ssh/id_rsa.pub. The key fingerprint is: SHA256:hV+uhg4hRTGHy3U3891ANGojAeAYmu2rA9E316XaBkc root@k8s-node1 The key's randomart image is: +---[RSA 2048]----+ | . =+o.. o+ | | + =.oE.o.+... | | .o o.o=.+o.=+ o.| |. ..o.= +o = .. o| | . .oo.=S . . | |. o..o. . | | . . ... o | | .. o . | | .. . | +----[SHA256]-----+ #拷贝公钥到其他需要同步到主机 ssh-copy-id -i ~/.ssh/id_rsa.pub root@10.0.0.11 使用ssh免密方式的lsyncd配置文件如下，如需同步到多台主机，则和之前使用密码文件同步方式都相同，都是增加多个sync标签 settings { logfile = \"/var/log/lsyncd/lsyncd.log\", statusFile = \"/var/log/lsyncd/lsyncd.status\", inotifyMode = \"CloseWrite\", maxProcesses = 1, maxDelays = 1, nodaemon = false, } sync { default.rsyncssh, source = \"/backup\", --监控目录 host = \"10.0.0.130\", --同步远程主机IP targetdir = \"/backup\", --同步远程主机目录 rsync = { archive = true, compress = false, verbose = false, _extra = { \"--bwlimit=200\", \"--omit-link-times\" } }, ssh = { port = 22 } } sync { default.rsyncssh, source = \"/backup\", --监控目录 host = \"10.0.0.134\", --同步远程主机IP targetdir = \"/backup\", --同步远程主机目录 --delete = true, exclude = { '.**', '.git/**', '*.bak', '*.tmp', 'runtime/**', 'cache/**' }, rsync = { archive = true, compress = false, verbose = false, _extra = { \"--bwlimit=200\", \"--omit-link-times\" } }, ssh = { port = 22 } } 还是使用lsyncd --nodaemon /etc/lsyncd.conf启动查看是否报错，如果不报错则使用systemctl启动lsyncd即可 3.创建用户认证密码文件及共享目录 ⚠️密码文件权限必须为600！！！ #创建用户认证密码文件 echo 1 > /etc/rsync.password #修改文件权限，必须为600！！！ chmod 600 /etc/rsync.password #创建rsync用户，与rsync服务端共享目录权限相同 useradd -M -s /sbin/nologin rsync #创建共享目录 mkdir /backup && chown rsync.rsync /backup 4.启动lsyncd #先使用如下命令启动看是否报错，如果不报错则ctrl+c停止然后用systemctl启动lsyncd $ lsyncd -nodaemon /etc/lsyncd.conf 16:31:18 Normal: --- Startup --- 16:31:18 Normal: recursive startup rsync: /backup/ -> rsync_backup@10.0.0.10::backup/ excluding .git/** runtime/** .** *.tmp cache/** *.bak 16:31:18 Normal: Startup of /backup/ -> rsync_backup@10.0.0.10::backup/ finished. #systemctl启动 systemcl start lsyncd && systemctl enable lsyncd 5.验证 启动lsyncd服务后，在lsyncd本地创建文件，然后到另外同步的机器目录查看是否同步文件即可 lsyncd密码文件方式与ssh免密方式配置文件需要注意的地方 密码文件方式 sync { default.rsync, source = \"/backup\", --监控目录 target = \"rsync_backup@10.0.0.10::backup\", --rsync的认证用户名、IP、模块 rsync = { binary = \"/usr/bin/rsync\", --rsync可执行文件路径， 必须为绝对路径 password_file = \"/etc/rsync.password\", --密码认证文件 } } ssh免密方式 sync { default.rsyncssh, source = \"/backup\", --监控目录 host = \"10.0.0.134\", --同步远程主机IP targetdir = \"/backup\", --同步远程主机目录 rsync = { archive = true, compress = false, verbose = false }, ssh = { port = 22 } } 不同点一 密码文件方式中sync标签中是default.rsync ssh免密方式中sync标签中是default.rsyncssh 不同点二 密码文件方式中sync标签中的target用于指定rsync的认证用户名、IP、模块 ssh免密方式中sync标签中则用到了host(指定同步远程主机IP)和targetdir(指定同步远程主机目录) 不同点三 密码文件方式中sync标签中的rsync标签下用到了binary(指定rsync命令绝对路径)和password_file(密码认证文件) ssh免密方式中sync标签中的rsync标签下不需要指定其他标注信息 详细配置看官网吧，写的非常清楚 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/php/1.centos7编译安装php7.3.html":{"url":"linux/linux服务/php/1.centos7编译安装php7.3.html","title":"centos7编译安装php","keywords":"","body":"centos7编译安装php7.3 php官网 php官方下载地址 php历史版本官方下载地址 php官方中文文档 php github地址 1.下载源码包 wget https://www.php.net/distributions/php-7.3.19.tar.xz 2.安装依赖包 #安装开发者工具包 yum -y group install \"Development Tools\" #安装依赖包 yum -y install systemd-devel libacl libacl-devel libxml2 libxml2-devel curl curl-devel libjpeg libjpeg-devel libpng libpng-devel gmp-devel libxslt libxslt-devel openssl openssl-devel zlib zlib-devel pcre pcre-devel glib2 glib2-devel bzip2 bzip2-devel glibc glibc-devel liblzf liblzf-devel libzstd libzstd-devel 3.解压缩包并编译安装 3.1 编译安装libzip 解决报错configure: error: Please reinstall the libzip distribution 3.1.1 编译安装libzip需要安装高版本的cmake cmake github下载地址 #下载源码包 wget https://github.com/Kitware/CMake/releases/download/v3.16.8/cmake-3.16.8.tar.gz #解压缩源码包 tar xf cmake-3.16.8.tar.gz #进入解压缩目录并编译安装 cd cmake-3.16.8/ ./configure --prefix=/usr/local/cmake gmake && make install #导出PATH环境变量并使配置生效 echo 'export PATH=/usr/local/cmake/bin:$PATH' >/etc/profile.d/cmake.sh source /etc/profile #验证 $ cmake --version cmake version 3.16.8 3.1.2 编译安装libzip libzip官网 #下载源码包 wget https://libzip.org/download/libzip-1.7.1.tar.xz #解压缩源码包 tar xf libzip-1.7.1.tar.xz #进入解压缩目录并编译安装 cd libzip-1.7.1 mkdir build && cd build && cmake .. && make && make install 3.2 编辑配置文件/etc/ld.so.conf内容 解决报错configure: error: off_t undefined; check your library configuration #备份配置文件 cp /etc/ld.so.conf{,.bak} #向配置文件写入以下内容 cat >/etc/ld.so.conf 3.3 解压缩包编译安装 #解压缩包 tar xf php-7.3.19.tar.xz #进入解压后的目录 cd php-7.3.19 #编译安装 ./configure --prefix=/usr/local/php7-3-19 \\ --with-config-file-path=/usr/local/php7-3-19/etc \\ --with-fpm-user=www \\ --with-fpm-group=www \\ --with-fpm-systemd \\ --with-fpm-acl \\ --with-mysql-sock \\ --with-mysqli \\ --with-libxml-dir \\ --with-openssl \\ --with-mhash \\ --with-pcre-regex \\ --with-zlib \\ --with-iconv \\ --with-bz2 \\ --with-curl \\ --with-cdb \\ --with-pcre-dir \\ --with-gd \\ --with-openssl-dir \\ --with-jpeg-dir \\ --with-png-dir \\ --with-zlib-dir \\ --with-freetype-dir \\ --with-gettext \\ --with-gmp \\ --with-mhash \\ --with-onig \\ --with-pdo-mysql \\ --with-zlib-dir \\ --with-readline \\ --with-libxml-dir \\ --with-xsl \\ --with-pear \\ --enable-fpm \\ --enable-soap \\ --enable-bcmath \\ --enable-calendar \\ --enable-dom \\ --enable-exif \\ --enable-fileinfo \\ --enable-filter \\ --enable-ftp \\ --enable-json \\ --enable-mbstring \\ --enable-mbregex \\ --enable-mbregex-backtrack \\ --enable-pdo \\ --enable-session \\ --enable-shmop \\ --enable-simplexml \\ --enable-sockets \\ --enable-sysvmsg \\ --enable-sysvsem \\ --enable-sysvshm \\ --enable-zip \\ --enable-mysqlnd-compression-support make && make install 3.4 拷贝相关文件 3.4.1 创建php安装目录软连接 ln -s /usr/local/php7-3-19/ /usr/local/php 3.4.2 导出PATH环境变量 echo 'export PATH=/usr/local/php/bin:$PATH' >/etc/profile.d/php.sh source /etc/profile 3.4.3 拷贝php.ini文件 cp /opt/php-7.3.19/php.ini-development /usr/local/php/etc/php.ini 3.4.4 拷贝php-fpm配置文件 cp /usr/local/php/etc/php-fpm.d/www.conf.default /usr/local/php/etc/php-fpm.conf 3.4.5 拷贝php-fpm服务文件 cp /opt/php-7.3.19/sapi/fpm/php-fpm.service /usr/lib/systemd/system/php-fpm.service 3.4.6 启动php-fpm systemctl daemon-reload && systemctl enable php-fpm && systemctl start php-fpm 3.4.7 检查php-fpm启动 #php默认监听tcp/9000端口 $ netstat -ntpl|grep 9000 tcp 0 0 127.0.0.1:9000 0.0.0.0:* LISTEN 12392/php-fpm: mast 4.结合nginx测试php-fpm功能是否正常 4.1 安装nginx并启动 #安装nginx yum -y install nginx #配置nginx以www用户运行 sed -i.bak '/^user/c user www;' /etc/nginx/nginx.conf #启动nginx systemctl start nginx 4.2 编辑nginx配置文件 cat >/etc/nginx/conf.d/php-test.conf 4.3 重载nginx #检测nginx语法 $ nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful #重载nginx nginx -s reload 4.4 编辑php测试页面 cat >/opt/index.php EOF 本机做hosts解析，然后浏览器直接访问域名即可，因为这里配置的nginx根目录下只有一个index.php文件，返回结果如下即为成功 5.安装扩展(可选) 5.1 安装redis扩展 5.1.1 安装方法一 pecl安装 pecl install redis echo \"extension=redis.so\" >> /usr/local/php/etc/php.ini 5.1.2 安装方法二 源码安装 从官网中获取最新稳定发行版 github phpredis地址 5.1.2.1 下载包 wget https://github.com/phpredis/phpredis/archive/5.2.2.tar.gz github phpredis安装说明 5.1.2.2 解压缩包并编译安装 #解压缩包 tar xf 5.2.2.tar.gz cd phpredis-5.2.2/ #生成configure文件 phpize ./configure --enable-redis-igbinary --enable-redis-msgpack --enable-redis-lzf --with-liblzf=/opt/phpredis-5.2.2 --enable-redis-zstd --with-php-config=/usr/local/php/bin/php-config #编译安装 make && make install #配置文件中启用redis模块 echo \"extension=redis.so\" >> /usr/local/php/etc/php.ini 报错1 checking for igbinary includes... configure: error: Cannot find igbinary.h 解决方法 pecl install igbinary echo \"extension=igbinary.so\" >> /usr/local/php/etc/php.ini 报错2 checking for msgpack includes... configure: error: Cannot find php_msgpack.h 解决方法 pecl install msgpack echo \"extension=msgpack.so\" >> /usr/local/php/etc/php.ini 5.2 安装mongo扩展 5.2.1 安装方法一 pecl安装 pecl install mongodb echo \"extension=mongodb.so\" >> /usr/local/php/etc/php.ini 5.2.2 安装方法二 源码安装 从官网中获取最新稳定发行版 php mongodb驱动程序官方说明 5.2.2.1 下载包 wget https://pecl.php.net/get/mongodb-1.7.3.tgz 5.2.2.2 解压缩包并编译安装 #解压缩包 tar xf mongodb-1.7.3.tgz cd mongodb-1.7.3 #生成configure文件 phpize ./configure --with-php-config=/usr/local/php/bin/php-config #编译安装 make && make install #配置文件中启用mongo模块 echo \"extension=mongodb.so\" >> /usr/local/php/etc/php.ini php核心配置参数列表 php官方核心配置选项列表 杂项选项 参数 说明 --enable-debug 编译时加入调试符号 --with-layout=TYPE 设置被安装文件的布局。TYPE 是 PHP（默认）或 GNU --with-pear=DIR 在 DIR（默认为 PREFIX/lib/php）中安装 PEAR --without-pear 不安装 PEAR --enable-sigchild 使用 PHP 自带的 SIGCHLD 处理器 --disable-rpath 禁用在搜索路径中传递其他运行库 --enable-libgcc 启用 libgcc 的精确链接 --enable-php-streams 包含试验性的 PHP 流。不要使用此选项，除非是要测试代码 --with-zlib-dir[=DIR] 定义 zlib 的安装目录 --with-tsrm-pthreads 使用 POSIX 线程（默认） --enable-shared[=PKGS] 编译共享库 [default=yes] --enable-static[=PKGS] 编译静态库 [default=yes] --enable-fast-install[=PKGS] 为快速安装优化 [default=yes] --with-gnu-ld 假设 C 编译器使用 GNU ld [default=no] --disable-libtool-lock 避免锁死（可能破坏并联的编译） --with-pic 尝试仅使用 PIC/非 PIC 对象 [default=use both] --enable-memory-limit 编译内存限制支持功能。(自PHP 5.2.1开始不可用，默认enable) --disable-url-fopen-wrapper 禁用 URL 形式的 fopen 封装协议。该协议允许通过 HTTP 或者 FTP 访问文件。 （自PHP5.2.5开始不可用） --enable-versioning 仅导出必须的符号。查看 INSTALL 文件以获得更多信息 php选项 参数 说明 --enable-maintainer-mode 对偶然安装一下的情形启用此选项，使得不检查编译规则和依赖关系 --with-config-file-path=PATH 设置 php.ini 的搜索路径。默认为 PREFIX/lib --disable-short-tags 默认禁用短形式的开始标签 --with-libdir 指定Uxin系统库文件目录用于构建 PHP。 对于64位系统, 需要指定 lib64 目录,比如--with-libdir=lib64 SAPI选项 下面的列表包含 PHP 可用的SAPI（服务器应用编程接口） 参数 说明 --with-aolserver=DIR 指定 AOLserver 的安装路径 --with-apxs[=FILE] 编译共享的 Apache 模块。FILE 是可选的 Apache apxs 工具的路径，默认指向 apxs。请确认指定的 apxs 已经安装在服务器中，并且它不是 Apache 源码包中的那个 apxs --with-apache[=DIR] 编译静态 Apache 模块。DIR 是 Apache 编译目录的顶层，默认为 /usr/local/apache --with-mod_charset 启用 mod_charset 的转换表（俄文的 Apache 使用） --with-apxs2[=FILE] 编译共享的 Apache 2.0 模块。FILE 是可选的 Apache apxs 工具的路径，默认指向 apxs --with-caudium=DIR 为使用 Caudium 编译 PHP 为一个 Pike 模块。DIR 是 Caudium 服务器目录，默认为 /usr/local/caudium/server --disable-cli PHP 4.3.0 之后的版本有效。禁止编译 PHP 的 CLI 版本（使用它将同时强制使用 --without-pear 选项）。更多信息请查考 PHP 的命令行模式 --enable-embed[=TYPE] 启用编译嵌入的 SAPI 库。TYPE 或者为 shared 或者为 static，默认为 shared。PHP 4.3.0 之后的版本有效 --with-fhttpd[=DIR] 编译 fhttpd 模块。DIR 是 fhttpd 源代码目录，默认为 /usr/local/src/fhttpd。PHP 4.3.0 及以后的版本此选项不再有效 --with-isapi=DIR 为 Zeus 服务器以 ISAPI 模块方式编译 PHP --with-nsapi=DIR 指定 Netscape/iPlanet/SunONE 的安装目录 --with-phttpd=DIR 编译PHP为phttpd模块 --with-pi3web=DIR 为 Pi3Web 服务器编译 PHP 模块 --with-roxen=DIR 以 Pike 模块方式编译 PHP。DIR 是 Roxen 的根目录，默认为 /usr/local/roxen/server --enable-roxen-zts 使用 Zend 线程安全（ZTS）编译 Roxen 模块 --with-servlet[=DIR] 包含 servlet 支持。DIR 是 JSDK 的安装目录。此 SAPI 要求 java 扩展必须作为共享模块编译到 PHP 中 --with-thttpd=SRCDIR 编译 PHP 为 thttpd 模块 --with-tux=MODULEDIR 编译 PHP 为 TUX 模块（仅在 Linux 下有效） --with-webjames=SRCDIR 编译 PHP 为 WebJames 模块（仅在 RISC 操作系统中有效） --disable-cgi 禁止编译 CGI 版本的 PHP。PHP 4.3.0 之后的版本有效，PHP5.3.0起，这个选项会启用FastCGI，而在以前，必须使用--enable-fastcgi启用FastCGI --enable-force-cgi-redirect 启用内部服务器重定向的安全检测。如果在 Apache 下使用 CGI 版本的 PHP，请启用该选项，PHP 5.3.0起，默认有效并不再存在。要禁用此功能,设置cgi.force_redirect ini指令为 0 --enable-discard-path 如果启用该选项，PHP CGI 目录可以安全的放在 web 目录树的外面，人们无法避开 .htaccess 的安全限制，PHP 5.3.0起，默认禁用并不在存在。要启用此功能，设置 cgi-redirect ini指令为1 --enable-fastcgi 如果启用，CGI 模块将被编译为支持 FastCGI。PHP 4.3.0 之后的版本有效，PHP 5.3.0起，此参数不再存在，并使用 --enable-cgi替代 --disable-path-info-check 如果该选项被禁用，例如 /info.php/test?a=b 形式的路径将不能工作。PHP 4.3.0 之后的版本有效。更多信息请参考 » Apache 手册 fpm选项 参数 说明 --with-fpm-user 设置 FPM 运行的用户身份（默认 - nobody） --with-fpm-group 设置 FPM 运行时的用户组（默认 - nobody） --with-fpm-systemd 启用 systemd 集成 (默认 - no) --with-fpm-acl 使用POSIX 访问控制列表 (默认 - no) 5.6.5版本起有效 php部分编译参数说明，更多参数使用命令./configure --help查看 php官方函数参考说明地址 参数 说明 --prefix php安装的路径 --with-config-file-path php配置文件路径 --with-fpm-user 设置 FPM 运行的用户身份（默认 - nobody） --with-fpm-group 设置 FPM 运行时的用户组（默认 - nobody） --with-fpm-systemd 启用systemd集成，默认为no --with-fpm-acl 使用POSIX 访问控制列表 (默认 - no) 5.6.5版本起有效 --with-mysql-sock 设置为所有MySQL扩展（包括PDO_MYSQL）的MySQL unix套接字指针的位置 --with-mysqli 支持mysql扩展 --with-libxml-dir 打开libxml2库的支持 --with-openssl openssl的支持，加密传输时用到的 --with-mhash mhash算法的扩展 --with-pcre-regex 支持perl正则表达式 --with-zlib 支持zlib库 --with-iconv 支持iconv函数，这个函数的作用就是字符编码强制转换 --with-bz2 支持bz2文件 --with-curl 支持curl浏览工具 --with-cdb cdb库添加了cdb_make处理程序，该处理程序允许创建cdb文件并允许使用PHP的流访问网络上的cdb文件。 --with-pcre-dir perl的正则库案安装位置 --with-gd 支持gd库 --with-openssl-dir openssl安装位置 --with-jpeg-dir 支持jpeg图片 --with-png-dir 支持png图片 --with-zlib-dir 支持zlib库 --with-freetype-dir 支持freetype字体库 --with-gettext 支持gnu的gettext，编码库用到 --with-gmp 支持gnu的mp --with-mhash 支持mhash算法 --with-onig 使用外部oniguruma --with-pdo-mysql PDO_MYSQL是一个驱动程序，该驱动程序实现PHP数据对象（PDO）接口 以允许从PHP访问MySQL数据库 --with-zlib-dir zlib安装位置 --with-readline 支持readline库 --with-libxml-dir libxml2安装位置 --with-xsl 支持xsl --with-pear 支持pear --enable-fpm 允许fpm --enable-soap 支持soap，SOAP扩展可用于编写SOAP服务器和客户端 --enable-bcmath 支持用字符串表示的任意大小和精度的数字的二进制计算 --enable-calendar 支持日历转换 --enable-dom 支持dom扩展，DOM扩展使您可以通过带有PHP的DOM API对XML文档进行操作 --enable-exif 支持exif扩展，操作图像元数据 --enable-fileinfo 支持fileinfo，文件给定位置查找特定魔术字节猜测文件的内容类型以及编码 --enable-filter 支持filter，通过验证或清除数据来过滤数据 --enable-ftp 支持ftp --enable-json 支持json --enable-mbstring 支持多字节字符串 --enable-mbregex 支持多字节正则表达式 --enable-pdo 支持php数据对象 --enable-session 支持 session --enable-shmop 支持shmop，允许PHP读取、写入、创建和删除Unix共享内存段的函数集 --enable-simplexml 支持simplexml，将XML转换成一个带有一般属性选择器和数组迭代器的对象 --enable-sockets 支持socket --enable-sysvmsg 支持sysvmsg消息队列 --enable-sysvsem 支持系统V信号量 --enable-sysvshm 支持sysvshm，实现进程间通信共享内存的操作 --enable-zip 支持zip压缩 --enable-mysqlnd-compression-support 支持mysql压缩 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/tomcat/centos7二进制安装tomcat8.html":{"url":"linux/linux服务/tomcat/centos7二进制安装tomcat8.html","title":"centos7二进制安装tomcat","keywords":"","body":"centos7二进制安装tomcat8 tomcat官网 tomcat官方安装文档 1.下载安装包 wget https://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-8/v8.5.56/bin/apache-tomcat-8.5.56.tar.gz 2.解压缩包 tar xf apache-tomcat-8.5.56.tar.gz -C /usr/local/ 3.做软连接 ln -s /usr/local/apache-tomcat-8.5.56/ /usr/local/tomcat-8.5.56 4.安装jdk oracle jdk官方下载地址 这里选择下载tar包，因为下载jdk需要登陆oracle账号，因此不能使用wget $ ls jdk-8u251-linux-x64.tar.gz 解压缩包 tar xf jdk-8u251-linux-x64.tar.gz -C /usr/local 导出环境变量 #导出jdk环境变量 cat >/etc/profile.d/jdk8.sh 5.使用systemd管理tomcat 5.1 为Tomcat添加启动参数 catalina.sh在执行的时候会调用同级路径下的setenv.sh来设置额外的环境变量，因此在/usr/local/tomcat-8.5.56/bin路径下创建setenv.sh文件，内容如下 cat >/usr/local/tomcat-8.5.56/bin/setenv.sh JVM选项说明 JAVA_OPTS='-Xms【初始化内存大小】 -Xmx【可以使用的最大内存】' 5.2 编写tomcat.service文件 在/usr/lib/systemd/system路径下添加tomcat.service文件，内容如下： cat >/usr/lib/systemd/system/tomcat.service 参数说明 [unit] 配置了服务的描述，规定了在network启动之后执行 [service] 配置服务的pid，服务的启动，停止，重启 [install] 配置了使用用户 5.3 修改tomcat bin目录下的catalina.sh 在catalina.sh文件中第2行开始添加如下内容，导出JAVA_HOME和JRE_HOME环境变量 sed -i.bak '2cexport JAVA_HOME=/usr/local/jdk1.8.0_251\\nexport JRE_HOME=/usr/local/jdk1.8.0_251/jre' /usr/local/tomcat-8.5.56/bin/catalina.sh 6.启动tomcat systemctl daemon-reload systemctl start tomcat && systemctl enable tomcat 浏览器访问8080端口 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/supervisor/1.supervisor安装.html":{"url":"linux/linux服务/supervisor/1.supervisor安装.html","title":"supervisor安装","keywords":"","body":"supervisor安装 一、Supervisor简介 Supervisor github地址 Supervisor官网 1.1 官网对于Supervisor的介绍 1.1.1 总览 Supervisor是一个客户端/服务器系统，允许其用户控制类似UNIX的操作系统上的许多进程。它受到以下方面的启发 方便 需要为每个单个流程实例编写rc.d脚本通常很不方便。 rc.d脚本是进程初始化/自动启动/管理的一个很好的最低公分母形式，但是编写和维护它们可能很麻烦。此外，rc.d脚本无法自动重新启动崩溃的进程，并且许多程序在崩溃时无法正确地自行重启。Supervisord将进程作为其子进程启动，并且可以配置为在崩溃时自动重新启动它们。也可以将其自动配置为自行调用启动进程。 准确性 在UNIX上，通常很难获得准确的启动/关闭状态信息。Pidfile经常说谎。Supervisord将流程作为子流程启动，因此它始终知道其子级的真实上/下状态，并且可以方便地查询该数据。 授权 需要控制流程状态的用户通常只需要这样做。他们不希望或不需要完全的Shell访问运行这些进程的计算机。侦听\"低\" TCP端口的进程通常需要以root用户身份启动和重新启动（UNIX功能不全）。通常情况下，允许\"正常\"人员停止或重新启动这样的过程是完全可以的，但是为他们提供shell访问通常是不切实际的，并且为他们提供root访问或sudo访问通常是不可能的。（正确）也很难向他们解释为什么存在此问题。如果超级用户以root用户身份启动，则可以允许\"普通\"用户控制此类过程，而无需向他们解释问题的复杂性。Supervisorctl允许以非常有限的形式访问计算机， 进程组 流程通常需要成组地启动和停止，有时甚至需要按照\"优先级顺序\"进行。通常很难向人们解释如何执行此操作。Supervisor允许您为进程分配优先级，并允许用户通过Supervisorctl客户端发出命令，如\"全部启动\"和\"全部重新启动\"，这将按预先分配的优先级顺序启动它们。此外，可以将进程分为\"进程组\"，并且可以将一组逻辑相关的进程作为一个单元停止和启动。 1.1.2 特征 简单 通过简单易懂的INI样式配置文件配置Supervisor。它提供了许多按进程选择的选项，使您的生活更加轻松，例如重新启动失败的进程和自动日志轮换。 集中 Supervisor为您提供了一个开始，停止和监视过程的地方。可以单独或成组控制过程。您可以配置Supervisor以提供本地或远程命令行和Web界面。 高效的 Supervisor通过fork / exec启动其子进程，并且子进程不守护。进程终止时，操作系统会立即向Supervisor发送信号，这与某些依赖麻烦的PID文件和定期轮询以重新启动失败的进程的解决方案不同。 可扩展的 Supervisor具有一个简单的事件通知协议，该协议可以使用任何语言编写的程序对其进行监视，并且具有用于控制的XML-RPC接口。它还使用扩展点构建，Python开发人员可以利用这些扩展点。 兼容 除Windows外，Supervisor几乎适用于所有其他方面。它已在Linux，Mac OS X，Solaris和FreeBSD上经过测试和支持。它完全用Python编写，因此安装不需要C编译器。 久经考验 尽管Supervisor如今非常活跃，但它不是新软件。Supervisor已经存在了很多年，并且已经在许多服务器上使用。 1.1.3 Supervisor组件 supervisord 服务器Supervisor的名称为supervisor。它负责自行调用启动子程序，响应来自客户端的命令，重新启动崩溃或退出的子进程，记录其子进程stdout和stderr 输出以及生成和处理与子进程生存期中的点相对应的\"事件\"。 服务器进程使用配置文件。它通常位于/etc/supervisord.conf中。此配置文件是\" Windows-INI\"样式的配置文件。通过适当的文件系统权限来确保此文件的安全很重要，因为它可能包含未加密的用户名和密码。 supervisorctl Supervisor的命令行客户端名为 supervisorctl。它提供了类似于shell的界面，可与supervisor提供的功能结合使用。从 supervisorctl，用户可以连接到不同的 supervisord进程（一次一个），对，停止控制的子流程获得地位和启动的子进程，并获得运行的进程的列表supervisord。 命令行客户端通过UNIX域套接字或Internet（TCP）套接字与服务器对话。服务器可以断言客户端的用户应该在允许客户端执行命令之前出示身份验证凭据。客户端进程通常使用与服务器相同的配置文件，但是任何带有[supervisorctl]节的配置文件都可以使用。 Web Server 与功能媲美A（稀疏）的Web用户界面 supervisorctl可以通过浏览器，如果你开始访问 supervisord对互联网插座。激活配置文件的[inet_http_server]部分后，请访问服务器URL（例如http://localhost:9001/）以通过Web界面查看和控制进程状态。 XML-RPC Interface 服务于Web UI的同一HTTP服务器提供XML-RPC接口，该接口可用于询问和控制管理程序及其运行的程序。请参阅XML-RPC API文档。 二、安装supervisor 2.1 系统python环境 $ python -V Python 2.7.5 2.2 安装suprvisor 配置国内pip源 mkdir ~/.pip cat > .pip/pip.conf 安装最新版 #方法一 pip install supervisor #方法二 yum -y install python-setuptools easy_install supervisor #查看版本 $ supervisord -v 4.2.0 安装指定版本 pip install supervisor==3.3.5 三、配置supervisor 3.1 运行echo_supervisord_conf命令生成默认配置文件 运行echo_supervisord_conf命令，会在当前终端的标准输出中打印一个样本Supervisor配置文件 $ echo_supervisord_conf ; Sample supervisor config file. ; ; For more information on the config file, please see: ; http://supervisord.org/configuration.html ; ; Notes: ; - Shell expansion (\"~\" or \"$HOME\") is not supported. Environment ; variables can be expanded using this syntax: \"%(ENV_HOME)s\". ; - Quotes around values are not supported, except in the case of ; the environment= options as shown below. ; - Comments must have a leading space: \"a=b ;comment\" not \"a=b;comment\". ; - Command will be truncated if it looks like a config file comment, e.g. ; \"command=bash -c 'foo ; bar'\" will truncate to \"command=bash -c 'foo \". ; ; Warning: ; Paths throughout this example file use /tmp because it is available on most ; systems. You will likely need to change these to locations more appropriate ; for your system. Some systems periodically delete older files in /tmp. ; Notably, if the socket file defined in the [unix_http_server] section below ; is deleted, supervisorctl will be unable to connect to supervisord. [unix_http_server] file=/tmp/supervisor.sock ; the path to the socket file ;chmod=0700 ; socket file mode (default 0700) ;chown=nobody:nogroup ; socket file uid:gid owner ;username=user ; default is no username (open server) ;password=123 ; default is no password (open server) ; Security Warning: ; The inet HTTP server is not enabled by default. The inet HTTP server is ; enabled by uncommenting the [inet_http_server] section below. The inet ; HTTP server is intended for use within a trusted environment only. It ; should only be bound to localhost or only accessible from within an ; isolated, trusted network. The inet HTTP server does not support any ; form of encryption. The inet HTTP server does not use authentication ; by default (see the username= and password= options to add authentication). ; Never expose the inet HTTP server to the public internet. ;[inet_http_server] ; inet (TCP) server disabled by default ;port=127.0.0.1:9001 ; ip_address:port specifier, *:port for all iface ;username=user ; default is no username (open server) ;password=123 ; default is no password (open server) [supervisord] logfile=/tmp/supervisord.log ; main log file; default $CWD/supervisord.log logfile_maxbytes=50MB ; max main logfile bytes b4 rotation; default 50MB logfile_backups=10 ; # of main logfile backups; 0 means none, default 10 loglevel=info ; log level; default info; others: debug,warn,trace pidfile=/tmp/supervisord.pid ; supervisord pidfile; default supervisord.pid nodaemon=false ; start in foreground if true; default false silent=false ; no logs to stdout if true; default false minfds=1024 ; min. avail startup file descriptors; default 1024 minprocs=200 ; min. avail process descriptors;default 200 ;umask=022 ; process file creation umask; default 022 ;user=supervisord ; setuid to this UNIX account at startup; recommended if root ;identifier=supervisor ; supervisord identifier, default is 'supervisor' ;directory=/tmp ; default is not to cd during start ;nocleanup=true ; don't clean up tempfiles at start; default false ;childlogdir=/tmp ; 'AUTO' child log dir, default $TEMP ;environment=KEY=\"value\" ; key value pairs to add to environment ;strip_ansi=false ; strip ansi escape codes in logs; def. false ; The rpcinterface:supervisor section must remain in the config file for ; RPC (supervisorctl/web interface) to work. Additional interfaces may be ; added by defining them in separate [rpcinterface:x] sections. [rpcinterface:supervisor] supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface ; The supervisorctl section configures how supervisorctl will connect to ; supervisord. configure it match the settings in either the unix_http_server ; or inet_http_server section. [supervisorctl] serverurl=unix:///tmp/supervisor.sock ; use a unix:// URL for a unix socket ;serverurl=http://127.0.0.1:9001 ; use an http:// url to specify an inet socket ;username=chris ; should be same as in [*_http_server] if set ;password=123 ; should be same as in [*_http_server] if set ;prompt=mysupervisor ; cmd line prompt (default \"supervisor\") ;history_file=~/.sc_history ; use readline history if available ; The sample program section below shows all possible program subsection values. ; Create one or more 'real' program: sections to be able to control them under ; supervisor. ;[program:theprogramname] ;command=/bin/cat ; the program (relative uses PATH, can take args) ;process_name=%(program_name)s ; process_name expr (default %(program_name)s) ;numprocs=1 ; number of processes copies to start (def 1) ;directory=/tmp ; directory to cwd to before exec (def no cwd) ;umask=022 ; umask for process (default None) ;priority=999 ; the relative start priority (default 999) ;autostart=true ; start at supervisord start (default: true) ;startsecs=1 ; # of secs prog must stay up to be running (def. 1) ;startretries=3 ; max # of serial start failures when starting (default 3) ;autorestart=unexpected ; when to restart if exited after running (def: unexpected) ;exitcodes=0 ; 'expected' exit codes used with autorestart (default 0) ;stopsignal=QUIT ; signal used to kill process (default TERM) ;stopwaitsecs=10 ; max num secs to wait b4 SIGKILL (default 10) ;stopasgroup=false ; send stop signal to the UNIX process group (default false) ;killasgroup=false ; SIGKILL the UNIX process group (def false) ;user=chrism ; setuid to this UNIX account to run the program ;redirect_stderr=true ; redirect proc stderr to stdout (default false) ;stdout_logfile=/a/path ; stdout log path, NONE for none; default AUTO ;stdout_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB) ;stdout_logfile_backups=10 ; # of stdout logfile backups (0 means none, default 10) ;stdout_capture_maxbytes=1MB ; number of bytes in 'capturemode' (default 0) ;stdout_events_enabled=false ; emit events on stdout writes (default false) ;stdout_syslog=false ; send stdout to syslog with process name (default false) ;stderr_logfile=/a/path ; stderr log path, NONE for none; default AUTO ;stderr_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB) ;stderr_logfile_backups=10 ; # of stderr logfile backups (0 means none, default 10) ;stderr_capture_maxbytes=1MB ; number of bytes in 'capturemode' (default 0) ;stderr_events_enabled=false ; emit events on stderr writes (default false) ;stderr_syslog=false ; send stderr to syslog with process name (default false) ;environment=A=\"1\",B=\"2\" ; process environment additions (def no adds) ;serverurl=AUTO ; override serverurl computation (childutils) ; The sample eventlistener section below shows all possible eventlistener ; subsection values. Create one or more 'real' eventlistener: sections to be ; able to handle event notifications sent by supervisord. ;[eventlistener:theeventlistenername] ;command=/bin/eventlistener ; the program (relative uses PATH, can take args) ;process_name=%(program_name)s ; process_name expr (default %(program_name)s) ;numprocs=1 ; number of processes copies to start (def 1) ;events=EVENT ; event notif. types to subscribe to (req'd) ;buffer_size=10 ; event buffer queue size (default 10) ;directory=/tmp ; directory to cwd to before exec (def no cwd) ;umask=022 ; umask for process (default None) ;priority=-1 ; the relative start priority (default -1) ;autostart=true ; start at supervisord start (default: true) ;startsecs=1 ; # of secs prog must stay up to be running (def. 1) ;startretries=3 ; max # of serial start failures when starting (default 3) ;autorestart=unexpected ; autorestart if exited after running (def: unexpected) ;exitcodes=0 ; 'expected' exit codes used with autorestart (default 0) ;stopsignal=QUIT ; signal used to kill process (default TERM) ;stopwaitsecs=10 ; max num secs to wait b4 SIGKILL (default 10) ;stopasgroup=false ; send stop signal to the UNIX process group (default false) ;killasgroup=false ; SIGKILL the UNIX process group (def false) ;user=chrism ; setuid to this UNIX account to run the program ;redirect_stderr=false ; redirect_stderr=true is not allowed for eventlisteners ;stdout_logfile=/a/path ; stdout log path, NONE for none; default AUTO ;stdout_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB) ;stdout_logfile_backups=10 ; # of stdout logfile backups (0 means none, default 10) ;stdout_events_enabled=false ; emit events on stdout writes (default false) ;stdout_syslog=false ; send stdout to syslog with process name (default false) ;stderr_logfile=/a/path ; stderr log path, NONE for none; default AUTO ;stderr_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB) ;stderr_logfile_backups=10 ; # of stderr logfile backups (0 means none, default 10) ;stderr_events_enabled=false ; emit events on stderr writes (default false) ;stderr_syslog=false ; send stderr to syslog with process name (default false) ;environment=A=\"1\",B=\"2\" ; process environment additions ;serverurl=AUTO ; override serverurl computation (childutils) ; The sample group section below shows all possible group values. Create one ; or more 'real' group: sections to create \"heterogeneous\" process groups. ;[group:thegroupname] ;programs=progname1,progname2 ; each refers to 'x' in [program:x] definitions ;priority=999 ; the relative start priority (default 999) ; The [include] section can just contain the \"files\" setting. This ; setting can list multiple files (separated by whitespace or ; newlines). It can also contain wildcards. The filenames are ; interpreted as relative to this file. Included files *cannot* ; include files themselves. ;[include] ;files = relative/directory/*.ini 去掉注释后的内容如下 $ echo_supervisord_conf > hehe $ egrep -v '^$|^;' hehe [unix_http_server] file=/tmp/supervisor.sock ; the path to the socket file [supervisord] logfile=/tmp/supervisord.log ; main log file; default $CWD/supervisord.log logfile_maxbytes=50MB ; max main logfile bytes b4 rotation; default 50MB logfile_backups=10 ; # of main logfile backups; 0 means none, default 10 loglevel=info ; log level; default info; others: debug,warn,trace pidfile=/tmp/supervisord.pid ; supervisord pidfile; default supervisord.pid nodaemon=false ; start in foreground if true; default false silent=false ; no logs to stdout if true; default false minfds=1024 ; min. avail startup file descriptors; default 1024 minprocs=200 ; min. avail process descriptors;default 200 [rpcinterface:supervisor] supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface [supervisorctl] serverurl=unix:///tmp/supervisor.sock ; use a unix:// URL for a unix socket 以上就是supervisor的默认配置文件 3.2 supervisor查找配置文件的顺序 supervisor配置文件通常被命名为supervisor.conf，supervisor和supervisorctl都使用这个配置文件，如果在没有-c选项的情况下启动了任一应用程序（该选项用于显式告知应用程序配置文件名），则该应用程序将在以下位置按指定顺序查找名为supervisord.conf的文件。它将使用找到的第一个文件。 ../etc/supervisord.conf (相对于可执行文件) ../supervisord.conf (相对于可执行文件) $CWD/supervisord.conf $CWD/etc/supervisord.conf /etc/supervisord.conf /etc/supervisor/supervisord.conf (自Supervisor 3.3.0版本开始) 3.3 手动编辑supervisor配置文件 创建配置文件和日志文件目录 mkdir -p /etc/supervisor/config.d mkdir /var/log/supervisor 创建supervisor运行用户supervisor useradd supervisor -s /sbin/nologin -M 手动编辑supervisor配置文件 cat >> /etc/supervisor/supervisord.conf 当有如下配置时，supervisor还提供了一个web界面 [inet_http_server] port=10.0.0.10:9001 username=test password=test 浏览器访问IP:9001，用户名和密码都是test 3.4 设置supervisor日志滚动 cat >/etc/logrotate.d/supervisor 3.5 设置Tmpfiles防止sock文件被清理 cat >> /usr/lib/tmpfiles.d/tmp.conf 3.6 使用systemd管理supervisor 对各操作系统提供supervisor脚本的github地址 克隆项目 $ git clone https://github.com/Supervisor/initscripts.git $ cd initscripts $ ls centos-systemd-etcs gentoo-matagus redhat-init-equeffelec redhat-sysconfig-equeffelec ubuntu debian-norrgard opensuse-garymonson redhat-init-jkoppe redhat-sysconfig-jkoppe fedora-bmbouter README.md redhat-init-mingalevme slackware #将centos-systemd-etcs中的内容拷贝到/usr/lib/systemd/system/supervisord.service cat centos-systemd-etcs >/usr/lib/systemd/system/supervisord.service centos-systemd-etcs文件内容 #centos-systemd-etcs文件内容 cat >> /usr/lib/systemd/system/supervisord.service 启动supervisord并加入开机自启 systemctl daemon-reload systemctl start supervisord && systemctl enable supervisord 四、supervisor相关命令 4.1 supervisord命令选项 supervisord命令 选项 说明 -c FILE, --configuration=FILE 指定supervisor配置文件 -n, --nodaemon 在前台运行supervisord -h, --help 查看帮助 -u USER, --user=USER UNIX用户名或数字用户标识。如果以root用户身份启动supervisord，请在启动期间尽快setuid给该用户 -m OCTAL, --umask=OCTAL 表示supervisord启动后应该使用的 umask 八进制数（例如022） -d PATH, --directory=PATH 当supervisord作为守护进程运行时，在守护进程之前cd到此目录 -l FILE, --logfile=FILE 用作supervisord活动日志的文件名路径 -y BYTES, --logfile_maxbytes=BYTES 旋转发生前，supervisord活动日志文件的最大大小。该值是后缀倍增的，例如“1”是一个字节，“1MB”是1兆字节，“1GB”是1千兆字节 -z NUM, --logfile_backups=NUM 要保持的supervisord活动日志的备份副本数。每个日志文件的大小为logfile_maxbytes -e LEVEL, --loglevel=LEVEL supervisor应该写入活动日志的日志记录级别。有效级别包括trace(追踪), debug(调试), info(信息), warn(警告), error(错误),critical(严重) -j FILE, --pidfile=FILE supervisord应该将其pid文件写入的文件名 -i STRING, --identifier=STRING 由supervisor实例的各种客户端UI公开的任意字符串标识符 -q PATH, --childlogdir=PATH 目录的路径（它必须已经存在），其中supervisor将写入其AUTO -mode子进程日志 -k, --nocleanup 防止supervisord在启动时执行清理（删除旧的AUTO进程日志文件） -a NUM, --minfds=NUM 在成功启动之前，supervisord进程必须可用的最小文件描述符数 -t, --strip_ansi 从所有子日志进程中剥离ANSI转义序列 -v, --version 查看版本 --profile_options=LIST 用于分析的逗号分隔选项列表。导致 supervisord在探查器下运行，并根据选项输出结果，这些选项是以逗号分隔的以下列表：累积，呼叫，呼叫者。例如累计，来电者 --minprocs=NUM 在成功启动之前，supervisord进程必须可用的最小OS进程槽数 4.2 supervisorctl命令选项及动作 supervisorctl命令选项 选项 说明 -c, --configuration 配置文件路径（默认为/etc/supervisord.conf） -h, --help 查看帮助 -i, --interactive 执行命令后启动交互式shell -s, --serverurl URL supervisord服务器正在侦听的URL(default “http://localhost:9001”) -u, --username 用于与服务器进行身份验证的用户名 -p, --password 用于与服务器进行身份验证的密码 -r, --history-file 保留readline历史记录（如果readline可用） supervisorctl命令动作 动作 说明 help 打印可用操作列表 help 打印的帮助 add [...] 激活进程/组的配置中的任何更新 remove [...] 从活动配置中删除进程/组 update 重新加载配置并根据需要添加/删除，并将重新启动受影响的程序 update all 重新加载配置并根据需要添加/删除，并将重新启动受影响的程序 update [...] 更新特定组，并将重新启动受影响的程序 clear 清除进程的日志文件 clear 清除多个进程的日志文件 clear all 清除所有进程的日志文件 fg 连接到前台模式的进程按Ctrl + C退出前台 pid 获得supervisord的PID pid 按名称获取单个子进程的PID pid all 获取每个子进程的PID，每行一个 reload 重新启动远程监控 reread 重新加载守护进程的配置文件，无需添加/删除（无重启） restart 重新启动进程 注意：重新启动不会重新读取配置文件。为此，请参阅重读和更新 restart :* 重新启动组中的所有进程 注意：restart不会重新读取配置文件。为此，请参阅重读和更新 restart 重新启动多个进程或组 注意：restart不会重新读取配置文件。为此，请参阅重读和更新 restart all 重启所有进程 注意：restart不会重新读取配置文件。为此，请参阅重读和更新 signal 没有信号帮助 start 启动一个进程 start :* 启动组中的所有进程 start 启动多个进程或组 start all 启动所有进程 status 获取所有进程状态信息 status 按名称获取单个进程的状态 status 获取多个进程的状态 stop 停止一个进程 stop :* 停止组中的所有进程 stop 停止多个进程或组 stop all 停止所有进程 **tail [-f] [stdout\\ stderr] (default stdout)** 输出过程日志的最后一部分例如：tail -f 实时输出标准输出 Ctrl-C退出。tail -100 输出进程的最后100 个字节，标准错误输出最后1600 个字节官方原文，看不懂到底说的是什么 Output the last part of process logs Ex: tail -f Continuous tail of named process stdout Ctrl-C to exit. tail -100 last 100 bytes of process stdout tail stderr last 1600 bytes of process stderr 五、supervisor信号 supervisor程序可能会被发送信号，使其在运行时执行某些操作。 你可以将这些信号中的任何一个发送到单个supervisord进程id，可以在配置文件的[supervisord]部分的pidfile参数表示的文件中找到此进程ID （默认情况下为$CWD/supervisord.pid） SIGTERM supervisord的所有子进程都将关闭。这可能需要几秒钟。 SIGINT supervisord的所有子进程都将关闭。这可能需要几秒钟。 SIGQUIT supervisord的所有子进程都将关闭。这可能需要几秒钟。 SIGHUP supervisord将停止所有进程，从它找到的第一个配置文件重新加载配置，然后启动所有进程。 SIGUSR2 supervisord将关闭并重新打开主活动日志和所有子日志文件。 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/supervisor/2.supervisor管理mysql.html":{"url":"linux/linux服务/supervisor/2.supervisor管理mysql.html","title":"supervisor管理mysql","keywords":"","body":"supervisor管理mysql supervisor配置文件/etc/supervisor/supervisord.conf中定义了include，因此如果想要管理服务，就需要编辑/etc/supervisor/config.d/*.ini文件 [include] files = /etc/supervisor/config.d/*.ini 编辑mysql服务配置文件/etc/supervisor/config.d/mysql.ini ⚠️示例中的mysql是二进制安装在了/usr/local/mysql，例如数据目录是/usr/local/mysql/data，其余插件目录、错误日志目录、pid目录等还需要根据实际情况修改 cat >/etc/supervisor/config.d/mysql.ini 创建存放日志目录 mkdir -p /var/log/supervisor 将mysql加入supervisor 方法一 使用supervisorctl update 程序名把相应服务加入supervisor $ supervisorctl update mysql mysql: added process group 方法二 使用supervisorctl命令进入交互操作界面，然后再添加服务 $ supervisorctl $ update mysql 查看服务运行 $ supervisorctl status mysql mysql RUNNING pid 4415, uptime 0:00:36 详细配置 [program:mysql] command=/usr/local/mysql/bin/mysqld --basedir=/usr/local/mysql --datadir=/data/db/mysql/data --plugin-dir=/usr/local/mysql/lib/plugin --user=mysql --log-error=/data/db/mysql/logs/mysqld.log --pid-file=/data/db/mysql/mysqld/mysqld.pid --socket=/data/db/mysql/sock/mysqld.sock priority=1 numprocs=1 autostart=true autorestart=true startretries=10 exitcodes=0 stopsignal=KILL stopwaitsecs=10 redirect_stderr=true stdout_logfile_maxbytes = 1024MB stdout_logfile_backups = 10 stdout_logfile = /var/log/supervisord/mysql.log mysql配置文件 [client] port = 3306 socket = /data/db/mysql/sock/mysql.sock [mysqld] port = 3306 socket = /data/db/mysql/sock/mysql.sock pid-file = /data/db/mysql/sock/mysqld.pid log-error = /data/db/mysql/logs/mysql-err.log log = /data/db/mysql/logs/mysqld.log tmpdir = /data/db/mysql/tmp/ slow_query_log = ON long_query_time = 5 slow_query_log_file = /data/db/mysql/logs/slow_query.log log_queries_not_using_indexes = ON skip-external-locking key_buffer_size = 256M max_allowed_packet = 64M table_open_cache = 256 sort_buffer_size = 1M read_buffer_size = 1M read_rnd_buffer_size = 4M myisam_sort_buffer_size = 64M thread_cache_size = 8 query_cache_size= 16M thread_concurrency = 8 max_connections = 20000 max_connect_errors = 20000 log-bin=/data/db/mysql/log-bin/mysql-bin expire_logs_days=4 relay-log =/data/db/mysql/relay-log log_slave_updates =1 relay_log_purge =1 relay_log_space_limit = 10G binlog_format=mixed server-id = 21 innodb_data_home_dir = /data/db/mysql/data innodb_data_file_path = ibdata1:20G;ibdata2:20G;ibdata3:20G;ibdataext:10M:autoextend innodb_log_group_home_dir = /data/db/mysql/data innodb_buffer_pool_size = 4800M innodb_additional_mem_pool_size = 20M innodb_log_file_size = 64M innodb_log_buffer_size = 8M innodb_lock_wait_timeout = 50 [mysqldump] quick max_allowed_packet = 16M [mysql] no-auto-rehash [myisamchk] key_buffer_size = 128M sort_buffer_size = 128M read_buffer = 2M write_buffer = 2M [mysqlhotcopy] interactive-timeout 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/supervisor/3.supervisor管理nginx.html":{"url":"linux/linux服务/supervisor/3.supervisor管理nginx.html","title":"supervisor管理nginx","keywords":"","body":"supervisor管理nginx supervisor配置文件/etc/supervisor/supervisord.conf中定义了include，因此如果想要管理服务，就需要编辑/etc/supervisor/config.d/*.ini文件 [include] files = /etc/supervisor/config.d/*.ini 编辑nginx服务配置文件/etc/supervisor/config.d/nginx.ini ⚠️需要注意的是/usr/sbin/nginx表示在后台运行，但是supervisor不能监控后台程序， 所以supervisor就一直执行这个命令 ，因此会报错 /usr/sbin/nginx后必须加参数 -g 'daemon off;' 表示在前台运行 cat >/etc/supervisor/config.d/nginx.ini 将nginx加入supervisor $ supervisorctl update nginx nginx: added process group 查看状态 $ supervisorctl status nginx nginx RUNNING pid 9464, uptime 0:00:03 详细配置 [program:nginx] # use default nginx config file and dir command = /usr/local/nginx/sbin/nginx -g 'daemon off;' stdout_logfile = /var/log/supervisord/nginx.log redirect_stderr = true autorestart = true nginx配置文件 #user www www; worker_processes auto; # worker_cpu_affinity auto; # openresty-1.9.15 worker_rlimit_nofile 65535; error_log logs/error.log; pid /var/run/nginx.pid; events { use epoll; worker_connections 65565; } http { server_tokens off; sendfile on; tcp_nodelay on; tcp_nopush on; keepalive_timeout 0; charset utf-8; include mime.types; default_type application/json; log_format main ' $http_X_Forwarded_Proto - $http_SLB_IP - $upstream_addr - $http_X_Forwarded_For - ' '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status [$upstream_response_time] ' '[$request_time] $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\"'; client_header_buffer_size 16k; large_client_header_buffers 8 16k; server_names_hash_bucket_size 128; client_max_body_size 4096m; client_header_timeout 30s; client_body_timeout 30s; send_timeout 30s; lingering_close off; gzip on; gzip_vary on; gzip_min_length 1000; gzip_comp_level 6; gzip_types text/plain text/xml text/css application/javascript application/json; gzip_http_version 1.0; #index index.html index.shtml index.php; include upstream.conf; include default.conf; include vhosts/*.conf; include vhosts/jr/*.conf; include vhosts/yg/*.conf; include vhosts/yjk/*.conf; include vhosts/ys/*.conf; include vhosts/sec/*.conf; include vhosts/saas/*.conf; include vhosts/bd/*.conf; include vhosts/autom/*.conf; lua_code_cache on; lua_package_path \"../?.lua;../lib/?.lua;../lib/lua-resty-core/lib/?.lua;;\"; lua_need_request_body on; } 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/supervisor/4.supervisor管理tomcat.html":{"url":"linux/linux服务/supervisor/4.supervisor管理tomcat.html","title":"supervisor管理tomcat","keywords":"","body":"supervisor管理tomcat ⚠️在生产环境中是不允许以root用户运行tomcat的，我们是以一个有root权限的运维专用用户来运行supervisor和tomcat的 supervisor配置文件/etc/supervisor/supervisord.conf中定义了include，因此如果想要管理服务，就需要编辑/etc/supervisor/config.d/*.ini文件 [include] files = /etc/supervisor/config.d/*.ini 编辑tomcat服务配置文件/etc/supervisor/config.d/tomcat.ini tomcat安装目录/usr/local/tomcat-8.5.56/ jdk1.8安装目录/usr/local/jdk1.8.0_251/ cat >/etc/supervisor/config.d/tomcat.ini 修改tomcat启动脚本文件startup.sh 本文示例是/usr/local/tomcat-8.5.56/bin/startup.sh 最后一行，将start修改为run #exec \"$PRGDIR\"/\"$EXECUTABLE\" start \"$@\" exec \"$PRGDIR\"/\"$EXECUTABLE\" run \"$@\" #用以下命令修改 sed -i.bak '$s/start/run/' startup.sh 将tomcat加入supervisor $ supervisorctl update tomcat tomcat: added process group 查看状态 $ supervisorctl status tomcat nginx RUNNING pid 9464, uptime 0:00:03 详细配置 [program:webServer] command=/data/webapp/webServer/bin/startup.sh environment=JAVA_HOME=\"/usr/local/jdk1.8.0/\",JAVA_BIN=\"/usr/local/jdk1.8.0/bin\" autostart = true autorestart=true redirect_stderr=true stdout_logfile=/data/logs/webServer/catalina.out 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/supervisor/5.supervisor管理redis.html":{"url":"linux/linux服务/supervisor/5.supervisor管理redis.html","title":"supervisor管理redis","keywords":"","body":"supervisor管理redis supervisor配置文件/etc/supervisor/supervisord.conf中定义了include，因此如果想要管理服务，就需要编辑/etc/supervisor/config.d/*.ini文件 [include] files = /etc/supervisor/config.d/*.ini supervisor管理redis有一个很奇怪的问题 redis配置文件中如果配置了daemonize yes用supervisor管理的时候是会报错如下redis FATAL Exited too quickly (process log may have details)，虽然有报错但是redis进程却是正常运行的，进程在端口也能启动！！！ 如果把daemonize改成no则没有问题，但是这样就不能把redis以守护进程的方式运行了 daemonize设置yes或者no区别 yes redis采用的是单进程多线程的模式。当redis.conf中选项daemonize设置成yes时，代表开启守护进程模式。在该模式下，redis会在后台运行，并将进程pid号写入至redis.conf选项pidfile设置的文件中，此时redis将一直运行，除非手动kill该进程。 no 当daemonize选项设置成no时，当前界面将进入redis的命令行界面，exit强制退出或者关闭连接工具(putty,xshell等)都会导致redis进程退出。 编辑redis服务配置文件/etc/supervisor/config.d/redis.ini cat > /etc/supervisor/config.d/redis.ini 将redis加入supervisor $ supervisorctl update redis redis: added process group 查看状态 $ supervisorctl status redis redis RUNNING pid 15430, uptime 0:00:06 详细配置 [program:redis] command=/usr/local/bin/redis-server /data/db/redis/cfg/redis.conf directory=/usr/local/redis/src/ autostart=true stdout_logfile=/var/log/supervisord/redis.log redis配置文件 daemonize yes pidfile /data/db/redis/pid/redis_6379.pid port 6379 tcp-backlog 511 timeout 300 tcp-keepalive 0 loglevel notice logfile \"/data/db/redis/logs/redis_6379.log\" databases 16 save 7200 1 stop-writes-on-bgsave-error yes rdbcompression yes rdbchecksum yes dbfilename dump_6379.rdb dir /data/db/redis/data slave-serve-stale-data yes slave-read-only yes repl-diskless-sync yes repl-diskless-sync-delay 5 repl-disable-tcp-nodelay no slave-priority 100 protected-mode no maxmemory 4gb appendonly no appendfilename \"appendonly_6379.aof\" no-appendfsync-on-rewrite no auto-aof-rewrite-percentage 50 auto-aof-rewrite-min-size 64mb aof-load-truncated yes lua-time-limit 5000 slowlog-log-slower-than 50000 slowlog-max-len 1024 latency-monitor-threshold 0 notify-keyspace-events \"\" hash-max-ziplist-entries 512 hash-max-ziplist-value 64 list-max-ziplist-entries 512 list-max-ziplist-value 64 set-max-intset-entries 512 zset-max-ziplist-entries 128 zset-max-ziplist-value 64 hll-sparse-max-bytes 3000 activerehashing yes client-output-buffer-limit normal 0 0 0 client-output-buffer-limit slave 256mb 64mb 60 client-output-buffer-limit pubsub 32mb 8mb 60 hz 10 aof-rewrite-incremental-fsync yes 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/supervisor/6.supervisor管理mongodb.html":{"url":"linux/linux服务/supervisor/6.supervisor管理mongodb.html","title":"supervisor管理mongodb","keywords":"","body":"supervisor管理mongodb supervisor配置文件/etc/supervisor/supervisord.conf中定义了include，因此如果想要管理服务，就需要编辑/etc/supervisor/config.d/*.ini文件 [include] files = /etc/supervisor/config.d/*.ini 编辑mongodb服务配置文件/etc/supervisor/config.d/mongodb.ini mongodb配置文件中要设置这一项fork = false，即不以守护进程方式运行mongodb cat >/etc/supervisor/config.d/mongodb.ini 将mongodb加入supervisor $ supervisorctl update mongodb mongodb: added process group 查看状态 $ supervisorctl status mongodb mongodb RUNNING pid 30352, uptime 0:10:26 详细配置 [program:mongodb] command=/usr/local/mongodb/bin/mongod -f /data/db/mongodb/cfg/mongod.conf directory=/usr/local/mongodb autostart=true user=testinadmin mongodb配置文件 bind_ip = 172.20.1.40 logpath = /data/db/mongodb/logs/mongod.log logappend = true pidfilepath = /data/db/mongodb/pid/mongod.pid dbpath = /data/db/mongodb/data storageEngine = wiredTiger directoryperdb = true #replSet = replset #rest = true oplogSize = 61440 #fork = true auth = false shardsvr = true port = 27010 journal = true maxConns = 30000 master = true #slave = true #source = 10.31.133.145:27010 #source = 10.47.125.99:27010 autoresync=true 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux服务/supervisor/7.supervisor自定义服务文件参数.html":{"url":"linux/linux服务/supervisor/7.supervisor自定义服务文件参数.html","title":"supervisor自定义服务文件参数","keywords":"","body":"supervisor自定义服务文件参数 supervisor配置文件/etc/supervisor/supervisord.conf中定义了include，因此如果想要管理服务，就需要编辑/etc/supervisor/config.d/*.ini文件，以下为/etc/supervisor/config.d/*.ini文件中用到的参数 参数 说明 command 启动程序使用的命令，可以是绝对路径或者相对路径 process_name 一个python字符串表达式，用来表示supervisor进程启动的这个的名称，默认值是%(program_name)s numprocs Supervisor启动这个程序的多个实例，如果numprocs>1，则process_name的表达式必须包含%(process_num)s，默认是1 numprocs_start 一个int偏移值，当启动实例的时候用来计算numprocs的值 priority 权重，可以控制程序启动和关闭时的顺序，权重越低：越早启动，越晚关闭。默认值是999 autostart 如果设置为true，当supervisord启动的时候，进程会自动重启 autorestart 值可以是false、true、unexpected。false：进程不会自动重启，unexpected：当程序退出时的退出码不是exitcodes中定义的时，进程会重启，true：进程会无条件重启当退出的时候 startsecs 程序启动后等待多长时间后才认为程序启动成功 startretries supervisord尝试启动一个程序时尝试的次数。默认是3 exitcodes 一个预期的退出返回码，默认是0,2 stopsignal 当收到stop请求的时候，发送信号给程序，默认是TERM信号，也可以是 HUP, INT, QUIT, KILL, USR1, or USR2 stopwaitsecs 在操作系统给supervisord发送SIGCHILD信号时等待的时间 stopasgroup 如果设置为true，则会使supervisor发送停止信号到整个进程组 killasgroup 如果设置为true，则在给程序发送SIGKILL信号的时候，会发送到整个进程组，它的子进程也会受到影响 user 如果supervisord以root运行，则会使用这个设置用户启动子程序 redirect_stderr 如果设置为true，进程则会把标准错误输出到supervisord后台的标准输出文件描述符 stdout_logfile 把进程的标准输出写入文件中，如果stdout_logfile没有设置或者设置为AUTO，则supervisor会自动选择一个文件位置 stdout_logfile_maxbytes 标准输出log文件达到多少后自动进行轮转，单位是KB、MB、GB。如果设置为0则表示不限制日志文件大小 stdout_logfile_backups 标准输出日志轮转备份的数量，默认是10，如果设置为0，则不备份 stdout_capture_maxbytes 当进程处于stderr capture mode模式的时候，写入FIFO队列的最大bytes值，单位可以是KB、MB、GB stdout_events_enabled 如果设置为true，当进程在写它的stderr到文件描述符的时候，PROCESS_LOG_STDERR事件会被触发 stderr_logfile 把进程的错误日志输出一个文件中，除非redirect_stderr参数被设置为true stderr_logfile_maxbytes 错误log文件达到多少后自动进行轮转，单位是KB、MB、GB。如果设置为0则表示不限制日志文件大小 stderr_logfile_backups 错误日志轮转备份的数量，默认是10，如果设置为0，则不备份 stderr_capture_maxbytes 当进程处于stderr capture mode模式的时候，写入FIFO队列的最大bytes值，单位可以是KB、MB、GB stderr_events_enabled 如果设置为true，当进程在写它的stderr到文件描述符的时候，PROCESS_LOG_STDERR事件会被触发 environment 一个k/v对的list列表 directory supervisord在生成子进程的时候会切换到该目录 umask 设置进程的umask serverurl 是否允许子进程和内部的HTTP服务通讯，如果设置为AUTO，supervisor会自动的构造一个url 重要参数 服务自动重启设置，supervisor提供了当服务挂掉时自动重启服务的功能autorestart autorestart可以写在supervisor配置文件中，也可以写在服务自定义文件中（supervisor配置文件中include指定的目录下的文件/etc/supervisor/config.d/*.ini） autorestart值可以是false、true、unexpected 值 说明 false 进程不会自动重启 unexpected 当程序退出时的退出码不是exitcodes中定义的时侯，进程会重启 true 当服务退出的时候进程会无条件重启 示例： [program:nginx] command = /usr/sbin/nginx -g 'daemon off;' stdout_logfile = /var/log/nginx/nginx.log redirect_stderr = true autorestart = unexpected 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/自动化运维平台/walle/CentOS7.5安装walle1.2.html":{"url":"linux/自动化运维平台/walle/CentOS7.5安装walle1.2.html","title":"walle1.2","keywords":"","body":"CentOS7.5安装walle1.2 walle1.0是基于php开发的，需要php5.4以上版本 瓦力官方文档 瓦力上线流程 一、依赖 Bash(git、ssh) 意味着不支持win、mac的zsh LNMP/LAMP(php5.4+) php需要开启pdo_mysql，exec函数执行 Composer 如果国内环境安装极慢，可以直接下载vendor解压到项目根目录 ansible 二、系统环境 2.1系统版本 $ cat /etc/redhat-release CentOS Linux release 7.5.1804 (Core) 2.2php版本 $ php -v PHP 7.2.16 (cli) (built: Mar 10 2019 21:22:49) ( NTS ) Copyright (c) 1997-2018 The PHP Group Zend Engine v3.2.0, Copyright (c) 1998-2018 Zend Technologies with Zend OPcache v7.2.16, Copyright (c) 1999-2018, by Zend Technologies 三、安装步骤 3.1更换系统yum源为阿里云yum源及添加epel源 //备份原有base源 mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup //下载阿里云yum源 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo //下载epel源 wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo //清空缓存、生成yum缓存 yum clean all yum makecache 3.2安装php-7.2 1.下载php7.2yum源 需要先安装epel-release yum -y install https://mirror.webtatic.com/yum/el7/webtatic-release.rpm 2.安装php7.2 yum -y install php72w php72w-cli php72w-common php72w-curl php72w-gd \\ php72w-mbstring php72w-mysqlnd php72w-process php72w-xml php72w-zip \\ php72w-opcache php72w-pecl-apcu php72w-intl php72w-pecl-redis php72w-fpm 3.启动php-fpm并设置为开机自启 systemctl start php-fpm && systemctl enable php-fpm 3.3安装mysql-5.7.22 gitbook链接-安装msql-5.7.22 有道云链接-安装mysql-5.7.22 3.4安装nginx-1.14并编辑配置文件 //添加nginx官方yum源 cat >/etc/yum.repos.d/nginx.repo /etc/nginx/conf.d/my.walle1.com.conf 3.5安装ansible yum -y install ansible 3.6代码检出 //创建目录 mkdir -p /data/www/walle-web && cd /data/www/walle-web //克隆代码 git clone https://github.com/meolu/walle-web-v1.x.git . 3.7设置mysql [root@walle walle-web]# pwd /data/www/walle-web [root@walle walle-web]# vim config/local.php 修改24行，25行，写入mysql用户名和密码 'username' => isset($_ENV['WALLE_DB_USER']) ? $_ENV['WALLE_DB_USER'] : 'root', 'password' => isset($_ENV['WALLE_DB_PASS']) ? $_ENV['WALLE_DB_PASS'] : '123456', //创建数据库walle mysql -uroot -p -e \"create database walle\" 3.8安装composer，Composer 是 PHP5.3以上 的一个依赖管理工具 //下载安装脚本composer-setup.php到当前目录 php -r \"copy('https://install.phpcomposer.com/installer', 'composer-setup.php');\" //执行安装过程 php composer-setup.php //删除安装脚本 php -r \"unlink('composer-setup.php');\" //将composer.phar移动至/usr/local/bin,以便能直接执行composer命令 mv composer.phar /usr/local/bin/composer 3.9安装vendor omposer install --prefer-dist --no-dev --optimize-autoloader -vvvv 3.10初始化项目 ./yii walle/setup 3.11绑定hosts文件 //windows C:\\Windows\\System32\\drivers\\etc 10.0.0.51 my.walle1.com //mac /etc/hosts 3.12浏览器访问my.walle1.com 初始化管理员账号密码为：admin/admin 初始化开发者账号密码为：demo/demo 登陆后首界面 到此，瓦力1.2安装完成！！！ 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/自动化运维平台/walle/CentOS7.5安装walle2.0.html":{"url":"linux/自动化运维平台/walle/CentOS7.5安装walle2.0.html","title":"walle2.0","keywords":"","body":"CentOS7.5安装walle2.0 标准安装 walle2.0是基于python开发的，需要python2.7+，mysql5.6.5以上版本 官方文档 瓦力上线流程 一、系统环境 1.1Linux系统版本 [root@walle ~]# cat /etc/redhat-release CentOS Linux release 7.5.1804 (Core) 1.2python版本 [root@walle ~]# python --version Python 2.7.5 二、安装步骤 2.1更换阿里云yum源及添加epel源 #备份原有base源 [root@walle ~]# mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup #下载阿里云yum源 [root@walle ~]# wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo #下载epel源 [root@walle ~]# wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo #清空缓存、生成yum缓存 [root@walle ~]# yum clean all && yum makecache 2.2安装依赖包 [root@walle ~]# yum -y install python2-pip python-virtualenv 2.3安装mysql-5.7.22 gitbook链接-安装msql-5.7.22 有道云链接-安装mysql-5.7.22 2.4安装nginx1.14并配置 #添加nginx官方yum源 [root@walle ~]# cat >/etc/yum.repos.d/nginx.repo /etc/nginx/conf.d/my.walle.com.conf 2.5克隆瓦力 #克隆瓦力项目 [root@walle ~]# git clone https://github.com/meolu/walle-web.git #将瓦利项目移至根下 [root@walle ~]# mv walle-web / 2.6编辑hosts文件 #域名要与nginx配置文件中一样 [root@walle ~]# echo \"127.0.0.1 my.walle2.com\" >>/etc/hosts 2.7安装python2.7+pip [root@walle ~]# cd /walle-web [root@walle walle-web]# sh admin.sh init 安装后提示如下即为成功 init walle success welcome to walle 2.0 # 注意：安装mysqlclient失败，需要先安装libmysqlclient-dev(ubuntu) # 注意：安装失败请指定python路径. mac 可能会有用anaconda的python，找到自己系统的python 2.7追加参数指定 -p /usr/bin/python2.7 即可 vim admin.sh +20 virtualenv --no-site-packages -p /usr/local/bin/python2.7 venv 2.8编辑python配置文件/walle-web/walle/config/settings_prod.py #编辑配置文件 [root@walle walle-web]# pwd /walle-web [root@walle walle-web]# vim walle/config/settings_prod.py 修改以下几项 25行，域名设置，要与nginx配置文件中的域名相同 HOST = 'my.walle2.com' 31行，数据库设置，修改user和password，这里为root用户，密码123456，端口为3306 SQLALCHEMY_DATABASE_URI = 'mysql://user:password@localhost:3306/walle?charset=utf8' 34行，指定本地代码检出路径（用户查询分支, 编译, 打包） CODE_BASE = '/data/walle/codebase/' 45行以下为邮箱设置 MAIL_SERVER = 'smtp.163.com' MAIL_PORT = 465 MAIL_USE_SSL = True MAIL_USE_TLS = False MAIL_DEFAULT_SENDER = 'xxx@163.com' MAIL_USERNAME = 'xxx' MAIL_PASSWORD = '123456' #创建本地代码检出路径 [root@walle walle-web]# mkdir -p /data/walle/codebase 2.9创建walle数据库并进行数据迁移 #创建walle数据库 [root@walle walle-web]# mysql -uroot -p -e \"create database walle\" #创建软连接，否则后续执行迁移脚本会出错 先找到libmysqlclient.so.20位置，这里为/usr/local/mysql-5.7.22/lib/libmysqlclient.so.20， 因为做了/usr/local/mysql软连接，所以可以直接使用/usr/local/mysql/lib/路径 [root@walle walle-web]# find / -name \"libmysqlclient.so.20\" /usr/local/mysql-5.7.22/lib/libmysqlclient.so.20 [root@walle walle-web]# ln -s /usr/local/mysql/lib/libmysqlclient.so.20 /usr/lib64/libmysqlclient.so.20 [root@walle walle-web]# sh admin.sh migration 最后提示OK即为成功 2.10启动瓦力并加入开机自启 [root@walle walle-web]# sh admin.sh start [root@walle walle-web]# echo \"cd /walle-web/ && sh admin.sh start\" >>/etc/rc.local [root@walle ~]# chmod +x /etc/rc.d/rc.local 2.11绑定hosts文件 //windows C:\\Windows\\System32\\drivers\\etc 10.0.0.11 my.walle2.com //mac /etc/hosts 2.12登陆瓦力 初始登陆账号 超管：super@walle-web.io \\ Walle123 所有者：owner@walle-web.io \\ Walle123 负责人：master@walle-web.io \\ Walle123 开发者：developer@walle-web.io \\ Walle123 访客：reporter@walle-web.io \\ Walle123 瓦力重启、升级、数据迁移 sh admin.sh restart # 重启 sh admin.sh upgrade # 升级walle，升级完需要重启walle服务。 升级前最好 git stash 暂存本地修改，升级后git stash pop弹出暂存， 然后重启服务。 sh admin.sh migration # Migration，数据迁移 登陆界面 登陆后首界面 到此，瓦力2.0标准安装完成！！！ docker安装 一、安装docker 1.1下载官方yum源 #添加yum源 [root@docker01 ~]# curl -o /etc/yum.repos.d/docker-ce.repo \\ https://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce.repo #添加官方yum源 [root@docker01 ~]# yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 1.2.修改docker官方yum源地址为清华源 [root@docker01 ~]# sed -i 's#download.docker.com#mirrors.tuna.tsinghua.edu.cn/docker-ce#g' \\ /etc/yum.repos.d/docker-ce.repo 1.3安装docker docker-ce 社区版 [root@docker01 ~]# yum -y install docker-ce 1.4.启动docker [root@docker01 ~]# systemctl start docker && systemctl enable docker 1.5查看docker版本 [root@docker01 ~]# docker version Client: Version: 18.09.1 API version: 1.39 Go version: go1.10.6 Git commit: 4c52b90 Built: Wed Jan 9 19:35:01 2019 OS/Arch: linux/amd64 Experimental: false Server: Docker Engine - Community Engine: Version: 18.09.1 API version: 1.39 (minimum version 1.12) Go version: go1.10.6 Git commit: 4c52b90 Built: Wed Jan 9 19:06:30 2019 OS/Arch: linux/amd64 Experimental: false 1.6配置docker镜像加速 #配置docker官方镜像加速地址 [root@docker01 ~]# cat > /etc/docker/daemon.json /etc/docker/daemon.json 二、安装docker-compose 2.1下载安装包 [root@docker01 ~]# curl -L \"https://github.com/docker/compose/releases/download/1.24.1/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose 2.2给二进制文件添加可执行权限 [root@docker01 ~]# chmod +x /usr/local/bin/docker-compose 2.3完成安装，查看版本 [root@docker01 ~]# docker-compose -v docker-compose version 1.24.1, build 4667896b 三、编辑walle2.0 docker-compose文件并启动walle2.0容器 3.1创建存放文件目录 [root@docker01 ~]# mkdir /usr/local/walle2.0 && cd /usr/local/walle2.0 3.2新建walle.env，连接数据库MYSQL_USER默认使用root,如需使用其他用户，需自建用户更改walle.env文件 cat >walle.env 3.3创建docker-compose文件 cat >docker-compose.yml =1024) # 0.0.0.0:要绑定的宿主机端口:docker容器内端口80 - \"80:80\" depends_on: - python networks: - walle-net restart: always python: image: alenx/walle-python:2.1 container_name: walle-python hostname: walle-python env_file: # walle.env需和docker-compose在同级目录 - ./walle.env command: bash -c \"cd /opt/walle_home/ && /bin/bash admin.sh migration && python waller.py\" expose: - \"5000\" volumes: - /opt/walle_home/plugins/:/opt/walle_home/plugins/ - /opt/walle_home/codebase/:/opt/walle_home/codebase/ - /opt/walle_home/logs/:/opt/walle_home/logs/ - /root/.ssh:/root/.ssh/ depends_on: - db networks: - walle-net restart: always db: image: mysql container_name: walle-mysql hostname: walle-mysql env_file: - ./walle.env command: [ '--default-authentication-plugin=mysql_native_password', '--character-set-server=utf8mb4', '--collation-server=utf8mb4_unicode_ci'] ports: - \"3306:3306\" expose: - \"3306\" volumes: - /data/walle/mysql:/var/lib/mysql networks: - walle-net restart: always networks: walle-net: driver: bridge EOF 3.4启动容器 docker-compose up -d 启动完成后浏览器访问宿主机IP地址80端口完成登陆 3.5初始账号及常用操作 //初始账号 超管：super@walle-web.io \\ Walle123 所有者：owner@walle-web.io \\ Walle123 负责人：master@walle-web.io \\ Walle123 开发者：developer@walle-web.io \\ Walle123 访客：reporter@walle-web.io \\ Walle123 //常用操作 # 构建服务 docker-compose build # 启动服务,启动过程中可以直接查看终端日志，观察启动是否成功 docker-compose up # 启动服务在后台，如果确认部署成功，则可以使用此命令，将应用跑在后台，作用类似 nohup python waller.py & docker-compose up -d # 查看日志,效果类似 tail -f waller.log docker-compose logs -f # 停止服务,会停止服务的运行，但是不会删除服务所所依附的网络，以及存储等 docker-compose stop # 删除服务，并删除服务产生的网络，存储等，并且会关闭服务的守护 docker-compose down 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/自动化运维平台/walle/walle1.2 上线示例.html":{"url":"linux/自动化运维平台/walle/walle1.2 上线示例.html","title":"walle1.2上线示例","keywords":"","body":"walle1.2 上线示例 一、瓦力上线流程示意图 1.1 个人总结版 瓦力上线流程示意图 过程说明 1.开发提交本地代码到gitlab(github、gitea等)仓库 2.瓦力从gitlab拉取最新代码到本机 注意需要把进程用户的密钥放到gitlab的ssh-keys列表，这里的进程用户指的是一个程序的运行用户，例如nginx的运行用户是www 如果是java项目，则会在瓦力机器上进行编译打包，因此maven仓库是部署在瓦力机器上的 3.瓦力推送最新代码到线上web机器的发布版本库(瓦力中配置，就是web机器上的一个目录) 既然是瓦力主动推送代码到线上web机器，因此需要把进程用户的公钥添加到线上web机器的用户ssh-key信任列表，即做瓦力机器--->线上web机器的免密登陆 4.程序web根目录软连接到发布版本库 在瓦力中会配置发布版本库，这个发布版本库就是每一次瓦力推送的代码存放地址，然后程序的web根目录软连接到发布版本库，如果要做升级或者回滚的话就是改变软连接的位置 1.2 官方说明版 瓦力原理示意图 宿主机、目标机群、操作用户关系如下图所示，宿主机（walle所在的机器），是一个中间机器，是代码托管与远程目标机群的纽带。所以宿主机需要与代码托管(github/gitlab)和远程目标机群都建立ssh-key信任。 上线流程示意图 二、瓦力上线项目配置项说明 2.1 项目配置说明 2.1.1 项目配置 项目名称 需要上线的项目名称，最好与项目类型名相同，例如项目是兼容测试类，则名称就命名为兼容-测试-1.0 项目环境 测试环境、预发布环境、线上环境 远程仓库地址 一般为git居多 2.1.2 宿主机配置(瓦力机器本身) 代码检出仓库 瓦力从gitlab拉取代码的存放路径，目录自定义设置，⚠️要保证程序运行用户对此目录有写权限 排除文件 可以填写要排除的文件，自定义 2.1.3 目标机器配置 用户 目标机器就是线上的web机器，这里填写程序的运行用户，例如tomcat的运行用户是www webroot 代码的最终部署路径，⚠️注意不要创建此目录，瓦力会自动生成软连接到此，正确设置父级目录即可 发布版本库 代码发布的版本库，每次发布更新webroot的软链到当前最新版本，格式是/data/releases/项目名/时间目录，回滚只需要修改软连接即可，目录自定义 版本保留数 过多的历史版本将被删除，只可回滚保留的版本 机器列表 要发布的机器列表，一行一个，非22端口可ip:port 2.1.3 高级任务(目标机器操作) pre_deploy 在部署代码之前的准备工作，如git的一些前置检查、vendor的安装（更新），一行一条 post_deploy git代码检出之后，可能做一些调整处理， 如vendor拷贝， 环境适配（mv config一test.phpconfig.php）一行一条 pre_release 同步完所有目标机器之后，更改版本软链之前触发任务。java可能要做一些暂停 服务的操作（双引号将会被转义为\\\"） post_release 所有目标机器都部署完毕之后，做一些清理工作， 如删除缓存、平滑重载/重启服务（nginx、php、task） ，一行一条（双引号将会被转义为\\\"） post_release_delay 按顺序在每台目标机执行高级任务，每台服务器执行完毕后暂停x秒。默认设置为0，应用服务使用平滑重载，仅当应用服务无法支持平滑重载必须重启时才配置此参数。设置为大于0的值会出现代码发布阶段各个服务器业务代码逻辑不一致的情况，请谨慎配置 三、项目配置示例 3.1 前提条件 生产环境程序运行环境及用户说明 生产环境中一般会以一个非root用户运行程序，这里假设以www用户运行程序，生产中www用户是所有开发登陆系统所用的用户(需要cmdb授权登陆机器)，还有一个是运维专用用户，除特殊情况外，所有机器中的服务及相关目录权限都是www用户 瓦力机器说明 瓦力机器中代码检出仓库的权限应该设置www用户可写，生产中我们直接设置为www用户所有 禁止root远程登陆，登陆用户是www，登陆方式是密钥登陆 目标机器说明 目标机器的发布版本库权限所有者是www用户 目标机器中的服务以supervisor管理，并且supervisor运行用户是www 禁止root远程登陆，登陆用户是www，登陆方式是密钥登陆 ssh-key说明 瓦力机器需要与代码托管(github/gitlab)和远程目标机群都建立ssh-key信任，即瓦力机器要把自身的公钥放到代码托管、目标机器的ssh-key列表中 3.2 配置示例 生产环境中有java、php、python项目，其中还是以java项目居多，本示例中以更新nginx首页面模拟项目 示例环境 角色 机器IP 主机名 walle 10.0.0.10 walle gitlab 10.0.0.12 gitlab web 10.0.0.13 webserver 3.2.1 用户、目录权限配置 3.2.1.1 瓦力、目标web机共同配置 瓦力机器、目标web机器禁止root远程登陆，配置sudo用户是www，并且www用户登陆方式是密钥登陆 禁止root远程登陆，编辑文件/etc/ssh/sshd_config，编辑完成后重启ssh服务 #禁止root远程登陆 PermitRootLogin no #禁用密码验证 PasswordAuthentication no www用户生成密钥 su - www && ssh-keygen -t rsa -f /root/.ssh/id_dsa -P \"\" -q 3.2.1.2 瓦力机器单独配置 创建代码检出仓库并设置目录所有者为www mkdir -p /data/walle/WebServer && chown www.www /data/walle/WebServer 推送本机www用户的公钥到目标web机器的www用户 把瓦力机器www用户~/.ssh/id_rsa.pub文件中的内容复制到目标机器www用户下的~/.ssh/authorized_keys中，并且authorized_keys文件权设置为644或600，目前只能手动复制内容，没有找到命令解决方法 把本机.ssh/id_rsa.pub放到后续创建的gitlab项目中，注意以下问题 ⚠️ssh服务配置文件/etc/ssh/sshd_config中有一项配置是AuthorizedKeysFile .ssh/authorized_keys，如果想要使用私钥免密登陆，则公钥必须写入到文件.ssh/authorized_keys中，即注册私钥，否则免密会失败！！！ 3.2.1.3 目标web机器单独配置 已经rpm包安装好nginx1.16.1，并且nginx以www用户运行 编辑nginx虚拟主机配置测试文件 cat > /etc/nginx/conf.d/walle-test.conf 在瓦力中我们配置了webroot是/data/nginx/website，但是瓦力会自动生成此软连接，因此只需要创建/data/nginx即可 mkdir -p /data/nginx && chown www.www /data/nginx 创建发布版本库并设置目录所有者为www mkdir -p /data/release && chown www.www /data/release 这里的流程就是，开发写好了index.html文件内容并提交到gitlab，瓦力从gitlab拉取index.html文件到本机的/data/walle/WebServer(自定义的代码检出仓库)，然后瓦力利用rsync推送代码至/data/release/项目名/时间目录，然后瓦力中配置的程序根目录(webroot中指定)会软链接到/data/release/项目名/时间目录，这样就可以访问web服务了 3.2.1.4 gitlab配置 如果是初次使用gitlab的话，还需要把gitlab机器的root用户的密钥添加到gitlab的ssh-key列表中 创建组 创建用户 配置个人选项信息 设置用户密码 ⚠️未登陆的用户第一次登陆后需要重新设置密码，生产中我们给开发创建完用户后设置一个初始密码，然后由开发自行修改密码 将用户添加到组中 gitlab用户在组里面有5种不同权限： Guest：可以创建issue、发表评论，不能读写版本库 Reporter：可以克隆代码，不能提交，QA、PM 可以赋予这个权限 Developer：可以克隆代码、开发、提交、push，普通开发可以赋予这个权限 Maintainer：可以创建项目、添加tag、保护分支、添加项目成员、编辑项目，核心开发可以赋予这个权限 Owner：可以设置项目访问权限 - Visibility Level、删除项目、迁移项目、管理组成员，开发组组长可以赋予这个权限 在用户组中创建项目 以刚才创建的新用户身份登录到gitlab，然后在用户组中创建新的项目 添加密钥，因为账号是给开发创建的，因此需要开发把本机的ssh密钥添加 把程序运行用户www的密钥添加到gitlab的项目仓库中，瓦力机器操作 ⚠️要把瓦力机器.ssh/id_rsa.pub写入到.ssh/authorized_keys文件中，并且权限是600，否则瓦力检测会报错 3.2.2 瓦力web页面项目具体配置及上线daemo演示 3.2.2.1 这里仅仅做一个简单的更新nginx服务的index.html文件模拟上线过程 配置项目 3.2.2.2 配置完成后检测 3.2.2.3 创建上线单 3.2.2.4 填写上线单信息 3.2.2.5 上线前提交测试代码，这一步应该是开发本机操作 编辑测试代码，提交到WebServer仓库 Title 第一次测试 3.2.2.6 开始上线 点击部署开始上线，如果报错根据报错内容解决 3.2.2.7 浏览器访问 目标web机器IP 地址即可 3.2.3 web机器项目目录说明 我们在nginx配置文件中指定了root根目录是/data/nginx/website，但是不需要创建website子目录，因为瓦力会自动设置软连接，只需要创建父目录即可，nginx的root根目录会自动软连接至/data/release/项目名/时间目录 ⚠️这里有一个问题，如果在瓦力配置界面中对于目标机器的发布版本库只指定/data/release的话，会默认在这个目录下面生成一个名为1的目录，虽然不影响访问，但是不太好见名知意，因此最好设置为/data/release/项目名 修改目标机器的发布版库为/data/release/项目名，这样的话就比较容易区分了 3.2.4 项目回滚操作 有的时候升级完成后可能会出现一些问题，并不是bug上的问题，例如开发忘记打开某一个功能按钮(之前生产环境中出现过这种情况，虽然不是bug问题，但是服务功能上有影响)，这个时候可能需要做回滚操作 回滚操作其实就是改变web机器上的软链接，web机器的程序根目录链接到不同的发布版本库下已实现不同的功能 3.2.4.1 进行第二次上线 模拟问题 之前已经有过第一次上线了，现在进行第二次上线，编辑代码并提交至WebServer仓库 Title 增加一个很牛逼的功能 瓦力上线 访问 web机器IP ，可以看到文件内容已更新 此时web机器的目录链接情况如下 链接的目录是20200720-201541，如果要回滚到上一个版本的话，链接应该会改为20200720-195809 3.2.4.2 发现问题，开始回滚 找到上一次升级的上线单，可以根据上线单标题和上线cimmit号(推荐)，点击回滚 开始回滚 浏览器访问 web机器IP，可以看到已经回滚到上一次提交的内容 此时web机器的目录链接情况如下 链接的目录是20200720-201541，如果要回滚到上一个版本的话，链接应该会改为20200720-195809 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/自动化运维平台/gitea/gitea安装.html":{"url":"linux/自动化运维平台/gitea/gitea安装.html","title":"gitea安装","keywords":"","body":"gitea安装 一、gitea简介 Gitea是用Go编写的由社区管理的轻量级代码托管解决方案，类似gitlab，但是比gitlab占用资源小太多了，gitlab起码2G+内存，而gitea挤需要90M就能跑起来！！！ 挤需体验三翻钟，泥造会干我一样，爱上这个软件！！！ ​ --- 渣渣灰 gitea官网 gitea英文文档 gitea中文文档 二、gitea安装 gitea安装方式有很多种，详情看官网，这里选择docker安装，docker安装中的数据库有3种，sqlite3、mysql、pg 2.1下载gitea镜像 可以通过dockerhub下载对应的gitea镜像 docker pull gitea/gitea:1.11.1 2.2下载dcoker-compose docker-compose国内地址 docker-compose官方地址 curl -L https://get.daocloud.io/docker/compose/releases/download/1.12.0/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose && chmod +x /usr/local/bin/docker-compose 2.3编辑gitea docker-compose文件 1.创建目录 mkdir /usr/local/gitea && cd /usr/local/gitea 2.编辑gitea文件 cat >docker-compose.yaml 3000/tcp, 0.0.0.0:222->22/tcp gitea_server_1 b8f0be18fe78 postgres:9.6 \"docker-entrypoint.s…\" 27 seconds ago Up 26 seconds 5432/tcp gitea_db_1 2.4gitea数据库设置 浏览器访问IP:3000 初始界面如下，第一个注册的用户就是管理员，后续可以设置只有管理员能注册账号，可以修改配置文件，也可以在可选设置中设置 数据库设置 一般设置 可以自定义仓库根目录和日志目录 可选设置 ⚠️如果这里勾选了禁止用户自主注册就必须设置管理员信息，否则你不允许注册又没设置管理员信息那企不是🐔🐔斯密达了？ 登陆后首界面 剩下的操作就不用多说了，创建仓库、组织、用户，上传代码、拉取代码等等 2.5配置文件修改项 关于服务的一些修改，配置文件是gitea/gitea/conf/app.ini 例如，手动关闭页面注册按钮，修改app.ini文件中的SHOW_REGISTRATION_BUTTON一项 其他的配置上官网看 我喜欢这个软件最重要的一点就是这个软件支持中文！！！ 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/自动化运维平台/gitlab/CentOS7.5安装gitlab-ce11.8.3.html":{"url":"linux/自动化运维平台/gitlab/CentOS7.5安装gitlab-ce11.8.3.html","title":"CentOS7.5安装gitlab-11.8.3","keywords":"","body":"CentOS7.5安装gitlab-ce11.8.3 gitlab官方安装文档 gitlab官方下载地址 一、系统环境 1.1系统版本 [root@gitlab ~]# cat /etc/redhat-release CentOS Linux release 7.5.1804 (Core) 1.2内存 [root@gitlab ~]# free -m total used free shared buff/cache available Mem: 3934 107 3696 11 130 3625 Swap: 1023 0 1023 1.3IP [root@gitlab ~]# ip a s eth0 2: eth0: mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:60:5b:13 brd ff:ff:ff:ff:ff:ff inet 10.0.0.70/24 brd 10.0.0.255 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:fe60:5b13/64 scope link valid_lft forever preferred_lft forever 二、安装步骤 2.1安装依赖包 //安装依赖包 [root@gitlab ~]# yum -y install curl openssh-server openssh-clients postfix cronie policycoreutils-python //启动postfix [root@gitlab ~]# systemctl start postfix && systemctl enable postfix 2.2下载gitlab安装包并安装 //从清华大学镜像源下载 [root@gitlab ~]# wget https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7/gitlab-ce-11.8.3-ce.0.el7.x86_64.rpm //安装bitlab [root@gitlab ~]# yum -y localinstall gitlab-ce-11.8.3-ce.0.el7.x86_64.rpm 2.3下载git [root@gitlab ~]# yum -y install git 2.4修改gitlab配置文件 [root@gitlab ~]# vim /etc/gitlab/gitlab.rb 修改13行 xternal_url 'http://gitlab.example.com' 修改为本机IP地址 external_url 'http://10.0.0.70' //说明 /opt/gitlab #gitlab的程序安装目录 /var/opt/gitlab #gitlab目录数据目录 /var/opt/gitlab/git-dfata #存放仓库数据 2.5启动gitlab //启动gitlab [root@gitlab ~]# gitlab-ctl start //重载gitlab配置文件 [root@gitlab ~]# gitlab-ctl reconfigure 重载完成后会提示如下 Running handlers: Running handlers complete Chef Client finished, 473/1265 resources updated in 03 minutes 25 seconds gitlab Reconfigured! //gitlab启动的端口 [root@gitlab ~]# netstat -ntpl Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:8060 0.0.0.0:* LISTEN 3456/nginx: master tcp 0 0 127.0.0.1:9121 0.0.0.0:* LISTEN 3901/redis_exporter tcp 0 0 127.0.0.1:9090 0.0.0.0:* LISTEN 3913/prometheus tcp 0 0 127.0.0.1:9187 0.0.0.0:* LISTEN 3960/postgres_expor tcp 0 0 127.0.0.1:9093 0.0.0.0:* LISTEN 3946/alertmanager tcp 0 0 127.0.0.1:9100 0.0.0.0:* LISTEN 3881/node_exporter tcp 0 0 127.0.0.1:9229 0.0.0.0:* LISTEN 3858/gitlab-workhor tcp 0 0 127.0.0.1:9168 0.0.0.0:* LISTEN 3891/puma 3.12.0 (t tcp 0 0 127.0.0.1:8080 0.0.0.0:* LISTEN 3360/unicorn master tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 3456/nginx: master tcp 0 0 127.0.0.1:8082 0.0.0.0:* LISTEN 3397/sidekiq 5.2.5 tcp 0 0 127.0.0.1:9236 0.0.0.0:* LISTEN 3841/gitaly tcp6 0 0 :::9094 :::* LISTEN 3946/alertmanager tcp6 0 0 ::1:9168 :::* LISTEN 3891/puma 3.12.0 (t //gitlab相关命令 gitlab-ctl status #查看目前gitlab所有服务运维状态 gitlab-ctl stop #停止gitlab服务 gitlab-ctl stop nginx #单独停止某个服务 gitlab-ctl tail #查看所有服务的日志 2.6gitlab汉化 //下载最新汉化包 [root@gitlab ~]# git clone https://gitlab.com/xhang/gitlab.git //下载gitlab对应版本汉化包，下载后是一个gitlab名称的目录 [root@gitlab ~]# git clone https://gitlab.com/xhang/gitlab.git -b v11.8.3-zh [root@gitlab ~]# ls //切换到汉化包目录，比较汉化标签和原标签，导出patch用的diff文件到/root下 [root@gitlab ~]# cd gitlab [root@gitlab gitlab]# git diff v11.8.3 v11.8.3-zh > ../11.8.3-zh.diff [root@gitlab ~]# ls 11.8.3-zh.diff //将11.8.3-zh.diff作为补丁更新到gitlab中 [root@gitlab ~]# yum -y install patch [root@gitlab ~]# patch -d /opt/gitlab/embedded/service/gitlab-rails -p1 2.7浏览器访问gitlab 如果浏览器访问出现502 需要稍等一会 gitlab还没有完全启动 设置密码，最少8位数 登陆gitlab，用户名为root，密码为自己设置的密码 登陆后首界面，有一部分没有汉化，汉化包的原因 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/自动化运维平台/gitlab/gitlab安装最新版.html":{"url":"linux/自动化运维平台/gitlab/gitlab安装最新版.html","title":"gitlab最新版安装","keywords":"","body":"安装gitlab最新版 一、docker安装gitlab最新版 docker安装gitlab官方文档 1.安装docker-compose 1.下载安装包 curl -L \"https://github.com/docker/compose/releases/download/1.24.1/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose 2.给二进制文件添加可执行权限 chmod +x /usr/local/bin/docker-compose 3.完成安装，查看版本 docker-compose -v docker-compose version 1.24.1, build 4667896b 2.创建存放docker-compose文件目录 mkdir /usr/local/gitlab cd /usr/local/gitlab 3.编辑docker-compose.yml文件 #需要修改相对应的域名及映射的端口 cat >docker-compose.yml 4.启动容器 docker-compose up -d 5.查看启动的容器 [root@docker1 gitlab]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 146a96210725 gitlab/gitlab-ce:latest \"/assets/wrapper\" 2 minutes ago Up 2 minutes (health: starting) 0.0.0.0:443->443/tcp, 0.0.0.0:22->22/tcp, 0.0.0.0:80->80/tcp gitlab_web_1 二、yum安装gitlab最新版 curl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash yum -y install gitlab-ce 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/自动化运维平台/gitlab/gitlab一些问题汇总.html":{"url":"linux/自动化运维平台/gitlab/gitlab一些问题汇总.html","title":"gitlab一些问题汇总","keywords":"","body":"gitlab一些问题汇总 1.关于gitlab7.12.0初始密码的问题 背景：公司用的gitlab版本是7.12.0，自己在虚拟机中安装的时候发现找不到初始密码，各种百度总结出以下两点 1.必须执行以下授权命令，否则会报502，原因未知 chmod -R o+x /var/opt/gitlab/gitlab-rails 2.gitlab7.12.0初始密码 root 5iveL!fe 2.gitlab官网注册时遇到的问题 注册gitlab时提示如下 原因 上面的错误是因为注册时有一个google的验证码需要输入。但是中国无法访问google,因此无法访问并输入该验证码导致 解决方法 翻墙或者通过下方的Github登陆 3.yum安装gitlab最新版 curl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash yum -y install gitlab-ce 4.修改gitlab默认80端口 ⚠️修改完gitlab默认的80端口后只需重启，不能重载配置文件，否则会还原 //修改gitlab默认80端口 vim /var/opt/gitlab/nginx/conf/gitlab-http.conf //重启即可，不能重载配置文件，否则会覆盖修改 gitlab-ctl restart 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/自动化运维平台/jenkins/CentOS7.5安装jenkins-2.176.html":{"url":"linux/自动化运维平台/jenkins/CentOS7.5安装jenkins-2.176.html","title":"CentOS7.5安装jenkins-2.176","keywords":"","body":"CentOS7.5安装jenkins-2.176 jenkins中文官网 jenkins官网 1.安装jdk8,jenkins运行依赖jdk 自行到oracle官网下载jdk oracle官网 1.解压缩包 [root@jenkins ~]# tar xf jdk-8u211-linux-x64.tar.gz -C /usr/local 2.导出环境变量 [root@jenkins ~]# cat >/etc/profile.d/jdk8.sh 2.安装jenkins，这里安装长期支持版 #安装LTS(长期支持版) LTS (长期支持) 版本每12周从常规版本流中选择，作为该时间段的稳定版本。 [root@jenkins ~]# curl -o /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo [root@jenkins ~]# rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key [root@jenkins ~]# yum -y install jenkins #安装每周更新版 每周都会发布一个新版本，为用户和插件开发人员提供错误修复和功能。 [root@jenkins ~]# curl -o /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat/jenkins.repo [root@jenkins ~]# rpm --import https://pkg.jenkins.io/redhat/jenkins.io.key [root@jenkins ~]# yum -y install jenkins #安装指定版本 https://pkg.jenkins.io/redhat-stable/ 3.修改jenkins配置文件，让jenkins以root用户运行 [root@jenkins ~]# sed -i.bak '29cJENKINS_USER=\"root\"' /etc/sysconfig/jenkins 4.启动jenkins #启动jenins并加入开机自启 [root@jenkins ~]# systemctl enable jenkins && systemctl start jenkins 5.浏览器访问jenkins jenkins刚启动比较慢，等待启动完成 从/var/lib/jenkins/secrets/initialAdminPassword文件按中获取密码 是否安装插件，自行选择 选择插件进行安装，必须选择Locale插件，修改jenkins语言 等待安装完成 插件安装完成后创建管理员用户，输入密码、用户全名、邮件地址 jenkins URL默认为主机IP地址加8080端口 jenkins首界面 6.设置jenkins默认语言为中文 选择jenkins管理 配置系统 默认语言填写zh_CN 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/自动化运维平台/ansible/ansible基础知识.html":{"url":"linux/自动化运维平台/ansible/ansible基础知识.html","title":"Ansible基础知识","keywords":"","body":"Ansible基础知识 1.Ansible基本概述 Ansible是一个配置管理系统configuration management system你只需要可以使用ssh访问你的服务器或设备就行 1.1Ansible能做什么 ansible可以帮助我们完成一些批量任务，或者完成一些需要经常重复的工作。 比如：同时在100台服务器上安装nginx服务，并在安装后启动服务。 比如：将某个文件一次性拷贝到100台服务器上。 比如：每当有新服务器加入工作环境时，你都要为新服务器部署某个服务，也就是说你需要经常重复的完成相同的工作。 这些场景中我们都可以使用到ansible。 1.2Ansible软件特点 1.ansible不需要单独安装客户端，SSH相当于ansible客户端。 2.ansible不需要启动任何服务，仅需安装对应工具即可。 3.ansible依赖大量的python模块来实现批量管理。 4.ansible配置文件/etc/ansible/ansible.cfg 1.3Ansible基础架构 1.连接插件(connectior plugins) 用于连接主机 用来连接被管理端 2.核心模块(core modules) 连接主机实现操作， 它依赖于具体的模块来做具体的事情 3.自定义模块(custom modules) 根据自己的需求编写具体的模块 4.插件(plugins) 完成模块功能的补充 5.剧本(playbooks)ansible的配置文件,将多个任务定义在剧本中，由ansible自动执行 6.主机清单(host inventory)定义ansible需要操作主机的范围 最重要的一点是 ansible是模块化的 它所有的操作都依赖于模块 2.Ansible安装配置 所有的受控主机必须与ansible服务端做ssh免密登陆 2.1.安装ansible(需要配置epel源) [root@m01 ~]# yum install ansible -y //检查ansible版本 [root@m01 ~]# ansible --version ansible 2.6.1 2.2配置ansible [root@m01 ~]# cat >> /etc/ansible/hosts 2.3验证ansible与受控机是否通信 //ansible是通过ssh端口探测通信 [root@m01 ~]# ansible hehe -m ping 10.0.0.30 | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } 10.0.0.40 | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } 2.4ansible语法格式 命令 主机模块名 指定模块参数 模块名称 指定利用模块执行的动作选项 批量执行操作动作 [root@m01 ~]# ansible all -m command -a \"hostname\" 10.0.0.31 | SUCCESS | rc=0 >> backup 10.0.0.41 | SUCCESS | rc=0 >> nfs01 all 模块名 -m 指定模块 command command模块，完成基础命令 -a 指定执行动作 \"hostname\" 执行hostname命令 3.Ansible系列命令 3.1ansiblie系列命令1：ansible 使用场景： 非固化需求 临时一次性操作 二次开发接口调用 使用示例 //检查服务器存活状态 ansible all -m ping 3.2ansiblie系列命令2：ansible-galaxy 命令作用： 根据下载量和关注量等信息，查找和安装优秀的roles 命令格式： ansible-galaxy [init|info|install|list|remove] [ --help] [options] ... 命令分为3部分 (1) [init|info|install|list|remove] init 初始化本地的roles配置，以备上传roles至galaxy info 列表指定role的详细信息 install 下载并安装galaxy指定的roles到本地 list 列出本地已经下载的roles remove 删除本地已经下载的roles (2) help用法显示[--help] ansible-galaxy init --help (3) 参数项 ansible-galaxy init [options] role_name 3.3ansiblie系列命令3：ansible-doc 命令作用： 模块文档说明 命令格式： ansible-doc [options] [module] 示例： //列出ansible支持的 模块 ansible-doc -l //模块功能说明 ansible-doc ping 3.4ansiblie系列命令4：ansible-playbook 命令作用： 读取预先编写好的playbook文件实现批量管理 命令格式： ansible-playbook xxx.yaml 示例： //执行http_install这个playbook种定义的所有任务集 ansible-playbook http_install.yaml 3.5ansiblie系列命令5：ansible-vault 命令作用： 用于配置文件加密 命令格式： ansible-vault [encrypt|decrypt|create|edit|rekey|view] [--help] [options] file 示例： //加密a.yaml文件 ansible-vault encrypt a.yaml encrypt 加密 //加密后查看a.yaml文件就会显示乱码 ​ //解密a.yaml文件 ansible-vault decrypt a.yaml decrypt 解密 4.Ansible正则 4.1ALL全量匹配 all或* 匹配所有主机，all与*号功能相同 //all和号功能相同，但是\\号需要用\"\"引起来 ansible all -m ping ansible \"*\" -m ping 4.2逻辑或匹配 ： 同时对多台主机或多个组同时执行，相互之间用\":\"分割 web1:web2 //检测web组和nfs组中所有主机的存活 ansible \"web:nfs\" -m ping 4.3逻辑非匹配 ！ 逻辑非用!表示，主要针对多重条件的匹配规则 //所有在a组但不在b组的主机 a:!b 4.4逻辑与匹配 & 逻辑与用&表示 //a组和b组中同时存在的主机 a:&b 4.5模糊匹配 * *通配符在ansible中表示0个或多个任意字符 //所有以www开头.com结尾的主机 4.6正则匹配 ~ ~在ansible中表示正则匹配 //匹配www.a.com和www.b.com ⚠️注意 ~要在最前边，一定要加双引号 5.Ansible清单管理 inventory文件通常用于定义要管理主机的认证信息， 例如ssh登录用户名、密码以及key相关信息。如何配置Inventory文件 主机 1.支持主机名通配以及正则表达式，例如web[1:3].abc.com 2.支持基于非标准的ssh端口，例如web1.abc.com:6666 3.支持指定变量，可对个别主机的特殊配置，如登陆用户，密码等 主机组 1.支持嵌套组，例如[game:children],那么在game模块下面的组都会被game所包含 2.支持指定变量，例如[game:vars]在下面指定变量 [root@m01 ~]# cat /etc/ansible/hosts [webservers] 10.0.0.8 10.0.0.31 10.0.0.41 10.0.0.61 //添加三台主机至webserver[low版] [webservers] web1.abc.com web2.abc.com web3.abc.com //添加三台主机至webserver[low改良版] [webservers] web[1:3].abc.com //添加三台主机至webserver[密码版] [webservers] web1.abc.com ansible_ssh_pass='123456' web2.abc.com ansible_ssh_pass='123456' web3.abc.com ansible_ssh_pass='123456' //添加三台主机至webserver[密码改良版] [webservers] web[1:3].abc.com ansible_ssh_pass='123456' //添加三台主机至webserver[密码拆分版] [webservers] web1.abc.com web2.abc.com web3.abc.com [webservers:vars] ansible_ssh_pass='123456' //定义多组，多组汇总整合 [apache] web1.abc.com web2.abc.com web3.abc.com [apache:vars] ansible_ssh_pass='123456' [nginx] 10.0.0.7 10.0.0.31 10.0.0.41 10.0.0.61 [nginx:vars] ansible_ssh_pass='123456' //webservers组包括两个子组[apapche,nginx] [webservers:children] apache nginx ansible nginx --list-hosts ansible apache --list-hosts ansible websers --list-hosts Ansible内置变量 参数 用途 示例 ansible_ssh_host 定义hosts ssh地址 ansible_ssh_host=192.168.1.10 ansible_ssh_port 定义hosts ssh端口 ansible_ssh_port=2222 ansible_ssh_user 定义hosts ssh认证用户 ansible_ssh_user=user ansible_ssh_pass 定义hosts ssh认证密码 ansible_ssh_pass=pass ansible_sudo 定义hosts sudo用户 ansible_sudo=www ansible_sudo_pass 定义hosts sudo密码 ansible_sudo_pass=pass ansible_sudo_exe 定义hosts sudo路径 ansible_sudo_exe=/usr/bin/sudo ansible_connection 定义hosts 连接方式 ansible_connection=local ansible_ssh_private_key_file 定义hosts 私钥 ansible_ssh_private_key_file=/root/key ansible_ssh_shell_type 定义hosts shell类型 ansible_ssh_shell_type=bash ansible_python_interpreter 定义hosts 任务执行python路径 ansible_python_interpreter=/usr/bin/python2.7 ansible_*_interpreter 定义hosts 其他语言解析路径 ansible_* _interpreter=/usr/bin/ruby 6.Ansible Playbook playbook是由一个或多个模块组成的，使用多个不同的模块，完成一件事情 playbook通过yaml语法识别描述的状态文件。扩展名是yaml或yml 6.1YAML三板斧 缩进 YAML使用一个固定的缩进风格表示层级结构,每个缩进由两个空格组成, 不能使用tabs 冒号 以冒号结尾的除外，其他所有冒号后面所有必须有空格 短横线 表示列表项，使用一个短横杠加一个空格 多个项使用同样的缩进级别作为同一列表 6.2ansible playbook安装Apache示例 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/自动化运维平台/ansible/ansible常用模块.html":{"url":"linux/自动化运维平台/ansible/ansible常用模块.html","title":"Ansible常用模块","keywords":"","body":"Ansible常用模块 模块在ansible中是指需要快速执行一条命令， 并且不需要保存的命令，对于复杂的命令则为playbook Ansible注意事项->提示颜色信息说明 翔黄色：对远程节点进行相应修改 帽子绿：对远程节点不进行相应修改，或者只是对远程节点信息进行查看 深红色：操作执行命令有异常 浅紫色：表示对命令执行发出警告信息（可能存在的问题，给你一下建议） ansible查看帮助方法 [root@m01 ~]# ansible-doc -l #查看所有模块说明信息 [root@m01 ~]# ansible-doc copy #表示指定查看某个模块参数用法信息 一、命令模块 1.1command模块 不支持管道 不支持通配符 //默认模块, 执行命令 [root@m01 ~]# ansible all -m command -a \"hostname\" [root@m01 ~]# ansible all -a hostname 1.2shell模块 支持管道 支持通配符 [root@m01 ~]# ansible all -m shell -a \"ifconfig|grep eth0\" -f 50 -f =forks /etc/ansible/ansible.cfg #结果返回的数量 1.3raw模块 支持管道 支持通配符 [root@m01 ~]# ansible all -m raw -a \"ifconfig\" 二、脚本模块 2.1script执行脚本模块 //编写脚本 [root@m01 ~]# mkdir -p /server/scripts [root@m01 ~]# cat /server/scripts/yum.sh #!/usr/bin/bash yum -y install iftop //在本地运行模块，等同于在远程执行，不需要将脚本文件进行推送目标主机执行 [root@m01 ~]# ansible web01 -m script -a \"/server/scripts/yum.sh\" 三、安装模块 3.1yum安装软件模块 [root@m01 ~]# ansible all -m yum -a \"name=httpd state=installed\" name #指定要安装的软件包名称 state #指定使用yum的方法 installed，present #安装软件包 removed，absent #移除软件包 latest #安装最新软件包 四、文件模块 4.1copy拷贝文件模块 //推送文件模块 [root@m01 ~]# ansible all -m copy -a \"src=/etc/hosts dest=/tmp/test.txt\" //在推送覆盖远程端文件前，对远端已有文件进行备份，按照时间信息备份 [root@m01 ~]# ansible all -m copy -a \"src=/etc/hosts dest=/tmp/test.txt backup=yes\" 注意：当ansible本地/etc/hosts文件内容变化之后，受控机本地才会有备份文件 [root@web01 tmp]# ls hehe test.txt test.txt.2772.2017-09-15@09:43:26~ //直接向远端文件内写入数据信息，并且会覆盖远端文件内原有数据信息 [root@m01 ~]# ansible all -m copy -a \"content='abc' dest=/tmp/abc\" src #推送数据的源文件信息 dest #推送数据的目标路径 backup #对推送传输过去的文件，进行备份 content #直接批量在被管理端文件中添加内容 group #将本地文件推送到远端，指定文件属组信息 owner #将本地文件推送到远端，指定文件属主信息 mode #将本地文件推送到远端，指定文件权限信息 4.2file文件配置模块 [root@m01 ~]# ansible all -m file -a \"path=/tmp/abc state=diretory\" [root@m01 ~]# ansible all -m file -a \"path=/tmp/tt state=touch mode=555 owner=root group=root\" [root@m01 ~]# ansible all -m file -a \"src=/tmp/tt path=/tmp/tt_link state=link\" path #指定远程主机目录或文件信息 recurse #递归授权 state directory #在远端创建目录 touch #在远端创建文件 link #link或hard表示创建链接文件 absent #表示删除文件或目录 mode #设置文件或目录权限 owner #设置文件或目录属主信息 group #设置文件或目录属组信息 五、服务模块 5.1service服务模块 [root@m01 ~]# ansible all -m service -a \"name=crond state=stopped enabled=yes\" name #定义要启动服务的名称 state #指定服务状态是停止或是运行，停止和运行指令要写成过去时 started #启动 stopped #停止 restarted #重启 reloaded #重载 enabled #是否让服务开启自启动 六、用户和组模块 6.1group组模块 [root@m01 ~]# ansible all -m group -a \"name=hehe gid=888\" name #指定创建的组名 gid #指定组的gid state absent #移除远端主机的组 present #创建远端主机的组（默认） 6.2user用户模块 //-123使用MD5进行加密 -stdin 非交互式 -salt 加密参数 [root@m01 ~]# echo \"bgx\" | openssl passwd -123 -stdin -salt 'salt' [root@m01 ~]# ansible all -m user -a \"name=hehe uid=888 group=888 shell=/sbin/nologin create_home=no\" [root@m01 ~]# ansible all -m user -a \"name=hehe password='$1$765yDGau$diDKPRoCIPMU6KEVEaPTZ0' \" uid #指定用户的uid group #指定用户组名称 groups #指定附加组名称 password #给用户添加密码 shell #指定用户登录shell create_home #是否创建家目录 七、计划任务模块 7.1cron定时任务模块 //正常使用crond服务 [root@m01 ~]# crontab -l * * * * * /bin/sh /server/scripts/yum.sh //使用ansible添加一条定时任务 [root@m01 ~]# ansible all -m cron -a \"minute=* hour=* day=* month=* weekday=* job='/bin/sh /server/scripts/test.sh'\" [root@m01 ~]# ansible all -m cron -a \"job='/bin/sh /server/scripts/test.sh'\" //设置定时任务注释信息，防止重复，name设定 [root@m01 ~]# ansible all -m cron -a \"name='cron01' job='/bin/sh /server/scripts/test.sh'\" //删除相应定时任务 [root@m01 ~]# ansible all -m cron -a \"name='ansible cron02' minute=0 hour=0 job='/bin/sh /server/scripts/test.sh' state=absent\" //注释相应定时任务，使定时任务失效 [root@m01 scripts]# ansible all -m cron -a \"name='ansible cron01' minute=0 hour=0 job='/bin/sh /server/scripts/test.sh' disabled=no\" minute #分钟 hour #小时 day #日期 month #月份 weekday #星期 job #要执行的命令或脚本 name #指定计划任务别名 disabled #是否注释 state absent #删除 八、挂载模块 8.1mount模块 [root@m01 ~]# ansible all -m mount -a \"src=172.16.1.31:/data path=/data fstype=nfs opts=defaults state=present\" [root@m01 ~]# ansible web -m mount -a \"src=172.16.1.31:/data path=/data fstype=nfs opts=defaults state=mounted\" [root@m01 ~]# ansible web -m mount -a \"src=172.16.1.31:/data path=/data fstype=nfs opts=defaults state=unmounted\" [root@m01 ~]# ansible web -m mount -a \"src=172.16.1.31:/data path=/data fstype=nfs opts=defaults state=absent\" src #指定要挂载的内容 path #本地挂载点 fstype #挂载类型 opts #挂载权限 state present #开机挂载，仅将挂载配置写入/etc/fstab mounted #挂载设备，并将配置写入/etc/fstab unmounted #卸载设备，不会清除/etc/fstab写入的配置 absent #卸载设备，会清理/etc/fstab写入的配置 九、解压缩模块 9.1unarchive模块 [root@m01 ~]# ansible all -m unarchive -a \"src=/tmp/hehe.tar.gz dest=/tmp\" [root@m01 ~]# ansible all -m unarchive -a \"src=/tmp/hehe.tar.gz dest=/tmp copy=no\" copy #默认为yes，即先在本地解压然后再传输到受控机，等于no，解压缩受控机压缩包 creates #当文件存在时，不再进行解压 mode #指定解压缩文件权限 list_files #是否列出文件列表，默认no remote_src #表示文件已经在受控机上，相当于copy =no 十、下载模块 10.1get_url模块 [root@m01 ~]# ansible all -m get_url -a \"url=xxx dest=/opt\" url #指定要下载的url地址 dest #指定将url下载至哪 十一、替换模块 11.1 lineinfile模块 [root@m01 ~]# ansible all -m lineinfile -a \"path=/root/hehe regexp='^user admin' line='user hehe'\" path #文件路径 regexp #匹配的规则，即要替换的内容 line #替换为什么 state adsent #删除 11.2 replace模块 [root@m01 ~]# ansible all -m replace -a \"path=/root/hehe regexp='^user admin' replace='hehe'\" path #文件路径 regexp #匹配的规则，即要替换的内容 replace #替换为什么 十二、mysql模块 12.1mysql_user管理用户模块 [root@m01 ~]# ansible mysql -m mysql_user -a 'login_host=localhost login_password=abc123 login_user=root name=abc password=abc123 priv=zabbix.*:ALL state=present' login_host #登陆主机 login_password #登陆密码 login_user #登陆用户 name #要创建的用户 password #创建的用户的密码 priv #授权 state present #创建 12.2mysql_db管理数据库模块 [root@m01 ~]# ansible mysql -m mysql_db -a 'login_host=localhost login_password=abc123 login_user=root name=hehe state=present' login_host #登陆主机 login_password #登陆密码 login_user #登陆用户 name #要创建的数据库 state present #创建 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/monitor/zabbix/zabbix故障/zabbix故障.html":{"url":"linux/monitor/zabbix/zabbix故障/zabbix故障.html","title":"zabbix故障记录","keywords":"","body":"zabbix故障 zabbix数据库迁移的一个小问题 背景： 原先zabbix5.0是部署在1c1g的华为云主机上，但是因为有其他服务运行因此会导致mysql经常被系统干掉，选择把数据库迁移至1c4g的腾讯云主机上 过程： 导出zabbix库，拷贝至腾讯云主机然后导入 修改zabbix-server配置文件/etc/zabbix/zabbix_server.conf中的DBHost为新主机IP或域名 腾讯云主机mysql中重新授权zabbix，即只允许华为云主机连接 问题： zabbix报错如下 排查过程： zabbix服务端日志中没有有用的信息 刚导入成功后zabbix是没有问题的，也可以获取数据，但是隔了一段时间报错Unknown database 'zabbix'，原因是在华为云机器上执行了删除zabbix数据库的操作，但是配置文件/etc/zabbix/web/zabbix.conf.php中的数据库指向还是本机，因此会报错未知的数据库 解决方法： 修改配置文件/etc/zabbix/web/zabbix.conf.php中$DB['SERVER']字段中的localhost为新mysql主机的IP或域名 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/monitor/zabbix/zabbix3.4/1.CentOS7.5安装zabbix-3.4.html":{"url":"linux/monitor/zabbix/zabbix3.4/1.CentOS7.5安装zabbix-3.4.html","title":"zabbix3.4安装","keywords":"","body":"CentOS7.5安装zabbix-3.4 一、安装环境 操作系统 IP地址 域名 内存 CentOS7.5 10.0.0.200 my.zabbix.com 1G 二、安装步骤 zabbix3.4 中文手册地址 2.1配置zabbix仓库 [root@zabbix-server ~]# rpm -ivh https://mirrors.aliyun.com/zabbix/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-2.el7.noarch.rpm //实际为下载zabbix.repo [root@zabbix-server ~]# cat /etc/yum.repos.d/zabbix.repo [zabbix] name=Zabbix Official Repository - $basearch baseurl=http://repo.zabbix.com/zabbix/3.4/rhel/7/$basearch/ enabled=1 gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-ZABBIX-A14FE591 [zabbix-non-supported] name=Zabbix Official Repository non-supported - $basearch baseurl=http://repo.zabbix.com/non-supported/rhel/7/$basearch/ enabled=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-ZABBIX gpgcheck=1 2.2安装Zabbix程序包，以及MySQL、Zabbix-agent [root@zabbix-server ~]# yum -y install zabbix-server-mysql zabbix-web-mysql zabbix-agent mariadb-server 2.3创建Zabbix数据库以及用户授权 #启动mariadb [root@zabbix-server ~]# systemctl start mariadb && systemctl enable mariadb #mariadb默认root用户密码为空 [root@zabbix-server ~]# mysql -uroot -e \"create database zabbix character set utf8 collate utf8_bin;\" && mysql -uroot -e \"grant all privileges on zabbix.* to zabbix@localhost identified by 'zabbix';\" && mysql -uroot -e \"flush privileges;\" 2.4导入Zabbix数据至数据库中 [root@zabbix-server ~]# zcat /usr/share/doc/zabbix-server-mysql-3.4.15/create.sql.gz |mysql -uroot zabbix 2.5编辑/etc/zabbix/zabbix_server.conf文件，修改数据库配置 #修改/etc/zabbix/zabbix_server.conf文件 91行，取消DBHost=localhost注释 125行，修改为DBPassword=zabbix #用以下命令修改 [root@zabbix-server ~]# sed -i.bak '/# DBHost=localhost/c DBHost=localhost' /etc/zabbix/zabbix_server.conf [root@zabbix-server ~]# sed -i '/# DBPassword=/c DBPassword=zabbix' /etc/zabbix/zabbix_server.conf #修改后的配置文件 [root@zabbix-server ~]# grep ^[a-Z] /etc/zabbix/zabbix_server.conf LogFile=/var/log/zabbix/zabbix_server.log LogFileSize=0 PidFile=/var/run/zabbix/zabbix_server.pid DBHost=localhost DBName=zabbix DBUser=zabbix DBPassword=zabbix SNMPTrapperFile=/var/log/snmptrap/snmptrap.log Timeout=4 AlertScriptsPath=/usr/lib/zabbix/alertscripts ExternalScripts=/usr/lib/zabbix/externalscripts LogSlowQueries=3000 2.6启动Zabbix服务进程，并加入开机自启 [root@zabbix-server ~]# systemctl start zabbix-server && systemctl enable zabbix-server 2.7配置Apache的配置文件/etc/httpd/conf.d/zabbix.conf，修改时区 #用以下命令修改 [root@zabbix-server ~]# sed -i.bak '/Riga$/c php_value date.timezone Asia/Shanghai' /etc/httpd/conf.d/zabbix.conf [root@zabbix-server ~]# vim /etc/httpd/conf.d/zabbix.conf php_value max_execution_time 300 php_value memory_limit 128M php_value post_max_size 16M php_value upload_max_filesize 2M php_value max_input_time 300 php_value always_populate_raw_post_data -1 //取消注释，设置正确的时区 # php_value date.timezone Europe/Riga php_value date.timezone Asia/Shanghai 2.8整合nginx，让zabbix可以以域名访问 因为本文用到了apache来展示zabbix web界面，因此设置apache监听8080端口，nginx监听80端口 #安装nginx，提前上传nginx离线包，也可以直接yum安装nginx [root@zabbix-server ~]# ls nginx-1.14.0-1.el7_4.ngx.x86_64.rpm [root@zabbix-server ~]# rpm -ivh nginx-1.14.0-1.el7_4.ngx.x86_64.rpm #配置apache主配置文件，修改监听端口 将Listen80修改为Listen 8080 [root@zabbix-server ~]# sed -i.bak '/Listen 80/c Listen 8080' /etc/httpd/conf/httpd.conf #配置nginx虚拟主机配置文件 [root@zabbix-server ~]# cat >> /etc/nginx/conf.d/my.zabbix.com.conf > /etc/nginx/proxy_params 2.9启动Apache Web服务器 [root@zabbix-server ~]# systemctl enable httpd && systemctl start httpd 2.10浏览器输入地址my.zabbix.com/zabbix开始安装 第一步 第二步，全部为OK才可以 第三步 配置数据库连接 第四步 第五步，确认信息 第六步，完成安装 完成安装后会生成一个配置信息文件 第七步，登陆 第八步，修改zabbix语言为中文 完成安装后首界面 2.11 解决图形中文乱码问题 2.11.1从windows找到楷体字体simkai，搜索楷体即可 windows路径 c盘-->Windows-->Fonts mac路径/Library/Fonts 2.11.2在zabbix-server上备份zabbix默认字体并且上传新字体 [root@zabbix-server ~]# cd /usr/share/fonts/dejavu/ [root@zabbix-server dejavu]# ls DejaVuSans-BoldOblique.ttf DejaVuSansCondensed-BoldOblique.ttf DejaVuSansCondensed-Oblique.ttf DejaVuSans-ExtraLight.ttf DejaVuSans.ttf DejaVuSans-Bold.ttf DejaVuSansCondensed-Bold.ttf DejaVuSansCondensed.ttf DejaVuSans-Oblique.ttf #然后上传字体，修改名称为DejaVuSans.ttf [root@zabbix-server dejavu]# mv DejaVuSans.ttf DejaVuSans.ttf.bak [root@zabbix-server dejavu]# mv simkai.ttf DejaVuSans.ttf #注意字体的权限要让zabbix用户可以读 [root@zabbix-server dejavu]# ll DejaVuSans.ttf -rw-r--r-- 1 root root 19647736 Jan 13 16:29 DejaVuSans.ttf 2.11.3验证效果 监测中-->图形 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/monitor/zabbix/zabbix3.4/2.配置zabbix基于apache、nginx用户认证.html":{"url":"linux/monitor/zabbix/zabbix3.4/2.配置zabbix基于apache、nginx用户认证.html","title":"zabbix基于apache、nginx用户认证","keywords":"","body":"配置zabbix基于apache、nginx用户认证 一、基于apache 1.修改Apache的配置文件/etc/httpd/conf/httpd.conf 对需要认证的资源所在的目录进行配置,在文件最后一行加入以下内容，其中Allowoverride authconfig一行表示允许对/etc/zabbix/web目录下的内容进行用户认证 [root@zabbix-server ~]# vim /etc/httpd/conf/httpd.conf Options Indexes FollowSymLinks Allowoverride AuthConfig Order allow,deny Allow from all 2.在限制访问目录/usr/share/zabbix下创建文件.htaccess，并写入以下内容 [root@zabbix-server ~]# cat > /usr/share/zabbix/.htaccess 3.创建一个用户名为admin,密码为123456的登陆认证用户，同时将密码存放于/etc/zabbix/auth_conf [root@zabbix-server ~]# yum -y install httpd-tools [root@zabbix-server ~]# htpasswd -b -c /usr/share/zabbix/auth_file admin 123456 Adding password for user admin 4.重启apache服务 [root@zabbix-server ~]# systemctl restart httpd 二、基于nginx 1.安装包 [root@zabbix-server ~]# yum -y install httpd-tools 2.创建认证文件、配置nginx 这里指定了认证文件是/etc/nginx/auth_file，认证的用户名是admin，密码是123456，文件的所有者为root，权限是644 [root@zabbix-server ~]# htpasswd -b -c /etc/nginx/auth_file admin 123456 #nginx配置文件写入auth_basic和auth_basic_user_file location / { auth_basic \"Auth access down Input your Passwd!\"; auth_basic_user_file /etc/nginx/auth_file; } 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/monitor/zabbix/zabbix3.4/3.zabbix3.4监控一台主机.html":{"url":"linux/monitor/zabbix/zabbix3.4/3.zabbix3.4监控一台主机.html","title":"zabbix3.4监控一台主机","keywords":"","body":"zabbix3.4监控一台主机 zabbix-serverIP地址：10.0.0.200 1.安装zabbix-agent [root@test1 ~]# rpm -ivh https://mirrors4.tuna.tsinghua.edu.cn/zabbix/zabbix/3.4/rhel/7/x86_64/zabbix-agent-3.4.15-1.el7.x86_64.rpm 2.配置zabbix-agent #指定zabbix-server地址 [root@test1 ~]# sed -i.bak 's/Server=127.0.0.1/Server=10.0.0.200/' /etc/zabbix/zabbix_agentd.conf 3.启动zabbix-agent #启动zabbix-agent并设置开机自起 [root@test1 ~]# systemctl start zabbix-agent && systemctl enable zabbix-agent #检测端口 netstat -ntpl|grep 10050tcp 0 0 0.0.0.0:10050 0.0.0.0:* LISTEN 5220/zabbix_agentd tcp6 0 0 :::10050 :::* LISTEN 5220/zabbix_agentd 4.在zabbix-server端web界面，点击配置-->主机-->创建主机 5.点击配置-->主机-->模板-->链接指示器 添加后的主机 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/monitor/zabbix/zabbix3.4/4.zabbix3.4创建自定义触发器.html":{"url":"linux/monitor/zabbix/zabbix3.4/4.zabbix3.4创建自定义触发器.html","title":"zabbix3.4创建自定义触发器","keywords":"","body":"zabbix3.4创建自定义触发器 触发器：trigger 当监控项超过阈值时，产生告警 第一步，配置-->主机-->主机列表处的触发器-->创建触发器 第二步，添加表达式 第三步，添加表达式后测试表达式 第四步，查看触发器列表中刚添加的触发器 第五步，查看监控项中刚添加的触发器 配置-->主机-->主机列表中的主机-->监控项 第六步，开启zabbix监控面板告警声音 右上角-->小人头-->正在发送消息-->勾选要接受的告警 第七步，查看zabbix监控首页 在用一个终端登陆zabbix-agent主机，此时root登陆数为2，就会触发告警 第八步，查看键值 添加完成后，可以在zabbix-server端获取监控项的值 配置-->主机-->主机列表-->监控项-->键值 zabbix-server端取值 #zabbix-server端安装zabbix-get包 [root@zabbix-server ~]# yum -y install zabbix-get #对agent端取键值，结果为2表明root用户登陆数为2 [root@zabbix-server ~]# zabbix_get -s 10.0.0.10 -k system.users.num 2 -s 指定agent端IP地址 -k 键值 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/monitor/zabbix/zabbix3.4/5.zabbix3.4自定义监控项.html":{"url":"linux/monitor/zabbix/zabbix3.4/5.zabbix3.4自定义监控项.html","title":"zabbix3.4自定义监控项","keywords":"","body":"zabbix3.4自定义监控项 一、实验环境 服务器角色 ip 主机名 zabbix-server 10.0.0.200 zabbix-server zabbix-agent 10.0.0.10 test1 二、zabbix自定义监控项整体过程 2.1在对应的agent主机上编写自定义监控TCP的11种状态（在agent本地进行取值） #进到/etc/zabbix/zabbix_agentd.d [root@test1 zabbix_agentd.d]# pwd /etc/zabbix/zabbix_agentd.d #编写自定义取值文件 [root@test1 zabbix_agentd.d]# cat > tcp_state.conf 2.2在server上使用zabbix_get获取对应主机的值 [root@test1 zabbix-server]# zabbix_get -s 10.0.0.10 -k tcp_state[estb] 2.3在web界面添加 监控项 将监控项制作了一个图形 将主机关联该 TCP状态的模板 三、创建zabbix自定义监控项 3.1自定义监控tcp11种状态(传参方式，在本地取值) //创建自定义监控项文件 [root@test ~]# cd /etc/zabbix/zabbix_agentd.d/ [root@test ~]# cat > tcp_state.conf 3.2在zabbix-web端先创建模板 配置-->模板-->创建模板 添加模板后可以在配置-->模板中看到刚新建的模板 3.3点击创建的模板中的监控项，不要点主机中的监控项，然后点击创建监控项 点击添加后就可以看到刚创建的监控项 3.4利用克隆快速添加监控项 点击刚创建的监控项 点击克隆 然后填写信息，再点击最下方添加 其余tcp状态依照克隆方法依次添加 tcp12种状态，tcp_state.conf为在agent端/etc/zabbix/zabbix_agentd.d路径下创建的文件中自定义的 [root@test1 zabbix_agentd.d]# cat tcp_state.conf UserParameter=tcp_state[*],ss -an|awk '{print $2}'|grep -i \"$1\"|wc -l tcp_state[ESTABLISHED] tcp_state[SYN-SENT] tcp_state[SYN-RECV] tcp_state[FIN-WAIT1] tcp_state[FIN-WAIT2] tcp_state[TIME-WAIT] tcp_state[CLOSE] tcp_state[CLOSE-WAIT] tcp_state[LAST-ACK] tcp_state[LISTEN] tcp_state[CLOSING] tcp_state[UNKNOWN] 在配置-->模板中可以看新建的模板的信息，此时的模板是新建的，与主机没有任何关系，除非主机链接这个模板，这里可以看到有刚创建的12项监控项，但是没有图形，需要手动再创建图形 3.5创建图形 配置-->模板-->创建的模板(这里为Linux TCP Status)-->图形-->创建图形 添加后的图形 配置-->模板-->新建的模板 可以看到刚创建的图形 配置-->主机-->模板 查看图形，监测中-->最新数据 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/monitor/zabbix/zabbix3.4/6.zabbix3.4自定义告警内容.html":{"url":"linux/monitor/zabbix/zabbix3.4/6.zabbix3.4自定义告警内容.html","title":"zabbix3.4自定义告警内容","keywords":"","body":"zabbix3.4自定义告警内容 1.启动默认告警项 配置-->动作 2.修改告警内容 默认告警信息 #告警标题 Problem: {TRIGGER.NAME} #告警内容 Problem started at {EVENT.TIME} on {EVENT.DATE} Problem name: {TRIGGER.NAME} Host: {HOST.NAME} Severity: {TRIGGER.SEVERITY} Original problem ID: {EVENT.ID} {TRIGGER.URL} 修改告警默认标题如下 服务器:{HOST.NAME}发生: {TRIGGER.NAME} 故障! 修改告警内容如下 服务器:{HOST.NAME}发生: {TRIGGER.NAME} 故障! { 告警主机:{HOST.NAME} 告警地址:{HOST.IP} 监控项目:{ITEM.NAME} 监控取值:{ITEM.LASTVALUE} 告警等级:{TRIGGER.SEVERITY} 当前状态:{TRIGGER.STATUS} 告警信息:{TRIGGER.NAME} 告警时间:{EVENT.DATE} {EVENT.TIME} 事件ID:{EVENT.ID} } 3.修改恢复内容 默认恢复信息 #恢复标题 Resolved: {TRIGGER.NAME} #恢复内容 Problem has been resolved at {EVENT.RECOVERY.TIME} on {EVENT.RECOVERY.DATE} Problem name: {TRIGGER.NAME} Host: {HOST.NAME} Severity: {TRIGGER.SEVERITY} Original problem ID: {EVENT.ID} {TRIGGER.URL} 修改恢复信息标题如下 服务器:{HOST.NAME}: {TRIGGER.NAME} 已恢复! 修改恢复信息如下 服务器:{HOST.NAME}: {TRIGGER.NAME} 已恢复! { 告警主机:{HOST.NAME} 告警地址:{HOST.IP} 监控项目:{ITEM.NAME} 监控取值:{ITEM.LASTVALUE} 告警等级:{TRIGGER.SEVERITY} 当前状态:{TRIGGER.STATUS} 告警信息:{TRIGGER.NAME} 告警时间:{EVENT.DATE} {EVENT.TIME} 恢复时间:{EVENT.RECOVERY.DATE} {EVENT.RECOVERY.TIME} 持续时间:{EVENT.AGE} 事件ID:{EVENT.ID} } 4.修改确认操作 默认确认信息 #确认标题 Acknowledged: {TRIGGER.NAME} #确认内容 {USER.FULLNAME} acknowledged problem at {ACK.DATE} {ACK.TIME} with the following message: {ACK.MESSAGE} Current problem status is {EVENT.STATUS} 修改确认标题如下 服务器:{HOST.NAME}: 报警确认 修改确认内容如下 { 确认人:{USER.FULLNAME} 时间:{ACK.DATE} {ACK.TIME} 确认信息如下: \"{ACK.MESSAGE}\" 问题服务器IP:{HOSTNAME1} 问题ID:{EVENT.ID} 当前的问题是: {TRIGGER.NAME} } 修改完后点击更新 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/monitor/zabbix/zabbix3.4/7.zabbix3.4配置触发zabbix-agent端shell脚本、命令.html":{"url":"linux/monitor/zabbix/zabbix3.4/7.zabbix3.4配置触发zabbix-agent端shell脚本、命令.html","title":"zabbix3.4配置触发zabbix-agent端shell脚本、命令","keywords":"","body":"zabbix3.4配置触发zabbix-agent端shell脚本、命令 一、说明 1.zabbix-server端配置了触发器，如果监控项的阀值达到触发器的值，会发出告警信息。我们还想增加一个功能，如磁盘使用空间达到80%阀值的时候，触发一个自动清理磁盘空间的脚本，达到所谓的“自愈”功能 2.要配置好监控项、触发器，要确保触发器在监控项达到设置的阀值的时候能正常触发，这个是实现触发zabbix-agent脚本任务执行的前提，此处以磁盘可用空间低于30%为例 二、执行步骤 2.1zabbix-agent端开启允许远程执行命令 //zabbix-agent端编辑配置文件/etc/zabbix/zabbix_agentd.conf第73行，取消# EnableRemoteCommands=0注释，并把值修改为1 EnableRemoteCommands=0 用以下命令修改 [root@zabbix-agent ~]# sed -i.bak '/# EnableRemoteCommands=0/a EnableRemoteCommands=1' /etc/zabbix/zabbix_agentd.conf //重启zabbix-agent [root@zabbix-agent ~]# systemctl restart zabbix-agent 2.2在zabbix-agent端编写脚本，交给触发器触发时执行 //创建存放脚本目录，在zabbix-server端配置触发脚本时要写脚本的绝对路径 [root@zabbix-agent ~]# mkdir /etc/zabbix/scripts //编写脚本,此处仅仅是为了演示触发效果 [root@zabbix-agent ~]# mkdir /etc/zabbix/scripts [root@zabbix-agent ~]# cat >/etc/zabbix/scripts/test.sh > /tmp/test.txt EOF 2.3在zabbix-agent端将zabbix用户加入到sudo中 visudo编辑文件，在93行新加入abbix ALL=(ALL) NOPASSWD: ALL viduso编辑文件，注释53行Defaults !visiblepw //用以下命令修改 [root@zabbix-agent ~]# sed -i.bak '/^root/a zabbix ALL=(ALL) NOPASSWD: ALL' /etc/sudoers && sed -i '/Defaults !visiblepw/c#Defaults !visiblepw' /etc/sudoers 2.4zabbix-server创建动作，并指定只让某个主机组执行命令 配置-->动作-->创建动作 操作-->新的 进行相关配置 在zabbix-agent端做如下操作 #创建一个8G的大文件让系统磁盘使用率大于80%，这样就会触发告警，从而执行我们自定义的脚本 dd if=/dev/zero of=/opt/bigfile bs=1M count=8192 #等待server端web界面告警后，就会在我们自定的脚本中设定的路径/tmp下创建一个test.txt文件 cat /tmp/test.txt 2018-01-10-22:28:13磁盘使用率超过80% 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/monitor/zabbix/zabbix3.4/8.zabbix3.4设置邮件告警.html":{"url":"linux/monitor/zabbix/zabbix3.4/8.zabbix3.4设置邮件告警.html","title":"zabbix3.4设置邮件告警","keywords":"","body":"zabbix3.4设置邮件告警 第一步、配置-->动作-->启用动作 第二步、管理-->报警媒介类型-->选择Email 第三步、设置服务器发件人，使用邮箱账户和授权密码，授权密码在qq邮箱官网中设置 第四步、设置收件人邮箱，右上角小人头-->报警媒介--添加 第五步、收件人类型选择Email，填写收件人邮箱，接受报警级别，添加 第六步、确认没有问题，点击更新 第七步、验证是否发送邮件 第八步、qq邮箱查看邮件 邮件发送失败 发送邮件失败原因1：qq邮箱服务器地址写错，正确为smtp.qq.com，而不是mail.qq.com 发送邮件失败原因2：填写发件人信息后没有保存 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/monitor/zabbix/zabbix3.4/9.zabbix3.4设置邮件告警升级.html":{"url":"linux/monitor/zabbix/zabbix3.4/9.zabbix3.4设置邮件告警升级.html","title":"zabbix3.4设置邮件告警升级","keywords":"","body":"zabbix3.4设置邮件告警升级 一、邮件告警升级过程 这里仅作示例 1.首先发给运维组，持续10分钟 2.运维组没有解决，发给经理组，持续10分钟 3.经理组没有解决，发给总监组 二、邮件告警升级过程配置 2.1配置-->动作-->选择动作(这里选择默认) 2.2操作-->点击 新的 2.3填写第一步发送设置 2.4填写第二步发送设置 2.5填写第三步发送设置 2.6添加完成后页面 操作步骤写1-2，2-3，3-4 1-2，3-4，5-6都可以 2.7添加完成后在相应用户填写收件地址即可，管理-->用户--报警媒介 2.8给创建的用户群组赋予读写权限 管理-->用户群组-->选择创建的用户群组-->权限 2.9验证 经过测试 1.管理员即运维组先收到告警，对应下图中问题下方1 2.规定时间没有完成发送给经理组，对应下图中问题下方2 3.经理组在规定时间内没有完成处理发送给总监组，对应下图中问题下方3，应为本文中设置总监接受1分钟，因此总监只接受一次 4.如果恢复，运维组、经理组、总监组都会收到恢复信息 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/monitor/zabbix/zabbix3.4/10.zabbix3.4使用企业微信告警.html":{"url":"linux/monitor/zabbix/zabbix3.4/10.zabbix3.4使用企业微信告警.html","title":"zabbix3.4使用企业微信告警","keywords":"","body":"zabbix3.4使用企业微信告警 第一步、注册企业微信，个人就可以注册，然后按照提示填写相关信息 企业微信注册地址 第二步、登陆企业微信 企业微信首界面 应用与小程序-->创建应用，根据提示填写相关信息，这里已经创建好了一个zabbix监控 点击创建的应用，后续python脚本会用到Agentld和Secret 点击我的企业，后续python脚本会用到企业ID 第三步、zabbix-server端配置python脚本 3.1环境准备 #安装依赖包 [root@zabbix-server ~]# yum -y install python-pip [root@zabbix-server ~]# pip install requests [root@zabbix-server ~]# cd /usr/lib/zabbix/alertscripts [root@zabbix-server alertscripts]# ls weixin.py #给脚本赋予执行权限 [root@zabbix-server alertscripts]# chmod +x weixin.py #一定要修改/tmp/weixin.log这个文件的权限为zabbix，因为zabbix程序在执行weixin.py的时候是以zabbix用户执行的，而这个文件默认是root，不修改权限会报错 [root@zabbix-server alertscripts]# chown zabbix.zabbix /tmp/weixin.log 3.2编写微信告警脚本 [root@zabbix-server alertscripts]# pwd /usr/lib/zabbix/alertscripts [root@zabbix-server alertscripts]# cat >weixin.py 成员信息中查看 [root@zabbix-server alertscripts]# ./weixin.py 企业微信号 test test 企业微信收到信息即为正确 第四步、zabbix-server端配置 4.1管理-->报警媒介类型-->创建媒体类型 4.2填写相关信息 脚本名称为自己定义的weixin.py，路径为在zabbix-server端/etc/zabbix/zabbix_server.conf中定义 AlertScriptsPath=/usr/lib/zabbix/alertscripts 在下图中脚本参数的地方写入以下3个参数，注意脚本参数一定要填写正确 {ALERT.SENDTO} {ALERT.SUBJECT} {ALERT.MESSAGE} 4.3设置收件人 右上角小人头-->报警媒介-->添加 第五步、修改告警相关信息 5.1修改告警操作 修改操作标题如下 服务器:{HOST.NAME}发生: {TRIGGER.NAME} 故障! 修改消息内容如下 服务器:{HOST.NAME}发生: {TRIGGER.NAME} 故障! { 告警主机:{HOST.NAME} 告警地址:{HOST.IP} 监控项目:{ITEM.NAME} 监控取值:{ITEM.LASTVALUE} 告警等级:{TRIGGER.SEVERITY} 当前状态:{TRIGGER.STATUS} 告警信息:{TRIGGER.NAME} 告警时间:{EVENT.DATE} {EVENT.TIME} 事件ID:{EVENT.ID} } 5.2修改恢复操作 修改恢复标题如下 服务器:{HOST.NAME}: {TRIGGER.NAME} 已恢复! 修改恢复内容如下 服务器:{HOST.NAME}: {TRIGGER.NAME} 已恢复! { 告警主机:{HOST.NAME} 告警地址:{HOST.IP} 监控项目:{ITEM.NAME} 监控取值:{ITEM.LASTVALUE} 告警等级:{TRIGGER.SEVERITY} 当前状态:{TRIGGER.STATUS} 告警信息:{TRIGGER.NAME} 告警时间:{EVENT.DATE} {EVENT.TIME} 恢复时间:{EVENT.RECOVERY.DATE} {EVENT.RECOVERY.TIME} 持续时间:{EVENT.AGE} 事件ID:{EVENT.ID} } 5.3修改确认信息 修改确认标题如下 服务器:{HOST.NAME}: 报警确认 修改确认内容如下 服务器:{HOST.NAME}: 报警确认 { 确认人:{USER.FULLNAME} 时间:{ACK.DATE} {ACK.TIME} 确认信息如下: \"{ACK.MESSAGE}\" 问题服务器IP:{HOSTNAME1} 问题ID:{EVENT.ID} 当前的问题是: {TRIGGER.NAME} } 第六步、验证 企业微信中创建的zabbix监控应用能收到信息即为正确 pc端企业微信 手机端企业微信 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/monitor/zabbix/zabbix3.4/11.zabbix3.4使用钉钉告警.html":{"url":"linux/monitor/zabbix/zabbix3.4/11.zabbix3.4使用钉钉告警.html","title":"zabbix3.4使用钉钉告警","keywords":"","body":"zabbix3.4使用钉钉告警 第一步、钉钉机器人创建 打开windows钉钉客户端-->右上角头像处-->机器人管理 选择自定义 选择添加 填写机器人名字和要添加到的群组 这里的webhook值需要写在后续python脚本中 第二步、zabbix-server端编写python脚本 #在zabbix-server端编辑python脚本 [root@zabbix-server alertscripts]# pwd /usr/lib/zabbix/alertscripts [root@zabbix-server alertscripts]# cat dingding.py #!/usr/bin/python # -*- coding: utf-8 -*- import requests import json import sys import os headers = {'Content-Type': 'application/json;charset=utf-8'} api_url = \"https://oapi.dingtalk.com/robot/send?xxx\" #注意，api_url到后边的一串是一行，且这里的api_url要写成自己企业钉钉中创建的机器人中的webhook def msg(text): json_text= { \"msgtype\": \"text\", \"at\": { \"atMobiles\": [ \"17310470653\" ], \"isAtAll\": False }, \"text\": { \"content\": text } } print requests.post(api_url,json.dumps(json_text),headers=headers).content if __name__ == '__main__': text = sys.argv[1] msg(text) #赋予脚本执行权限 [root@zabbix-server alertscripts]# chmod +x dingding.py #修改脚本所有者为zabbix [root@zabbix-server alertscripts]# chown zabbix.zabbix dingding.py #安装依赖包 [root@zabbix-server ~]# yum -y install python-pip [root@zabbix-server ~]# pip install requests #执行脚本进行测试，返回以下内容即为正确，并且钉钉能够收到信息 [root@zabbix-server alertscripts]# ./dingding.py test {\"errmsg\":\"ok\",\"errcode\":0} 第三步、zabbix web界面设置 3.1创建钉钉告警 管理-->报警媒介类型-->创建媒体类型 填写相关信息，注意脚本参数写 {ALERT.MESSAGE} 右上角小人头-->报警媒介-->添加 3.2修改告警操作 修改操作标题如下 服务器:{HOST.NAME}发生: {TRIGGER.NAME} 故障! 修改消息内容如下 服务器:{HOST.NAME}发生: {TRIGGER.NAME} 故障! { 告警主机:{HOST.NAME} 告警地址:{HOST.IP} 监控项目:{ITEM.NAME} 监控取值:{ITEM.LASTVALUE} 告警等级:{TRIGGER.SEVERITY} 当前状态:{TRIGGER.STATUS} 告警信息:{TRIGGER.NAME} 告警时间:{EVENT.DATE} {EVENT.TIME} 事件ID:{EVENT.ID} } 3.3修改恢复操作 修改恢复标题如下 服务器:{HOST.NAME}: {TRIGGER.NAME} 已恢复! 修改恢复内容如下 服务器:{HOST.NAME}: {TRIGGER.NAME} 已恢复! { 告警主机:{HOST.NAME} 告警地址:{HOST.IP} 监控项目:{ITEM.NAME} 监控取值:{ITEM.LASTVALUE} 告警等级:{TRIGGER.SEVERITY} 当前状态:{TRIGGER.STATUS} 告警信息:{TRIGGER.NAME} 告警时间:{EVENT.DATE} {EVENT.TIME} 恢复时间:{EVENT.RECOVERY.DATE} {EVENT.RECOVERY.TIME} 持续时间:{EVENT.AGE} 事件ID:{EVENT.ID} } 3.4修改确认信息 修改确认标题如下 服务器:{HOST.NAME}: 报警确认 修改确认内容如下 服务器:{HOST.NAME}: 报警确认 { 确认人:{USER.FULLNAME} 时间:{ACK.DATE} {ACK.TIME} 确认信息如下: \"{ACK.MESSAGE}\" 问题服务器IP:{HOSTNAME1} 问题ID:{EVENT.ID} 当前的问题是: {TRIGGER.NAME} } 第四步、钉钉验证 pc端钉钉 手机端钉钉 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/monitor/zabbix/zabbix5.0/1.centos7安装zabbix5.0.html":{"url":"linux/monitor/zabbix/zabbix5.0/1.centos7安装zabbix5.0.html","title":"1.zabbix5.0安装","keywords":"","body":"centos7安装zabbix5.0 zabbix5.0标准安装官方文档 一、标准安装 1.添加yum源 rpm -Uvh https://repo.zabbix.com/zabbix/5.0/rhel/7/x86_64/zabbix-release-5.0-1.el7.noarch.rpm 2.安装zabbix-server和zabbix-agent yum -y install zabbix-server-mysql zabbix-agent 3.安装Zabbix frontend 启用红帽软件集合 yum -y install centos-release-scl 4.编辑配置文件/etc/yum.repos.d/zabbix.repo以使用zabbix-frontend库 [zabbix-frontend] enabled=1 #使用如下命令修改 sed -i '11s/0/1/' /etc/yum.repos.d/zabbix.repo 5.安装Zabbix frontend包 yum -y install zabbix-web-mysql-scl zabbix-apache-conf-scl 6.创建数据库 mysql -e \"create database zabbix character set utf8 collate utf8_bin;\" mysql -e \"create user zabbix@localhost identified by 'zabbix';\" mysql -e \"grant all privileges on zabbix.* to zabbix@localhost;\" 7.导入数据库 zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p zabbix 8.为Zabbix server配置数据库 编辑配置文件/etc/zabbix/zabbix_server.conf //配置数据库密码 DBPassword=zabbix #使用如下命令 sed -i.bak '/# DBPassword=/c DBPassword=zabbix' /etc/zabbix/zabbix_server.conf 9.为Zabbix前端配置PHP 编辑配置文件/etc/opt/rh/rh-php72/php-fpm.d/zabbix.conf设置时区 sed -i.bak '/^;/c php_value[date.timezone] = Asia/Shanghai' /etc/opt/rh/rh-php72/php-fpm.d/zabbix.conf [root@hwy ~]# 10.给/etc/zabbix所有文件权限设置为zabbix chown -R zabbix.zabbix /etc/zabbix/ 11.启动服务 systemctl restart zabbix-server zabbix-agent httpd rh-php72-php-fpm systemctl enable zabbix-server zabbix-agent httpd rh-php72-php-fpm 12.完成安装 第一步、浏览器访问 IP:端口/zabbix 点击Next step 第二步、检查配置，要全部OK才可以 第三步、配置数据库信息 第四步、zabbix-server名称配置 第五步、确认配置信息 如果遇到这个则是权限问题，点击链接下载配置文件并存放至/etc/zabbix/web目录下，并且权限设置为644，属主和属组都是zabbix 第七步、完成安装 第八步、登陆zabbix 用户名Admin 密码zabbix 登陆后首界面 设置中文 点击左下角User settings，Language处选择Chinese(zh_CN)，然后点击Update 13.修改中文乱码问题 点击主机-->图形，会看到有乱码 解决方法 从windows找到楷体字体simkai，搜索楷体即可 windows路径 c盘-->Windows-->Fonts mac路径/Library/Fonts 在zabbix-server上备份zabbix默认字体并且上传新字体 [root@zabbix-server ~]# cd /usr/share/fonts/dejavu/ [root@zabbix-server dejavu]# ls DejaVuSans-BoldOblique.ttf DejaVuSansCondensed-BoldOblique.ttf DejaVuSansCondensed-Oblique.ttf DejaVuSans-ExtraLight.ttf DejaVuSans.ttf DejaVuSans-Bold.ttf DejaVuSansCondensed-Bold.ttf DejaVuSansCondensed.ttf DejaVuSans-Oblique.ttf #然后上传字体，修改名称为DejaVuSans.ttf [root@zabbix-server dejavu]# mv DejaVuSans.ttf DejaVuSans.ttf.bak [root@zabbix-server dejavu]# mv simkai.ttf DejaVuSans.ttf #注意字体的权限要让zabbix用户可以读 [root@zabbix-server dejavu]# chmod 644 DejaVuSans.ttf [root@zabbix-server dejavu]# ll DejaVuSans.ttf -rw-r--r-- 1 root root 19647736 Jan 13 16:29 DejaVuSans.ttf 浏览器刷新验证 二、docker安装 zabbix5.0 docker安装官方文档 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/monitor/grafana/1.centos7安装grafana7.0.3并结合zabbix数据源进行基础监控.html":{"url":"linux/monitor/grafana/1.centos7安装grafana7.0.3并结合zabbix数据源进行基础监控.html","title":"grafana7.0.3安装并结合zabbix数据源进行基础监控","keywords":"","body":"centos7安装grafana7.0.3并结合zabbix数据源进行基础监控 frafana官网 grafana官方下载地址 grafana官方管理配置文档 1.下载安装包并安装 wget https://dl.grafana.com/oss/release/grafana-7.0.3-1.x86_64.rpm yum -y localinstall grafana-7.0.3-1.x86_64.rpm 2.启动服务并设置开机自启 grafana默认监听TCP/3000端口 grafana配置文件/etc/grafana/grafana.ini systemctl enable grafana-server && systemctl start grafana-server 3.登陆grafana 初始默认账户和密码都是admin 登陆成功后会提示修改密码，也可以选择跳过不修改 登陆后首界面 4.安装zabbix插件 grafana 官方插件下载地址 grafana-cli plugins install alexanderzobnin-zabbix-app #插件安装完成后要重启grafana systemctl restart grafana-server 5.启用zabbix插件 第一步、点击左侧设置按钮，然后点击Plugins 第二步、在最下边找到zabbix插件，红色警告表明插件是外部插件 第三步、允许zabbix插件 6.配置zabbix数据源 第一步、点击左侧设置按钮，然后选择Data Sources 第二步、选择Add data source 第三步、选择zabbix 第四步、配置zabbix用户密码信息 grafana会自动使用默认的zabbix api地址 配置完成后点击下方的Save & Test zabbix api地址如下，如果localhost无法解析，则需要把localhost改成zabbix的域名 http://localhost/zabbix/api_jsonrpc.php 检测成功会提示如下 7.添加dashboard进行自定义监控 7.1 创建dashboard 点击左侧+号，选择Dashboard 选择右上角Dashboard settings 对dashboard进行重命名 确认dashboard名称 创建完成后的dashboard 7.2 创建监控图形 选择创建好的dashboard，然后点击右上角的Add panel，添加一个面板 示例：创建CPU负载监控图形 修改标题 7.3 保存dashboard 右上角点击Save 保存dashboard的时候会要求添加改变的描述信息，即修改了哪些内容 保存完后点击Apply 最终效果如下，左上角是新建的dashboard，最好以部门名称命名，这样便于区分不同部门的机器，这里是示例创建了CPU负载监控图形，其余监控创建方法一致，面板大小也可以调整 创建其他监控图形 如果想要创建其他监控项图形，先选择对应的dashboard，然后在创建面板，最后在面板中选择相应的监控信息即可 修改监控图形指标单位 在可用内存监控中，默认的单位不太好识别 修改指标单位 点击右侧的Axes(轴)，选择相对应的轴，比如Left Y(左Y轴)，然后在Unit(单位)选项卡处选择相应的单位，选择Data(Metric)下的bytes(Metric) 最终效果，这样看起来左侧显示单位就比较明了了 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/性能测试/文件删除效率测试/测试Linux下删除大量文件的效率.html":{"url":"linux/性能测试/文件删除效率测试/测试Linux下删除大量文件的效率.html","title":"文件删除效率测试","keywords":"","body":"测试Linux下删除大量文件的效率 创建50万个测试文件 //创建50万个文件 mkdir /test && cd /test time for i in $(seq 1 500000);do echo text >>$i.txt;done real 1m9.177s user 0m9.731s sys 0m48.238s //总大小为2G du -sh /test/ 2.0G /test/ 1.rm删除 time rm -rf * -bash: /usr/bin/rm: Argument list too long real 0m1.709s user 0m1.580s sys 0m0.123s 文件太多，rm不起作用 2.find删除 time find ./ -type f -exec rm {} \\; real 10m56.698s user 2m13.203s sys 8m35.653s 用时10分钟 3.find with delete time find ./ -type f -delete real 0m26.757s user 0m1.222s sys 0m23.112s 用时26秒 4.rsync删除 //先建立一个空文件夹test-bak mkdir test-bak time rsync -a --delete test-bak/ /test/ real 0m25.440s user 0m1.364s sys 0m22.082s 用时25秒 5.python2.7 import os import timeit def main(): for pathname,dirnames,filenames in os.walk('/test'): for filename in filenames: file=os.path.join(pathname,filename) os.remove(file) if __name__=='__main__': t=timeit.Timer('main()','from __main__ import main') print t.timeit(1) 用时35秒 6.perl time perl -e 'for(){((stat)[9] 系统环境 ucloud 1c2g centos7.7 #使用dd命令测试磁盘读写速度为78.6MB/s dd if=/dev/zero of=/opt/bigfile bs=1M count=1024 1024+0 records in 1024+0 records out 1073741824 bytes (1.1 GB) copied, 13.668 s, 78.6 MB/s #使用hdparm测试磁盘读写速度为74.60MB/s hdparm -t --direct /dev/vda1 /dev/vda1: Timing O_DIRECT disk reads: 230 MB in 3.08 seconds = 74.60 MB/sec 50万个文件删除所用时间 rm删除：文件太多，无法删除 find删除：用时10分钟 find with delete删除：用时26秒 rsync删除：用时25秒 python2.7删除：用时35秒 perl删除：用时33秒 rsync删除最快 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux系统/centos8/CentOS8使用记录.html":{"url":"linux/linux系统/centos8/CentOS8使用记录.html","title":"centos8使用记录","keywords":"","body":"CentOS8使用记录 centos8的作者应该很喜欢腾讯的地下城与勇士(dnf)，否则踏🐎怎么会把安装命令yum尼玛改成dnf ？？？ 1.更换yum源 1.备份 mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 2.下载阿里云yum源 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-8.repo 或 curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-8.repo 3.生成缓存 dnf clean all dnf makecache 4.安装epol源 yum install -y https://mirrors.aliyun.com/epel/epel-release-latest-8.noarch.rpm sed -i 's|^#baseurl=https://download.fedoraproject.org/pub|baseurl=https://mirrors.aliyun.com|' /etc/yum.repos.d/epel* sed -i 's|^metalink|#metalink|' /etc/yum.repos.d/epel* 2.同步时间 centos8不支持ntpdate了，改用chrony 1.安装 dnf -y install chrony 2.修改配置文件/etc/chrony.conf，注释pool开头一行，新增阿里云地址 #pool 2.centos.pool.ntp.org iburst server ntp.aliyun.com iburst sed -i.bak '3s/^/#&/g' /etc/chrony.conf && sed -i '4cserver ntp.aliyun.com iburst' /etc/chrony.conf server：指明时间服务器地址； allow NETADD/NETMASK allow all：允许所有客户端主机； deny NETADDR/NETMASK deny all：拒绝所有客户端； bindcmdaddress：命令管理接口监听的地址； local stratum 10：即使自己未能通过网络时间服务器同步到时间，也允许将本地时间作为标准时间授时给其它客户端； 3.启动服务 systemctl enable chronyd && systemctl start chronyd 4.检查端口 chronyd服务监听udp32端口 netstat -nupl|grep chronyd 5.验证同步 chronyc sources 210 Number of sources = 1 MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^* 203.107.6.88 2 6 17 44 -2379us[-3100us] +/- 43ms 个人实际使用，这个chrony不好用，绝对没有ntpdate好用，我手动更改了时间，尼玛5分钟了还没有同步，垃圾 还是直接使用命令来的快 chronyd -q \"server ntp.aliyun.com iburst\" centos8继续使用ntpdate 1.添加wlnmp源 rpm -ivh http://mirrors.wlnmp.com/centos/wlnmp-release-centos.noarch.rpm 2.安装ntp服务 dnf -y install wntp 3.时间同步 ntpdate ntp.aliyun.com 3.centos8网络服务 centos8使用的是NetworkManager管理网络，不能使用systemctld管理network systemctl enable NetworkManager nmcli c reload eth0 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux系统/ubuntu/ubuntu18.04使用记录.html":{"url":"linux/linux系统/ubuntu/ubuntu18.04使用记录.html","title":"ubuntu使用记录","keywords":"","body":"ubuntu18.04使用记录 1.设置静态IP //编辑文件 root@ubuntu18:~# cat /etc/netplan/01-network-manager-all.yaml # Let NetworkManager manage all devices on this system network: ethernets: enp0s5: #⚠️这里要看一下网卡的名称 dhcp4: false addresses: [10.0.0.15/24] gateway4: 10.0.0.1 nameservers: addresses: [223.5.5.5,114.114.114.114] version: 2 renderer: networkd //使设置生效 netplan apply 2.开启ssh服务 //ubuntu-18.04desktpo版默认只安装ssh-agent sudo apt -y install openssh-server //启动服务 sudo service ssh start 3.安装python3.6 //ubuntu18.04默认python版本是3.7 root@ubuntu18:~# python3 Python 3.7.5rc1 (default, Oct 8 2019, 16:47:45) [GCC 9.2.1 20191008] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. root@ubuntu18:~# python3.7 Python 3.7.5rc1 (default, Oct 8 2019, 16:47:45) [GCC 9.2.1 20191008] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. //安装依赖包 apt -y install python3-dev libffi-dev libssl-dev zlib* //源码编译安装python3.6 ./configure --enable-optimizations --prefix=/usr/local/python36 make make altinstall #防止覆盖原来的版本 //设置环境变量 echo \"PATH=/usr/local/python36/bin:$PATH\" >/etc/profile.d/python36.sh && source /etc/ //设置pip国内源 mkdir /root/.pip cat >/root/.pip/pip.conf ubuntu安装python3.6问题 4.更换国内源(ubuntu18.04) //备份原有文件 cp /etc/apt/sources.list{,.bak} //设置为阿里云源 cat >/etc/apt/sources.list 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux系统/kali/kali2020.1使用记录.html":{"url":"linux/linux系统/kali/kali2020.1使用记录.html","title":"kali使用记录","keywords":"","body":"kali2020.1使用记录 1.开启ssh kali默认ssh服务部开启 //启动ssh服务 service ssh start //开机自启 update-rc.d ssh enable 2.配置网卡 1.编辑文件/etc/network/interfaces #注释以下两行 #auto lo #iface lo inet loopback auto eth0 iface eth0 inet static address 10.0.0.17 netmask 255.255.255.0 gateway 10.0.0.1 2.重启网路服务 service networking restart 3.配置阿里云源 #编辑文件/etc/apt/sources.list，写入以下两行 deb https://mirrors.aliyun.com/kali kali-rolling main non-free contrib deb-src https://mirrors.aliyun.com/kali kali-rolling main non-free contrib #更新 apt update 4.设置图形界面 1.安装包 apt install x-window-system-core xfce4 -y 2.在命令行输入”dpkg-reconfigure locales”。进入图形化界面之后，（空格是选择，Tab是切换，*是选中），选中zh_CN.UTF-8，确定后，将h_CN.UTF-8选为默认。 接下来的几步就是选择zh_CN.UTF-8 3.安装中文字体 apt-get -y install xfonts-intl-chinese apt-get -y install ttf-wqy-microhei 安装完后如果没有显示中文重启即可 #开机设置进入图形界面 1.编辑/etc/default/grub 修改quite为text GRUB_CMDLINE_LINUX_DEFAULT=\"quiet\" 2.使配置生效 update-grub 5.kali设置服务开机自启 //设置开机自启 update-rc.d 服务 enable //禁止开机启动 update-rc.d 服务 disable // 删除开机启动 update-rc.d -f 服务 remove 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/linux系统/deepin/deepin15.11使用记录.html":{"url":"linux/linux系统/deepin/deepin15.11使用记录.html","title":"deepin使用记录","keywords":"","body":"deepin15.11使用记录 深度官方下载地址 深度系统管理官方文档 1.修改网卡名称为eth0 1.备份文件 cp /etc/default/grub{,.bak} 2.修改/etc/default/grub 修改GRUB_CMDLINE_LINUX=\"\" 修改为GRUB_CMDLINE_LINUX=\"net.ifnames=0 biosdevname=0\" 3.更新grub update-grub 重启系统 2.设置IP地址 1.备份网卡配置文件 cp /etc/network/interfaces{,.bak} #注释这行 #source-directory /etc/network/interfaces.d #写入以下配置信息 auto eth0 iface eth0 inet static address 10.0.0.18 netmask 255.255.255.0 gateway 10.0.0.1 2.重启网络服务 systemctl restart networking 3.安装ssh服务 1.安装 apt -y install openssh-server 2.启动 systemctl start sshd 3.设置开机自启，需要自行创建/etc/rc.local文件，然后把要启动的服务命令写上(此方式适用于systemd管理的服务) cat >/etc/rc.local 检测包是否安装 dpkg --list |grep 包名 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/网络协议/tcp:ip/TCP:IP 协议.html":{"url":"linux/网络协议/tcp:ip/TCP:IP 协议.html","title":"TCP/IP协议","keywords":"","body":"TCP/IP 协议 本文严重抄袭至互联网 总纲 一、 计算机网络体系结构分层 计算机网络体系结构分层 不难看出，TCP/IP 与 OSI 在分层模块上稍有区别。OSI 参考模型注重“通信协议必要的功能是什么”，而 TCP/IP 则更强调“在计算机上实现协议应该开发哪种程序”。 二、TCP/IP基础 2.1 TCP/IP 的具体含义 从字面意义上讲，有人可能会认为 TCP/IP 是指 TCP 和 IP 两种协议。实际生活当中有时也确实就是指这两种协议。然而在很多情况下，它只是利用 IP 进行通信时所必须用到的协议群的统称。具体来说，IP 或 ICMP、TCP 或 UDP、TELNET 或 FTP、以及 HTTP 等都属于 TCP/IP 协议。他们与 TCP 或 IP 的关系紧密，是互联网必不可少的组成部分。TCP/IP 一词泛指这些协议，因此，有时也称 TCP/IP 为网际协议群。 互联网进行通信时，需要相应的网络协议，TCP/IP 原本就是为使用互联网而开发制定的协议族。因此，互联网的协议就是 TCP/IP，TCP/IP 就是互联网的协议。 网际协议群 2.2 数据包 包、帧、数据包、段、消息 以上五个术语都用来表述数据的单位，大致区分如下： 包可以说是全能性术语； 帧用于表示数据链路层中包的单位； 数据包是 IP 和 UDP 等网络层以上的分层中包的单位； 段则表示 TCP 数据流中的信息； 消息是指应用协议中数据的单位。 每个分层中，都会对所发送的数据附加一个首部，在这个首部中包含了该层必要的信息，如发送的目标地址以及协议相关信息。通常，为协议提供的信息为包首部，所要发送的内容为数据。在下一层的角度看，从上一层收到的包全部都被认为是本层的数据。 数据包首部 网络中传输的数据包由两部分组成：一部分是协议所要用到的首部，另一部分是上一层传过来的数据。首部的结构由协议的具体规范详细定义。在数据包的首部，明确标明了协议应该如何读取数据。反过来说，看到首部，也就能够了解该协议必要的信息以及所要处理的数据。包首部就像协议的脸。 2.3 数据处理流程 下图以用户 a 向用户 b 发送邮件为例子： 数据处理流程 ① 应用程序处理 首先应用程序会进行编码处理，这些编码相当于 OSI 的表示层功能； 编码转化后，邮件不一定马上被发送出去，这种何时建立通信连接何时发送数据的管理功能，相当于 OSI 的会话层功能。 ② TCP 模块的处理 TCP 根据应用的指示，负责建立连接、发送数据以及断开连接。TCP 提供将应用层发来的数据顺利发送至对端的可靠传输。为了实现这一功能，需要在应用层数据的前端附加一个 TCP 首部。 ③ IP 模块的处理 IP 将 TCP 传过来的 TCP 首部和 TCP 数据合起来当做自己的数据，并在 TCP 首部的前端加上自己的 IP 首部。IP 包生成后，参考路由控制表决定接受此 IP 包的路由或主机。 ④ 网络接口（以太网驱动）的处理 从 IP 传过来的 IP 包对于以太网来说就是数据。给这些数据附加上以太网首部并进行发送处理，生成的以太网数据包将通过物理层传输给接收端。 ⑤ 网络接口（以太网驱动）的处理 主机收到以太网包后，首先从以太网包首部找到 MAC 地址判断是否为发送给自己的包，若不是则丢弃数据。 如果是发送给自己的包，则从以太网包首部中的类型确定数据类型，再传给相应的模块，如 IP、ARP 等。这里的例子则是 IP 。 ⑥ IP 模块的处理 IP 模块接收到 数据后也做类似的处理。从包首部中判断此 IP 地址是否与自己的 IP 地址匹配，如果匹配则根据首部的协议类型将数据发送给对应的模块，如 TCP、UDP。这里的例子则是 TCP。 另外吗，对于有路由器的情况，接收端地址往往不是自己的地址，此时，需要借助路由控制表，在调查应该送往的主机或路由器之后再进行转发数据。 ⑦ TCP 模块的处理 在 TCP 模块中，首先会计算一下校验和，判断数据是否被破坏。然后检查是否在按照序号接收数据。最后检查端口号，确定具体的应用程序。数据被完整地接收以后，会传给由端口号识别的应用程序。 ⑧ 应用程序的处理 接收端应用程序会直接接收发送端发送的数据。通过解析数据，展示相应的内容。 三、传输层中的 TCP 和 UDP TCP/IP 中有两个具有代表性的传输层协议，分别是 TCP 和 UDP。 TCP 是面向连接的、可靠的流协议。流就是指不间断的数据结构，当应用程序采用 TCP 发送消息时，虽然可以保证发送的顺序，但还是犹如没有任何间隔的数据流发送给接收端。TCP 为提供可靠性传输，实行“顺序控制”或“重发控制”机制。此外还具备“流控制（流量控制）”、“拥塞控制”、提高网络利用率等众多功能。 UDP 是不具有可靠性的数据报协议。细微的处理它会交给上层的应用去完成。在 UDP 的情况下，虽然可以确保发送消息的大小，却不能保证消息一定会到达。因此，应用有时会根据自己的需要进行重发处理。 TCP 和 UDP 的优缺点无法简单地、绝对地去做比较：TCP 用于在传输层有必要实现可靠传输的情况；而在一方面，UDP 主要用于那些对高速传输和实时性有较高要求的通信或广播通信。TCP 和 UDP 应该根据应用的目的按需使用。 3.1端口号 数据链路和 IP 中的地址，分别指的是 MAC 地址和 IP 地址。前者用来识别同一链路中不同的计算机，后者用来识别 TCP/IP 网络中互连的主机和路由器。在传输层也有这种类似于地址的概念，那就是端口号。端口号用来识别同一台计算机中进行通信的不同应用程序。因此，它也被称为程序地址。 3.1.1 根据端口号识别应用 一台计算机上同时可以运行多个程序。传输层协议正是利用这些端口号识别本机中正在进行通信的应用程序，并准确地将数据传输。 数据端口号识别应用 3.1.2 通过 IP 地址、端口号、协议号进行通信识别 仅凭目标端口号识别某一个通信是远远不够的。 通过端口号、IP地址、协议号进行通信识别 ① 和② 的通信是在两台计算机上进行的。它们的目标端口号相同，都是80。这里可以根据源端口号加以区分。 ③ 和 ① 的目标端口号和源端口号完全相同，但它们各自的源 IP 地址不同。 此外，当 IP 地址和端口号全都一样时，我们还可以通过协议号来区分（TCP 和 UDP） 3.1.3 端口号的确定 标准既定的端口号：这种方法也叫静态方法。它是指每个应用程序都有其指定的端口号。但并不是说可以随意使用任何一个端口号。例如 HTTP、FTP、TELNET 等广为使用的应用协议中所使用的端口号就是固定的。这些端口号被称为知名端口号，分布在 0~1023 之间；除知名端口号之外，还有一些端口号被正式注册，它们分布在 1024~49151 之间，不过这些端口号可用于任何通信用途。 时序分配法：服务器有必要确定监听端口号，但是接受服务的客户端没必要确定端口号。在这种方法下，客户端应用程序完全可以不用自己设置端口号，而全权交给操作系统进行分配。动态分配的端口号范围在 49152~65535 之间。 3.1.4 端口号与协议 端口号由其使用的传输层协议决定。因此，不同的传输层协议可以使用相同的端口号。 此外，那些知名端口号与传输层协议并无关系。只要端口一致都将分配同一种应用程序进行处理。 3.2 UDP UDP 不提供复杂的控制机制，利用 IP 提供面向无连接的通信服务。 并且它是将应用程序发来的数据在收到的那一刻，立即按照原样发送到网络上的一种机制。即使是出现网络拥堵的情况，UDP 也无法进行流量控制等避免网络拥塞行为。 此外，传输途中出现丢包，UDP 也不负责重发。 甚至当包的到达顺序出现乱序时也没有纠正的功能。 如果需要以上的细节控制，不得不交由采用 UDP 的应用程序去处理。 UDP 常用于一下几个方面：1.包总量较少的通信（DNS、SNMP等）；2.视频、音频等多媒体通信（即时通信）；3.限定于 LAN 等特定网络中的应用通信；4.广播通信（广播、多播）。 3.3 TCP TCP 与 UDP 的区别相当大。它充分地实现了数据传输时各种控制功能，可以进行丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。而这些在 UDP 中都没有。 此外，TCP 作为一种面向有连接的协议，只有在确认通信对端存在时才会发送数据，从而可以控制通信流量的浪费。 根据 TCP 的这些机制，在 IP 这种无连接的网络上也能够实现高可靠性的通信（ 主要通过检验和、序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现）。 3.3.1 三次握手（重点） TCP 提供面向有连接的通信传输。面向有连接是指在数据通信开始之前先做好两端之间的准备工作。 所谓三次握手是指建立一个 TCP 连接时需要客户端和服务器端总共发送三个包以确认连接的建立。在socket编程中，这一过程由客户端执行connect来触发。 下面来看看三次握手的流程图： 第一次握手：客户端将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给服务器端，客户端进入SYN_SENT状态，等待服务器端确认。 第二次握手：服务器端收到数据包后由标志位SYN=1知道客户端请求建立连接，服务器端将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给客户端以确认连接请求，服务器端进入SYN_RCVD状态。 第三次握手：客户端收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给服务器端，服务器端检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，客户端和服务器端进入ESTABLISHED状态，完成三次握手，随后客户端与服务器端之间可以开始传输数据了。 3.3.2 四次挥手（重点） 四次挥手即终止TCP连接，就是指断开一个TCP连接时，需要客户端和服务端总共发送4个包以确认连接的断开。在socket编程中，这一过程由客户端或服务端任一方执行close来触发。 由于TCP连接是全双工的，因此，每个方向都必须要单独进行关闭，这一原则是当一方完成数据发送任务后，发送一个FIN来终止这一方向的连接，收到一个FIN只是意味着这一方向上没有数据流动了，即不会再收到数据了，但是在这个TCP连接上仍然能够发送数据，直到这一方向也发送了FIN。首先进行关闭的一方将执行主动关闭，而另一方则执行被动关闭。 下面来看看四次挥手的流程图： 中断连接端可以是客户端，也可以是服务器端。 第一次挥手：客户端发送一个FIN=M，用来关闭客户端到服务器端的数据传送，客户端进入FIN_WAIT_1状态。意思是说\"我客户端没有数据要发给你了\"，但是如果你服务器端还有数据没有发送完成，则不必急着关闭连接，可以继续发送数据。 第二次挥手：服务器端收到FIN后，先发送ack=M+1，告诉客户端，你的请求我收到了，但是我还没准备好，请继续你等我的消息。这个时候客户端就进入FIN_WAIT_2 状态，继续等待服务器端的FIN报文。 第三次挥手：当服务器端确定数据已发送完成，则向客户端发送FIN=N报文，告诉客户端，好了，我这边数据发完了，准备好关闭连接了。服务器端进入LAST_ACK状态。 第四次挥手：客户端收到FIN=N报文后，就知道可以关闭连接了，但是他还是不相信网络，怕服务器端不知道要关闭，所以发送ack=N+1后进入TIME_WAIT状态，如果Server端没有收到ACK则可以重传。服务器端收到ACK后，就知道可以断开连接了。客户端等待了2MSL后依然没有收到回复，则证明服务器端已正常关闭，那好，我客户端也可以关闭连接了。最终完成了四次握手。 上面是一方主动关闭，另一方被动关闭的情况，实际中还会出现同时发起主动关闭的情况， 具体流程如下图： 3.3.3 通过序列号与确认应答提高可靠性 在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个已收到消息的通知。这个消息叫做确认应答（ACK）。当发送端将数据发出之后会等待对端的确认应答。如果有确认应答，说明数据已经成功到达对端。反之，则数据丢失的可能性很大。 在一定时间内没有等待到确认应答，发送端就可以认为数据已经丢失，并进行重发。由此，即使产生了丢包，仍然能够保证数据能够到达对端，实现可靠传输。 未收到确认应答并不意味着数据一定丢失。也有可能是数据对方已经收到，只是返回的确认应答在途中丢失。这种情况也会导致发送端误以为数据没有到达目的地而重发数据。 此外，也有可能因为一些其他原因导致确认应答延迟到达，在源主机重发数据以后才到达的情况也屡见不鲜。此时，源主机只要按照机制重发数据即可。 对于目标主机来说，反复收到相同的数据是不可取的。为了对上层应用提供可靠的传输，目标主机必须放弃重复的数据包。为此我们引入了序列号。 序列号是按照顺序给发送数据的每一个字节（8位字节）都标上号码的编号。接收端查询接收数据 TCP 首部中的序列号和数据的长度，将自己下一步应该接收的序列号作为确认应答返送回去。通过序列号和确认应答号，TCP 能够识别是否已经接收数据，又能够判断是否需要接收，从而实现可靠传输。 序列号和确认应答 3.3.4 重发超时的确定 重发超时是指在重发数据之前，等待确认应答到来的那个特定时间间隔。如果超过这个时间仍未收到确认应答，发送端将进行数据重发。最理想的是，找到一个最小时间，它能保证“确认应答一定能在这个时间内返回”。 TCP 要求不论处在何种网络环境下都要提供高性能通信，并且无论网络拥堵情况发生何种变化，都必须保持这一特性。为此，它在每次发包时都会计算往返时间及其偏差。将这个往返时间和偏差时间相加，重发超时的时间就是比这个总和要稍大一点的值。 在 BSD 的 Unix 以及 Windows 系统中，超时都以0.5秒为单位进行控制，因此重发超时都是0.5秒的整数倍。不过，最初其重发超时的默认值一般设置为6秒左右。 数据被重发之后若还是收不到确认应答，则进行再次发送。此时，等待确认应答的时间将会以2倍、4倍的指数函数延长。 此外，数据也不会被无限、反复地重发。达到一定重发次数之后，如果仍没有任何确认应答返回，就会判断为网络或对端主机发生了异常，强制关闭连接。并且通知应用通信异常强行终止。 3.3.5 以段为单位发送数据 在建立 TCP 连接的同时，也可以确定发送数据包的单位，我们也可以称其为“最大消息长度”（MSS）。最理想的情况是，最大消息长度正好是 IP 中不会被分片处理的最大数据长度。 TCP 在传送大量数据时，是以 MSS 的大小将数据进行分割发送。进行重发时也是以 MSS 为单位。 MSS 在三次握手的时候，在两端主机之间被计算得出。两端的主机在发出建立连接的请求时，会在 TCP 首部中写入 MSS 选项，告诉对方自己的接口能够适应的 MSS 的大小。然后会在两者之间选择一个较小的值投入使用。 3.3.6 利用窗口控制提高速度 TCP 以1个段为单位，每发送一个段进行一次确认应答的处理。这样的传输方式有一个缺点，就是包的往返时间越长通信性能就越低。 为解决这个问题，TCP 引入了窗口这个概念。确认应答不再是以每个分段，而是以更大的单位进行确认，转发时间将会被大幅地缩短。也就是说，发送端主机，在发送了一个段以后不必要一直等待确认应答，而是继续发送。如下图所示： 窗口控制 窗口大小就是指无需等待确认应答而可以继续发送数据的最大值。上图中窗口大小为4个段。这个机制实现了使用大量的缓冲区，通过对多个段同时进行确认应答的功能。 3.3.7 滑动窗口控制 上图中的窗口内的数据即便没有收到确认应答也可以被发送出去。不过，在整个窗口的确认应答没有到达之前，如果其中部分数据出现丢包，那么发送端仍然要负责重传。为此，发送端主机需要设置缓存保留这些待被重传的数据，直到收到他们的确认应答。 在滑动窗口以外的部分包括未发送的数据以及已经确认对端已收到的数据。当数据发出后若如期收到确认应答就可以不用再进行重发，此时数据就可以从缓存区清除。 收到确认应答的情况下，将窗口滑动到确认应答中的序列号的位置。这样可以顺序地将多个段同时发送提高通信性能。这种机制也别称为滑动窗口控制。 3.3.8 窗口控制中的重发控制 在使用窗口控制中， 出现丢包一般分为两种情况： ① 确认应答未能返回的情况。在这种情况下，数据已经到达对端，是不需要再进行重发的，如下图： ② 某个报文段丢失的情况。接收主机如果收到一个自己应该接收的序列号以外的数据时，会针对当前为止收到数据返回确认应答。如下图所示，当某一报文段丢失后，发送端会一直收到序号为1001的确认应答，因此，在窗口比较大，又出现报文段丢失的情况下，同一个序列号的确认应答将会被重复不断地返回。而发送端主机如果连续3次收到同一个确认应答，就会将其对应的数据进行重发。这种机制比之前提到的超时管理更加高效，因此也被称为高速重发控制。 四、网络层中的 IP 协议 IP（IPv4、IPv6）相当于 OSI 参考模型中的第3层——网络层。网络层的主要作用是“实现终端节点之间的通信”。这种终端节点之间的通信也叫“点对点通信”。 网络的下一层——数据链路层的主要作用是在互连同一种数据链路的节点之间进行包传递。而一旦跨越多种数据链路，就需要借助网络层。网络层可以跨越不同的数据链路，即使是在不同的数据链路上也能实现两端节点之间的数据包传输。 IP 大致分为三大作用模块，它们是 IP 寻址、路由（最终节点为止的转发）以及 IP 分包与组包。 4.1 IP 地址 4.1.1 IP 地址概述 在计算机通信中，为了识别通信对端，必须要有一个类似于地址的识别码进行标识。在数据链路中的 MAC 地址正是用来标识同一个链路中不同计算机的一种识别码。 作为网络层的 IP ,也有这种地址信息，一般叫做 IP 地址。IP 地址用于在“连接到网络中的所有主机中识别出进行通信的目标地址”。因此，在 TCP/IP 通信中所有主机或路由器必须设定自己的 IP 地址。 不论一台主机与哪种数据链路连接，其 IP 地址的形式都保持不变。 IP 地址（IPv4 地址）由32位正整数来表示。IP 地址在计算机内部以二进制方式被处理。然而，由于我们并不习惯于采用二进制方式，我们将32位的 IP 地址以每8位为一组，分成4组，每组以 “.” 隔开，再将每组数转换成十进制数。如下： 4.1.2 IP 地址由网络和主机两部分标识组成 如下图，网络标识在数据链路的每个段配置不同的值。网络标识必须保证相互连接的每个段的地址不相重复。而相同段内相连的主机必须有相同的网络地址。IP 地址的“主机标识”则不允许在同一个网段内重复出现。由此，可以通过设置网络地址和主机地址，在相互连接的整个网络中保证每台主机的 IP 地址都不会相互重叠。即 IP 地址具有了唯一性。 IP地址的主机标识 如下图，IP 包被转发到途中某个路由器时，正是利用目标 IP 地址的网络标识进行路由。因为即使不看主机标识，只要一见到网络标识就能判断出是否为该网段内的主机。 IP地址的网络标识 4.1.3 IP 地址的分类 IP 地址分为四个级别，分别为A类、B类、C类、D类。它根据 IP 地址中从第 1 位到第 4 位的比特列对其网络标识和主机标识进行区分。 A 类 IP 地址是首位以 “0” 开头的地址。从第 1 位到第 8 位是它的网络标识。用十进制表示的话，0.0.0.0~127.0.0.0 是 A 类的网络地址。A 类地址的后 24 位相当于主机标识。因此，一个网段内可容纳的主机地址上限为16,777,214个。 B 类 IP 地址是前两位 “10” 的地址。从第 1 位到第 16 位是它的网络标识。用十进制表示的话，128.0.0.0~191.255.0.0 是 B 类的网络地址。B 类地址的后 16 位相当于主机标识。因此，一个网段内可容纳的主机地址上限为65,534个。 C 类 IP 地址是前三位为 “110” 的地址。从第 1 位到第 24 位是它的网络标识。用十进制表示的话，192.0.0.0~223.255.255.0 是 C 类的网络地址。C 类地址的后 8 位相当于主机标识。因此，一个网段内可容纳的主机地址上限为254个。 D 类 IP 地址是前四位为 “1110” 的地址。从第 1 位到第 32 位是它的网络标识。用十进制表示的话，224.0.0.0~239.255.255.255 是 D 类的网络地址。D 类地址没有主机标识，常用于多播。 在分配 IP 地址时关于主机标识有一点需要注意。即要用比特位表示主机地址时，不可以全部为 0 或全部为 1。因为全部为 0 只有在表示对应的网络地址或 IP 地址不可以获知的情况下才使用。而全部为 1 的主机通常作为广播地址。因此，在分配过程中，应该去掉这两种情况。这也是为什么 C 类地址每个网段最多只能有 254（ 28 - 2 = 254）个主机地址的原因。 4.1.4 广播地址 广播地址用于在同一个链路中相互连接的主机之间发送数据包。将 IP 地址中的主机地址部分全部设置为 1，就成了广播地址。 广播分为本地广播和直接广播两种。在本网络内的广播叫做本地广播；在不同网络之间的广播叫做直接广播。 4.1.5 IP 多播 多播用于将包发送给特定组内的所有主机。由于其直接使用 IP 地址，因此也不存在可靠传输。 相比于广播，多播既可以穿透路由器，又可以实现只给那些必要的组发送数据包。请看下图： IP多播 多播使用 D 类地址。因此，如果从首位开始到第 4 位是 “1110”，就可以认为是多播地址。而剩下的 28 位可以成为多播的组编号。 此外， 对于多播，所有的主机（路由器以外的主机和终端主机）必须属于 224.0.0.1 的组，所有的路由器必须属于 224.0.0.2 的组。 1.6 子网掩码 现在一个 IP 地址的网络标识和主机标识已不再受限于该地址的类别，而是由一个叫做“子网掩码”的识别码通过子网网络地址细分出比 A 类、B 类、C 类更小粒度的网络。这种方式实际上就是将原来 A 类、B 类、C 类等分类中的主机地址部分用作子网地址，可以将原网络分为多个物理网络的一种机制。 子网掩码用二进制方式表示的话，也是一个 32 位的数字。它对应 IP 地址网络标识部分的位全部为 “1”，对应 IP 地址主机标识的部分则全部为 “0”。由此，一个 IP 地址可以不再受限于自己的类别，而是可以用这样的子网掩码自由地定位自己的网络标识长度。当然，子网掩码必须是 IP 地址的首位开始连续的 “1”。 对于子网掩码，目前有两种表示方式。第一种是，将 IP 地址与子网掩码的地址分别用两行来表示。以 172.20.100.52 的前 26 位是网络地址的情况为例，如下： 第二种表示方式是，在每个 IP 地址后面追加网络地址的位数用 “/ ” 隔开，如下： 另外，在第二种方式下记述网络地址时可以省略后面的 “0” 。例如：172.20.0.0/26 跟 172.20/26 其实是一个意思。 4.2 路由 发送数据包时所使用的地址是网络层的地址，即 IP 地址。然而仅仅有 IP 地址还不足以实现将数据包发送到对端目标地址，在数据发送过程中还需要类似于“指明路由器或主机”的信息，以便真正发往目标地址。保存这种信息的就是路由控制表。 该路由控制表的形成方式有两种：一种是管理员手动设置，另一种是路由器与其他路由器相互交换信息时自动刷新。前者也叫做静态路由控制，而后者叫做动态路由控制。 IP 协议始终认为路由表是正确的。然后，IP 本身并没有定义制作路由控制表的协议。即 IP 没有制作路由控制表的机制。该表示由一个叫做“路由协议”的协议制作而成。 4.2.1 IP 地址与路由控制 IP 地址的网络地址部分用于进行路由控制。 路由控制表中记录着网络地址与下一步应该发送至路由器的地址。 在发送 IP 包时，首先要确定 IP 包首部中的目标地址，再从路由控制表中找到与该地址具有相同网络地址的记录，根据该记录将 IP 包转发给相应的下一个路由器。如果路由控制表中存在多条相同网络地址的记录，就选择一个最为吻合的网络地址。 路由控制表与IP包发送 4.3 IP 分包与组包 每种数据链路的最大传输单元（MTU）都不尽相同，因为每个不同类型的数据链路的使用目的不同。使用目的不同，可承载的 MTU 也就不同。 任何一台主机都有必要对 IP 分片进行相应的处理。分片往往在网络上遇到比较大的报文无法一下子发送出去时才会进行处理。 经过分片之后的 IP 数据报在被重组的时候，只能由目标主机进行。路由器虽然做分片但不会进行重组。 4.3.1 路径 MTU 发现 分片机制也有它的不足。如路由器的处理负荷加重之类。因此，只要允许，是不希望由路由器进行 IP 数据包的分片处理的。 为了应对分片机制的不足，“路径 MTU 发现” 技术应运而生。路径 MTU 指的是，从发送端主机到接收端主机之间不需要分片是最大 MTU 的大小。即路径中存在的所有数据链路中最小的 MTU 。 进行路径 MTU 发现，就可以避免在中途的路由器上进行分片处理，也可以在 TCP 中发送更大的包。 4.4 IPv6 IPv6（IP version 6）是为了根本解决 IPv4 地址耗尽的问题而被标准化的网际协议。IPv4 的地址长度为 4 个 8 位字节，即 32 比特。而 IPv6 的地址长度则是原来的 4 倍，即 128 比特，一般写成 8 个 16 位字节。 4.4.1 IPv6 的特点 IP 得知的扩大与路由控制表的聚合。 性能提升。包首部长度采用固定的值（40字节），不再采用首部检验码。简化首部结构，减轻路由器负担。路由器不再做分片处理。 支持即插即用功能。即使没有DHCP服务器也可以实现自动分配 IP 地址。 采用认证与加密功能。应对伪造 IP 地址的网络安全功能以及防止线路窃听的功能。 多播、Mobile IP 成为扩展功能。 4.4.2 IPv6 中 IP 地址的标记方法 一般人们将 128 比特 IP 地址以每 16 比特为一组，每组用冒号（“：”）隔开进行标记。 而且如果出现连续的 0 时还可以将这些 0 省略，并用两个冒号（“：：”）隔开。但是，一个 IP 地址中只允许出现一次两个连续的冒号。 4.4.3 IPv6 地址的结构 IPv6 类似 IPv4，也是通过 IP 地址的前几位标识 IP 地址的种类。 在互联网通信中，使用一种全局的单播地址。它是互联网中唯一的一个地址，不需要正式分配 IP 地址。 4.4.4 全局单播地址 全局单播地址是指世界上唯一的一个地址。它是互联网通信以及各个域内部通信中最为常用的一个 IPv6 地址。 格式如下图所示，现在 IPv6 的网络中所使用的格式为，n = 48，m = 16 以及 128 - n - m = 64。即前 64 比特为网络标识，后 64 比特为主机标识。 全局单播地址 4.4.5 链路本地单播地址 链路本地单播地址是指在同一个数据链路内唯一的地址。它用于不经过路由器，在同一个链路中的通信。通常接口 ID 保存 64 比特版的 MAC 地址。 链路本地单播地址 4.4.6 唯一本地地址 唯一本地地址是不进行互联网通信时所用的地址。 唯一本地地址虽然不会与互联网连接，但是也会尽可能地随机生成一个唯一的全局 ID。 L 通常被置为 1 全局 ID 的值随机决定 子网 ID 是指该域子网地址 接口 ID 即为接口的 ID 唯一本地地址 4.4.7 IPv6 分段处理 IPv6 的分片处理只在作为起点的发送端主机上进行，路由器不参与分片。 IPv6 中最小 MTU 为 1280 字节，因此，在嵌入式系统中对于那些有一定系统资源限制的设备来说，不需要进行“路径 MTU 发现”，而是在发送 IP 包时直接以 1280 字节为单位分片送出。 4.4.8 IP 首部（暂略） 4.5 IP 协议相关技术 IP 旨在让最终目标主机收到数据包，但是在这一过程中仅仅有 IP 是无法实现通信的。必须还有能够解析主机名称和 MAC 地址的功能，以及数据包在发送过程中异常情况处理的功能。 4.5.1 DNS 我们平常在访问某个网站时不适用 IP 地址，而是用一串由罗马字和点号组成的字符串。而一般用户在使用 TCP/IP 进行通信时也不使用 IP 地址。能够这样做是因为有了 DNS （Domain Name System）功能的支持。DNS 可以将那串字符串自动转换为具体的 IP 地址。 这种 DNS 不仅适用于 IPv4，还适用于 IPv6。 4.5.2 ARP 只要确定了 IP 地址，就可以向这个目标地址发送 IP 数据报。然而，在底层数据链路层，进行实际通信时却有必要了解每个 IP 地址所对应的 MAC 地址。 ARP 是一种解决地址问题的协议。以目标 IP 地址为线索，用来定位下一个应该接收数据分包的网络设备对应的 MAC 地址。不过 ARP 只适用于 IPv4，不能用于 IPv6。IPv6 中可以用 ICMPv6 替代 ARP 发送邻居探索消息。 RARP 是将 ARP 反过来，从 MAC 地址定位 IP 地址的一种协议。 4.5.3 ICMP ICMP 的主要功能包括，确认 IP 包是否成功送达目标地址，通知在发送过程当中 IP 包被废弃的具体原因，改善网络设置等。 IPv4 中 ICMP 仅作为一个辅助作用支持 IPv4。也就是说，在 IPv4 时期，即使没有 ICMP，仍然可以实现 IP 通信。然而，在 IPv6 中，ICMP 的作用被扩大，如果没有 ICMPv6，IPv6 就无法进行正常通信。 4.5.4 DHCP 如果逐一为每一台主机设置 IP 地址会是非常繁琐的事情。特别是在移动使用笔记本电脑、只能终端以及平板电脑等设备时，每移动到一个新的地方，都要重新设置 IP 地址。 于是，为了实现自动设置 IP 地址、统一管理 IP 地址分配，就产生了 DHCP（Dynamic Host Configuration Protocol）协议。有了 DHCP，计算机只要连接到网络，就可以进行 TCP/IP 通信。也就是说，DHCP 让即插即用变得可能。 DHCP 不仅在 IPv4 中，在 IPv6 中也可以使用。 4.5.5 NAT NAT（Network Address Translator）是用于在本地网络中使用私有地址，在连接互联网时转而使用全局 IP 地址的技术。 除转换 IP 地址外，还出现了可以转换 TCP、UDP 端口号的 NAPT（Network Address Ports Translator）技术，由此可以实现用一个全局 IP 地址与多个主机的通信。 NAT（NAPT）实际上是为正在面临地址枯竭的 IPv4 而开发的技术。不过，在 IPv6 中为了提高网络安全也在使用 NAT，在 IPv4 和 IPv6 之间的相互通信当中常常使用 NAT-PT。 4.5.6 IP 隧道 夹着 IPv4 网络的两个 IPv6 网络 如上图的网络环境中，网络 A 与网络 B 之间无法直接进行通信，为了让它们之间正常通信，这时必须得采用 IP 隧道的功能。 IP 隧道可以将那些从网络 A 发过来的 IPv6 的包统合为一个数据，再为之追加一个 IPv4 的首部以后转发给网络 C。 一般情况下，紧接着 IP 首部的是 TCP 或 UDP 的首部。然而，现在的应用当中“ IP 首部的后面还是 IP 首部”或者“ IP 首部的后面是 IPv6 的首部”等情况与日俱增。这种在网络层的首部后面追加网络层首部的通信方法就叫做“ IP 隧道”。 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/网络协议/http/HTTP 协议.html":{"url":"linux/网络协议/http/HTTP 协议.html","title":"HTTP协议","keywords":"","body":"HTTP 协议 本文严重抄袭至互联网 总纲 一、概述 1.1 计算机网络体系结构分层 1.2 TCP/IP 通信传输流 利用 TCP/IP 协议族进行网络通信时，会通过分层顺序与对方进行通信。发送端从应用层往下走，接收端则从链路层往上走。如下： TCP/IP 通信传输流 首先作为发送端的客户端在应用层（HTTP 协议）发出一个想看某个 Web 页面的 HTTP 请求。 接着，为了传输方便，在传输层（TCP 协议）把从应用层处收到的数据（HTTP 请求报文）进行分割，并在各个报文上打上标记序号及端口号后转发给网络层。 在网络层（IP 协议），增加作为通信目的地的 MAC 地址后转发给链路层。这样一来，发往网络的通信请求就准备齐全了。 接收端的服务器在链路层接收到数据，按序往上层发送，一直到应用层。当传输到应用层，才能算真正接收到由客户端发送过来的 HTTP请求。 HTTP请求如下图所示： 在网络体系结构中，包含了众多的网络协议，这篇文章主要围绕 HTTP 协议（HTTP/1.1版本）展开。 HTTP协议（HyperText Transfer Protocol，超文本传输协议）是用于从WWW服务器传输超文本到本地浏览器的传输协议。它可以使浏览器更加高效，使网络传输减少。它不仅保证计算机正确快速地传输超文本文档，还确定传输文档中的哪一部分，以及哪部分内容首先显示(如文本先于图形)等。 HTTP是客户端浏览器或其他程序与Web服务器之间的应用层通信协议。在Internet上的Web服务器上存放的都是超文本信息，客户机需要通过HTTP协议传输所要访问的超文本信息。HTTP包含命令和传输信息，不仅可用于Web访问，也可以用于其他因特网/内联网应用系统之间的通信，从而实现各类应用资源超媒体访问的集成。 我们在浏览器的地址栏里输入的网站地址叫做URL (Uniform Resource Locator，统一资源定位符)。就像每家每户都有一个门牌地址一样，每个网页也都有一个Internet地址。当你在浏览器的地址框中输入一个URL或是单击一个超级链接时，URL就确定了要浏览的地址。浏览器通过超文本传输协议(HTTP)，将Web服务器上站点的网页代码提取出来，并翻译成漂亮的网页。 二、HTTP 工作过程 HTTP请求响应模型 HTTP通信机制是在一次完整的 HTTP 通信过程中，客户端与服务器之间将完成下列7个步骤： 1.建立 TCP 连接 在HTTP工作开始之前，客户端首先要通过网络与服务器建立连接，该连接是通过 TCP 来完成的，该协议与 IP 协议共同构建 Internet，即著名的 TCP/IP 协议族，因此 Internet 又被称作是 TCP/IP 网络。HTTP 是比 TCP 更高层次的应用层协议，根据规则，只有低层协议建立之后，才能进行高层协议的连接，因此，首先要建立 TCP 连接，一般 TCP 连接的端口号是80； 2.客户端向服务器发送请求命令 一旦建立了TCP连接，客户端就会向服务器发送请求命令； 例如：GET/sample/hello.jsp HTTP/1.1 3.客户端发送请求头信息 客户端发送其请求命令之后，还要以头信息的形式向服务器发送一些别的信息，之后客户端发送了一空白行来通知服务器，它已经结束了该头信息的发送； 4.服务器应答 客户端向服务器发出请求后，服务器会客户端返回响应； 例如： HTTP/1.1 200 OK 响应的第一部分是协议的版本号和响应状态码 5.服务器返回响应头信息 正如客户端会随同请求发送关于自身的信息一样，服务器也会随同响应向用户发送关于它自己的数据及被请求的文档； 6.服务器向客户端发送数据 服务器向客户端发送头信息后，它会发送一个空白行来表示头信息的发送到此为结束，接着，它就以 Content-Type 响应头信息所描述的格式发送用户所请求的实际数据； 7.服务器关闭 TCP 连接 一般情况下，一旦服务器向客户端返回了请求数据，它就要关闭 TCP 连接，然后如果客户端或者服务器在其头信息加入了这行代码 Connection:keep-alive ，TCP 连接在发送后将仍然保持打开状态，于是，客户端可以继续通过相同的连接发送请求。保持连接节省了为每个请求建立新连接所需的时间，还节约了网络带宽。 三、HTTP 协议基础 3.1 通过请求和响应的交换达成通信 应用 HTTP 协议时，必定是一端担任客户端角色，另一端担任服务器端角色。仅从一条通信线路来说，服务器端和客服端的角色是确定的。HTTP 协议规定，请求从客户端发出，最后服务器端响应该请求并返回。换句话说，肯定是先从客户端开始建立通信的，服务器端在没有接收到请求之前不会发送响应。 3.2 HTTP 是不保存状态的协议 HTTP 是一种无状态协议。协议自身不对请求和响应之间的通信状态进行保存。也就是说在 HTTP 这个级别，协议对于发送过的请求或响应都不做持久化处理。这是为了更快地处理大量事务，确保协议的可伸缩性，而特意把 HTTP 协议设计成如此简单的。 可是随着 Web 的不断发展，我们的很多业务都需要对通信状态进行保存。于是我们引入了 Cookie 技术。有了 Cookie 再用 HTTP 协议通信，就可以管理状态了。 3.3 使用 Cookie 的状态管理 Cookie 技术通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。Cookie 会根据从服务器端发送的响应报文内的一个叫做 Set-Cookie 的首部字段信息，通知客户端保存Cookie。当下次客户端再往该服务器发送请求时，客户端会自动在请求报文中加入 Cookie 值后发送出去。服务器端发现客户端发送过来的 Cookie 后，会去检查究竟是从哪一个客户端发来的连接请求，然后对比服务器上的记录，最后得到之前的状态信息。 Cookie 的流程 3.4 请求 URI 定位资源 HTTP 协议使用 URI 定位互联网上的资源。正是因为 URI 的特定功能，在互联网上任意位置的资源都能访问到。 3.5 告知服务器意图的 HTTP 方法（HTTP/1.1） 方法 描述 请求 响应 GET 用来请求访问已被URI识别的资源指定的资源经服务器端解析后返回响应内容 GET /index.html HTTP/1.1Host: www.baidu.com 返回index.html的页面资源 POST 用来传输实体的主体虽然用GET方法也可以传输实体的主体，但一般不用GET方法进行传输，而是用POST方法虽说POST的功能与GET相似，但POST的主要目的并不是获取响应的主体内容 POST /submit.cgi HTTP/1.1Host: www.baidu.comContent-Length: 1500(1500字节的数据) 返回submit.cgi接收数据的处理结果 PUT 用来传输文件就像FTP协议的文件上传一样，要求在请求报文的主体中包含文件的内容，然后保存到请求URI指定的位置 PUT /example.html HTTP/1.1Host: www.baidu.comContent-Type: text/htmlContent-Length: 1560(1560字节的数据) 响应返回状态吗 204 No Content(比如：该html已存在于服务器上) HEAD 用于确认URI的有效性及资源更新的日期时间等，和GET方法一样，只是不返回报文主体部分 HEAD /index.html HTTP/1.1Host: www.baidu.com 返回index.html有关的响应头部 DELETE 用来删除文件，是与PUT 相反的方法按请求URI删除指定的资源 DELETE /example.html HTTP/1.1Host: www.baidu.com 响应返回状态吗 204 No Content(比如：该html已存在于服务器上) OPTIONS 用来查询针对请求URI指定的资源支持的方法 OPTIONS * HTTP/1.1Host: www.baidu.com HTTP/1.1 200 OKAllow: GET,POST,HEAD,OPTIONS(返回服务器支持的方法) TRACE 让web服务器端将之前的请求通信环回给客户端的方法发送请求时，在Max-Forwards首部字段中填入数值，每经过一个服务端就将该数字减1，当数值刚好剑到0时就停止持续传输，最后接收到请求的服务端则返回状态码 200 OK 的响应 TRACE /HTTP/1.1Host: www.baidu.comMax-Forwards: 2 HTTP/1.1 200 OkContent-Type: message/httpContent-Length: 1024TRACE / HTTP/1.1Host: www.baidu.comMax-Forwards: 2(返回响应包含请求内容) CONNECT 要求在与代理服务器通信时建立隧道，实现用隧道协议进行TCP通信，主要使用SSL和TLS协议把通信内容加密后经网络隧道传输 CONNECT proxy.sample.com:8000 HTTP/1.1Host: proxy.sample.com HTTP/1.1 200 OK(之后进入网络隧道) 3.6 持久连接 HTTP 协议的初始版本中，每进行一个 HTTP 通信都要断开一次 TCP 连接。比如使用浏览器浏览一个包含多张图片的 HTML 页面时，在发送请求访问 HTML 页面资源的同时，也会请求该 HTML 页面里包含的其他资源。因此，每次的请求都会造成无畏的 TCP 连接建立和断开，增加通信量的开销。 为了解决上述 TCP 连接的问题，HTTP/1.1 和部分 HTTP/1.0 想出了持久连接的方法。其特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。旨在建立一次 TCP 连接后进行多次请求和响应的交互。在 HTTP/1.1 中，所有的连接默认都是持久连接。 3.7 管线化 持久连接使得多数请求以管线化方式发送成为可能。以前发送请求后需等待并接收到响应，才能发送下一个请求。管线化技术出现后，不用等待亦可发送下一个请求。这样就能做到同时并行发送多个请求，而不需要一个接一个地等待响应了。 比如，当请求一个包含多张图片的 HTML 页面时，与挨个连接相比，用持久连接可以让请求更快结束。而管线化技术要比持久连接速度更快。请求数越多，时间差就越明显。 四、HTTP 协议报文结构 4.1 HTTP 报文 用于 HTTP 协议交互的信息被称为 HTTP 报文。请求端（客户端）的 HTTP 报文叫做请求报文；响应端（服务器端）的叫做响应报文。HTTP 报文本身是由多行（用 CR+LF 作换行符）数据构成的字符串文本。 4.2 HTTP 报文结构 HTTP 报文大致可分为报文首部和报文主体两部分。两者由最初出现的空行（CR+LF）来划分。通常，并不一定有报文主体。如下： HTTP 报文结构 4.2.1 请求报文结构 请求报文结构 请求报文的首部内容由以下数据组成： 请求行 —— 包含用于请求的方法、请求 URI 和 HTTP 版本。 首部字段 —— 包含表示请求的各种条件和属性的各类首部。（通用首部、请求首部、实体首部以及RFC里未定义的首部如 Cookie 等） 请求报文的示例，如下： 4.2.2 响应报文结构 响应报文的首部内容由以下数据组成： 状态行 —— 包含表明响应结果的状态码、原因短语和 HTTP 版本。 首部字段 —— 包含表示请求的各种条件和属性的各类首部。（通用首部、响应首部、实体首部以及RFC里未定义的首部如 Cookie 等） 响应报文的示例，如下： 五、HTTP 报文首部之请求行、状态行 5.1 请求行 举个栗子，下面是一个 HTTP 请求的报文： GET /index.htm HTTP/1.1 Host: sample.com 其中，下面的这行就是请求行， GET /index.htm HTTP/1.1 开头的 GET 表示请求访问服务器的类型，称为方法； 随后的字符串 /index.htm 指明了请求访问的资源对象，也叫做请求 URI； 最后的 HTTP/1.1，即 HTTP 的版本号，用来提示客户端使用的 HTTP 协议功能。 综合来看，大意是请求访问某台 HTTP 服务器上的 /index.htm 页面资源。 5.2 状态行 同样举个栗子，下面是一个 HTTP 响应的报文： HTTP/1.1 200 OK Date: Mon, 10 Jul 2017 15:50:06 GMT Content-Length: 256 Content-Type: text/html ... 其中，下面的这行就是状态行， HTTP/1.1 200 OK 开头的 HTTP/1.1 表示服务器对应的 HTTP 版本； 紧挨着的 200 OK 表示请求的处理结果的状态码和原因短语。 六、HTTP 报文首部之首部字段（重点分析） 6.1 首部字段概述 先来回顾一下首部字段在报文的位置，HTTP 报文包含报文首部和报文主体，报文首部包含请求行（或状态行）和首部字段。 在报文众多的字段当中，HTTP 首部字段包含的信息最为丰富。首部字段同时存在于请求和响应报文内，并涵盖 HTTP 报文相关的内容信息。使用首部字段是为了给客服端和服务器端提供报文主体大小、所使用的语言、认证信息等内容。 6.2 首部字段结构 HTTP 首部字段是由首部字段名和字段值构成的，中间用冒号“：”分隔。 另外，字段值对应单个 HTTP 首部字段可以有多个值。 当 HTTP 报文首部中出现了两个或以上具有相同首部字段名的首部字段时，这种情况在规范内尚未明确，根据浏览器内部处理逻辑的不同，优先处理的顺序可能不同，结果可能并不一致。 首部字段名 冒号 字段值 Content-Type ： text/html Keep-Alive ： timeout=30, max=120 6.3 首部字段类型 首部字段根据实际用途被分为以下4种类型： 类型 描述 通用首部字段 请求报文和响应报文两方都会使用的首部 请求首部字段 从客户端向服务器端发送请求报文时使用的首部。补充了请求的附加内容、客户端信息、响应内容相关优先级等信息 响应首部字段 从服务器端向客户端返回响应报文时使用的首部。补充了响应的附加内容，也会要求客户端附加额外的内容信息。 实体首部字段 针对请求报文和响应报文的实体部分使用的首部。补充了资源内容更新时间等与实体有关的的信息。 6.4 通用首部字段（HTTP/1.1） 首部字段名 说明 Cache-Control 控制缓存的行为 Connection 逐挑首部、连接的管理 Date 创建报文的日期时间 Pragma 报文指令 Trailer 报文末端的首部一览 Transfer-Encoding 指定报文主体的传输编码方式 Upgrade 升级为其他协议 Via 代理服务器的相关信息 Warning 错误通知 6.4.1 Cache-Control 通过指定首部字段 Cache-Control 的指令，就能操作缓存的工作机制。 6.4.1.1 可用的指令一览 可用的指令按请求和响应分类如下： 缓存请求指令 指令 参数 说明 no-cache 无 强制向服务器再次验证 no-store 无 不缓存请求或响应的任何内容 max-age = [秒] 必需 响应的最大Age值 max-stale( =[秒]) 可省略 接收已过期的响应 min-fresh = [秒] 必需 期望在指定时间内的响应仍有效 no-transform 无 代理不可更改媒体类型 only-if-cached 无 从缓存获取资源 cache-extension - 新指令标记（token） 缓存响应指令 指令 参数 说明 public 无 可向任意方提供响应的缓存 private 可省略 仅向特定用户返回响应 no-cache 可省略 缓存前必须先确认其有效性 no-store 无 不缓存请求或响应的任何内容 no-transform 无 代理不可更改媒体类型 must-revalidate 无 可缓存但必须再向源服务器进行确认 proxy-revalidate 无 要求中间缓存服务器对缓存的响应有效性再进行确认 max-age = [秒] 必需 响应的最大Age值 s-maxage = [秒] 必需 公共缓存服务器响应的最大Age值 cache-extension - 新指令标记（token） 6.4.1.2 表示能否缓存的指令 public 指令 Cache-Control: public 当指定使用 public 指令时，则明确表明其他用户也可利用缓存。 private 指令 Cache-Control: private 当指定 private 指令后，响应只以特定的用户作为对象，这与 public 指令的行为相反。缓存服务器会对该特定用户提供资源缓存的服务，对于其他用户发送过来的请求，代理服务器则不会返回缓存。 no-cache 指令 Cache-Control: no-cache 使用 no-cache 指令是为了防止从缓存中返回过期的资源。 客户端发送的请求中如果包含 no-cache 指令，则表示客户端将不会接收缓存过的响应。于是，“中间”的缓存服务器必须把客户端请求转发给源服务器。 如果服务器中返回的响应包含 no-cache 指令，那么缓存服务器不能对资源进行缓存。源服务器以后也将不再对缓存服务器请求中提出的资源有效性进行确认，且禁止其对响应资源进行缓存操作。 Cache-Control: no-cache=Location 由服务器返回的响应中，若报文首部字段 Cache-Control 中对 no-cache 字段名具体指定参数值，那么客户端在接收到这个被指定参数值的首部字段对应的响应报文后，就不能使用缓存。换言之，无参数值的首部字段可以使用缓存。只能在响应指令中指定该参数。 no-store 指令 Cache-Control: no-store 当使用 no-store 指令时，暗示请求（和对应的响应）或响应中包含机密信息。因此，该指令规定缓存不能在本地存储请求或响应的任一部分。 注意：no-cache 指令代表不缓存过期的指令，缓存会向源服务器进行有效期确认后处理资源；no-store 指令才是真正的不进行缓存。 6.4.1.3 指定缓存期限和认证的指令 s-maxage 指令 Cache-Control: s-maxage=604800（单位：秒） s-maxage 指令的功能和 max-age 指令的相同，它们的不同点是 s-maxage 指令只适用于供多位用户使用的公共缓存服务器（一般指代理）。也就是说，对于向同一用户重复返回响应的服务器来说，这个指令没有任何作用。 另外，当使用 s-maxage 指令后，则直接忽略对 Expires 首部字段及 max-age 指令的处理。 max-age 指令 Cache-Control: max-age=604800（单位：秒） 当客户端发送的请求中包含 max-age 指令时，如果判定缓存资源的缓存时间数值比指定的时间更小，那么客户端就接收缓存的资源。另外，当指定 max-age 的值为0，那么缓存服务器通常需要将请求转发给源服务器。 当服务器返回的响应中包含 max-age 指令时，缓存服务器将不对资源的有效性再作确认，而 max-age 数值代表资源保存为缓存的最长时间。 应用 HTTP/1.1 版本的缓存服务器遇到同时存在 Expires 首部字段的情况时，会优先处理 max-age 指令，并忽略掉 Expires 首部字段；而 HTTP/1.0 版本的缓存服务器则相反。 min-fresh 指令 Cache-Control: min-fresh=60（单位：秒） min-fresh 指令要求缓存服务器返回至少还未过指定时间的缓存资源。 max-stale 指令 Cache-Control: max-stale=3600（单位：秒） 使用 max-stale 可指示缓存资源，即使过期也照常接收。 如果指令未指定参数值，那么无论经过多久，客户端都会接收响应；如果指定了具体参数值，那么即使过期，只要仍处于 max-stale 指定的时间内，仍旧会被客户端接收。 only-if-cached 指令 Cache-Control: only-if-cached 表示客户端仅在缓存服务器本地缓存目标资源的情况下才会要求其返回。换言之，该指令要求缓存服务器不重新加载响应，也不会再次确认资源的有效性。 must-revalidate 指令 Cache-Control: must-revalidate 使用 must-revalidate 指令，代理会向源服务器再次验证即将返回的响应缓存目前是否仍有效。另外，使用 must-revalidate 指令会忽略请求的 max-stale 指令。 proxy-revalidate 指令 Cache-Control: proxy-revalidate proxy-revalidate 指令要求所有的缓存服务器在接收到客户端带有该指令的请求返回响应之前，必须再次验证缓存的有效性。 no-transform 指令 Cache-Control: no-transform 使用 no-transform 指令规定无论是在请求还是响应中，缓存都不能改变实体主体的媒体类型。这样做可防止缓存或代理压缩图片等类似操作。 6.4.1.4 Cache-Control 扩展 Cache-Control: private, community=\"UCI\" 通过 cache-extension 标记（token），可以扩展 Cache-Control 首部字段内的指令。上述 community 指令即扩展的指令，如果缓存服务器不能理解这个新指令，就会直接忽略掉。 6.4.2 Connection Connection 首部字段具备以下两个作用： 控制不再转发的首部字段 Connection: Upgrade 在客户端发送请求和服务器返回响应中，使用 Connection 首部字段，可控制不再转发给代理的首部字段，即删除后再转发（即Hop-by-hop首部）。 管理持久连接 Connection: close HTTP/1.1 版本的默认连接都是持久连接。当服务器端想明确断开连接时，则指定 Connection 首部字段的值为 close。 Connection: Keep-Alive HTTP/1.1 之前的 HTTP 版本的默认连接都是非持久连接。为此，如果想在旧版本的 HTTP 协议上维持持续连接，则需要指定 Connection 首部字段的值为 Keep-Alive。 6.4.3 Date 表明创建 HTTP 报文的日期和时间。 Date: Mon, 10 Jul 2017 15:50:06 GMT HTTP/1.1 协议使用在 RFC1123 中规定的日期时间的格式。 6.4.4 Pragma Pragma 首部字段是 HTTP/1.1 版本之前的历史遗留字段，仅作为与 HTTP/1.0 的向后兼容而定义。 Pragma: no-cache 该首部字段属于通用首部字段，但只用在客户端发送的请求中，要求所有的中间服务器不返回缓存的资源。 所有的中间服务器如果都能以 HTTP/1.1 为基准，那直接采用 Cache-Control: no-cache 指定缓存的处理方式最为理想。但是要整体掌握所有中间服务器使用的 HTTP 协议版本却是不现实的，所以，发送的请求会同时包含下面两个首部字段： Cache-Control: no-cache Pragma: no-cache 6.4.5 Trailer Trailer: Expires 首部字段 Trailer 会事先说明在报文主体后记录了哪些首部字段。可应用在 HTTP/1.1 版本分块传输编码时。 6.4.6 Transfer-Encoding Transfer-Encoding: chunked 规定了传输报文主体时采用的编码方式。 HTTP/1.1 的传输编码方式仅对分块传输编码有效。 6.4.7 Upgrade Upgrade: TSL/1.0 用于检测 HTTP 协议及其他协议是否可使用更高的版本进行通信，其参数值可以用来指定一个完全不同的通信协议。 6.4.8 Via Via: 1.1 a1.sample.com(Squid/2.7) 为了追踪客户端和服务器端之间的请求和响应报文的传输路径。 报文经过代理或网关时，会现在首部字段 Via 中附加该服务器的信息，然后再进行转发。 首部字段 Via 不仅用于追踪报文的转发，还可避免请求回环的发生。 6.4.9 Warning 该首部字段通常会告知用户一些与缓存相关的问题的警告。 Warning 首部字段的格式如下： Warning：[警告码][警告的主机:端口号] \"[警告内容]\"([日期时间]) 最后的日期时间可省略。 HTTP/1.1 中定义了7种警告，警告码对应的警告内容仅推荐参考，另外，警告码具备扩展性，今后有可能追加新的警告码。 警告码 警告内容 说明 110 Response is stale(响应已过期) 代理返回已过期的资源 111 Revalidation failed(再验证失败) 代理再验证资源有效性时失败（服务器无法到达等原因） 112 Disconnection operation(断开连接操作) 代理与互联网连接被故意切断 113 Heuristic expiration(试探性过期) 响应的试用期超过24小时(有效缓存的设定时间大于24小时的情况下) 199 Miscellaneous warning(杂项警告) 任意的警告内容 214 Transformation applied(使用了转换) 代理对内容编码或媒体类型等执行了某些处理时 299 Miscellaneous persistent warning(持久杂项警告) 任意的警告内容 6.5 请求首部字段（HTTP/1.1） 首部字段名 说明 Accept 用户代理可处理的媒体类型 Accept-Charset 优先的字符集 Accept-Encoding 优先的内容编码 Accept-Language 优先的语言（自然语言） Authorization Web认证信息 Expect 期待服务器的特定行为 From 用户的电子邮箱地址 Host 请求资源所在服务器 If-Match 比较实体标记（ETag） If-Modified-Since 比较资源的更新时间 If-None-Match 比较实体标记（与 If-Macth 相反） If-Range 资源未更新时发送实体 Byte 的范围请求 If-Unmodified-Since 比较资源的更新时间(与 If-Modified-Since 相反) Max-Forwards 最大传输逐跳数 Proxy-Authorization 代理服务器要求客户端的认证信息 Range 实体的字节范围请求 Referer 对请求中 URI 的原始获取方 TE 传输编码的优先级 User-Agent HTTP 客户端程序的信息 6.5.1 Accept Accept: text/html, application/xhtml+xml, application/xml; q=0.5 Accept 首部字段可通知服务器，用户代理能够处理的媒体类型及媒体类型的相对优先级。可使用 type/subtype 这种形式，一次指定多种媒体类型。 若想要给显示的媒体类型增加优先级，则使用 q=[数值] 来表示权重值，用分号（;）进行分隔。权重值的范围 0~1（可精确到小数点后三位），且 1 为最大值。不指定权重值时，默认为 1。 6.5.2 Accept-Charset Accept-Charset: iso-8859-5, unicode-1-1; q=0.8 Accept-Charset 首部字段可用来通知服务器用户代理支持的字符集及字符集的相对优先顺序。另外，可一次性指定多种字符集。同样使用 q=[数值] 来表示相对优先级。 6.5.3 Accept-Encoding Accept-Encoding: gzip, deflate Accept-Encoding 首部字段用来告知服务器用户代理支持的内容编码及内容编码的优先顺序，并可一次性指定多种内容编码。同样使用 q=[数值] 来表示相对优先级。也可使用星号（*）作为通配符，指定任意的编码格式。 6.5.4 Accept-Language Accept-Lanuage: zh-cn,zh;q=0.7,en=us,en;q=0.3 告知服务器用户代理能够处理的自然语言集（指中文或英文等），以及自然语言集的相对优先级，可一次性指定多种自然语言集。同样使用 q=[数值] 来表示相对优先级。 6.5.5 Authorization Authorization: Basic ldfKDHKfkDdasSAEdasd== 告知服务器用户代理的认证信息（证书值）。通常，想要通过服务器认证的用户代理会在接收到返回的 401 状态码响应后，把首部字段 Authorization 加入请求中。共用缓存在接收到含有 Authorization 首部字段的请求时的操作处理会略有差异。 6.5.6 Expect Expect: 100-continue 告知服务器客户端期望出现的某种特定行为。 6.5.7 From From: Deeson_Woo@163.com 告知服务器使用用户代理的电子邮件地址。 6.5.8 Host Host: www.jianshu.com 告知服务器，请求的资源所处的互联网主机和端口号。 Host 首部字段是 HTTP/1.1 规范内唯一一个必须被包含在请求内的首部字段。 若服务器未设定主机名，那直接发送一个空值即可 Host: 。 6.5.9 If-Match 形如 If-xxx 这种样式的请求首部字段，都可称为条件请求。服务器接收到附带条件的请求后，只有判断指定条件为真时，才会执行请求。 If-Match: \"123456\" 首部字段 If-Match，属附带条件之一，它会告知服务器匹配资源所用的实体标记（ETag）值。这时的服务器无法使用弱 ETag 值。 服务器会比对 If-Match 的字段值和资源的 ETag 值，仅当两者一致时，才会执行请求。反之，则返回状态码 412 Precondition Failed 的响应。 还可以使用星号（*）指定 If-Match 的字段值。针对这种情况，服务器将会忽略 ETag 的值，只要资源存在就处理请求。 6.5.10 If-Modified-Since If-Modified-Since: Mon, 10 Jul 2017 15:50:06 GMT 首部字段 If-Modified-Since，属附带条件之一，用于确认代理或客户端拥有的本地资源的有效性。 它会告知服务器若 If-Modified-Since 字段值早于资源的更新时间，则希望能处理该请求。而在指定 If-Modified-Since 字段值的日期时间之后，如果请求的资源都没有过更新，则返回状态码 304 Not Modified 的响应。 6.5.11 If-None-Match If-None-Match: \"123456\" 首部字段 If-None-Match 属于附带条件之一。它和首部字段 If-Match 作用相反。用于指定 If-None-Match 字段值的实体标记（ETag）值与请求资源的 ETag 不一致时，它就告知服务器处理该请求。 6.5.12 If-Range If-Range: \"123456\" 首部字段 If-Range 属于附带条件之一。它告知服务器若指定的 If-Range 字段值（ETag 值或者时间）和请求资源的 ETag 值或时间相一致时，则作为范围请求处理。反之，则返回全体资源。 下面我们思考一下不使用首部字段 If-Range 发送请求的情况。服务器端的资源如果更新，那客户端持有资源中的一部分也会随之无效，当然，范围请求作为前提是无效的。这时，服务器会暂且以状态码 412 Precondition Failed 作为响应返回，其目的是催促客户端再次发送请求。这样一来，与使用首部字段 If-Range 比起来，就需要花费两倍的功夫。 6.5.13 If-Unmodified-Since If-Unmodified-Since: Mon, 10 Jul 2017 15:50:06 GMT 首部字段 If-Unmodified-Since 和首部字段 If-Modified-Since 的作用相反。它的作用的是告知服务器，指定的请求资源只有在字段值内指定的日期时间之后，未发生更新的情况下，才能处理请求。如果在指定日期时间后发生了更新，则以状态码 412 Precondition Failed 作为响应返回。 6.5.14 Max-Forwards Max-Forwards: 10 通过 TRACE 方法或 OPTIONS 方法，发送包含首部字段 Max-Forwards 的请求时，该字段以十进制整数形式指定可经过的服务器最大数目。服务器在往下一个服务器转发请求之前，Max-Forwards 的值减 1 后重新赋值。当服务器接收到 Max-Forwards 值为 0 的请求时，则不再进行转发，而是直接返回响应。 6.5.15 Proxy-Authorization Proxy-Authorization: Basic dGlwOjkpNLAGfFY5 接收到从代理服务器发来的认证质询时，客户端会发送包含首部字段 Proxy-Authorization 的请求，以告知服务器认证所需要的信息。 这个行为是与客户端和服务器之间的 HTTP 访问认证相类似的，不同之处在于，认证行为发生在客户端与代理之间。 6.5.16 Range Range: bytes=5001-10000 对于只需获取部分资源的范围请求，包含首部字段 Range 即可告知服务器资源的指定范围。 接收到附带 Range 首部字段请求的服务器，会在处理请求之后返回状态码为 206 Partial Content 的响应。无法处理该范围请求时，则会返回状态码 200 OK 的响应及全部资源。 6.5.17 Referer Referer: http://www.sample.com/index.html 首部字段 Referer 会告知服务器请求的原始资源的 URI。 6.5.18 TE TE: gzip, deflate; q=0.5 首部字段 TE 会告知服务器客户端能够处理响应的传输编码方式及相对优先级。它和首部字段 Accept-Encoding 的功能很相像，但是用于传输编码。 首部字段 TE 除指定传输编码之外，还可以指定伴随 trailer 字段的分块传输编码的方式。应用后者时，只需把 trailers 赋值给该字段值。TE: trailers 6.5.19 User-Agent User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:13.0) Gecko/20100101 首部字段 User-Agent 会将创建请求的浏览器和用户代理名称等信息传达给服务器。 由网络爬虫发起请求时，有可能会在字段内添加爬虫作者的电子邮件地址。此外，如果请求经过代理，那么中间也很可能被添加上代理服务器的名称。 6.6 响应首部字段（HTTP/1.1） 首部字段名 说明 Accept-Ranges 是否接受字节范围请求 Age 推算资源创建经过时间 ETag 资源的匹配信息 Location 令客户端重定向至指定 URI Proxy-Authenticate 代理服务器对客户端的认证信息 Retry-After 对再次发起请求的时机要求 Server HTTP 服务器的安装信息 Vary 代理服务器缓存的管理信息 WWW-Authenticate 服务器对客户端的认证信息 6.6.1 Accept-Ranges Accept-Ranges: bytes 首部字段 Accept-Ranges 是用来告知客户端服务器是否能处理范围请求，以指定获取服务器端某个部分的资源。 可指定的字段值有两种，可处理范围请求时指定其为 bytes，反之则指定其为 none。 6.6.2 Age Age: 1200 首部字段 Age 能告知客户端，源服务器在多久前创建了响应。字段值的单位为秒。 若创建该响应的服务器是缓存服务器，Age 值是指缓存后的响应再次发起认证到认证完成的时间值。代理创建响应时必须加上首部字段 Age。 6.6.3 ETag ETag: \"usagi-1234\" 首部字段 ETag 能告知客户端实体标识。它是一种可将资源以字符串形式做唯一性标识的方式。服务器会为每份资源分配对应的 ETag 值。 另外，当资源更新时，ETag 值也需要更新。生成 ETag 值时，并没有统一的算法规则，而仅仅是由服务器来分配。 ETag 中有强 ETag 值和弱 ETag 值之分。强 ETag 值，不论实体发生多么细微的变化都会改变其值；弱 ETag 值只用于提示资源是否相同。只有资源发生了根本改变，产生差异时才会改变 ETag 值。这时，会在字段值最开始处附加 W/： ETag: W/\"usagi-1234\"。 6.6.4 Location Location: http://www.sample.com/sample.html 使用首部字段 Location 可以将响应接收方引导至某个与请求 URI 位置不同的资源。 基本上，该字段会配合 3xx ：Redirection 的响应，提供重定向的 URI。 几乎所有的浏览器在接收到包含首部字段 Location 的响应后，都会强制性地尝试对已提示的重定向资源的访问。 6.6.5 Proxy-Authenticate Proxy-Authenticate: Basic realm=\"Usagidesign Auth\" 首部字段 Proxy-Authenticate 会把由代理服务器所要求的认证信息发送给客户端。 它与客户端和服务器之间的 HTTP 访问认证的行为相似，不同之处在于其认证行为是在客户端与代理之间进行的。 6.6.6 Retry-After Retry-After: 180 首部字段 Retry-After 告知客户端应该在多久之后再次发送请求。主要配合状态码 503 Service Unavailable 响应，或 3xx Redirect 响应一起使用。 字段值可以指定为具体的日期时间（Mon, 10 Jul 2017 15:50:06 GMT 等格式），也可以是创建响应后的秒数。 6.6.7 Server Server: Apache/2.2.6 (Unix) PHP/5.2.5 首部字段 Server 告知客户端当前服务器上安装的 HTTP 服务器应用程序的信息。不单单会标出服务器上的软件应用名称，还有可能包括版本号和安装时启用的可选项。 6.6.8 Vary Vary: Accept-Language 首部字段 Vary 可对缓存进行控制。源服务器会向代理服务器传达关于本地缓存使用方法的命令。 从代理服务器接收到源服务器返回包含 Vary 指定项的响应之后，若再要进行缓存，仅对请求中含有相同 Vary 指定首部字段的请求返回缓存。即使对相同资源发起请求，但由于 Vary 指定的首部字段不相同，因此必须要从源服务器重新获取资源。 6.6.9 WWW-Authenticate WWW-Authenticate: Basic realm=\"Usagidesign Auth\" 首部字段 WWW-Authenticate 用于 HTTP 访问认证。它会告知客户端适用于访问请求 URI 所指定资源的认证方案（Basic 或是 Digest）和带参数提示的质询（challenge）。 6.7 实体首部字段（HTTP/1.1） 首部字段名 说明 Allow 资源可支持的 HTTP 方法 Content-Encoding 实体主体适用的编码方式 Content-Language 实体主体的自然语言 Content-Length 实体主体的大小（单位：字节） Content-Location 替代对应资源的 URI Content-MD5 实体主体的报文摘要 Content-Range 实体主体的位置范围 Content-Type 实体主体的媒体类型 Expires 实体主体过期的日期时间 Last-Modified 资源的最后修改日期时间 6.7.1 Allow Allow: GET, HEAD 首部字段 Allow 用于通知客户端能够支持 Request-URI 指定资源的所有 HTTP 方法。 当服务器接收到不支持的 HTTP 方法时，会以状态码 405 Method Not Allowed 作为响应返回。与此同时，还会把所有能支持的 HTTP 方法写入首部字段 Allow 后返回。 6.7.2 Content-Encoding Content-Encoding: gzip 首部字段 Content-Encoding 会告知客户端服务器对实体的主体部分选用的内容编码方式。内容编码是指在不丢失实体信息的前提下所进行的压缩。 主要采用这 4 种内容编码的方式（gzip、compress、deflate、identity）。 6.7.3 Content-Language Content-Language: zh-CN 首部字段 Content-Language 会告知客户端，实体主体使用的自然语言（指中文或英文等语言）。 6.7.4 Content-Length Content-Length: 15000 首部字段 Content-Length 表明了实体主体部分的大小（单位是字节）。对实体主体进行内容编码传输时，不能再使用 Content-Length首部字段。 6.7.5 Content-Location Content-Location: http://www.sample.com/index.html 首部字段 Content-Location 给出与报文主体部分相对应的 URI。和首部字段 Location 不同，Content-Location 表示的是报文主体返回资源对应的 URI。 6.7.6 Content-MD5 Content-MD5: OGFkZDUwNGVhNGY3N2MxMDIwZmQ4NTBmY2IyTY== 首部字段 Content-MD5 是一串由 MD5 算法生成的值，其目的在于检查报文主体在传输过程中是否保持完整，以及确认传输到达。 6.7.7 Content-Range Content-Range: bytes 5001-10000/10000 针对范围请求，返回响应时使用的首部字段 Content-Range，能告知客户端作为响应返回的实体的哪个部分符合范围请求。字段值以字节为单位，表示当前发送部分及整个实体大小。 6.7.8 Content-Type Content-Type: text/html; charset=UTF-8 首部字段 Content-Type 说明了实体主体内对象的媒体类型。和首部字段 Accept 一样，字段值用 type/subtype 形式赋值。参数 charset 使用 iso-8859-1 或 euc-jp 等字符集进行赋值。 6.7.9 Expires Expires: Mon, 10 Jul 2017 15:50:06 GMT 首部字段 Expires 会将资源失效的日期告知客户端。 缓存服务器在接收到含有首部字段 Expires 的响应后，会以缓存来应答请求，在 Expires 字段值指定的时间之前，响应的副本会一直被保存。当超过指定的时间后，缓存服务器在请求发送过来时，会转向源服务器请求资源。 源服务器不希望缓存服务器对资源缓存时，最好在 Expires 字段内写入与首部字段 Date 相同的时间值。 6.7.10 Last-Modified Last-Modified: Mon, 10 Jul 2017 15:50:06 GMT 首部字段 Last-Modified 指明资源最终修改的时间。一般来说，这个值就是 Request-URI 指定资源被修改的时间。但类似使用 CGI 脚本进行动态数据处理时，该值有可能会变成数据最终修改时的时间。 6.8 为 Cookie 服务的首部字段 首部字段名 说明 首部类型 Set-Cookie 开始状态管理所使用的 Cookie 信息 响应首部字段 Cookie 服务器接收到的 Cookie 信息 请求首部字段 6.8.1 Set-Cookie Set-Cookie: status=enable; expires=Mon, 10 Jul 2017 15:50:06 GMT; path=/; 下面的表格列举了 Set-Cookie 的字段值。 属性 说明 NAME=VALUE 赋予 Cookie 的名称和其值（必需项） expires=DATE Cookie 的有效期（若不明确指定则默认为浏览器关闭前为止） path=PATH 将服务器上的文件目录作为Cookie的适用对象（若不指定则默认为文档所在的文件目录） domain=域名 作为 Cookie 适用对象的域名 （若不指定则默认为创建 Cookie的服务器的域名） Secure 仅在 HTTPS 安全通信时才会发送 Cookie HttpOnly 加以限制，使 Cookie 不能被 JavaScript 脚本访问 6.8.1.1 expires 属性 Cookie 的 expires 属性指定浏览器可发送 Cookie 的有效期。 当省略 expires 属性时，其有效期仅限于维持浏览器会话（Session）时间段内。这通常限于浏览器应用程序被关闭之前。 另外，一旦 Cookie 从服务器端发送至客户端，服务器端就不存在可以显式删除 Cookie 的方法。但可通过覆盖已过期的 Cookie，实现对客户端 Cookie 的实质性删除操作。 6.8.1.2 path 属性 Cookie 的 path 属性可用于限制指定 Cookie 的发送范围的文件目录。 6.8.1.3 domain 属性 通过 Cookie 的 domain 属性指定的域名可做到与结尾匹配一致。比如，当指定 example.com 后，除example.com 以外，www.example.com 或 www2.example.com 等都可以发送 Cookie。 因此，除了针对具体指定的多个域名发送 Cookie 之 外，不指定 domain 属性显得更安全。 6.8.1.4 secure 属性 Cookie 的 secure 属性用于限制 Web 页面仅在 HTTPS 安全连接时，才可以发送 Cookie。 6.8.1.5 HttpOnly 属性 Cookie 的 HttpOnly 属性是 Cookie 的扩展功能，它使 JavaScript 脚本无法获得 Cookie。其主要目的为防止跨站脚本攻击（Cross-site scripting，XSS）对 Cookie 的信息窃取。 通过上述设置，通常从 Web 页面内还可以对 Cookie 进行读取操作。但使用 JavaScript 的 document.cookie 就无法读取附加 HttpOnly 属性后的 Cookie 的内容了。因此，也就无法在 XSS 中利用 JavaScript 劫持 Cookie 了。 6.8.2 Cookie Cookie: status=enable 首部字段 Cookie 会告知服务器，当客户端想获得 HTTP 状态管理支持时，就会在请求中包含从服务器接收到的 Cookie。接收到多个 Cookie 时，同样可以以多个 Cookie 形式发送。 6.9 其他首部字段 HTTP 首部字段是可以自行扩展的。所以在 Web 服务器和浏览器的应用上，会出现各种非标准的首部字段。 以下是最为常用的首部字段。 6.9.1 X-Frame-Options X-Frame-Options: DENY 首部字段 X-Frame-Options 属于 HTTP 响应首部，用于控制网站内容在其他 Web 网站的 Frame 标签内的显示问题。其主要目的是为了防止点击劫持（clickjacking）攻击。首部字段 X-Frame-Options 有以下两个可指定的字段值： DENY：拒绝 SAMEORIGIN：仅同源域名下的页面（Top-level-browsing-context）匹配时许可。（比如，当指定 http://sample.com/sample.html 页面为 SAMEORIGIN 时，那么 sample.com 上所有页面的 frame 都被允许可加载该页面，而 example.com 等其他域名的页面就不行了） 6.9.2 X-XSS-Protection X-XSS-Protection: 1 首部字段 X-XSS-Protection 属于 HTTP 响应首部，它是针对跨站脚本攻击（XSS）的一种对策，用于控制浏览器 XSS 防护机制的开关。首部字段 X-XSS-Protection 可指定的字段值如下: 0 ：将 XSS 过滤设置成无效状态 1 ：将 XSS 过滤设置成有效状态 6.9.3 DNT DNT: 1 首部字段 DNT 属于 HTTP 请求首部，其中 DNT 是 Do Not Track 的简称，意为拒绝个人信息被收集，是表示拒绝被精准广告追踪的一种方法。首部字段 DNT 可指定的字段值如下： 0 ：同意被追踪 1 ：拒绝被追踪 由于首部字段 DNT 的功能具备有效性，所以 Web 服务器需要对 DNT做对应的支持。 6.9.4 P3P P3P: CP=\"CAO DSP LAW CURa ADMa DEVa TAIa PSAa PSDa IVAa IVDa OUR BUS IND 首部字段 P3P 属于 HTTP 响应首部，通过利用 P3P（The Platform for Privacy Preferences，在线隐私偏好平台）技术，可以让 Web 网站上的个人隐私变成一种仅供程序可理解的形式，以达到保护用户隐私的目的。 要进行 P3P 的设定，需按以下操作步骤进行： 步骤 1：创建 P3P 隐私 步骤 2：创建 P3P 隐私对照文件后，保存命名在 /w3c/p3p.xml 步骤 3：从 P3P 隐私中新建 Compact policies 后，输出到 HTTP 响应中 七、HTTP 响应状态码（重点分析） 7.1 状态码概述 HTTP 状态码负责表示客户端 HTTP 请求的返回结果、标记服务器端的处理是否正常、通知出现的错误等工作。 HTTP 状态码如 200 OK ，以 3 位数字和原因短语组成。数字中的第一位指定了响应类别，后两位无分类。 不少返回的响应状态码都是错误的，但是用户可能察觉不到这点。比如 Web 应用程序内部发生错误，状态码依然返回 200 OK。 7.2 状态码类别 类别 原因短语 1xx Informational(信息性状态码) 接收的请求正在处理 2xx Success(成功状态码) 请求正常处理完毕 3xx Redirection(重定向状态码) 需要进行附加操作以完成请求 4xx Client Error(客户端错误状态码) 服务器无法处理请求 5xx Server Error(服务器错误状态码) 服务器处理请求出错 我们可以自行改变 RFC2616 中定义的状态码或者服务器端自行创建状态码，只要遵守状态码的类别定义就可以了。 7.3 常用状态码解析 HTTP 状态码种类繁多，数量达几十种。其中最常用的有以下 14 种，一起来看看。 7.3.1 200 OK 表示从客户端发来的请求在服务器端被正常处理了。 7.3.2 204 No Content 代表服务器接收的请求已成功处理，但在返回的响应报文中不含实体的主体部分。另外，也不允许返回任何实体的主体。 一般在只需要从客户端向服务器端发送消息，而服务器端不需要向客户端发送新消息内容的情况下使用。 7.3.3 206 Partial Content 表示客户端进行了范围请求，而服务器成功执行了这部分的 GET 请求。响应报文中包含由 Content-Range 首部字段指定范围的实体内容。 7.3.4 301 Moved Permanently 永久性重定向。表示请求的资源已被分配了新的 URI。以后应使用资源现在所指的 URI。也就是说，如果已经把资源对应的 URI 保存为书签了，这时应该按 Location 首部字段提示的 URI 重新保存。 7.3.5 302 Found 临时性重定向。表示请求的资源已被分配了新的 URI，希望用户（本次）能使用新的 URI 访问。 和 301 Moved Permanently 状态码相似，但 302 Found 状态码代表资源不是被永久移动，只是临时性质的。换句话说，已移动的资源对应的 URI 将来还有可能发生改变。 7.3.6 303 See Other 表示由于请求的资源存在着另一个 URI，应使用 GET 方法定向获取请求的资源。 303 See Other 和 302 Found 状态码有着相同的功能，但 303 See Other 状态码明确表示客户端应采用 GET 方法获取资源，这点与 302 Found 状态码有区别。 7.3.7 304 Not Modified 表示客户端发送附带条件的请求时，服务器端允许请求访问的资源，但未满足条件的情况。 304 Not Modified 状态码返回时，不包含任何响应的主体部分。 304 Not Modified 虽然被划分到 3xx 类别中，但和重定向没有关系。 7.3.8 307 Temporary Redirect 临时重定向。该状态码与 302 Found 有着相同的含义。 7.3.9 400 Bad Request 表示请求报文中存在语法错误。当错误发生时，需修改请求的内容后再次发送请求。 另外，浏览器会像 200 OK 一样对待该状态码。 7.3.10 401 Unauthorized 表示发送的请求需要有通过 HTTP 认证（BASIC 认证、DIGEST 认证）的认证信息。 另外，若之前已进行过 1 次请求，则表示用户认证失败。 返回含有 401 Unauthorized 的响应必须包含一个适用于被请求资源的 WWW-Authenticate 首部用以质询（challenge）用户信息。 7.3.11 403 Forbidden 表明对请求资源的访问被服务器拒绝了。服务器端没有必要给出详细的拒绝理由，当然也可以在响应报文的实体主体部分对原因进行描述。 7.3.12 404 Not Found 表明服务器上无法找到请求的资源。除此之外，也可以在服务器端拒绝请求且不想说明理由的时候使用。 7.3.13 500 Internal Server Error 表明服务器端在执行请求时发生了错误。也可能是 Web 应用存在的 bug 或某些临时的故障。 7.3.14 503 Service Unavailable 表明服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。如果事先得知解除以上状况需要的时间，最好写入 Retry-After 首部字段再返回给客户端。 八、HTTP 报文实体 8.1 HTTP 报文实体概述 HTTP 报文结构 大家请仔细看看上面示例中，各个组成部分对应的内容。 接着，我们来看看报文和实体的概念。如果把 HTTP 报文想象成因特网货运系统中的箱子，那么 HTTP 实体就是报文中实际的货物。 报文：是网络中交换和传输的数据单元，即站点一次性要发送的数据块。报文包含了将要发送的完整的数据信息，其长短很不一致，长度不限且可变。 实体：作为请求或响应的有效载荷数据（补充项）被传输，其内容由实体首部和实体主体组成。（实体首部相关内容在上面第六点中已有阐述。） 我们可以看到，上面示例右图中深红色框的内容就是报文的实体部分，而蓝色框的两部分内容分别就是实体首部和实体主体。而左图中粉红框内容就是报文主体。 通常，报文主体等于实体主体。只有当传输中进行编码操作时，实体主体的内容发生变化，才导致它和报文主体产生差异。 8.2 内容编码 HTTP 应用程序有时在发送之前需要对内容进行编码。例如，在把很大的 HTML 文档发送给通过慢速连接上来的客户端之前，服务器可能会对其进行压缩，这样有助于减少传输实体的时间。服务器还可以把内容搅乱或加密，以此来防止未授权的第三方看到文档的内容。 这种类型的编码是在发送方应用到内容之上的。当内容经过内容编码后，编好码的数据就放在实体主体中，像往常一样发送给接收方。 内容编码类型： 编码方式 描述 gzip 表明实体采用 GNU zip 编码 compress 表明实体采用 Unix 的文件压缩程序 deflate 表明实体采用 zlib 的格式压缩的 identity 表明没有对实体进行编码，当没有 Content-Encoding 首部字段时，默认采用此编码方式 8.3 传输编码 内容编码是对报文的主体进行的可逆变换，是和内容的具体格式细节紧密相关的。 传输编码也是作用在实体主体上的可逆变换，但使用它们是由于架构方面的原因，同内容的格式无关。使用传输编码是为了改变报文中的数据在网络上传输的方式。 内容编码和传输编码的对比 8.4 分块编码 分块编码把报文分割成若干已知大小的块。块之间是紧挨着发送的，这样就不需要在发送之前知道整个报文的大小了。分块编码是一种传输编码，是报文的属性。 分块编码与持久连接 若客户端与服务器端之间不是持久连接，客户端就不需要知道它在读取的主体的长度，而只需要读取到服务器关闭主体连接为止。 当使用持久连接时，在服务器写主体之前，必须知道它的大小并在 Content-Length 首部中发送。如果服务器动态创建内容，就可能在发送之前无法知道主体的长度。 分块编码为这种困难提供了解决方案，只要允许服务器把主体分块发送，说明每块的大小就可以了。因为主体是动态创建的，服务器可以缓冲它的一部分，发送其大小和相应的块，然后在主体发送完之前重复这个过程。服务器可以用大小为 0 的块作为主体结束的信号，这样就可以继续保持连接，为下一个响应做准备。 来看看一个分块编码的报文示例： 分块编码的报文 8.5 多部分媒体类型 MIME 中的 multipart（多部分）电子邮件报文中包含多个报文，它们合在一起作为单一的复杂报文发送。每一部分都是独立的，有各自的描述其内容的集，不同部分之间用分界字符串连接在一起。 相应得，HTTP 协议中也采纳了多部分对象集合，发送的一份报文主体内可包含多种类型实体。 多部分对象集合包含的对象如下： multipart/form-data：在 Web 表单文件上传时使用。 multipart/byteranges：状态码 206 Partial Content 响应报文包含了多个范围的内容时使用。 8.6 范围请求 假设你正在下载一个很大的文件，已经下了四分之三，忽然网络中断了，那下载就必须重头再来一遍。为了解决这个问题，需要一种可恢复的机制，即能从之前下载中断处恢复下载。要实现该功能，这就要用到范围请求。 有了范围请求， HTTP 客户端可以通过请求曾获取失败的实体的一个范围（或者说一部分），来恢复下载该实体。当然这有一个前提，那就是从客户端上一次请求该实体到这一次发出范围请求的时间段内，该对象没有改变过。例如： GET /bigfile.html HTTP/1.1 Host: www.sample.com Range: bytes=20224- ··· 实体范围请求示例 上面示例中，客户端请求的是文档开头20224字节之后的部分。 九、与 HTTP 协作的 Web 服务器 HTTP 通信时，除客户端和服务器外，还有一些用于协助通信的应用程序。如下列出比较重要的几个：代理、缓存、网关、隧道、Agent 代理。 9.1 代理 HTTP 代理服务器是 Web 安全、应用集成以及性能优化的重要组成模块。代理位于客户端和服务器端之间，接收客户端所有的 HTTP 请求，并将这些请求转发给服务器（可能会对请求进行修改之后再进行转发）。对用户来说，这些应用程序就是一个代理，代表用户访问服务器。 出于安全考虑，通常会将代理作为转发所有 Web 流量的可信任中间节点使用。代理还可以对请求和响应进行过滤，安全上网或绿色上网。 9.2 缓存 浏览器第一次请求： 浏览器再次请求： Web 缓存或代理缓存是一种特殊的 HTTP 代理服务器，可以将经过代理传输的常用文档复制保存起来。下一个请求同一文档的客户端就可以享受缓存的私有副本所提供的服务了。客户端从附近的缓存下载文档会比从远程 Web 服务器下载快得多。 9.3 网关 HTTP / FTP 网关 网关是一种特殊的服务器，作为其他服务器的中间实体使用。通常用于将 HTTP 流量转换成其他的协议。网关接收请求时就好像自己是资源的源服务器一样。客户端可能并不知道自己正在跟一个网关进行通信。 9.4 隧道 HTTP/SSL 隧道 隧道是会在建立起来之后，就会在两条连接之间对原始数据进行盲转发的 HTTP 应用程序。HTTP 隧道通常用来在一条或多条 HTTP 连接上转发非 HTTP 数据，转发时不会窥探数据。 HTTP 隧道的一种常见用途就是通过 HTTP 连接承载加密的安全套接字层（SSL）流量，这样 SSL 流量就可以穿过只允许 Web 流量通过的防火墙了。 9.5 Agent 代理 自动搜索引擎“网络蜘蛛” Agent 代理是代表用户发起 HTTP 请求的客户端应用程序。所有发布 Web 请求的应用程序都是 HTTP Agent 代理。 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/网络协议/http/HTTPS协议.html":{"url":"linux/网络协议/http/HTTPS协议.html","title":"HTTPS协议","keywords":"","body":"HTTPS协议 本文严重抄袭至互联网 本篇将讨论 HTTPS 的加解密原理，很多人都知道 RSA，以为 HTTPS=RSA，使用 RSA 加解密数据，实际上这是不对的。 HTTPS 是使用 RSA 进行身份验证和交换密钥，然后再使用交换的密钥进行加解密数据。 身份验证是使用 RSA 的非对称加密，而数据传输是双方使用相同的密钥进行的对称加密。那么，什么是对称加密和非对称加密？ 对称加密和非对称加密 假设隔壁小王想要约小红出来，但是他不想让小明知道，于是他想用对称加密给小红传了个小纸条。 如下图所示： 他想发送的数据是\"Meet at 5:00 PM\"（5 点见面，如果是中文的话可以使用 UTF-8 编码），加密方式是直接在 ASCII 表进行左移或右移。 他的密钥是 3，表示在 ASCII 表往后移 3 位，就会变成\"Phhw#dw#8=33#SP\"，这样一般人如果截获了不知道是什么意思的。 但是我们可以想一下，如果既然他可以截获你的数据，自然也可以截获你的密钥，进而进行解密。 如下图所示： 所以小王打算用非对称加密，非对称加密的特点是双方都有自己的公钥和私钥对，其中公钥发给对方，密钥不交换自己保管不泄漏。 如下图所示： 其中小红的公钥为： public_key = (N, e) = (3233, 17) 她把公钥发给了小明，她自己的私钥为： private_key = (N, e) = (3233, 2753) 这里注意公钥和私钥都是两个数，N 通常是一个大整数，e 表示一个幂指数。现在小王想给小红发消息，于是他用小红的公钥进行加密，怎么加密呢？ 他要发送的第一个字母为 t=“M”，“M”的 ASCII 编码为 77，77 的加密过程如下计算： T = 77 ^ e % N = 77 ^ 17 % 3233 = 3123 把 77 做 e 次幂然后模以 N，便得到了 T=3123，然后把这个数发给小红（其他字母按同样方式处理）。 小红收到 T 之后便用她的私钥进行解密，计算如下： t = T ^ e % N = 3123 ^ 2753 % 3233 = 77 计算方法是一样的，这样便把 T 还原成了 t，只要公私钥配对，便可通过一些数学公式证明上面的推算是成立的。这个就是 RSA 的加解密原理，如果无法知道私钥便无法进行正确解密。 反过来，使用私钥进行加密，公钥进行解密也是可行的。那么 HTTPS 是怎么利用 RSA 进行加解密的呢，我们从 HTTPS 连接建立过程说起。 HTTPS 连接建立过程 HTTPS 主要有以下作用： 验证服务方身份，如我访问 google.com 的时候连的确实就是谷歌服务器 防止数据被劫持，例如有些运营商会给 http 的页面插入广告 防止敏感数据被窃取篡改等 正如 openssl 的注释所说，这是防止中间人攻击的唯一方法： 我们以 MDN（https://developer.mozilla.org）的网站为例，然后用 wireshark 抓包，观察 HTTPS 连接建立的过程。 如下图所示： 首先是 TCP 三次握手，然后客户端（浏览器）发起一个 HTTPS 连接建立请求，客户端先发一个 Client Hello 的包，然后服务端响应一个 Server Hello。 接着再给客户端发送它的证书，然后双方经过密钥交换，最后使用交换的密钥加行加解密数据。 在 Client Hello 里面客户端会告知服务端自己当前的一些信息，如下图所示： 包括客户端要使用的 TLS 版本，支持的加密套装，要访问的域名，给服务端生成的一个随机数（Nonce）等。 需要提前告知服务器想要访问的域名以便服务器发送相应的域名的证书过来，因为此时还没有发生 HTTP 请求。 服务端在 Server Hello 里面会做一些响应： 服务端选中的加密套装叫 TLSECDHERSAWITHAES128GCM_SHA256，这一串的意思是： 密钥交换使用 ECDHE 证书签名算法 RSA 数据加密使用 AES 128 GCM 签名校验使用 SHA256 接着服务给客户端发来了 4 个证书： 第一个证书的公用名（common name）就是我们当前访问的域名 developer.mozilla.org。 如果公用名是 *.mozilla.org 的话那么这个证书便能给 mozilla.org 的所有二级子域名使用。 第二个证书是第一个证书的签发机构（CA）的证书，它是 Amazon，也就是说 Amazon 会用它的私钥给 developer.mozilla.org 进行签名。 依此类推，第三个证书会给第二个证书签名，第四个证书会给第三个证书签名，并且我们可以看到第四个证书是一个根（Root）证书。 一个证书里面会有什么东西呢，我们可以展开第一个证书看一下，如下图所示： 证书包含三部分内容： tbsCertificate（to be signed certificate）待签名证书内容 证书签名算法 CA 给的签名 也就是说 CA 会用它的私钥对 tbsCertificate 进行签名，并放在签名部分。为什么证书要签名呢？签名是为了验证身份。 身份验证 我们先来看一下 tbsCertificate 里面有什么内容，如下图所示： 它里面包括了证书的公钥、证书的适用公用名、证书的有效期还有它的签发者等信息。 Amazon 的证书也具备上述结构，我们可以把 Amazon 证书的公钥拷出来，如下图所示： 中间有一些填充的数字，用灰色字表示。可以看到N通常是一个很大的整数（二进制 2048 位），而 e 通常为 65537。 然后我们用这个 CA 的公钥对 mozilla.org 的证书签名进行解密，方法和上面的类似： 取解密后的数字 decrypted 的十六进制的末 64 位，即为二进制 256 位的 SHA 哈希签名。 接下来我们手动计算一下 tbsCertificate 的 SHA256 哈希值，方法是在 wireshark 里面把 tbsCertificate 导出一个原始二进制文件： 然后再使用 openssl 计算它的哈希值，如下所示： liyinchengs-MBP:https liyincheng$ openssl dgst -sha256 ~/tbsCertificate.binSHA256(/Users/liyincheng/tbsCertificate.bin)= 5e300091593a10b944051512d39114d56909dc9a504e55cfa2e2984a883a827d 我们发现手动计算的哈希值和加密后的证书里的哈希值一致！说明只有知道了 Amazon 私钥的人才能正确地对 mozilla.org 的证书签名，因为公私钥是唯一匹配的。 因此我们验证了第一个证书 mozilla.org 确实是由第二个证书 Amazon 签发的，使用同样的方式，我们可以验证 Amazon 是由第三个签发的，第三个是由第四个根证书签发。 并且第四个证书是根证书，它是内置于操作系统的（通过 Mac 的 keychain 工具可以查看）： 假如 Hacker 通过 DNS 欺骗之类的方式把你访问的域名指向了他的机器，然后他再伪造一个证书。 但是由于根证书都是内置于操作系统的，所以它改不了签名的公钥，并且它没有正确的私钥，只能用自己的私钥，由于公私钥不配对，很难保证加解密后的信息一致。 或者直接把浏览器拿到的证书搬到他自己的服务器？这样再给浏览器发的证书便是一模一样，但是由于他不知道证书的私钥，所以无法进行后续的操作，因此这样是没有意义的。 这个就是 HTTPS 能够验证身份的原理。另外一个例子是 SSH，需要手动验证签名是否正确。 例如通过打电话或者发邮件等方式告知服务器的签名，与自己算的证书的签名是否一致，如果一致说明证书没有被篡改过（如证书的公钥没有被改为 Hacker 的公钥）： 上面展示的便是自己手动计算的值，拿这个值和之前的值进行比较是否相等便可知发过来的证书是否被修改过。 那么，为什么不直接使用 RSA 的密钥对进行加密数据？因为 RSA 的密钥对数值太大，不太合适频繁地加解密数据，所以需要更小的密钥。 另一个原因是服务端没有浏览器或者客户端的密钥，无法向浏览器发送加密的数据（不能用自己的私钥加密，因为公钥是公开的）。所以需要进行密钥交换。 密钥交换 密钥交换的方式有两种：RSA 和 ECDHE，RSA 的方式比较简单，浏览器生成一把密钥，然后使用证书 RSA 的公钥进行加密发给服务端，服务再使用它的密钥进行解密得到密钥，这样就能够共享密钥了。 它的缺点是攻击者虽然在发送的过程中无法破解，但是如果它保存了所有加密的数据，等到证书到期没有被维护之类的原因导致私钥泄露，那么它就可以使用这把私钥去解密之前传送过的所有数据。 而使用 ECDHE 是一种更安全的密钥交换算法。如下图所示，双方通过 ECDHE 进行密钥交换： ECDHE 的全称是 Elliptic Curve Diffie–Hellman key Exchange 椭圆曲线迪非-赫尔曼密钥交换，它是对迪非-赫尔曼密钥交换算法的改进。 这个算法的思想如下图所示： 为了得到共享秘钥 K，甲用它的私钥计算一个数 g^a，发送给乙，乙的私钥为 b，乙便得到 K= g^a^b，同时发送 g^b 给甲，甲也得到了 K=g^b^a。 这个应该比较好理解，而引入椭圆曲线加密能够提高破解难度。 椭圆曲线加密 现在的证书的签名算法有两种：RSA 和新起的 EC。如下图所示，google.com 便是使用的 ECC 证书： 我们上面讨论的便是 RSA，破解 RSA 的难点在于无法对公钥的 N 进行质数分解。 如果你能对证书的 N 拆成两个质数相乘，便可推算出证书的私钥，但是在当前的计算能力下是不可能的。而 ECC 的破解难点在于找到指定点的系数。 如下图所示，有一条椭圆曲线方程： y ^ 3 = x ^ 2 + ax + b: 给定一个起点 G（x，y），现在要计算点 P=2G 的坐标，其过程是在 G 点上做一条线与曲线相切于 -2G，做 -2G 相对于 x 轴的反射便得到 2G 点。 为了计算 3G 的坐标，如下图所示： 连接 2G 与 G 与曲线相郊于 -3G，再做反射得到 3G，同理计算 4G 便是连接 G 与 3G 再做反射。如果最后一个点和起点的连线垂直于 x 轴，说明所有的点已用完。 EC 的难点在于给定起点 G 和点 K： K = kG 想要得到 K（K 足够大）是一件很困难的事情。这个 K 便是私钥，而 K=kG 便是公钥。ECC 是怎么加解密数据的呢？ 假设要加密的数据为 m，把这个点当作x坐标得到在曲线上的一个点 M，取定一个随机数 r，计算点 C1=rG，C2=M+rK。 把这两个点便是加密后的数据，发给对方，对方收到后使用私钥 K 进行解密，过程如下： M = C2 - rK = C2 - rkG = C2 - rkG = C2 - kC1 通过上面的计算便能还原得到 M，而不知道私钥 K 的人是无法解密的。更多细节可见 Medium 的这篇文章《ECC elliptic curve encryption》。这样我们便理解了 ECC 的原理，那么怎么利用 ECC 进行密钥交换呢？ ECC 密钥交换 原理很简单，如下图所示： 之前交换的是两个幂次方的数，现在变成交换两个曲线上的点。 而曲线方程是规定好的，例如 Curve X25519 使用的曲线方程为： y^2 = x^3 + 486662x^2 + x 在密钥交换里面会指定所使用的曲线方程，如下图所示： mozilla.org 所使用的曲线方程为 secp256r1，这个也是比较流行的一个，它的参数比 Curve X25519 大很多。 密钥交换也使用了证书的私钥进行签名，保证交换的密钥不会被人篡改，只是这里的私钥是 mozilla 自己的私钥。 也就是说从连接建立到现在都是明文传输的。接下来双方发送 Change Cipher Spec 的包通知，接下来的包都按照之前约定好的方式进行加密。至此整个安全连接建立完毕。 HTTPS 证书的应用 那么是谁在做 HTTPS 加密呢？服务端通常是 Nginx、Apache 这些反向代理服务器做的，而具体的业务服务器不需要处理，客户端通常是浏览器等做的加解密，Chrome 是使用 boringSSL 这个库，fork 自 openssl。 我们通过 let’s encrypt 可以申请免费的 TLS 证书，每 3 个月需要手动续。 证书分为 3 种：DV、OV、EV，DV 适用于个人，OV 和 EV 需要身份审核，EV 最高端。 EV 证书会在浏览器的地址栏显示证书的企业名称： 但是新版的 Chrome 似乎把这个去掉了，所以我们打开 medium 的控制台可以看到一个提示： As part of an experiment, Chrome temporarily shows only the lock icon in the address bar. Your SSL certificate with Extended Validation is still valid. 另外我们可以用 openssl 生成一个自签名证书，执行以下命令： openssl req -x509 -nodes -sha256 -days 365 -newkey rsa:2048 -keyout test.com.key -out test.com.crt 便会得到两个文件，test.com.crt 是证书，test.com.key 是证书的私钥，如下图所示： 然后把这两个文件给 Nginx 使用便能使用 HTTPS 访问，如下代码所示： server { listen 443; server_name test.com; ssl on; ssl_certificate test.com.crt; ssl_certificate_key test.com.key; } 可以把这个证书添加到系统证书里面，这样浏览器等便能信任，或者直接使用 mkcert 工具一步到位。 客户端证书 还有一种证书叫客户端证书，同样需要向 CA 机构申请一个客户端证书，和服务端 TLS 证书不一样的地方是，服务端证书通常是和域名绑定的，而客户端证书可以给本地的任意可执行文件进行签名。 签名验证算法和上文讨论的 TLS 证书一致。为什么可执行文件需要签名呢，因为如果不签名的话，系统会拦截安装或者运行，如 Mac 双击一个未签名的 dmg 包的提示： 直接不让你运行了，而 Windows 也有类似的提示，Windows 是会给一个警告： 而当我们运行一个已签名的 exe 文件将会是正常的提示，如 Chrome 的提示： 综上本文主要讨论了对称加密和非对称加密的原理，并介绍了如何利用 RSA 对证书签名的检验以验证连接服务器的身份，怎么利用 ECC 进行数据加密和密钥交换，介绍了下怎么生成和使用 HTTPS 证书，并介绍了下客户端证书。 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/网络协议/tcp:ip/TCP三次握手和四次挥手.html":{"url":"linux/网络协议/tcp:ip/TCP三次握手和四次挥手.html","title":"TCP三次握手和四次挥手","keywords":"","body":"TCP三次握手和四次挥手 三次握手（重点） TCP 提供面向有连接的通信传输。面向有连接是指在数据通信开始之前先做好两端之间的准备工作。 所谓三次握手是指建立一个 TCP 连接时需要客户端和服务器端总共发送三个包以确认连接的建立。在socket编程中，这一过程由客户端执行connect来触发。 下面来看看三次握手的流程图： 第一次握手：客户端将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给服务器端，客户端进入SYN_SENT状态，等待服务器端确认。 第二次握手：服务器端收到数据包后由标志位SYN=1知道客户端请求建立连接，服务器端将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给客户端以确认连接请求，服务器端进入SYN_RCVD状态。 第三次握手：客户端收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给服务器端，服务器端检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，客户端和服务器端进入ESTABLISHED状态，完成三次握手，随后客户端与服务器端之间可以开始传输数据了。 这里小写的ack为确认编号(上一次对方主机传输过来的seq+1)，大写的ACK是确认值，确认值为1表示确认连接 四次挥手（重点） 四次挥手即终止TCP连接，就是指断开一个TCP连接时，需要客户端和服务端总共发送4个包以确认连接的断开。在socket编程中，这一过程由客户端或服务端任一方执行close来触发。 由于TCP连接是全双工的，因此，每个方向都必须要单独进行关闭，这一原则是当一方完成数据发送任务后，发送一个FIN来终止这一方向的连接，收到一个FIN只是意味着这一方向上没有数据流动了，即不会再收到数据了，但是在这个TCP连接上仍然能够发送数据，直到这一方向也发送了FIN。首先进行关闭的一方将执行主动关闭，而另一方则执行被动关闭。 下面来看看四次挥手的流程图： 中断连接端可以是客户端，也可以是服务器端。 第一次挥手：客户端发送一个FIN=M，用来关闭客户端到服务器端的数据传送，客户端进入FIN_WAIT_1状态。意思是说\"我客户端没有数据要发给你了\"，但是如果你服务器端还有数据没有发送完成，则不必急着关闭连接，可以继续发送数据。 第二次挥手：服务器端收到FIN后，先发送ack=M+1，告诉客户端，你的请求我收到了，但是我还没准备好，请继续你等我的消息。这个时候客户端就进入FIN_WAIT_2 状态，继续等待服务器端的FIN报文。 第三次挥手：当服务器端确定数据已发送完成，则向客户端发送FIN=N报文，告诉客户端，好了，我这边数据发完了，准备好关闭连接了。服务器端进入LAST_ACK状态。 第四次挥手：客户端收到FIN=N报文后，就知道可以关闭连接了，但是他还是不相信网络，怕服务器端不知道要关闭，所以发送ack=N+1后进入TIME_WAIT状态，如果Server端没有收到ACK则可以重传。服务器端收到ACK后，就知道可以断开连接了。客户端等待了2MSL后依然没有收到回复，则证明服务器端已正常关闭，那好，我客户端也可以关闭连接了。最终完成了四次握手。 上面是一方主动关闭，另一方被动关闭的情况，实际中还会出现同时发起主动关闭的情况， 具体流程如下图： 关于TCP协议中三次握手中的大写ACK和小写ack number的区别 在三次握手发送的数据包中有两个ACK值（Acknowledgement），人们习惯一个大写，一个小写来加以区分。大小写只是为了便于区分 一个是确认值(Acknowledgement)，为1便是确认连接。 另一个是确认编号(Acknowledgement Number)，即接收到的上一次远端主机传来的seq然后+1，再发送给远端主机。提示远端主机已经成功接收上一次所有数据。 三次握手的数据包 第一次握手 红框内为第一次握手时IP为192.168.56.1的请求端（请求连接端）发送的seq，值为0（实际中此值不一定为0） 第二次握手 红框内为第二次握手时IP为192.168.56.130的服务端（被请求连接端）发送的seq，因为是服务端发给请求端的一个新的seq，所以值为0（实际中此值不一定为0） 蓝框内为Ack（Acknowledgement Number确认编号）即我理解的小写的ack，值为第一次握手时请求端发送来的seq+1即0+1=1 第三次握手 红框内为第三次握手时IP为192.168.56.1的请求端（请求连接端）发送的seq，因为第一次握手时它发送给服务端的seq为0（黄框内），在上次的基础上+1，值就是1。 蓝框内的Ack（Acknowledgement Number确认编号）还是我理解的小写的ack，值为第二次握手时请求端发来的seq+1，即绿框中的seq+1，值为0+1=1 那么问题来了，那个起确认连接作用的确认值即我理解的那个大写的ACK在哪呢？ 在这里，展开看一下： 对照网上找到的关于第二次握手的标志位的一张图可以看出： 确认位即ACK，为1即为确认进行连接 同步位即SYN，从第一次握手时，此位就为1 下面是网上找到的三次握手的标志图，供参考： 第一次握手的标志位 我们可以看到标志位里面只有个同步位，也就是在做请求(SYN) 第二次握手的标志位 我们可以看到标志位里面有个确认位和同步位，也就是在做应答(SYN + ACK) 第三次握手的标志位 我们可以看到标志位里面只有个确认位，也就是再做再次确认(ACK) 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mysql/mysql基础/1.mysql基本操作.html":{"url":"db/mysql/mysql基础/1.mysql基本操作.html","title":"1.mysql基本操作","keywords":"","body":"mysql基础 mysql基本操作 Mysql 关系型数据库，表跟表之间可以建立关系 库-->表：列(字段 faield) ​ 行(记录 record) 1.连接mysql mysql -u用户名 -p密码 [root@mysql ~]# mysql -u root -p Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 32 Server version: 5.6.40 MySQL Community Server (GPL) Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> 2.设置root密码 方法一 命令行设置 mysqladmin -uroot password '密码' 方法二 进入mysql设置 set password = password('密码'); 3.mysql初始安全设置 mysql_secure_installation [root@mysql ~]# mysql_secure_installation Enter current password for root (enter for none): #输入root密码 Change the root password? [Y/n] #是否改变root密码 Remove anonymous users? [Y/n] #是否移除匿名用户 Disallow root login remotely? [Y/n] #是否允许root远程登陆 Remove test database and access to it? [Y/n] #是否移除test库并且不能访问 Reload privilege tables now? [Y/n] #是否重新加载权限表 Enter current password for root (enter for none): #输入root密码 4.mysql文件(yum安装) [root@mysql ~]# cd /var/lib/mysql/ [root@mysql mysql]# ls ibdata1 ib_logfile0 ib_logfile1 mysql mysql.sock ibdata1 #InnoDB存储引擎的系统表空间，存放InnoDB表的数据、回滚段 ib_logfile0、ib_logfile1 #InnoDB日志文件组 mysql #数据库 库名字 mysql.sock #mysql的socket文件，用于本机用户登陆mysql mysql主配置文件 /etc/my.cnf 5.库的管理 5.1创建数据库 create database 数据库名 mysql> create database DB1; Query OK, 1 row affected (0.00 sec) mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | DB1 | | mysql | | performance_schema | | sys | +--------------------+ 5 rows in set (0.05 sec) 5.2删除数据库 drop database 数据库名 mysql> drop database DB1; Query OK, 0 rows affected (0.00 sec) mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | +--------------------+ 4 rows in set (0.09 sec) 5.3查询数据库 show databases mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | +--------------------+ 2 rows in set (0.00 sec) 5.4使用数据库 use 数据库名 mysql> use DB1; Database changed mysql> select database(); #查看当前使用哪个数据库 +------------+ | database() | +------------+ | DB1 | +------------+ 1 row in set (0.00 sec) 6.表的管理 6.1创建表 create table 表名(列名1 数据类型,列名2 数据类型); mysql> create table t1(id int(3),name char(30),sex enum('M','F'),hobby set('a','b','c')); Query OK, 0 rows affected (0.03 sec) #desc 表名 //描述表 mysql> desc t1; +-------+------------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+------------------+------+-----+---------+-------+ | id | int(3) | YES | | NULL | | | name | char(30) | YES | | NULL | | | sex | enum('M','F') | YES | | NULL | | | hobby | set('a','b','c') | YES | | NULL | | +-------+------------------+------+-----+---------+-------+ 4 rows in set (0.13 sec) #insert into 表名 values(......); //向表中插入数据 mysql> insert into t1 values(1,'xiaoming','M','a,b,c'); Query OK, 1 row affected (0.00 sec) mysql> select * from t1; +----+----------+-----+-------+ | id | name | sex | hobby | +----+----------+-----+-------+ | 1 | xiaoming | M | a,b,c | +----+----------+-----+-------+ 1 row in set (0.12 sec) 6.2删除表 删除一个表 drop table 表名 删除多个表 drop table 表1,表2，。。。表n; #删除一个表 mysql> show tables; +---------------+ | Tables_in_db1 | +---------------+ | t1 | +---------------+ 1 row in set (0.13 sec) mysql> drop table t1; Query OK, 0 rows affected (0.12 sec) #删除多个表 mysql> show tables; +---------------+ | Tables_in_db1 | +---------------+ | t1 | | t2 | +---------------+ 2 rows in set (0.16 sec) mysql> drop table t1,t2; Query OK, 0 rows affected (0.20 sec) 6.3修改表 6.3.1增加列 alter table 表名 add 列名 数据类型; #查看t1表，此时表中只有一个列id，现在想增加一个列name mysql> desc t1; +-------+--------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+--------+------+-----+---------+-------+ | id | int(3) | YES | | NULL | | +-------+--------+------+-----+---------+-------+ 1 row in set (0.10 sec) #给t1表增加列name mysql> alter table t1 add name char(10); Query OK, 0 rows affected (0.15 sec) Records: 0 Duplicates: 0 Warnings: 0 #查看t1表，已经增加name列 mysql> desc t1; +-------+----------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+----------+------+-----+---------+-------+ | id | int(3) | YES | | NULL | | | name | char(10) | YES | | NULL | | +-------+----------+------+-----+---------+-------+ 2 rows in set (0.10 sec) add增加列默认是在最后边添加，如果需要指定追到的位置需要做以下操作 #t2表内容如下，现在要追加一个phone列，追加到name列的后边 mysql> desc t2; +---------+----------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +---------+----------+------+-----+---------+-------+ | id | int(11) | YES | | NULL | | | name | char(10) | YES | | NULL | | | address | char(30) | YES | | NULL | | +---------+----------+------+-----+---------+-------+ 3 rows in set (0.01 sec) #需要用到after关键字，此语句表明在name列后追加phone列 mysql> alter table t2 add phone char(11) after name; Query OK, 0 rows affected (0.04 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql> desc t2; +---------+----------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +---------+----------+------+-----+---------+-------+ | id | int(11) | YES | | NULL | | | name | char(10) | YES | | NULL | | | phone | char(11) | YES | | NULL | | | address | char(30) | YES | | NULL | | +---------+----------+------+-----+---------+-------+ 4 rows in set (0.00 sec) #如果要追加到第一列，需要用到first关键字 mysql> alter table t2 add sex enum('F','M') first; Query OK, 0 rows affected (0.05 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql> desc t2; +---------+---------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +---------+---------------+------+-----+---------+-------+ | sex | enum('F','M') | YES | | NULL | | | id | int(11) | YES | | NULL | | | name | char(10) | YES | | NULL | | | phone | char(11) | YES | | NULL | | | address | char(30) | YES | | NULL | | +---------+---------------+------+-----+---------+-------+ 5 rows in set (0.00 sec) ⚠️⚠️⚠️ 修改列中不支持before，只有after和first 6.3.2删除列 alter table 表名 drop 列名; #查看t1表，表中有两个列id和name,现在要删除name列 mysql> desc t1; +-------+----------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+----------+------+-----+---------+-------+ | id | int(3) | YES | | NULL | | | name | char(10) | YES | | NULL | | +-------+----------+------+-----+---------+-------+ 2 rows in set (0.10 sec) #删除name列 mysql> alter table t1 drop name; Query OK, 0 rows affected (0.14 sec) Records: 0 Duplicates: 0 Warnings: 0 #查看t1表name列已经删除 mysql> desc t1; +-------+--------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+--------+------+-----+---------+-------+ | id | int(3) | YES | | NULL | | +-------+--------+------+-----+---------+-------+ 1 row in set (0.12 sec) 6.3.3修改列名 alter table 表名 change 旧列名 新列名 数据类型; change既可以修改列名，又可以修改列类型 #查看t1表，表中有id和name两个列，现在要将name列修改为address列 mysql> desc t1; +-------+----------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+----------+------+-----+---------+-------+ | id | int(3) | YES | | NULL | | | name | char(10) | YES | | NULL | | +-------+----------+------+-----+---------+-------+ 2 rows in set (0.10 sec) #修改name列 mysql> alter table t1 change name address varchar(30); Query OK, 0 rows affected (0.19 sec) Records: 0 Duplicates: 0 Warnings: 0 #查看t1表，原name列已经修改为address，列类型已由char修改为varchar mysql> desc t1; +---------+-------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +---------+-------------+------+-----+---------+-------+ | id | int(3) | YES | | NULL | | | address | varchar(30) | YES | | NULL | | +---------+-------------+------+-----+---------+-------+ 2 rows in set (0.17 sec) 6.3.4修改列的数据类型 alter table 表名 modify 列名 新列数据类型; #t1表中有id列和address列，现在要把address列的数据类型由varchar改为char mysql> desc t1; +---------+-------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +---------+-------------+------+-----+---------+-------+ | id | int(3) | YES | | NULL | | | address | varchar(30) | YES | | NULL | | +---------+-------------+------+-----+---------+-------+ 2 rows in set (0.16 sec) #修改address列数据类型为char mysql> alter table t1 modify address char(20); Query OK, 0 rows affected (0.22 sec) Records: 0 Duplicates: 0 Warnings: 0 #查看t1表，address列的数据类型已经修改为char mysql> desc t1; +---------+----------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +---------+----------+------+-----+---------+-------+ | id | int(3) | YES | | NULL | | | address | char(20) | YES | | NULL | | +---------+----------+------+-----+---------+-------+ 2 rows in set (0.19 sec) 6.3.5修改表名 rename table 旧表名 to 新表名 #查看表，现在要将表t1修改为table1 mysql> show tables; +---------------+ | Tables_in_db1 | +---------------+ | t1 | +---------------+ 1 row in set (0.14 sec) #修改表t1为table1 mysql> rename table t1 to table1; Query OK, 0 rows affected (0.16 sec) mysql> show tables; +---------------+ | Tables_in_db1 | +---------------+ | table1 | +---------------+ 1 row in set (0.18 sec) 6.4查看表 show tables #先进入一个库 mysql> use db1; Database changed #查看库中所有的表 mysql> show tables; +---------------+ | Tables_in_db1 | +---------------+ | t1 | +---------------+ 1 row in set (0.18 sec) 7.数据管理 7.1增加数据 insert into 表名 values(......); 方式一 直接插入值 #查看表t1，现在是一张空表 mysql> desc t1; +---------+----------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +---------+----------+------+-----+---------+-------+ | id | int(3) | YES | | NULL | | | address | char(20) | YES | | NULL | | +---------+----------+------+-----+---------+-------+ 2 rows in set (0.17 sec) mysql> select * from t1; Empty set //向表中插入数据，插入一条 mysql> insert into t1 values(1,'北京'); Query OK, 1 row affected (0.19 sec) //向表中插入数据，插入多条 mysql> insert into t1 values(2,'上海'),(3,'广州'),(4,'深圳'); Query OK, 3 rows affected (0.15 sec) Records: 3 Duplicates: 0 Warnings: 0 //查看t1表中的数据 mysql> select * from t1; +----+---------+ | id | address | +----+---------+ | 1 | 北京 | | 2 | 上海 | | 3 | 广州 | | 4 | 深圳 | +----+---------+ 4 rows in set (0.16 sec) 方式二 从别的表中选择数据插入 #创建t1表 mysql> create table t1(id int primary key auto_increment,address char(10)); Query OK, 0 rows affected (0.02 sec) //向表中插入数据 mysql> insert into t1(address) values('北京'),('杭州'),('深圳'); Query OK, 3 rows affected (0.00 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql> select * from t1; +----+---------+ | id | address | +----+---------+ | 1 | 北京 | | 2 | 杭州 | | 3 | 深圳 | +----+---------+ 3 rows in set (0.00 sec) #创建t2表 mysql> create table t2(id int primary key auto_increment,address char(10)); Query OK, 0 rows affected (0.02 sec) //将t1表中的内容插入到t2表中 mysql> insert into t2(select * from t1); Query OK, 3 rows affected (0.01 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql> select * from t2; +----+---------+ | id | address | +----+---------+ | 1 | 北京 | | 2 | 杭州 | | 3 | 深圳 | +----+---------+ 3 rows in set (0.00 sec) ⚠️如果两个表中的字段不一致，从另一张表中插入数据的时候需要手动指定字段 #创建t3表 mysql> create table t3(id int primary key auto_increment,address char(10),qnum tinyint); Query OK, 0 rows affected (0.02 sec) //此时想插入t1表的数据，需要手动指定一下两张表中的共同字段 mysql> insert into t3(id,address) (select * from t1); Query OK, 3 rows affected (0.01 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql> select * from t3; +----+---------+------+ | id | address | qnum | +----+---------+------+ | 1 | 北京 | NULL | | 2 | 杭州 | NULL | | 3 | 深圳 | NULL | +----+---------+------+ 3 rows in set (0.00 sec) 7.2删除数据 delete from 表名 where 条件; #查看t1表中的数据 mysql> select * from t1; +----+---------+ | id | address | +----+---------+ | 1 | 北京 | | 2 | 上海 | | 3 | 广州 | | 4 | 深圳 | +----+---------+ 4 rows in set (0.16 sec) //删除表中地址为上海的数据 mysql> delete from t1 where id=2; Query OK, 1 row affected (0.16 sec) //查看t1表中内容 mysql> select * from t1; +----+---------+ | id | address | +----+---------+ | 1 | 北京 | | 3 | 广州 | | 4 | 深圳 | +----+---------+ 3 rows in set (0.16 sec) #再次新建t1表 ysql> create table t1(id int primary key auto_increment,address char(10)); Query OK, 0 rows affected (0.02 sec) //向t1表中插入数据 mysql> insert into t1(address) values('北京'),('上海'),('广州'); Query OK, 3 rows affected (0.00 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql> select * from t1; +----+---------+ | id | address | +----+---------+ | 1 | 北京 | | 2 | 上海 | | 3 | 广州 | +----+---------+ //delete方式清空t1表 mysql> delete from t1; Query OK, 3 rows affected (0.00 sec) mysql> select * from t1; Empty set (0.00 sec) //向表中插入数据 mysql> insert into t1(address) values('杭州'),('深圳'); Query OK, 2 rows affected (0.00 sec) Records: 2 Duplicates: 0 Warnings: 0 //发现并没有清空自增字段，如果需要清空自增字段，需要用到truncate语句 mysql> select * from t1; +----+---------+ | id | address | +----+---------+ | 4 | 杭州 | | 5 | 深圳 | +----+---------+ 2 rows in set (0.00 sec) truncate table 表名 清空表并重置自增字段 #创建一个t1表 mysql> create table t1(id int,address char(10)); Query OK, 0 rows affected (0.02 sec) mysql> insert into t1 values(1,'北京'); Query OK, 1 row affected (0.00 sec) mysql> select * from t1; +------+---------+ | id | address | +------+---------+ | 1 | 北京 | +------+---------+ 1 row in set (0.00 sec) #truncate清空表，两种写法，truncate后边的table可以不加 mysql> truncate t1; Query OK, 0 rows affected (0.01 sec) mysql> truncate table t1; Query OK, 0 rows affected (0.03 sec) //查看表t1，已经清空 mysql> select * from t1; Empty set (0.00 sec) #再创建一个t2表，表中有自增字段 mysql> create table t2(id int primary key auto_increment,address char(10)); Query OK, 0 rows affected (0.02 sec) //向表中插入数据 mysql> insert into t2(address) values('杭州'),('深圳'); Query OK, 2 rows affected (0.00 sec) Records: 2 Duplicates: 0 Warnings: 0 mysql> select * from t2; +----+---------+ | id | address | +----+---------+ | 1 | 杭州 | | 2 | 深圳 | +----+---------+ 2 rows in set (0.00 sec) //truncate清空表 mysql> truncate t2; Query OK, 0 rows affected (0.02 sec) //向表中插入数据 mysql> insert into t2(address) values('杭州'),('深圳'); Query OK, 2 rows affected (0.01 sec) Records: 2 Duplicates: 0 Warnings: 0 //truncate清空表的方式会将表中的自增字段同时删除，而delete from 表名的方式不可以删除自增 mysql> select * from t2; +----+---------+ | id | address | +----+---------+ | 1 | 杭州 | | 2 | 深圳 | +----+---------+ 2 rows in set (0.00 sec) 7.3修改数据 update 表名 set 旧值=新值 where 条件; #查看表t1，现在要将表中的上海修改为杭州 mysql> select * from t1; +----+---------+ | id | address | +----+---------+ | 1 | 北京 | | 2 | 上海 | | 3 | 广州 | | 4 | 深圳 | +----+---------+ 4 rows in set (0.12 sec) #修改表t1中地址为上海的列为杭州 mysql> update t1 set address='杭州' where id=2; Query OK, 1 row affected (0.18 sec) Rows matched: 1 Changed: 1 Warnings: 0 #查看表t1，上海已经修改为杭州 mysql> select * from t1; +----+---------+ | id | address | +----+---------+ | 1 | 北京 | | 2 | 杭州 | | 3 | 广州 | | 4 | 深圳 | +----+---------+ 4 rows in set (0.13 sec) 7.4查询数据 select 列名 from 表名 where 条件 #查询表中所有内容 mysql> select * from t1; +----+---------+ | id | address | +----+---------+ | 1 | 北京 | | 2 | 杭州 | | 3 | 广州 | | 4 | 深圳 | +----+---------+ 4 rows in set (0.14 sec) #根据条件查询 查询t1表中id=1的address列 mysql> select address from t1 where id=1; +---------+ | address | +---------+ | 北京 | +---------+ 1 row in set (0.18 sec) 8.mysql常用函数 常用函数 user() #查看当前用户 database() #查看当前所属库 version() #查看MySQL版本 now() #系统时间 sum() #求和 avg() #平均值 max() #最大值 min() #最小值 count() #统计数量 8.1user() 查看当前用户 mysql> select user(); +----------------+ | user() | +----------------+ | root@localhost | +----------------+ 1 row in set (0.00 sec) 当前登陆用户是root，登陆的主机是本机 8.2database() 查看当前所在库 mysql> select database(); +------------+ | database() | +------------+ | db1 | +------------+ 1 row in set (0.12 sec) 当前所在数据库是db1 8.3version() 查看mysql版本 mysql> select version(); +-----------+ | version() | +-----------+ | 5.7.22 | +-----------+ 1 row in set (0.11 sec) 当前mysql版本是5.7.22 8.4now() 查看当前系统时间 mysql> select now(); +---------------------+ | now() | +---------------------+ | 2018-10-25 21:10:18 | +---------------------+ 1 row in set (0.11 sec) 当前系统时间是2018年10月25日21时10分18秒 8.5sum() 求和 #查看student表 mysql> select * from student; +------+--------+-------+ | id | name | score | +------+--------+-------+ | 1 | 小明 | 99 | | 2 | 小红 | 80 | | 3 | 小丽 | 70 | | 4 | 小强 | 59 | | 5 | 小洲 | 66 | +------+--------+-------+ 5 rows in set (0.00 sec) #求学生表中所有人的总成绩 mysql> select sum(score) as total_points from student; +--------------+ | total_points | +--------------+ | 374 | +--------------+ #求学生表中成绩大于70分的总和 mysql> select sum(score) as total_points from student where score>=70; +--------------+ | total_points | +--------------+ | 249 | +--------------+ 1 row in set (0.00 sec) 8.6avg() 平均值 #查看student表 mysql> select * from student; +------+--------+-------+ | id | name | score | +------+--------+-------+ | 1 | 小明 | 99 | | 2 | 小红 | 80 | | 3 | 小丽 | 70 | | 4 | 小强 | 59 | | 5 | 小洲 | 66 | +------+--------+-------+ 5 rows in set (0.00 sec) #求所有人分数的平均值 mysql> select avg(score) as avg_points from student; +------------+ | avg_points | +------------+ | 74.8 | +------------+ 1 row in set (0.00 sec) #求70分以上的人的分数平均值 mysql> select avg(score) as avg_points from student where score>=70; +------------+ | avg_points | +------------+ | 83 | +------------+ 1 row in set (0.00 sec) 8.7max() 最大值 #查看student表 mysql> select * from student; +------+--------+-------+ | id | name | score | +------+--------+-------+ | 1 | 小明 | 99 | | 2 | 小红 | 80 | | 3 | 小丽 | 70 | | 4 | 小强 | 59 | | 5 | 小洲 | 66 | +------+--------+-------+ 5 rows in set (0.00 sec) #查询student表中分数最高的 mysql> select max(score) from student; +------------+ | max(score) | +------------+ | 99 | +------------+ 1 row in set (0.00 sec) 8.8min() 最小值 #查看student表 mysql> select * from student; +------+--------+-------+ | id | name | score | +------+--------+-------+ | 1 | 小明 | 99 | | 2 | 小红 | 80 | | 3 | 小丽 | 70 | | 4 | 小强 | 59 | | 5 | 小洲 | 66 | +------+--------+-------+ 5 rows in set (0.00 sec) #传student表中分数最低的 mysql> select min(score) from student; +------------+ | min(score) | +------------+ | 59 | +------------+ 1 row in set (0.00 sec) 8.9count() 统计数量 #查看student表 mysql> select * from student; +------+--------+-------+ | id | name | score | +------+--------+-------+ | 1 | 小明 | 99 | | 2 | 小红 | 80 | | 3 | 小丽 | 70 | | 4 | 小强 | 59 | | 5 | 小洲 | 66 | +------+--------+-------+ 5 rows in set (0.00 sec) #查询student表中分数大于60的人数 mysql> select count(*) from student where score>60; +----------+ | count(*) | +----------+ | 4 | +----------+ 1 row in set (0.00 sec) 9.mysql数据查询操作 9.1数学运算 + 加法 mysql> select 1+1; +-----+ | 1+1 | +-----+ | 2 | +-----+ 1 row in set (0.00 sec) - 减法 mysql> select 100-1; +-------+ | 100-1 | +-------+ | 99 | +-------+ 1 row in set (0.00 sec) * 乘法 mysql> select 100*3; +-------+ | 100*3 | +-------+ | 300 | +-------+ 1 row in set (0.00 sec) / 除法 mysql> select 100/3; +---------+ | 100/3 | +---------+ | 33.3333 | +---------+ 1 row in set (0.00 sec) % 取余 mysql> select 7%3; +------+ | 7%3 | +------+ | 1 | +------+ 1 row in set (0.00 sec) pow 幂运算 mysql> select pow(3,3); +----------+ | pow(3,3) | +----------+ | 27 | +----------+ 1 row in set (0.00 sec) ⚠️mysql中不支持**方式的幂运算，需要用到pow方法 9.2比较运算 > 大于 #返回值为0表示结果为假 mysql> select 3>6; +-----+ | 3>6 | +-----+ | 0 | +-----+ 1 row in set (0.01 sec) #返回值为1表示结果为真 mysql> select 6>3; +-----+ | 6>3 | +-----+ | 1 | +-----+ 1 row in set (0.00 sec) #返回值为1表示结果为真 mysql> select 6>3; +-----+ | 6>3 | +-----+ | 1 | +-----+ 1 row in set (0.00 sec) #返回值为0表示结果为假 mysql> select 6 >= 大于等于 #返回值为0表示结果为假 mysql> select 6 select 6>=3; +------+ | 6>=3 | +------+ | 1 | +------+ 1 row in set (0.00 sec) #返回值为1表示结果为真 mysql> select 6 select 6 = 等于 #返回值为1表示结果为真 mysql> select 5=5; +-----+ | 5=5 | +-----+ | 1 | +-----+ 1 row in set (0.00 sec) #返回值为0表示结果为假 mysql> select 5=6; +-----+ | 5=6 | +-----+ | 0 | +-----+ 1 row in set (0.00 sec) != 不等于 #返回值为1表示结果为真 mysql> select 3!=2; +------+ | 3!=2 | +------+ | 1 | +------+ 1 row in set (0.01 sec) #返回值为0表示结果为假 mysql> select 3!=3; +------+ | 3!=3 | +------+ | 0 | +------+ 1 row in set (0.00 sec) 9.3逻辑运算 && 与 #返回值为1表示结果为真 mysql> select 3>1 && 5>1; +------------+ | 3>1 && 5>1 | +------------+ | 1 | +------------+ 1 row in set (0.00 sec) #返回值为0表示结果为假 mysql> select 3>1 && 51 && 5 || 或 #返回值为1表示结果为真 或关系中有一个为真结果就为真 mysql> select 3>1 || 51 || 5 select 3 not 非 #此写法不正确 mysql> select 3>6 not 3>5; ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '3>5' at line 1 #返回值为1表示结果为真 mysql> select not 3>5; +---------+ | not 3>5 | +---------+ | 1 | +---------+ 1 row in set (0.00 sec) #返回值为0表示结果为假 mysql> select not 5>3; +---------+ | not 5>3 | +---------+ | 0 | +---------+ 1 row in set (0.00 sec) 9.4排序 order by order by 列名 #默认升序 order by 列名 desc #降序 #student表内容如下 mysql> select * from student; +------+--------+-------+ | id | name | score | +------+--------+-------+ | 1 | 小明 | 99 | | 2 | 小红 | 79 | | 3 | 小丽 | 88 | | 4 | 小强 | 59 | | 5 | 小洲 | 66 | +------+--------+-------+ 5 rows in set (0.00 sec) #按照成绩升序排序 mysql> select * from student order by score; +------+--------+-------+ | id | name | score | +------+--------+-------+ | 4 | 小强 | 59 | | 5 | 小洲 | 66 | | 2 | 小红 | 79 | | 3 | 小丽 | 88 | | 1 | 小明 | 99 | +------+--------+-------+ 5 rows in set (0.00 sec) #按照成绩降序排序 mysql> select * from student order by score desc; +------+--------+-------+ | id | name | score | +------+--------+-------+ | 1 | 小明 | 99 | | 3 | 小丽 | 88 | | 2 | 小红 | 79 | | 5 | 小洲 | 66 | | 4 | 小强 | 59 | +------+--------+-------+ 5 rows in set (0.00 sec) 9.5限制 limit limit用于限制查询结果的条数 #student表内容如下 mysql> select * from student; +------+--------+-------+ | id | name | score | +------+--------+-------+ | 1 | 小明 | 99 | | 2 | 小红 | 79 | | 3 | 小丽 | 88 | | 4 | 小强 | 59 | | 5 | 小洲 | 66 | +------+--------+-------+ 5 rows in set (0.00 sec) #限制查询结果显示3条 mysql> select * from student limit 3; +------+--------+-------+ | id | name | score | +------+--------+-------+ | 1 | 小明 | 99 | | 2 | 小红 | 79 | | 3 | 小丽 | 88 | +------+--------+-------+ 3 rows in set (0.00 sec) 9.6分组 group by 9.6.1group by简单使用示例 #t1表内容如下 mysql> select * from t1; +------+--------+-------+ | id | name | score | +------+--------+-------+ | 1 | 小明 | 99.9 | | 2 | 小明 | 60.6 | | 3 | 小红 | 70 | | 4 | 小洲 | 88.5 | | 5 | 小明 | 77.5 | | 6 | 小洲 | 59 | +------+--------+-------+ 6 rows in set (0.00 sec) #根据姓名分组，group by会将列中值相同的行合并 mysql> select name from t1 group by name; +--------+ | name | +--------+ | 小明 | | 小洲 | | 小红 | +--------+ 3 rows in set (0.00 sec) #来个错误示例 mysql> select * from t1 group by name; ERROR 1055 (42000): Expression #1 of SELECT list is not in GROUP BY clause and contains nonaggregated column 'db1.t1.id' which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by 错误原因： group by语句会将列中值相同的行合并，例如上边的t1表中，有多个名字相同的人小明，group by已经将多个小明的值合并为一个，但是小明是姓名相同的不同的人，成绩也不同，因此查询的时候会报错 9.6.2group by+having 分组后再过滤 #创建score表 mysql> create table score(sname char(10), cname char(10), grade int); Query OK, 0 rows affected (0.03 sec) //向表中插入数据 mysql> insert into score(sname,cname,grade) values ('张三','数学',80), ('张三','语文',90), ('张三','英语',70), ('张三','物理',60), ('李四','数学',66), ('李四','语文',60), ('李四','英语',80), ('李四','物理',90), ('刘五','语文',99), ('刘五','数学',50), ('刘五','英语',50), ('刘五','物理',89), ('罗六','语文',99), ('罗六','数学',80), ('罗六','物理',78), ('罗六','英语',96), ('许七','数学',96), ('许七','语文',96), ('许七','英语',96), ('许七','物理',96); Query OK, 20 rows affected (0.03 sec) Records: 20 Duplicates: 0 Warnings: 0 //查询平均成绩大于90分并且语文课95分以上的学生名和平均成绩 mysql> select sname,avg(grade) from score where sname in (select sname from score where cname='语文' and grade > 95) group by sname; +--------+------------+ | sname | avg(grade) | +--------+------------+ | 刘五 | 72.0000 | | 罗六 | 88.2500 | | 许七 | 96.0000 | +--------+------------+ 3 rows in set (0.00 sec) mysql> select sname,avg(grade) from score where sname in (select sname from score where cname='语文' and grade > 95) group by sname having avg(grade) > 90; +--------+------------+ | sname | avg(grade) | +--------+------------+ | 许七 | 96.0000 | +--------+------------+ 1 row in set (0.00 sec) 9.6.3group by+group_concat函数使用示例 #创建book表 mysql> create table book(书名 char(20) not null, 作者 char(10) not null, 出版社 char(20) not null, 价格 int unsigned, 出版日期 date); Query OK, 0 rows affected (0.02 sec) #向book表中插入数据 mysql> insert into book values( '那个女孩','小明','工业出版社',80,'2016-07-01'), ('阿三传说','小洲','人民出版社',10,'2019-09-09'), ('奔跑的草泥马','小明','盗版出版社',60,'2017-07-12'), ('上课必备三件套','小颖','人民出版社',250,'2018-11-11'), ('童话故事','','工业出版社',50,'2019-09-01'); Query OK, 5 rows affected (0.01 sec) Records: 5 Duplicates: 0 Warnings: 0 mysql> select * from book; +-----------------------+--------+-----------------+--------+--------------+ | 书名 | 作者 | 出版社 | 价格 | 出版日期 | +-----------------------+--------+-----------------+--------+--------------+ | 那个女孩 | 小明 | 工业出版社 | 80 | 2016-07-01 | | 阿三传说 | 小洲 | 人民出版社 | 10 | 2019-09-09 | | 奔跑的草泥马 | 小明 | 盗版出版社 | 60 | 2017-07-12 | | 上课必备三件套 | 小颖 | 人民出版社 | 250 | 2018-11-11 | | 童话故事 | | 工业出版社 | 50 | 2019-09-01 | +-----------------------+--------+-----------------+--------+--------------+ 5 rows in set (0.00 sec) //查询各出版社出版的所有图书，这里需要用到group_concat()函数 mysql> select 出版社,group_concat(书名) from book group by 出版社; +-----------------+------------------------------------+ | 出版社 | group_concat(书名) | +-----------------+------------------------------------+ | 人民出版社 | 阿三传说,上课必备三件套 | | 工业出版社 | 那个女孩,童话故事 | | 盗版出版社 | 奔跑的草泥马 | +-----------------+------------------------------------+ 3 rows in set (0.00 sec) 9.7检索区间 between...and... #student表内容如下 mysql> select * from student; +------+--------+-------+ | id | name | score | +------+--------+-------+ | 1 | 小明 | 99 | | 2 | 小红 | 79 | | 3 | 小丽 | 88 | | 4 | 小强 | 59 | | 5 | 小洲 | 66 | +------+--------+-------+ 5 rows in set (0.00 sec) #查询成绩在60分到90分之间的学生姓名 mysql> select name,score from student where score between 60 and 90; +--------+-------+ | name | score | +--------+-------+ | 小红 | 79 | | 小丽 | 88 | | 小洲 | 66 | +--------+-------+ 3 rows in set (0.00 sec) 9.8判断是否在范围 in not in #in 在一个范围内 //查看t1表 mysql> select * from t1; +------+---------+------+ | id | name | age | +------+---------+------+ | 1 | 小明 | 20 | | 2 | 大B哥 | 30 | | 3 | 小B哥 | 25 | | 4 | 龙哥 | 38 | | 5 | 小颖 | 18 | | 6 | 小洲 | 19 | +------+---------+------+ 6 rows in set (0.00 sec) //查询年龄是18、20、30岁之间的人的信息 mysql> select * from t1 where age in(18,19,30); +------+---------+------+ | id | name | age | +------+---------+------+ | 2 | 大B哥 | 30 | | 5 | 小颖 | 18 | | 6 | 小洲 | 19 | +------+---------+------+ 3 rows in set (0.00 sec) #not in 不在一个范围内 //查询年龄不在18、20、30岁之间的人的信息 mysql> select * from t1 where age not in(18,19,30); +------+---------+------+ | id | name | age | +------+---------+------+ | 1 | 小明 | 20 | | 3 | 小B哥 | 25 | | 4 | 龙哥 | 38 | +------+---------+------+ 3 rows in set (0.00 sec) 10.mysql的API及接口自带命令 API：应用程序接口 10.1mysql API mysql API就是能够不进入mysql而在命令行中执行sql语句，在命令行中使用-e选项 mysqlAPI示例1，在命令行中使用SQL语句 [root@mysql ~]# mysql -uroot -p123 mysql -e \"show databases;\" +--------------------+ | Database | +--------------------+ | information_schema | | DB1 | | mysql | | performance_schema | | test | +--------------------+ mysqlAPI示例2，php连接mysql 10.2mysql接口自带命令 以下命令在mysql中或者命令行执行都可以 help 或？ #查看帮助 \\G #格式化查看数据（key：value） \\T 或 tee #记录日志 \\c（5.7可以ctrl+c） #结束命令 \\s 或 status #查看状态信息 \\. 或 source #导入SQL数据 \\u或 use #使用数据库 \\q 或 exit 或 quit #退出 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mysql/mysql基础/2.mysql下载.html":{"url":"db/mysql/mysql基础/2.mysql下载.html","title":"2.mysql下载教程","keywords":"","body":"mysql官网可能会应为更新而导致下载界面跟本文不一致，请以官网为准 1.登陆mysql官网www.mysql.com,然后点击DOWNLOADS 2.点击[MySQL Community (GPL) Downloads »（社区版） 3.点击MySQL Community Server（MySQL社区服务器） 4.选择Looking for previous GA versions（存档版本），这项为选择旧版本mysql 5.选择相应的mysql版本，选择Linux-Generc（通用linxu 独立架构）这个界面只能下载当前版本的最后一个小版本 ⚠️这里下载的是mysql二进制包 6.下载指定的版本 点击Archived versions »(存档版本) 选择社区版 选择自己想要下载的版本、包类型(源码、二进制、rpm等)、安装平台 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mysql/mysql基础/3.CentOS7.5二进制安装MySQL-5.6.40.html":{"url":"db/mysql/mysql基础/3.CentOS7.5二进制安装MySQL-5.6.40.html","title":"MySQL-5.6.40","keywords":"","body":"CentOS7.5二进制安装MySQL-5.6.40 mysql-5.6.40二进制包下载地址 MD5值 10f61e60f8c42b6635e5c1f423bce8be https://cdn.mysql.com/archives/mysql-5.6/mysql-5.6.40-linux-glibc2.12-x86_64.tar.gz mysql-5.6.41二进制包下载地址 MD5值 b0ac6851908b5c17b6a283d10709fcfd https://cdn.mysql.com/archives/mysql-5.6/mysql-5.6.41-linux-glibc2.12-x86_64.tar.gz mysql-5.6.42二进制包下载地址 MD5值 fc8c6df660ba42b280c3b1d59bd8ee27 https://cdn.mysql.com/archives/mysql-5.6/mysql-5.6.42-linux-glibc2.12-x86_64.tar.gz 1.下载MySQL-5.6.40二进制包 wget https://cdn.mysql.com/archives/mysql-5.6/mysql-5.6.40-linux-glibc2.12-x86_64.tar.gz 2.解压缩mysql二进制包到/usr/local tar xf mysql-5.6.40-linux-glibc2.12-x86_64.tar.gz -C /usr/local 3.修改名称、做软连接 mv /usr/local/mysql-5.6.40-linux-glibc2.12-x86_64 /usr/local/mysql-5.6.40 ln -s /usr/local/mysql-5.6.40 /usr/local/mysql 4.创建mysql用户 #创建mysql用户 useradd mysql -s /bin/nologin -M 5.拷贝主配置文件 #备份/etc/my.cnf mv /etc/my.cnf /etc/my.cnf.old #拷贝主配置文件 cp /usr/local/mysql/support-files/my-default.cnf /etc/my.cnf 6.拷贝启动脚本 cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld 7.相关目录、文件授权 chown -R mysql.mysql /usr/local/mysql* chown mysql.mysql /etc/my.cnf 8.初始化mysql #初始化前安装依赖包 yum -y install autoconf #初始化mysql cd /usr/local/mysql/scripts && ./mysql_install_db --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data --user #指定mysql用户 --basedir #指定mysql安装目录 --datadir #指定mysql数据目录 9.添加mysql命令环境变量 #导出mysql命令环境变量 echo \"export PATH=/usr/local/mysql/bin:$PATH\" > /etc/profile.d/mysql.sh #使配置生效 source /etc/profile 10.配置systemd管理mysql cat > /etc/systemd/system/mysqld.service 11.启动mysql、检查启动 #重新加载systemd系统服务 systemctl daemon-reload #启动mysql systemctl start mysqld && systemctl enable mysqld #查看mysql端口 $ netstat -ntpl | grep 3306 tcp6 0 0 :::3306 :::* LISTEN 31349/mysqld 12.进入mysql并设置密码 #进入mysql mysql #设置mysql密码 mysql> set password='123'; Query OK, 0 rows affected (0.00 sec) mysql> flush privileges; Query OK, 0 rows affected (0.01 sec) 到此，mysql5.6.40二进制安装完成！！！ 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mysql/mysql基础/4.CentOS7.5二进制安装MySQL-5.7.22.html":{"url":"db/mysql/mysql基础/4.CentOS7.5二进制安装MySQL-5.7.22.html","title":"MySQL-5.7.22","keywords":"","body":"CentOS7.5二进制安装MySQL-5.7.22 mysql-5.7.22二进制包下载地址 MD5值 9ef7a05695f8b4ea29f8d077c3b415e2 https://cdn.mysql.com/archives/mysql-5.7/mysql-5.7.22-linux-glibc2.12-x86_64.tar.gz mysql-5.7.23二进制包下载地址 MD5值 d903d3dbf235b74059a4b3e216c71161 https://cdn.mysql.com/archives/mysql-5.7/mysql-5.7.23-linux-glibc2.12-x86_64.tar.gz mysql-5.7.24二进制包下载地址 MD5值 9ef7a05695f8b4ea29f8d077c3b415e2 https://cdn.mysql.com/archives/mysql-5.7/mysql-5.7.24-linux-glibc2.12-x86_64.tar.gz ⚠️⚠️⚠️ 二进制安装mysql的启动脚本和 安装目录/mysql/bin/mysqld_safe 这两个文件中都是默认/usr/local/mysql，如果安装目录不在/usr/local/下，需要修改这两个文件中的路径，即把/usr/local替换为mysql安装目录 sed -i 's#/usr/local#/application#g' /etc/init.d/mysql /application/mysql/bin/mysqld_safe 1.下载MySQL-5.7.22二进制包 wget https://cdn.mysql.com/archives/mysql-5.7/mysql-5.7.22-linux-glibc2.12-x86_64.tar.gz 2.解压缩mysql二进制包到/usr/local tar xf mysql-5.7.22-linux-glibc2.12-x86_64.tar.gz -C /usr/local 3.修改名称、做软连接 mv /usr/local/mysql-5.7.22-linux-glibc2.12-x86_64 /usr/local/mysql-5.7.22 && ln -s /usr/local/mysql-5.7.22 /usr/local/mysql 4.创建mysql用户 useradd -M -s /bin/nologin mysql 5.编辑主配置文件，myql-5.7.22二进制包默认没有mysql配置文件 ⚠️如果指定了mysql的socket文件位置，则必须添加[client]标签并同时指定socket文件位置，否则客户端会从/tmp下找socket文件 #备份/etc/my.cnf mv /etc/my.cnf /etc/my.cnf.old #以下配置为最精简版，可根据实际情况进行相应设置 cat >> /etc/my.cnf 6.创建socket文件目录 mkdir -p /var/lib/mysql 7.相关目录、文件授权 chown -R mysql.mysql /usr/local/mysql* /var/lib/mysql chown mysql.mysql /etc/my.cnf 8.拷贝启动脚本 cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld 9.初始化mysql /usr/local/mysql/bin/mysqld --initialize-insecure --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data --user #指定mysql用户 --basedir #指定mysql安装目录 --datadir #指定mysql数据目录 --initialize-insecure #不生成随机密码 ⚠️⚠️⚠️mysql-5.7.22初始化没有提示！！！ 10.添加mysql命令环境变量 #导出mysql命令环境变量 echo \"export PATH=/usr/local/mysql/bin:$PATH\" > /etc/profile.d/mysql.sh #使配置生效 source /etc/profile 11.配置systemd管理mysql cat >> /etc/systemd/system/mysqld.service 12.启动mysql、检查启动 #重新加载systemd系统服务 systemctl daemon-reload #启动mysql并加入开机自启 systemctl start mysqld && systemctl enable mysqld #查看mysql端口 $ netstat -ntpl | grep 3306 tcp6 0 0 :::3306 :::* LISTEN 31349/mysqld 13.进入mysql并设置密码 #进入mysql mysql #设置mysql密码 mysql> set password='123'; Query OK, 0 rows affected (0.00 sec) mysql> flush privileges; Query OK, 0 rows affected (0.01 sec) 到此，mysql5.7.22二进制安装完成！！！ 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mysql/mysql基础/5.CentOS7.5二进制安装MySQL-8.0.12.html":{"url":"db/mysql/mysql基础/5.CentOS7.5二进制安装MySQL-8.0.12.html","title":"MySQL-8.0.12","keywords":"","body":"CentOS7.5二进制安装MySQL-8.0.12 mysql-8.0.12二进制包下载地址 MD5值 58bcd8af8b9d966140430ae4c846df73 https://cdn.mysql.com/archives/mysql-8.0/mysql-8.0.12-linux-glibc2.12-x86_64.tar.xz mysql-8.0.13二进制包下载地址 MD5值 ea0b14eaf516784aa0f8af6015ccdbf2 https://cdn.mysql.com/archives/mysql-8.0/mysql-8.0.13-linux-glibc2.12-x86_64.tar.xz mysql-8.0.14二进制包下载地址 MD5值 b9a04efa353f4b16d5c034a4e6e73cc8 https://cdn.mysql.com/archives/mysql-8.0/mysql-8.0.14-linux-glibc2.12-x86_64.tar.xz 1.安装依赖包 yum -y install -y gcc gcc-c++ autoconf bison-devel ncurses-devel libaio-devel numactl 2.创建mysql用户 useradd -M -s /sbin/nologin mysql 3.下载mysql-8.0.12二进制包 wget https://downloads.mysql.com/archives/get/file/mysql-8.0.12-linux-glibc2.12-x86_64.tar.xz 4.解压缩mysql二进制包到/usr/local tar xf mysql-8.0.12-linux-glibc2.12-x86_64.tar.xz -C /usr/local/ 5.修改目录名称、修改mysql目录所有者、做软连接 mv mysql-8.0.12-linux-glibc2.12-x86_64 /usr/local/mysql-8.0.12 ln -s /usr/local/mysql-8.0.12/ /usr/local/mysql 6.编辑主配置文件，mysql-8.0.12默认没有主配置文件 ⚠️如果指定了mysql的socket文件位置，则必须添加[client]标签并同时指定socket文件位置，否则客户端会从/tmp下找socket文件 #备份原有/etc/my.cnf mv /etc/my.cnf /etc/my.cnf.old #以下为精简版主配置文件，后续根据实际情况修改 cat >> /etc/my.cnf 6.创建socket文件目录 mkdir -p /var/lib/mysql 7.相关目录、文件授权 chown -R mysql.mysql /usr/local/mysql* /var/lib/mysql chown mysql.mysql /etc/my.cnf 8.拷贝启动脚本 cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld 9.初始化mysql /usr/local/mysql/bin/mysqld --initialize-insecure --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data mysql8.0.12初始化没有提示！！！ --initialize --user #指定mysql用户 --basedir #指定mysql安装目录 --datadir #指定mysql数据目录 --initialize-insecure #不生成随机密码 10.添加mysql命令环境变量 #导出mysql命令环境变量 echo \"export PATH=/usr/local/mysql/bin:$PATH\" > /etc/profile.d/mysql.sh #使配置生效 source /etc/profile 11.配置systemd管理mysql cat > /etc/systemd/system/mysqld.service 12.启动mysql、检查启动 #重新加载systemd系统服务 systemctl daemon-reload #启动mysql并加入开机自启 systemctl start mysqld && systemctl enable mysqld #查看mysql端口 $ netstat -ntpl | grep 3306 tcp6 0 0 :::3306 :::* LISTEN 31349/mysqld 13.连接mysql并设置密码 #进入mysql mysql #设置mysql密码 mysql> set password='123'; Query OK, 0 rows affected (0.00 sec) mysql> flush privileges; Query OK, 0 rows affected (0.01 sec) 到此，mysql8.0.12二进制安装完成！！！ 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mysql/mysql基础/6.CentOS7.5编译安装MySQL-5.6.40.html":{"url":"db/mysql/mysql基础/6.CentOS7.5编译安装MySQL-5.6.40.html","title":"MySQL-5.6.40","keywords":"","body":"CentOS7.5编译安装MySQL-5.6.40 1.安装依赖包 [root@db01 ~]# yum install -y gcc gcc-c++ automake autoconf cmake bison-devel ncurses-devel libaio-devel 2.下载MySQL-5.6.40.tar.gz [root@db01 ~]# wget https://downloads.mysql.com/archives/get/file/mysql-5.6.40.tar.gz 3.解压缩 [root@db01 ~]# tar xf mysql-5.6.40.tar.gz 4.进入解压缩目录，进行编译安装 //进入到解压目录 [root@db01 ~]# cd mysql-5.6.40 //进行cmake [root@db01 mysql-5.6.40]# cmake . -DCMAKE_INSTALL_PREFIX=/usr/local/mysql-5.6.40 \\ > -DDEFAULT_CHARSET=utf8 \\ > -DDEFAULT_COLLATION=utf8_general_ci \\ > -DWITH_EXTRA_CHARSETS=all \\ > -DWITH_INNOBASE_STORAGE_ENGINE=1 \\ > -DWITH_FEDERATED_STORAGE_ENGINE=1 \\ > -DWITH_BLACKHOLE_STORAGE_ENGINE=1 \\ > -DWITHOUT_EXAMPLE_STORAGE_ENGINE=1 \\ > -DWITH_ZLIB=bundled \\ > -DWITH_SSL=bundled \\ > -DENABLED_LOCAL_INFILE=1 \\ > -DWITH_EMBEDDED_SERVER=1 \\ > -DENABLE_DOWNLOADS=1 \\ > -DWITH_DEBUG=0 //编译并安装 [root@db01 mysql-5.6.40]# make && make install 5.创建mysql用户和组并做mysql安装目录软连接 //创建mysql组 [root@db01 ~]# groupadd mysql //创建mysql用户 [root@db01 ~]# useradd -r -g mysql -s /bin/false mysql //修改mysql目录权限 [root@db01 ~]# chown -R mysql.mysql /usr/local/mysql-5.6.40 //做mysql安装目录软连接 [root@db01 ~]# ln -s /usr/local/mysql-5.6.40 /usr/local/mysql 6.初始化数据库 [root@db01 ~]# /usr/local/mysql/scripts/mysql_install_db --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data 7.拷贝mysql主配置文件 //备份/etc/my.cnf [root@db01 ~]# mv /etc/my.cnf /etc/my.cnf.old //拷贝mysql配置文件 [root@db01 ~]# cp /usr/local/mysql/support-files/my-default.cnf /etc/my.cnf 8.拷贝mysql启动文件 [root@db01 ~]# cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld 9.导出mysql命令环境变量 //最好不要直接追加到/etc/profile，可选择在/etc/profile.d/创建一个x.sh [root@db01 ~]# echo \"export PATH=/usr/local/mysql/bin:$PATH\" > /etc/profile.d/mysql.sh //使配置生效 [root@db01 ~]# source /etc/profile 10.启动mysql [root@db01 ~]# /etc/init.d/mysqld start 11.用systemd管理mysql //编辑/usr/lib/systemd/system/mysqld.service，写入以下几行 [root@db01 ~]# cat > /usr/lib/systemd/system/mysqld.service 到此，mysql5.6.40编译安装完成！！！ 扩展：一台主机mysql已经编译好，通过拷贝相关目录和文件的方式快速部署其他mysql实例 步骤： 1.几台机器的环境要一致，操作系统、硬件环境 2.拷贝mysql编译安装路径目录，本文为/usr/local/mysql-5.6.40 3.拷贝mysql配置文件、启动文件、mysql命令环境变量文件/etc/profile(或者在另外的mysql主机手动填写) 4.拷贝systemd管理文件 5.创建mysql用户和组 1.已经编译安装好的mysql主机拷贝相关包 //打包mysql编译安装目录 [root@db01 ~]# cd /usr/local [root@db01 local]# tar cf /root/mysql.tar mysql-5.6.40 //将包拷贝至另一台mysql主机 [root@db01 ~]# scp mysql.tar 10.0.0.3:/usr/local //拷贝配置文件 [root@db01 ~]# scp /usr/local/mysql-5.6.40/support-files/my-default.cnf 10.0.0.3:/etc //拷贝启动文件 [root@db01 ~]# scp /etc/init.d/mysqld 10.0.0.3:/etc/init.d //拷贝systemd管理文件 [root@db01 ~]# scp /usr/lib/systemd/system/mysqld.service 10.0.0.3:/usr/lib/systemd/system //拷贝mysql命令环境变量文件 [root@db01 local]# scp /etc/profile.d/mysql.sh 10.0.0.3:/etc/profile.d 2.另外一台mysql主机操作 /创建mysql用户和组 [root@db03 ~]# groupadd mysql [root@db03 ~]# useradd -r -g mysql -s /bin/false mysql //解压缩拷贝过来的mysql包 [root@db03 ~]# cd /usr/local [root@db03 local]# tar xf mysql.tar //修改mysql所有者 [root@db03 local]# chown -R mysql.mysql mysql-5.6.40 //做软连接 [root@db03 local]# ln -s mysql-5.6.40/ mysql //使mysql命令环境变量配置生效 [root@db03 local]# source /etc/profile //备份/etc/my.cnf [root@db03 local]# mv my.cnf my.cnf.old //修改拷贝过来的mysql配置文件 [root@db03 local]# mv my-default.cnf my.cnf //启动mysql并设置开机自启 [root@db03 ~]# systemctl start mysqld ; systemctl enable mysqld 或者 [root@db03 ~]# /etc/init.d/mysqld start //验证端口 [root@db03 ~]# netstat -ntpl|grep 3306 tcp6 0 0 :::3306 :::* LISTEN 1799/mysqld 到此，快速部署mysql完成 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mysql/mysql基础/7.CentOS7.5编译安装MySQL-5.7.23.html":{"url":"db/mysql/mysql基础/7.CentOS7.5编译安装MySQL-5.7.23.html","title":"MySQL-5.7.23","keywords":"","body":"CentOS7.5编译安装MySQL-5.7.23 1.安装依赖包 [root@db03 ~]# yum -y install -y gcc gcc-c++ automake autoconf cmake bison-devel ncurses-devel libaio-devel 2.创建mysql相关目录及用户和组 //创建mysql安装目录 [root@db03 ~]# mkdir /usr/local/mysql-5.7.23 //创建mysql组 [root@db01 ~]# groupadd mysql //创建mysql用户 [root@db01 ~]# useradd -r -g mysql -s /bin/false mysql 3.下载boost 5.7版本需要下载一个Boost C++ 1.59.0（这是一组扩充C++功能的经过同行评审（Peer-reviewed）且开放源代码程序库。大多数的函数为了能够以开放源代码、封闭项目的方式运作，而授权于Boost软件许可协议（Boost Software License）之下。） [root@db03 ~]# wget https://sourceforge.net/projects/boost/files/boost/1.59.0/boost_1_59_0.tar.gz 4.解压缩boost至/usr/local/mysql-5.7.23 [root@db03 ~]# tar xf boost_1_59_0.tar.gz -C /usr/local/mysql-5.7.23 5.下载mysql-5.7.23 [root@db03 ~]# wget https://downloads.mysql.com/archives/get/file/mysql-5.7.23.tar.gz 6.解压缩mysql //解压缩下载的包 [root@db03 ~]# tar xf mysql-5.7.23.tar.gz 7.进入解压目录，开始编译安装 [root@db03 ~]# cd mysql-5.7.23 [root@db03 mysql-5.7.23]# cmake -DCMAKE_INSTALL_PREFIX=/usr/local/mysql-5.7.23 \\ -DMYSQL_USER=mysql \\ -DWITH_MYISAM_STORAGE_ENGINE=1 \\ -DWITH_INNOBASE_STORAGE_ENGINE=1 \\ -DEXTRA_CHARSETS=all \\ -DDEFAULT_CHARSET=utf8 \\ -DDEFAULT_COLLATION=utf8_general_ci \\ -DWITH_DEBUG=0 \\ -DMYSQL_MAINTAINER_MODE=0 \\ -DWITH_SSL:STRING=bundled \\ -DWITH_ZLIB:STRING=bundled \\ -DWITH_SYSTEMD=1 \\ -DDOWNLOAD_BOOST=0 \\ -DWITH_DEBUG=0 \\ -DWITH_BOOST=/usr/local/mysql-5.7.23/boost //编译并安装 [root@db03 mysql-5.7.23]# make && make install 8.修改mysql安装目录所有者并做软连接 //修改目录所有者 [root@db03 ~]# chown -R mysql.mysql /usr/local/mysql-5.7.23 //做软连接 [root@db03 ~]# ln -s /usr/local/mysql-5.7.23/ /usr/local/mysql 9.初始化mysql //进入mysql编译安装目录 [root@db03 ~]# cd /usr/local/mysql ⚠️⚠️⚠️注意！！！ MySQL 5.7.6之前的版本执行这个脚本初始化系统数据库 ./bin/mysql_install_db --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data MySQL 5.7.6之后用以下脚本初始化系统数据库 ./bin/mysqld --initialize-insecure --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data //初始化mysql [root@db03 mysql]# ./bin/mysqld --initialize-insecure --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data --initialize-insecure #初始化加此选项表示初始化后不生成随机密码 通过mysqld --verbose --help|grep initialize查看说明 返回以下结果表明初始化正确 10.编辑mysql主配置文件 注意mysql-5.7.23源码包默认没有配置文件！！！！！！ //备份/etc/my.cnf [root@db03 local]# mv /etc/my.cnf /etc/my.cnf.old [root@db03 local]# cd //以下配置为最精简版，可根据实际情况进行相应设置 [root@db03 ~]# vim /etc/my.cnf [mysqld] basedir=/usr/local/mysql datadir=/usr/local/mysql/data user=mysql log-error=/usr/local/mysql/data/error.log 11.拷贝mysql启动文件 //拷贝mysql.server文件就可以使用/etc/init.d/mysqld 方式启动mysql [root@db03 ~]# cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld 12.systemd管理mysql [root@db03 ~]# cat > /etc/systemd/system/mysqld.service 13.导出mysql命令环境变量，使mysql命令可以使用 //最好不要往/etc/profile中追加内容，可以创建/etc/profile.d/x.sh [root@db03 ~]# echo 'export PATH=/usr/local/mysql/bin:$PATH' > /etc/profile.d/mysql.sh //使配置生效 [root@db03 ~]# source /etc/profile 14.启动mysql，检查启动 //启动mysql [root@db03 ~]# systemctl start mysqld //检查启动 [root@db03 ~]# netstat -ntpl tcp6 0 0 :::3306 :::* LISTEN 21196/mysqld 扩展：一台主机mysql已经编译好，通过拷贝相关目录和文件的方式快速部署其他mysql 步骤： 1.几台机器的环境要一致，操作系统、硬件环境 2.拷贝mysql编译安装路径目录，本文为/usr/local/mysql-5.7.23 3.拷贝mysql配置文件、启动文件、mysql命令环境变量文件/etc/profile.d/mysql.sh(或者在另外的mysql主机手动填写) 4.拷贝systemd管理文件 5.创建mysql用户和组 1.已经编译安装好的mysql主机拷贝相关包 //打包mysql编译安装目录 [root@db01 ~]# cd /usr/local [root@db01 local]# tar cf /root/mysql.tar mysql-5.7.23 //将包拷贝至另一台mysql主机 [root@db01 ~]# scp mysql.tar 10.0.0.3:/usr/local //拷贝配置文件,5.7.23默认没有配置文件，这个配置文件是手动写的 [root@db01 ~]# scp /etc/my.cnf 10.0.0.3:/etc //拷贝启动文件 [root@db01 ~]# scp /etc/init.d/mysqld 10.0.0.3:/etc/init.d //拷贝systemd管理文件 [root@db01 ~]# scp /etc/systemd/system/mysqld.service 10.0.0.3:/etc/systemd/system //拷贝mysql命令环境变量文件 [root@db01 ~]# scp /etc/profile.d/mysql.sh 10.0.0.3:/etc/profile.d 2.另外一台mysql主机操作 //创建mysql用户和组 [root@db03 ~]# groupadd mysql [root@db03 ~]# useradd -r -g mysql -s /bin/false mysql //解压缩拷贝过来的mysql包 [root@db03 ~]# cd /usr/local [root@db03 local]# tar xf mysql.tar //修改mysql所有者 [root@db03 local]# chown -R mysql.mysql mysql-5.7.23 //做软连接 [root@db03 local]# ln -s mysql-5.7.23/ mysql //使mysql命令环境变量配置生效 [root@db03 local]# source /etc/profile //启动mysql [root@db03 ~]# systemctl start mysqld ；systemctl enable mysqld 或者 [root@db03 ~]# /etc/init.d/mysqld start //验证端口 [root@db03 ~]# netstat -ntpl|grep 3306 tcp6 0 0 :::3306 :::* LISTEN 1799/mysqld 到此，快速部署mysql完成 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mysql/mysql基础/9.mysql连接与启动过程.html":{"url":"db/mysql/mysql基础/9.mysql连接与启动过程.html","title":"4.mysql连接与启动过程","keywords":"","body":"mysql连接与启动过程 1.mysql连接管理 1.1连接工具 1)MySQL自带的连接工具 mysql 常见的特定于客户机的连接选项： -u：指定用户 -p：指定密码 -h：指定主机 -P：指定端口 -S：指定sock文件 -e：指定SQL(命令行执行sql命令) 2)第三方的连接工具 sqlyog、navicat 应用程序连接MySQL 注意：需要加载对应语言程序的API 1.2连接方式 1.2.1socket连接 第一种方式 //mysql -uroot -p [root@db01 ~]# mysql -uroot -p mysql> status; Connection: Localhost via UNIX socket 第二种方式 [root@db01 ~]# mysql -uroot -p -S /tmp/mysql.sock mysql> status; Connection: Localhost via UNIX socket 1.2.2TCP/IP连接 [root@db01 ~]# mysql -uroot -p -h10.0.0.11 -P3306 mysql> status; Connection: 10.0.0.11 via TCP/IP 2.mysql启动流程 2.1示意图 /etc/init.d/mysqld start ------> mysqld_safe ------> mysqld 2.2mysql启动优先顺序 1.命令行选项 2.初始化配置文件 3.预编译选项，预编译选项优先级最低，因此，即使在编译的时候没有指定某些选项，也可以在配置文件中修改 2.3配置文件读取顺序 ⚠️⚠️⚠️此顺序为使用/etc/init.d/mysql.service启动脚本方法生效，使用systemd不生效 1./etc/my.cnf 2./etc/mysql/my.cnf 3.安装目录/my.cnf（前提是在环境变量中定义了 安装目录 变量） 4.defaults-extra-file （类似include） 5.~/.my.cnf 命令行中加上--defaults-file=xxx，以上文件都不读取 ⚠️⚠️⚠️配置文件顺序优先，但是配置优先级最低 配置文件优先级最终结论 1、命令行 2、defaults-file 3、配置文件 4、预编译 查看mysql默认读取my.cnf的顺序 $ mysql --help --verbose | grep 'my.cnf' order of preference, my.cnf, $MYSQL_TCP_PORT, /etc/my.cnf /etc/mysql/my.cnf /usr/local/mysql/etc/my.cnf ~/.my.cnf 查看mysqld默认读取my.cnf的顺序 $ mysqld --verbose --help | grep 'my.cnf' /etc/my.cnf /etc/mysql/my.cnf /usr/local/mysql/etc/my.cnf ~/.my.cnf my.cnf, $MYSQL_TCP_PORT, /etc/services, built-in default 2.4命令行与defaults-file优先级比较示例 在/tmp/a.txt中指定socket文件位置，然后用mysqld_safe启动，socket文件最终会在/tmp/b.sock //编辑一个文件 [root@db01 ~]# cat /tmp/a.txt [mysqld] socket=/tmp/a.sock //用mysqld_safe启动并指定socket文件位置 [root@db01 ~]# mysqld_safe --defaults-file=/etc/my.cnf --socket=/tmp/b.sock 最终socket文件在/tmp/b.sock，因此说明了在命令行中的优先级最大 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mysql/mysql基础/10.mysql数据类型和SQL语句分类.html":{"url":"db/mysql/mysql基础/10.mysql数据类型和SQL语句分类.html","title":"5.mysql数据类型和SQL语句分类","keywords":"","body":"mysql数据类型和SQL语句分类 1.SQL语句分类 DDL(Data Definition Language)数据定义语言 create、alter、drop DML(Data Manipulation Language)数据操纵语言 insert、update、delete DCL(Data Control Language)数据控制语言 grant、revoke DQL(Data Query Language)数据查询语言 select、show 2.mysql数据类型 2.1数值类型 2.1.1整型 类型 大小 范围（有符号） 范围（无符号）unsigned约束 用途 TINYINT 1 字节 (-128，127) (0，255) 小整数值 SMALLINT 2 字节 (-32 768，32 767) (0，65 535) 大整数值 MEDIUMINT 3 字节 (-8 388 608，8 388 607) (0，16 777 215) 大整数值 INT或INTEGER 4 字节 (-2 147 483 648，2 147 483 647) (0，4 294 967 295) 大整数值 BIGINT 8 字节 (-9 233 372 036 854 775 808，9 223 372 036 854 775 807) (0，18 446 744 073 709 551 615) 极大整数值 2.1.1.1 int和tinyint使用示例 常用的数据类型是tinyint和int #创建表t1 mysql> create table t1(t tinyint,i int); Query OK, 0 rows affected (0.02 sec) //向表中插入数据，有符号的tinyint下限是-128，因此插入-129报错 mysql> insert into t1 values(-129,-129); ERROR 1264 (22003): Out of range value for column 't' at row 1 mysql> insert into t1 values(-128,-129); Query OK, 1 row affected (0.01 sec) #创建表t2 mysql> create table t2(t tinyint(3),i int(3)); Query OK, 0 rows affected (0.08 sec) //向表t2中插入数据 mysql> insert into t2 values(1000,1000); ERROR 1264 (22003): Out of range value for column 't' at row 1 mysql> insert into t2 values(999,1000); ERROR 1264 (22003): Out of range value for column 't' at row 1 mysql> insert into t2 values(128,999); ERROR 1264 (22003): Out of range value for column 't' at row 1 mysql> insert into t2 values(127,999); Query OK, 1 row affected (0.01 sec) 2.1.2浮点型 类型 大小 范围(有符号) 范围(无符号) 用途 FLOAT 4 字节float(255,30) (-3.402 823 466 E+38，-1.175 494 351 E-38)，0，(1.175 494 351 E-38，3.402 823 466 351 E+38) 0，(1.175 494 351 E-38，3.402 823 466 E+38) 单精度 浮点数值 DOUBLE 8 字节double(255,30) (-1.797 693 134 862 315 7 E+308，-2.225 073 858 507 201 4 E-308)，0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) 0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) 双精度 浮点数值 DECIMAL 对DECIMAL(M,D) ，如果M>D，为M+2否则为D+2double(65,30) 依赖于M和D的值 依赖于M和D的值 小数值 float、double、decimal的格式相同 float(m,n) double(m,n) decimal(m,n) 其中m表示一共有m位，有n位小数 #创建t1表，三个字段分别为float，double和decimal参数表示一共显示5位，小数部分占2位 mysql> create table t1(id1 float(5,2),id2 double(5,2),id3 decimal(5,2)); Query OK, 0 rows affected (0.01 sec) mysql> desc t1; +-------+--------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+--------------+------+-----+---------+-------+ | id1 | float(5,2) | YES | | NULL | | | id2 | double(5,2) | YES | | NULL | | | id3 | decimal(5,2) | YES | | NULL | | +-------+--------------+------+-----+---------+-------+ 3 rows in set (0.00 sec) //向表中插入1.11，结果正常 mysql> insert into t1 values(1.11,1.11,1.11); Query OK, 1 row affected (0.00 sec) mysql> select * from t1; +------+------+------+ | id1 | id2 | id3 | +------+------+------+ | 1.11 | 1.11 | 1.11 | +------+------+------+ 1 row in set (0.00 sec) //向表中插入1.234发现只能保留2位小数 mysql> insert into t1 values(1.234,1.234,1.234); Query OK, 1 row affected, 1 warning (0.01 sec) mysql> select * from t1; +------+------+------+ | id1 | id2 | id3 | +------+------+------+ | 1.11 | 1.11 | 1.11 | | 1.23 | 1.23 | 1.23 | +------+------+------+ 2 rows in set (0.00 sec) //mysql> insert into t1 values(1.236,1.236,1.236); Query OK, 1 row affected, 1 warning (0.02 sec) mysql> select * from t1; +------+------+------+ | id1 | id2 | id3 | +------+------+------+ | 1.11 | 1.11 | 1.11 | | 1.23 | 1.23 | 1.23 | | 1.24 | 1.24 | 1.24 | +------+------+------+ 3 rows in set (0.00 sec).236，虽然只能保留2位小数，但是有四舍五入的规则 #新建t2表 mysql> create table t2(f float,do double,de decimal); Query OK, 0 rows affected (0.08 sec) mysql> desc t2; +-------+---------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+---------------+------+-----+---------+-------+ | f | float | YES | | NULL | | | do | double | YES | | NULL | | | de | decimal(10,0) | YES | | NULL | | +-------+---------------+------+-----+---------+-------+ 3 rows in set (0.00 sec) //分别插入1.2345，查看表可以看到decimal默认是整型 mysql> insert into t2 values(1.2345,1.2345,1.2345); Query OK, 1 row affected, 1 warning (0.00 sec) mysql> select * from t2; +--------+--------+------+ | f | do | de | +--------+--------+------+ | 1.2345 | 1.2345 | 1 | +--------+--------+------+ 1 row in set (0.00 sec) //分别插入超长的数，查看3者的区别，可以看到double的精度更高 mysql> insert into t2 values(1.234567890123456789,1.234567890123456789,1.234567890123456789); Query OK, 1 row affected, 1 warning (0.02 sec) mysql> select * from t2; +---------+--------------------+------+ | f | do | de | +---------+--------------------+------+ | 1.2345 | 1.2345 | 1 | | 1.23457 | 1.2345678901234567 | 1 | +---------+--------------------+------+ 2 rows in set (0.00 sec) 结论： 在不指定长度的情况下，decimal默认是整型存储 double的精度要比float高 2.2字符串类型 类型 大小 用途 CHAR 0-255字节 定长字符串 VARCHAR 0-65535 字节 变长字符串 TINYBLOB 0-255字节 不超过 255 个字符的二进制字符串 TINYTEXT 0-255字节 短文本字符串 BLOB 0-65 535字节 二进制形式的长文本数据 TEXT 0-65 535字节 长文本数据 MEDIUMBLOB 0-16 777 215字节 二进制形式的中等长度文本数据 MEDIUMTEXT 0-16 777 215字节 中等长度文本数据 LONGBLOB 0-4 294 967 295字节 二进制形式的极大文本数据 LONGTEXT 0-4 294 967 295字节 极大文本数据 2.2.1 char与varchar使用示例 CHAR 和 VARCHAR 类型类似，但它们保存和检索的方式不同。它们的最大长度和是否尾部空格被保留等方面也不同。在存储或检索过程中不进行大小写转换。 CHAR列的长度固定为创建表是声明的长度,范围(0-255);而VARCHAR的值是可变长字符串范围(0-65535)。 #创建表t1 mysql> create table t1(c char(4),v varchar(4)); Query OK, 0 rows affected (0.09 sec) //向t1表中插入数据 mysql> insert into t1 values('ab ','ab '); Query OK, 1 row affected (0.01 sec) mysql> select * from t1; +------+------+ | c | v | +------+------+ | ab | ab | +------+------+ 1 row in set (0.00 sec) //检索的时候char会去掉空格 mysql> select length(c),length(v) from t1; +-----------+-----------+ | length(c) | length(v) | +-----------+-----------+ | 2 | 4 | +-----------+-----------+ 1 row in set (0.00 sec) //给查询结果加上一个符号会看的更清晰，char在检索的时候会去掉空格 mysql> select concat(c,'+'),concat(v,'+') from t1; +---------------+---------------+ | concat(c,'+') | concat(v,'+') | +---------------+---------------+ | ab+ | ab + | +---------------+---------------+ 1 row in set (0.01 sec) char存储的时候是定长，例如，char(5)，但是只插入了一个字符a，则会在字符a后边补全4个空格 varchar存储的时候是变长，例如，varchar(5)，但是只插入了一个字符a，则存储a后还会在a的位置后边加一个a的位置编号 2.3日期和时间类型 类型 大小 (字节) 范围 格式 用途 DATE 3 1000-01-01/9999-12-31 YYYY-MM-DD 年月日 TIME 3 '-838:59:59'/'838:59:59' HH:MM:SS 时分秒 YEAR 1 1901/2155 YYYY 年份值 DATETIME 8 1000-01-01 00:00:00/9999-12-31 23:59:59 YYYY-MM-DD HH:MM:SS 年月日时分秒 TIMESTAMP 4 1970-01-01 00:00:00/2038结束时间是第 2147483647 秒，北京时间 2038-1-19 11:14:07，格林尼治时间 2038年1月19日 凌晨 03:14:07 YYYYMMDD HHMMSS 混合日期和时间值，时间戳 ⚠️⚠️⚠️IMESTAM只支持到2038年的时间，因此用的比较少 2.3.1 DATE、TIME、DATETIME使用示例 #创建表t2，3个列数据类型依次为date、time、datetime mysql> create table t2(d date,t time,dt datetime); Query OK, 0 rows affected (0.02 sec) //向t2表中插入数据，这里使用now()函数 mysql> insert into t2 values(now(),now(),now()); Query OK, 1 row affected, 1 warning (0.00 sec) //查看t2表中的数据 列d的数据类型是date 年月日 列t的数据类型是time 时分秒 列dt的数据类型是datetime 年月日时分秒 mysql> select * from t2; +------------+----------+---------------------+ | d | t | dt | +------------+----------+---------------------+ | 2018-10-28 | 17:32:33 | 2018-10-28 17:32:33 | +------------+----------+---------------------+ 1 row in set (0.00 sec) //向t2表中插入数据，这里手动指定，有两种方法 方法一 mysql> insert into t2 values('2018-08-08','08:08:08','2016-06-06 06:06:06'); Query OK, 1 row affected (0.01 sec) 方法二 mysql> insert into t2 values('20180808','080808','20160606060606'); Query OK, 1 row affected (0.00 sec) mysql> select * from t2; +------------+----------+---------------------+ | d | t | dt | +------------+----------+---------------------+ | 2018-08-08 | 08:08:08 | 2016-06-06 06:06:06 | | 2018-08-08 | 08:08:08 | 2016-06-06 06:06:06 | +------------+----------+---------------------+ 2 rows in set (0.00 sec) ⚠️只有TIMESTAMP类型插入数据为空时会自动添加当前时间，其余数据类型插入为空就是空 mysql> insert into t2 values(null,null,null); Query OK, 1 row affected (0.04 sec) mysql> select * from t2; +------------+----------+---------------------+ | d | t | dt | +------------+----------+---------------------+ | 2018-10-28 | 17:32:33 | 2018-10-28 17:32:33 | | NULL | NULL | NULL | +------------+----------+---------------------+ 2 rows in set (0.00 sec) 2.3.2 YEAR使用示例 #创建t3表，列y的类型为year mysql> create table t3(y year); Query OK, 0 rows affected (0.02 sec) //插入数据，这里使用now()方法 mysql> insert into t3 values(now()); Query OK, 1 row affected (0.01 sec) //插入数据，这里手动指定 mysql> insert into t3 values('2020'); Query OK, 1 row affected (0.00 sec) mysql> select * from t3; +------+ | y | +------+ | 2019 | | 2020 | +------+ 2 rows in set (0.00 sec) 2.3.3 TIMESTAMP使用示例 #创建t1表 mysql> create table t1(t timestamp); Query OK, 0 rows affected (0.03 sec) #描述t1表，可以看到timestamp有默认的CURRENT_TIMESTAMP和on update CURRENT_TIMESTAMP，即更新当前的时间 mysql> desc t1; +-------+-----------+------+-----+-------------------+-----------------------------+ | Field | Type | Null | Key | Default | Extra | +-------+-----------+------+-----+-------------------+-----------------------------+ | t | timestamp | NO | | CURRENT_TIMESTAMP | on update CURRENT_TIMESTAMP | +-------+-----------+------+-----+-------------------+-----------------------------+ 1 row in set (0.00 sec) //向t1表中插入数据,使用now()函数 mysql> insert into t1 values(now()); Query OK, 1 row affected (0.01 sec) //向t1表中插入空，timestamp会自动补全当前时间 mysql> insert into t1 values(null); Query OK, 1 row affected (0.00 sec) mysql> select * from t1; +---------------------+ | t | +---------------------+ | 2018-10-28 17:54:32 | | 2018-10-28 17:56:07 | +---------------------+ 2 rows in set (0.00 sec) timestamp时间上限及下限 mysql> desc t1; +-------+-----------+------+-----+-------------------+-----------------------------+ | Field | Type | Null | Key | Default | Extra | +-------+-----------+------+-----+-------------------+-----------------------------+ | t | timestamp | NO | | CURRENT_TIMESTAMP | on update CURRENT_TIMESTAMP | +-------+-----------+------+-----+-------------------+-----------------------------+ 1 row in set (0.00 sec) //timestamp时间上限是2038-01-19 11:14:07 mysql> insert into t1 values('2038-01-19 11:14:08'); ERROR 1292 (22007): Incorrect datetime value: '2038-01-19 11:14:08' for column 't' at row 1 mysql> insert into t1 values('2038-01-19 11:14:07'); Query OK, 1 row affected (0.01 sec) //timestamp时间下限是1970-01-01 08:00:01 mysql> insert into t1 values('1970-01-01 08:00:00'); ERROR 1292 (22007): Incorrect datetime value: '1970-01-01 08:00:00' for column 't' at row 1 mysql> insert into t1 values('1970-01-01 08:00:01'); Query OK, 1 row affected (0.00 sec) 2.4ENUM和SET类型 类型 大小 用途 ENUM 对1-255个成员的枚举需要1个字节存储;对于255-65535个成员，需要2个字节存储;最多允许65535个成员。 单选：选择性别 SET 1-8个成员的集合，占1个字节9-16个成员的集合，占2个字节17-24个成员的集合，占3个字节25-32个成员的集合，占4个字节33-64个成员的集合，占8个字节 多选：兴趣爱好 2.4.1 ENUM(枚举)使用示例 ENUM中文名称叫枚举类型，它的值范围需要在创建表时通过枚举方式显示。ENUM只允许从值集合中选取单个值，而不能一次取多个值 //创建t1表，性别设置为ENUM类型 mysql> create table t1(id int,name char(10),sex enum('F','M')); Query OK, 0 rows affected (0.02 sec) //向t1表中插入数据，性别是在ENUM中定义的就可插入成功 mysql> insert into t1 values(1,'小明','M'); Query OK, 1 row affected (0.00 sec) mysql> insert into t1 values(1,'小红','F'); Query OK, 1 row affected (0.01 sec) //性别插入ENUM中没有定义的就会报错 mysql> insert into t1 values(1,'小红','A'); ERROR 1265 (01000): Data truncated for column 'sex' at row 1 2.4.2 SET(集合)使用示例 SET和ENUM非常相似，也是一个字符串对象，里面可以包含0-64个成员。根据成员的不同，存储上也有所不同。set类型可以允许值集合中任意选择1或多个元素进行组合。对超出范围的内容将不允许注入，而对重复的值将进行自动去重。 //创建表t1，爱好列设置为SET类型 mysql> create table t1(id int,name char(10),hobby set('篮球','足球','看电影')); Query OK, 0 rows affected (0.02 sec) mysql> insert into t1 values(1,'小明','篮球'); Query OK, 1 row affected (0.01 sec) mysql> insert into t1 values(2,'小洲','篮球,足球'); Query OK, 1 row affected (0.00 sec) mysql> insert into t1 values(3,'小丽','篮球,足球,篮球,看电影,足球'); Query OK, 1 row affected (0.00 sec) //查询结果可以看到SET可以只选择一个爱好，选择多个爱好，并且可以去重 mysql> select * from t1; +------+--------+-------------------------+ | id | name | hobby | +------+--------+-------------------------+ | 1 | 小明 | 篮球 | | 2 | 小洲 | 篮球,足球 | | 3 | 小丽 | 篮球,足球,看电影 | +------+--------+-------------------------+ 3 rows in set (0.00 sec) 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mysql/mysql基础/11.mysql中表与表之间的关系.html":{"url":"db/mysql/mysql基础/11.mysql中表与表之间的关系.html","title":"6.mysql中表与表之间的关系","keywords":"","body":"mysql中表与表之间的关系 1.如何分析表与表之间的关系 分析步骤： #1、先站在左表的角度去找 是否左表的多条记录可以对应右表的一条记录，如果是，则证明左表的一个字段foreign key 右表一个字段（通常是id） #2、再站在右表的角度去找 是否右表的多条记录可以对应左表的一条记录，如果是，则证明右表的一个字段foreign key 左表一个字段（通常是id） #3、总结： #多对一： 如果只有步骤1成立，则是左表多对一右表 如果只有步骤2成立，则是右表多对一左表 #多对多 如果步骤1和2同时成立，则证明这两张表时一个双向的多对一，即多对多,需要定义一个这两张表的关系表来专门存放二者的关系 #一对一: 如果1和2都不成立，而是左表的一条记录唯一对应右表的一条记录，反之亦然。这种情况很简单，就是在左表foreign key右表的基础上，将左表的外键字段设置成unique即可 2.mysql中表与表之间的关系 2.1 一对多 关联方式 外键 foreign key 表与表之间的关系为一对多 例如，出版社与书之间的关系就是一对多，一个出版社可以出版多个书 例如，班级表和学生表，一个班级可以有多个学生，但是一个学生只能属于一个班级 例如，服务器和机房，一个机房可以有多台服务器，但是一个服务器只能属于一个机房 2.1.1示例1，出版社表与图书表 一个出版社可以出版多个书 #创建出版社表 mysql> create table chubanshe(id int primary key auto_increment,name char(10)); Query OK, 0 rows affected (0.02 sec) #创建图书表 mysql> create table book( id int primary key auto_increment, name char(20), chubanshe_id int not null, foreign key(chubanshe_id) references chubanshe(id) on delete cascade on update cascade); Query OK, 0 rows affected (0.04 sec) //向出版社表中插入数据 mysql> insert into chubanshe(name) values ('人民出版社'), ('邮电出版社'), ('机械出版社'); Query OK, 3 rows affected (0.01 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql> select * from chubanshe; +----+-----------------+ | id | name | +----+-----------------+ | 1 | 人民出版社 | | 2 | 邮电出版社 | | 3 | 机械出版社 | +----+-----------------+ 3 rows in set (0.00 sec) //向图书表中插入数据 mysql> insert into book(name,chubanshe_id) values ('童话故事',1), ('阿童木',2), ('老人与海',1), ('会飞的鸟',3), ('葵花宝典',2); Query OK, 5 rows affected (0.00 sec) Records: 5 Duplicates: 0 Warnings: 0 mysql> select * from book; +----+--------------+--------------+ | id | name | chubanshe_id | +----+--------------+--------------+ | 1 | 童话故事 | 1 | | 2 | 阿童木 | 2 | | 3 | 老人与海 | 1 | | 4 | 会飞的鸟 | 3 | | 5 | 葵花宝典 | 2 | +----+--------------+--------------+ 5 rows in set (0.00 sec) 现在出版社表与图书表就是一对多关系，图书表中的chubanshe_id对应出版社表中的出版社id，一个出版社可以出版多个书 2.1.2示例2，学生表和班级表 一个班级可以有多个学生，但是一个学生只能属于一个班级 #创建学生表 mysql> create table student( sid int primary key auto_increment, sname char(10) not null, class_id int not null, foreign key(class_id) references class(cid)); Query OK, 0 rows affected (0.02 sec) #创建班级表 mysql> create table class(cid int auto_increment primary key); Query OK, 0 rows affected (0.04 sec) //向学生表中插入数据 mysql> insert into student(sname,class_id) values('小明',1),('小红',1),('小洲',2),('小肖',3),('小丽',3); Query OK, 5 rows affected (0.00 sec) Records: 5 Duplicates: 0 Warnings: 0 mysql> select * from student; +-----+--------+----------+ | sid | sname | class_id | +-----+--------+----------+ | 1 | 小明 | 1 | | 2 | 小红 | 1 | | 3 | 小洲 | 2 | | 4 | 小肖 | 3 | | 5 | 小丽 | 3 | +-----+--------+----------+ 5 rows in set (0.00 sec) //向班级表中插入数据，因为只有一个cid，自动增长 mysql> insert into class values(); Query OK, 1 row affected (0.01 sec) mysql> select * from class; +-----+ | cid | +-----+ | 1 | | 2 | | 3 | +-----+ 3 rows in set (0.00 sec) //错误示例，向学生表中插入一条数据，班级id指定一个不存在的，会报错 mysql> insert into student(sname,class_id) values('小黑',4); ERROR 1452 (23000): Cannot add or update a child row: a foreign key constraint fails (`ppp`.`student`, CONSTRAINT `student_ibfk_1` FOREIGN KEY (`class_id`) REFERENCES `class` (`cid`)) //错误示例，尝试删除班级表中的一个记录，报错，不可以删除，因为学生表中有对应的班级，这个无法删除 mysql> delete from class where cid=1; ERROR 1451 (23000): Cannot delete or update a parent row: a foreign key constraint fails (`ppp`.`student`, CONSTRAINT `student_ibfk_1` FOREIGN KEY (`class_id`) REFERENCES `class` (`cid`)) 2.1.3示例3，机房表与服务器表 一个机房可以有多个服务器，但是一个服务器只能归属一个机房 #创建机房表 mysql> create table server_room( rid int primary key auto_increment, rname char(10) not null); Query OK, 0 rows affected (0.03 sec) #创建服务器表 mysql> create table server( sid int primary key auto_increment, sname char(10) not null,room_id int not null, foreign key(room_id) references server_room(rid)); Query OK, 0 rows affected (0.02 sec) //向机房表中插入数据 mysql> insert into server_room(rname) values('房山机房'),('石景山机房'),('丰台 机房'); Query OK, 3 rows affected (0.00 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql> select * from server_room; +-----+-----------------+ | rid | rname | +-----+-----------------+ | 1 | 房山机房 | | 2 | 石景山机房 | | 3 | 丰台机房 | +-----+-----------------+ 3 rows in set (0.00 sec) //向服务器表中插入数据 mysql> insert into server(sname,room_id) values('HP',1),('DELL',1),('联想',2),('IBM',3),('华为',3); Query OK, 5 rows affected (0.00 sec) Records: 5 Duplicates: 0 Warnings: 0 mysql> select * from server; +-----+--------+---------+ | sid | sname | room_id | +-----+--------+---------+ | 1 | HP | 1 | | 2 | DELL | 1 | | 3 | 联想 | 2 | | 4 | IBM | 3 | | 5 | 华为 | 3 | +-----+--------+---------+ 5 rows in set (0.00 sec) //错误示例，尝试修改机房表中的机房编号，结果报错，因为服务器表中有对应编号为3的丰台机房的服务器 mysql> select * from server_room; +-----+-----------------+ | rid | rname | +-----+-----------------+ | 1 | 房山机房 | | 2 | 石景山机房 | | 3 | 丰台机房 | +-----+-----------------+ 3 rows in set (0.00 sec) mysql> update server_room set rid=5 where rid=3; ERROR 1451 (23000): Cannot delete or update a parent row: a foreign key constraint fails (`ppp`.`server`, CONSTRAINT `server_ibfk_1` FOREIGN KEY (`room_id`) REFERENCES `server_room` (`rid`)) 2.2 一对一 关联方式 foreign key+unique 表与表之间的关系是一对一 例如，公司中员工与员工的企业邮箱就是一对一关系 2.2.1示例1，员工表与企业邮箱表 #创建员工表 mysql> create table employee( eid int primary key auto_increment, #员工id，主键，自增 ename char(20) not null, #员工姓名 sex enum('F','M'), #员工性别 enterprise_mail_id int unique); #企业邮箱id，不能重复 Query OK, 0 rows affected (0.03 sec) #创建企业邮箱表 mysql> create table enterprise_mail( mid int primary key, #企业邮箱id，主键 email char(50), #邮箱信息 employee_id int unique not null, #员工id，不能重复 foreign key(employee_id) references employee(eid)); #企业邮箱表中的员工id是外键，关联员工表中的员工id Query OK, 0 rows affected (0.03 sec) //向员工表中插入数据 mysql> insert into employee(ename,sex,enterprise_mail_id) values -> ('小明','M',101), -> ('小洲','M',102), -> ('小颖','F',103); Query OK, 3 rows affected (0.00 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql> select * from employee; +-----+--------+------+--------------------+ | eid | ename | sex | enterprise_mail_id | +-----+--------+------+--------------------+ | 1 | 小明 | M | 101 | | 2 | 小洲 | M | 102 | | 3 | 小颖 | F | 103 | +-----+--------+------+--------------------+ 3 rows in set (0.00 sec) //向企业邮箱表中插入数据 mysql> insert into enterprise_mail values (101,'xiaoming@testin.cn',1), (102,'xiaozhou@testin.cn',2), (103,'xiaoying@testin.cn',3); Query OK, 3 rows affected (0.01 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql> select * from enterprise_mail; +-----+--------------------+-------------+ | mid | email | employee_id | +-----+--------------------+-------------+ | 101 | xiaoming@testin.cn | 1 | | 102 | xiaozhou@testin.cn | 2 | | 103 | xiaoying@testin.cn | 3 | +-----+--------------------+-------------+ 3 rows in set (0.00 sec) //尝试删除员工表中的任意一条数据，因为有外键约束，因此无法删除 mysql> delete from employee where eid=1; ERROR 1451 (23000): Cannot delete or update a parent row: a foreign key constraint fails (`db1`.`enterprise_mail`, CONSTRAINT `enterprise_mail_ibfk_1` FOREIGN KEY (`employee_id`) REFERENCES `employee` (`eid`)) //尝试删除企业邮箱表中的任意一条数据 mysql> delete from enterprise_mail where mid=101; Query OK, 1 row affected (0.01 sec) 2.3 多对多 关联方式 外键foreign key+一张新的表 表与表之间的关系是多对多 例如，一本书可以有多个作者，一个作者可以写多本书 2.3.1示例1，书籍表、作者表、关联书籍表与作者表的第3张表 #创建书籍表 mysql> create table book( bid int primary key auto_increment, bname char(20) not null); Query OK, 0 rows affected (0.02 sec) #创建作者表 mysql> create table author( aid int primary key auto_increment, aname char(20) not null); Query OK, 0 rows affected (0.03 sec) #创建关联书籍与作者表，表中有书籍id和作者id，分别作为书籍表中bid和作者表中aid的外键 mysql> create table book_and_author( book_id int not null, author_id int not null, foreign key(book_id) references book(bid), foreign key(author_id) references author(aid)); Query OK, 0 rows affected (0.03 sec) //向书籍表中插入数据 mysql> insert into book(bname) values('童话故事'),('那个女孩'),('上课必备三件套'); Query OK, 3 rows affected (0.00 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql> select * from book; +-----+-----------------------+ | bid | bname | +-----+-----------------------+ | 1 | 童话故事 | | 2 | 那个女孩 | | 3 | 上课必备三件套 | +-----+-----------------------+ 3 rows in set (0.00 sec) //向作者表中插入数据 mysql> insert into author(aname) values('作者小明'),('作者小丽'),('作者小洲'); Query OK, 3 rows affected (0.01 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql> select * from author; +-----+--------------+ | aid | aname | +-----+--------------+ | 1 | 作者小明 | | 2 | 作者小丽 | | 3 | 作者小洲 | +-----+--------------+ 3 rows in set (0.00 sec) //向关联表中插入数据 mysql> insert into book_and_author values(1,1),(1,2),(2,2),(2,3),(3,1),(3,3); Query OK, 6 rows affected (0.00 sec) Records: 6 Duplicates: 0 Warnings: 0 mysql> select * from book_and_author; +---------+-----------+ | book_id | author_id | +---------+-----------+ | 1 | 1 | #童话故事的作者是小明 | 1 | 2 | #童话故事的作者是小丽 | 2 | 2 | #那个女孩的作者是小丽 | 2 | 3 | #那个女孩的作者是小洲 | 3 | 1 | #上课必备三件套的作者是小明 | 3 | 3 | #上课必备三件套的作者是小洲 +---------+-----------+ 6 rows in set (0.00 sec) 这个关联书籍表与作者表的关联表中就是一个作者写了多本书，一本书有多个作者 //错误示范，尝试删除书籍表与作者表中的任意一条数据 mysql> delete from book where bid=1; ERROR 1451 (23000): Cannot delete or update a parent row: a foreign key constraint fails (`db1`.`book_and_author`, CONSTRAINT `book_and_author_ibfk_1` FOREIGN KEY (`book_id`) REFERENCES `book` (`bid`)) mysql> delete from author where aid=3; ERROR 1451 (23000): Cannot delete or update a parent row: a foreign key constraint fails (`db1`.`book_and_author`, CONSTRAINT `book_and_author_ibfk_2` FOREIGN KEY (`author_id`) REFERENCES `author` (`aid`)) //删除关联表中的数据，是可以删除的，因为这只是一个关联表，删除了关联id，只是把原来两张表的关联关系删除了 这里删除了关联表中的图书id，这样就是原来的图书表中为1的书找不到对应的作者了 mysql> delete from book_and_author where book_id=1; Query OK, 2 rows affected (0.01 sec) mysql> select * from book_and_author; +---------+-----------+ | book_id | author_id | +---------+-----------+ | 2 | 2 | | 2 | 3 | | 3 | 1 | | 3 | 3 | +---------+-----------+ 4 rows in set (0.00 sec) //删除关联id后就可以删除原先不能删除的图书或者作者id了 mysql> delete from book where bid=1; Query OK, 1 row affected (0.00 sec) //关联id为2的没有删除，因此不能删除图书表中bid为2的 mysql> delete from book where bid=2; ERROR 1451 (23000): Cannot delete or update a parent row: a foreign key constraint fails (`db1`.`book_and_author`, CONSTRAINT `book_and_author_ibfk_1` FOREIGN KEY (`book_id`) REFERENCES `book` (`bid`)) 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mysql/mysql基础/12.mysql关键字和sql语句执行顺序.html":{"url":"db/mysql/mysql基础/12.mysql关键字和sql语句执行顺序.html","title":"7.mysql关键字和sql语句执行顺序","keywords":"","body":"mysql关键字和sql语句执行顺序 1.mysql关键字 关键字 含义 not null 非空 primary key 主键(唯一且非空) foreign key 外键 unique 唯一键 auto_increment 自增(此列必须是主键或者唯一键) default 默认值 unsigned 非负数 comment 注释说明 distinct 去重 limit 限制 having 过滤 group by 分组 order by 排序(默认升序，加desc降序) like where条件中使用，与%配合使用，表示模糊匹配 in where条件中使用，查询范围内的数据 2.sql语句执行顺序 单表查询语句 语句 含义 select dictinct 字段名 去重，可以使用函数，四则运算，重命名 from 表名 as 别名 查询的时候临时修改表名 where 条件 条件可以用比较运算，逻辑运算，like，in group by 根据某个字段一致的项进行分组 having 过滤，可以使用聚合函数，在分组之后对数据 order by 字段 排序，默认升序，desc降序 limit m,n 从m+1开始取n条，m默认为0 执行顺序 1.from 2.where 3.group by 4.having 5.select 6.distinct 7.order by 8.limit 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mysql/mysql基础/13.select高级用法.html":{"url":"db/mysql/mysql基础/13.select高级用法.html","title":"8.select高级用法","keywords":"","body":"select高级用法 一、多表连接查询 select 表1.列名,表2.列名 from 表1,表2 where 表1.列1=表2.列1 and 表1.列2=值 1.1创建两张表 mysql> create table t1(id int,name char(20)); Query OK, 0 rows affected (0.02 sec) mysql> create table t2(id int,age tinyint); Query OK, 0 rows affected (0.02 sec) 1.2向表中插入数据 mysql> insert into t1 values(1,'aaa'),(2,'bbb'),(3,'ccc'); Query OK, 3 rows affected (0.01 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql> insert into t2 values(1,25),(2,26),(3,27); Query OK, 3 rows affected (0.00 sec) Records: 3 Duplicates: 0 Warnings: 0 1.3查询t1、t2表中id为1的人的年龄 mysql> select t1.name,t2.age from t1,t2 where t1.id=t2.id and t1.id=1; +------+------+ | name | age | +------+------+ | aaa | 25 | +------+------+ 1 row in set (0.00 sec) 二、sql join连接 2.1sql join连接示意图 下图展示了 LEFT JOIN、RIGHT JOIN、INNER JOIN、OUTER JOIN 相关的 7 种用法 2.2sql数据准备 2.2.1创建一个人名表和地址表 1.创建一个数据库 mysql> create database DB1 charset utf8 collate=utf8_general_ci; Query OK, 1 row affected (0.01 sec) 2.创建人名表 mysql> create table person(person_id int,name varchar(20)); Query OK, 0 rows affected (0.02 sec) 3.创建地址表 mysql> create table address(address_id int,person_id int,city varchar(20)); Query OK, 0 rows affected (0.02 sec) 2.2.2向表中插入数据 1.向人名表中插入数据 mysql> insert into person values(1,'张三'),(2,'李四'),(3,'王五'),(4,'杨六'); Query OK, 4 rows affected (0.01 sec) Records: 4 Duplicates: 0 Warnings: 0 2.向地址表中插入数据 mysql> insert into address values(1,1,'北京'),(2,2,'上海'),(3,3,'广州'),(5,5,'杭州'); Query OK, 4 rows affected (0.01 sec) Records: 4 Duplicates: 0 Warnings: 0 2.2.3查看表信息 //人名表 mysql> select * from person; +-----------+--------+ | person_id | name | +-----------+--------+ | 1 | 张三 | | 2 | 李四 | | 3 | 王五 | | 4 | 杨六 | +-----------+--------+ 4 rows in set (0.01 sec) //地址表 mysql> select * from address; +------------+-----------+--------+ | address_id | person_id | city | +------------+-----------+--------+ | 1 | 1 | 北京 | | 2 | 2 | 上海 | | 3 | 3 | 广州 | | 5 | 5 | 杭州 | +------------+-----------+--------+ 4 rows in set (0.00 sec) 2.3sql join连接查询示例 2.3.1传统连接与JOIN ON //使用DB1库 mysql> use DB1; Database changed //查询张三的地址 传统连接 mysql> select person.name,address.city from person,address where person.name='张三' and person.person_id=address.person_id; +--------+--------+ | name | city | +--------+--------+ | 张三 | 北京 | +--------+--------+ 1 row in set (0.01 sec) //查询张三的地址 JOIN ON连接 mysql> select person.name,address.city from person join address on(person.person_id=address.person_id) where person.name='张三'; +--------+--------+ | name | city | +--------+--------+ | 张三 | 北京 | +--------+--------+ 1 row in set (0.00 sec) ⚠️传统连接与JOIN ON查询的结果是一样的 2.3.2自连接 NATURAL JOIN 自然连接:根据连接的两个表中的公共列为您创建隐式连接子句。公共列是两个表中名称相同的列。自然连接可以是内连接、左外连接或右外连接。默认情况下是内部连接。 自连接的表要有共同的列名字，person表和address表中都有列person_id //查询张三的地址 mysql> select person.name,address.city from person natural join address where person.name='张三'; +--------+--------+ | name | city | +--------+--------+ | 张三 | 北京 | +--------+--------+ 1 row in set (0.00 sec) 2.3.3内连接 INNER JOIN INNER JOIN 关键字在表中存在至少一个匹配时返回行。 //person表中和address表中相同的id列 mysql> select * from person inner join address on person.person_id=address.address_id; +-----------+--------+------------+-----------+--------+ | person_id | name | address_id | person_id | city | +-----------+--------+------------+-----------+--------+ | 1 | 张三 | 1 | 1 | 北京 | | 2 | 李四 | 2 | 2 | 上海 | | 3 | 王五 | 3 | 3 | 广州 | +-----------+--------+------------+-----------+--------+ 3 rows in set (0.00 sec) 2.3.4左外连接 LEFT JOIN ON 左外连接:从左表返回所有的行(表1),与正确的匹配行(表2)。当没有匹配时，右边的结果为NULL。 select 查询内容 from 左表 left join 右表 on 左表.列=右表.列 //人名表person为左表，地址表address为右表 左外连接 mysql> select * from person left join address on person.person_id=address.person_id; +-----------+--------+------------+-----------+--------+ | person_id | name | address_id | person_id | city | +-----------+--------+------------+-----------+--------+ | 1 | 张三 | 1 | 1 | 北京 | | 2 | 李四 | 2 | 2 | 上海 | | 3 | 王五 | 3 | 3 | 广州 | | 4 | 杨六 | NULL | NULL | NULL | +-----------+--------+------------+-----------+--------+ 4 rows in set (0.01 sec) //地址表address为左表，人名表person位右表 右外连接 mysql> select * from address right join person on person.person_id=address.person_id; +------------+-----------+--------+-----------+--------+ | address_id | person_id | city | person_id | name | +------------+-----------+--------+-----------+--------+ | 1 | 1 | 北京 | 1 | 张三 | | 2 | 2 | 上海 | 2 | 李四 | | 3 | 3 | 广州 | 3 | 王五 | | NULL | NULL | NULL | 4 | 杨六 | +------------+-----------+--------+-----------+--------+ 4 rows in set (0.00 sec) 2.3.5右外连接 RIGHT JOIN ON 右外连接:返回右表(表2)中的所有行，以及左表(表1)中的匹配行。当没有匹配时，左边的结果为NULL。 select 查询内容 from 左表 right join 右表 on 右表.列=左表.列 //人名表person为左表，地址表address为右表 mysql> select * from person right join address on person.person_id=address.person_id; +-----------+--------+------------+-----------+--------+ | person_id | name | address_id | person_id | city | +-----------+--------+------------+-----------+--------+ | 1 | 张三 | 1 | 1 | 北京 | | 2 | 李四 | 2 | 2 | 上海 | | 3 | 王五 | 3 | 3 | 广州 | | NULL | NULL | 5 | 5 | 杭州 | +-----------+--------+------------+-----------+--------+ 4 rows in set (0.00 sec) //address表为左表，person表为右表 mysql> select * from address left join person on person.person_id=address.person_id; +------------+-----------+--------+-----------+--------+ | address_id | person_id | city | person_id | name | +------------+-----------+--------+-----------+--------+ | 1 | 1 | 北京 | 1 | 张三 | | 2 | 2 | 上海 | 2 | 李四 | | 3 | 3 | 广州 | 3 | 王五 | | 5 | 5 | 杭州 | NULL | NULL | +------------+-----------+--------+-----------+--------+ 4 rows in set (0.00 sec) 2.3.6合并查询 UNION UNION 去重复并合并 UNION ALL 不去重 全交: 返回左表的所有行和右表的所有行，是左交和右交的联合。 注意，由于MySql中没有Full Join命令，所以我们通过把Left Join和Right Join的结果Union起来也是可以的： //查询城市为北京或上海的所有信息 mysql> select * from address where city='北京' or city='上海'; +------------+-----------+--------+ | address_id | person_id | city | +------------+-----------+--------+ | 1 | 1 | 北京 | | 2 | 2 | 上海 | +------------+-----------+--------+ 2 rows in set (0.00 sec) 或 mysql> select * from address where city in ('北京','上海'); +------------+-----------+--------+ | address_id | person_id | city | +------------+-----------+--------+ | 1 | 1 | 北京 | | 2 | 2 | 上海 | +------------+-----------+--------+ 2 rows in set (0.01 sec) //union合并查询效率最高 mysql> select * from address where city='北京' union select * from address where city='上海'; +------------+-----------+--------+ | address_id | person_id | city | +------------+-----------+--------+ | 1 | 1 | 北京 | | 2 | 2 | 上海 | +------------+-----------+--------+ 2 rows in set (0.00 sec) 或 mysql> select * from address where city='北京' union all select * from address where city='上海'; +------------+-----------+--------+ | address_id | person_id | city | +------------+-----------+--------+ | 1 | 1 | 北京 | | 2 | 2 | 上海 | +------------+-----------+--------+ 2 rows in set (0.00 sec) 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mysql/mysql基础/14.mysql字符集.html":{"url":"db/mysql/mysql基础/14.mysql字符集.html","title":"9.mysql字符集","keywords":"","body":"mysql字符集 1.字符集定义 字符集(charset)：是一个系统支持的所有抽象字符的集合。字符是各种文字和符号的总称， 包括各国家文字、标点符号、图形符号、数字等 2.mysql数据库的字符集 1.字符集 charset 2.校对规则 collation 3.mysql中常见的字符集 ASCII字符集 1.一共128个字符，包括空格、标点符号、数字、大小写字母和一些不可见字符 2.每个字符使用一个字节编码--一个字节是8位，一共有256个编码方式足以承担128个 ISO 8859-1字符集-latin1 1.一共256个字符，足以用一个字节标识。 2.共收录256个字符，是在ASCII字符集的基础上又扩充了128个西欧常用字符 GB2312字符集 1.收录了汉字以及拉丁字母、希腊字母、日文平假名及片假名字母、俄语西里尔字母 2.同时这种字符集又兼容ASCII字符集 3.如果该字符在ASCII字符集中，则采用1字节编码。否则采用2字节编码。 4.类似这种一个字符需要的字节数不同称为边长编码 GBK字符集 GBK字符集只是在收录字符范围上对GB2312字符集作了扩充，编码方式上兼容GB2312 utf8字符集 1.收录地球上能想到的所有字符，而且还在不断扩充。这种字符集兼容ASCII字符集，采用变长编码方式，编码一个字符需要使用1～4个字节 2.兼容ASCII 3.utf8只是Unicode字符集的一种编码方案，Unicode字符集可以采用utf8、utf16、utf32这几种编码方案，utf8使用1～4个字节编码一个字符，utf16使用2个或4个字节编码一个字符，utf32使用4个字节编码一个字符。 4.mysql常见校对规则 1.ci：大小写不敏感 2.cs或bin：大小写敏感 示例 create database DB1 charset utf8 collate=utf8_general_ci 5.查看字符集和校对规则 查看字符集(mysql5.7) mysql> show charset; +----------+---------------------------------+---------------------+--------+ | Charset | Description | Default collation | Maxlen | +----------+---------------------------------+---------------------+--------+ | big5 | Big5 Traditional Chinese | big5_chinese_ci | 2 | | dec8 | DEC West European | dec8_swedish_ci | 1 | | cp850 | DOS West European | cp850_general_ci | 1 | | hp8 | HP West European | hp8_english_ci | 1 | | koi8r | KOI8-R Relcom Russian | koi8r_general_ci | 1 | | latin1 | cp1252 West European | latin1_swedish_ci | 1 | | latin2 | ISO 8859-2 Central European | latin2_general_ci | 1 | | swe7 | 7bit Swedish | swe7_swedish_ci | 1 | | ascii | US ASCII | ascii_general_ci | 1 | | ujis | EUC-JP Japanese | ujis_japanese_ci | 3 | | sjis | Shift-JIS Japanese | sjis_japanese_ci | 2 | | hebrew | ISO 8859-8 Hebrew | hebrew_general_ci | 1 | | tis620 | TIS620 Thai | tis620_thai_ci | 1 | | euckr | EUC-KR Korean | euckr_korean_ci | 2 | | koi8u | KOI8-U Ukrainian | koi8u_general_ci | 1 | | gb2312 | GB2312 Simplified Chinese | gb2312_chinese_ci | 2 | | greek | ISO 8859-7 Greek | greek_general_ci | 1 | | cp1250 | Windows Central European | cp1250_general_ci | 1 | | gbk | GBK Simplified Chinese | gbk_chinese_ci | 2 | | latin5 | ISO 8859-9 Turkish | latin5_turkish_ci | 1 | | armscii8 | ARMSCII-8 Armenian | armscii8_general_ci | 1 | | utf8 | UTF-8 Unicode | utf8_general_ci | 3 | | ucs2 | UCS-2 Unicode | ucs2_general_ci | 2 | | cp866 | DOS Russian | cp866_general_ci | 1 | | keybcs2 | DOS Kamenicky Czech-Slovak | keybcs2_general_ci | 1 | | macce | Mac Central European | macce_general_ci | 1 | | macroman | Mac West European | macroman_general_ci | 1 | | cp852 | DOS Central European | cp852_general_ci | 1 | | latin7 | ISO 8859-13 Baltic | latin7_general_ci | 1 | | utf8mb4 | UTF-8 Unicode | utf8mb4_general_ci | 4 | | cp1251 | Windows Cyrillic | cp1251_general_ci | 1 | | utf16 | UTF-16 Unicode | utf16_general_ci | 4 | | utf16le | UTF-16LE Unicode | utf16le_general_ci | 4 | | cp1256 | Windows Arabic | cp1256_general_ci | 1 | | cp1257 | Windows Baltic | cp1257_general_ci | 1 | | utf32 | UTF-32 Unicode | utf32_general_ci | 4 | | binary | Binary pseudo charset | binary | 1 | | geostd8 | GEOSTD8 Georgian | geostd8_general_ci | 1 | | cp932 | SJIS for Windows Japanese | cp932_japanese_ci | 2 | | eucjpms | UJIS for Windows Japanese | eucjpms_japanese_ci | 3 | | gb18030 | China National Standard GB18030 | gb18030_chinese_ci | 4 | +----------+---------------------------------+---------------------+--------+ 41 rows in set (0.00 sec) 查看校对规则 mysql> show collation; +--------------------------+----------+-----+---------+----------+---------+ | Collation | Charset | Id | Default | Compiled | Sortlen | +--------------------------+----------+-----+---------+----------+---------+ | big5_chinese_ci | big5 | 1 | Yes | Yes | 1 | | big5_bin | big5 | 84 | | Yes | 1 | | dec8_swedish_ci | dec8 | 3 | Yes | Yes | 1 | | dec8_bin | dec8 | 69 | | Yes | 1 | | cp850_general_ci | cp850 | 4 | Yes | Yes | 1 | | cp850_bin | cp850 | 80 | | Yes | 1 | | hp8_english_ci | hp8 | 6 | Yes | Yes | 1 | | hp8_bin | hp8 | 72 | | Yes | 1 | | koi8r_general_ci | koi8r | 7 | Yes | Yes | 1 | | koi8r_bin | koi8r | 74 | | Yes | 1 | | latin1_german1_ci | latin1 | 5 | | Yes | 1 | | latin1_swedish_ci | latin1 | 8 | Yes | Yes | 1 | | latin1_danish_ci | latin1 | 15 | | Yes | 1 | | latin1_german2_ci | latin1 | 31 | | Yes | 2 | | latin1_bin | latin1 | 47 | | Yes | 1 | | latin1_general_ci | latin1 | 48 | | Yes | 1 | | latin1_general_cs | latin1 | 49 | | Yes | 1 | | latin1_spanish_ci | latin1 | 94 | | Yes | 1 | | latin2_czech_cs | latin2 | 2 | | Yes | 4 | | latin2_general_ci | latin2 | 9 | Yes | Yes | 1 | | latin2_hungarian_ci | latin2 | 21 | | Yes | 1 | | latin2_croatian_ci | latin2 | 27 | | Yes | 1 | | latin2_bin | latin2 | 77 | | Yes | 1 | | swe7_swedish_ci | swe7 | 10 | Yes | Yes | 1 | | swe7_bin | swe7 | 82 | | Yes | 1 | | ascii_general_ci | ascii | 11 | Yes | Yes | 1 | | ascii_bin | ascii | 65 | | Yes | 1 | | ujis_japanese_ci | ujis | 12 | Yes | Yes | 1 | | ujis_bin | ujis | 91 | | Yes | 1 | | sjis_japanese_ci | sjis | 13 | Yes | Yes | 1 | | sjis_bin | sjis | 88 | | Yes | 1 | | hebrew_general_ci | hebrew | 16 | Yes | Yes | 1 | | hebrew_bin | hebrew | 71 | | Yes | 1 | | tis620_thai_ci | tis620 | 18 | Yes | Yes | 4 | | tis620_bin | tis620 | 89 | | Yes | 1 | | euckr_korean_ci | euckr | 19 | Yes | Yes | 1 | | euckr_bin | euckr | 85 | | Yes | 1 | | koi8u_general_ci | koi8u | 22 | Yes | Yes | 1 | | koi8u_bin | koi8u | 75 | | Yes | 1 | | gb2312_chinese_ci | gb2312 | 24 | Yes | Yes | 1 | | gb2312_bin | gb2312 | 86 | | Yes | 1 | | greek_general_ci | greek | 25 | Yes | Yes | 1 | | greek_bin | greek | 70 | | Yes | 1 | | cp1250_general_ci | cp1250 | 26 | Yes | Yes | 1 | | cp1250_czech_cs | cp1250 | 34 | | Yes | 2 | | cp1250_croatian_ci | cp1250 | 44 | | Yes | 1 | | cp1250_bin | cp1250 | 66 | | Yes | 1 | | cp1250_polish_ci | cp1250 | 99 | | Yes | 1 | | gbk_chinese_ci | gbk | 28 | Yes | Yes | 1 | | gbk_bin | gbk | 87 | | Yes | 1 | | latin5_turkish_ci | latin5 | 30 | Yes | Yes | 1 | | latin5_bin | latin5 | 78 | | Yes | 1 | | armscii8_general_ci | armscii8 | 32 | Yes | Yes | 1 | | armscii8_bin | armscii8 | 64 | | Yes | 1 | | utf8_general_ci | utf8 | 33 | Yes | Yes | 1 | | utf8_bin | utf8 | 83 | | Yes | 1 | | utf8_unicode_ci | utf8 | 192 | | Yes | 8 | | utf8_icelandic_ci | utf8 | 193 | | Yes | 8 | | utf8_latvian_ci | utf8 | 194 | | Yes | 8 | | utf8_romanian_ci | utf8 | 195 | | Yes | 8 | | utf8_slovenian_ci | utf8 | 196 | | Yes | 8 | | utf8_polish_ci | utf8 | 197 | | Yes | 8 | | utf8_estonian_ci | utf8 | 198 | | Yes | 8 | | utf8_spanish_ci | utf8 | 199 | | Yes | 8 | | utf8_swedish_ci | utf8 | 200 | | Yes | 8 | | utf8_turkish_ci | utf8 | 201 | | Yes | 8 | | utf8_czech_ci | utf8 | 202 | | Yes | 8 | | utf8_danish_ci | utf8 | 203 | | Yes | 8 | | utf8_lithuanian_ci | utf8 | 204 | | Yes | 8 | | utf8_slovak_ci | utf8 | 205 | | Yes | 8 | | utf8_spanish2_ci | utf8 | 206 | | Yes | 8 | | utf8_roman_ci | utf8 | 207 | | Yes | 8 | | utf8_persian_ci | utf8 | 208 | | Yes | 8 | | utf8_esperanto_ci | utf8 | 209 | | Yes | 8 | | utf8_hungarian_ci | utf8 | 210 | | Yes | 8 | | utf8_sinhala_ci | utf8 | 211 | | Yes | 8 | | utf8_german2_ci | utf8 | 212 | | Yes | 8 | | utf8_croatian_ci | utf8 | 213 | | Yes | 8 | | utf8_unicode_520_ci | utf8 | 214 | | Yes | 8 | | utf8_vietnamese_ci | utf8 | 215 | | Yes | 8 | | utf8_general_mysql500_ci | utf8 | 223 | | Yes | 1 | | ucs2_general_ci | ucs2 | 35 | Yes | Yes | 1 | | ucs2_bin | ucs2 | 90 | | Yes | 1 | | ucs2_unicode_ci | ucs2 | 128 | | Yes | 8 | | ucs2_icelandic_ci | ucs2 | 129 | | Yes | 8 | | ucs2_latvian_ci | ucs2 | 130 | | Yes | 8 | | ucs2_romanian_ci | ucs2 | 131 | | Yes | 8 | | ucs2_slovenian_ci | ucs2 | 132 | | Yes | 8 | | ucs2_polish_ci | ucs2 | 133 | | Yes | 8 | | ucs2_estonian_ci | ucs2 | 134 | | Yes | 8 | | ucs2_spanish_ci | ucs2 | 135 | | Yes | 8 | | ucs2_swedish_ci | ucs2 | 136 | | Yes | 8 | | ucs2_turkish_ci | ucs2 | 137 | | Yes | 8 | | ucs2_czech_ci | ucs2 | 138 | | Yes | 8 | | ucs2_danish_ci | ucs2 | 139 | | Yes | 8 | | ucs2_lithuanian_ci | ucs2 | 140 | | Yes | 8 | | ucs2_slovak_ci | ucs2 | 141 | | Yes | 8 | | ucs2_spanish2_ci | ucs2 | 142 | | Yes | 8 | | ucs2_roman_ci | ucs2 | 143 | | Yes | 8 | | ucs2_persian_ci | ucs2 | 144 | | Yes | 8 | | ucs2_esperanto_ci | ucs2 | 145 | | Yes | 8 | | ucs2_hungarian_ci | ucs2 | 146 | | Yes | 8 | | ucs2_sinhala_ci | ucs2 | 147 | | Yes | 8 | | ucs2_german2_ci | ucs2 | 148 | | Yes | 8 | | ucs2_croatian_ci | ucs2 | 149 | | Yes | 8 | | ucs2_unicode_520_ci | ucs2 | 150 | | Yes | 8 | | ucs2_vietnamese_ci | ucs2 | 151 | | Yes | 8 | | ucs2_general_mysql500_ci | ucs2 | 159 | | Yes | 1 | | cp866_general_ci | cp866 | 36 | Yes | Yes | 1 | | cp866_bin | cp866 | 68 | | Yes | 1 | | keybcs2_general_ci | keybcs2 | 37 | Yes | Yes | 1 | | keybcs2_bin | keybcs2 | 73 | | Yes | 1 | | macce_general_ci | macce | 38 | Yes | Yes | 1 | | macce_bin | macce | 43 | | Yes | 1 | | macroman_general_ci | macroman | 39 | Yes | Yes | 1 | | macroman_bin | macroman | 53 | | Yes | 1 | | cp852_general_ci | cp852 | 40 | Yes | Yes | 1 | | cp852_bin | cp852 | 81 | | Yes | 1 | | latin7_estonian_cs | latin7 | 20 | | Yes | 1 | | latin7_general_ci | latin7 | 41 | Yes | Yes | 1 | | latin7_general_cs | latin7 | 42 | | Yes | 1 | | latin7_bin | latin7 | 79 | | Yes | 1 | | utf8mb4_general_ci | utf8mb4 | 45 | Yes | Yes | 1 | | utf8mb4_bin | utf8mb4 | 46 | | Yes | 1 | | utf8mb4_unicode_ci | utf8mb4 | 224 | | Yes | 8 | | utf8mb4_icelandic_ci | utf8mb4 | 225 | | Yes | 8 | | utf8mb4_latvian_ci | utf8mb4 | 226 | | Yes | 8 | | utf8mb4_romanian_ci | utf8mb4 | 227 | | Yes | 8 | | utf8mb4_slovenian_ci | utf8mb4 | 228 | | Yes | 8 | | utf8mb4_polish_ci | utf8mb4 | 229 | | Yes | 8 | | utf8mb4_estonian_ci | utf8mb4 | 230 | | Yes | 8 | | utf8mb4_spanish_ci | utf8mb4 | 231 | | Yes | 8 | | utf8mb4_swedish_ci | utf8mb4 | 232 | | Yes | 8 | | utf8mb4_turkish_ci | utf8mb4 | 233 | | Yes | 8 | | utf8mb4_czech_ci | utf8mb4 | 234 | | Yes | 8 | | utf8mb4_danish_ci | utf8mb4 | 235 | | Yes | 8 | | utf8mb4_lithuanian_ci | utf8mb4 | 236 | | Yes | 8 | | utf8mb4_slovak_ci | utf8mb4 | 237 | | Yes | 8 | | utf8mb4_spanish2_ci | utf8mb4 | 238 | | Yes | 8 | | utf8mb4_roman_ci | utf8mb4 | 239 | | Yes | 8 | | utf8mb4_persian_ci | utf8mb4 | 240 | | Yes | 8 | | utf8mb4_esperanto_ci | utf8mb4 | 241 | | Yes | 8 | | utf8mb4_hungarian_ci | utf8mb4 | 242 | | Yes | 8 | | utf8mb4_sinhala_ci | utf8mb4 | 243 | | Yes | 8 | | utf8mb4_german2_ci | utf8mb4 | 244 | | Yes | 8 | | utf8mb4_croatian_ci | utf8mb4 | 245 | | Yes | 8 | | utf8mb4_unicode_520_ci | utf8mb4 | 246 | | Yes | 8 | | utf8mb4_vietnamese_ci | utf8mb4 | 247 | | Yes | 8 | | cp1251_bulgarian_ci | cp1251 | 14 | | Yes | 1 | | cp1251_ukrainian_ci | cp1251 | 23 | | Yes | 1 | | cp1251_bin | cp1251 | 50 | | Yes | 1 | | cp1251_general_ci | cp1251 | 51 | Yes | Yes | 1 | | cp1251_general_cs | cp1251 | 52 | | Yes | 1 | | utf16_general_ci | utf16 | 54 | Yes | Yes | 1 | | utf16_bin | utf16 | 55 | | Yes | 1 | | utf16_unicode_ci | utf16 | 101 | | Yes | 8 | | utf16_icelandic_ci | utf16 | 102 | | Yes | 8 | | utf16_latvian_ci | utf16 | 103 | | Yes | 8 | | utf16_romanian_ci | utf16 | 104 | | Yes | 8 | | utf16_slovenian_ci | utf16 | 105 | | Yes | 8 | | utf16_polish_ci | utf16 | 106 | | Yes | 8 | | utf16_estonian_ci | utf16 | 107 | | Yes | 8 | | utf16_spanish_ci | utf16 | 108 | | Yes | 8 | | utf16_swedish_ci | utf16 | 109 | | Yes | 8 | | utf16_turkish_ci | utf16 | 110 | | Yes | 8 | | utf16_czech_ci | utf16 | 111 | | Yes | 8 | | utf16_danish_ci | utf16 | 112 | | Yes | 8 | | utf16_lithuanian_ci | utf16 | 113 | | Yes | 8 | | utf16_slovak_ci | utf16 | 114 | | Yes | 8 | | utf16_spanish2_ci | utf16 | 115 | | Yes | 8 | | utf16_roman_ci | utf16 | 116 | | Yes | 8 | | utf16_persian_ci | utf16 | 117 | | Yes | 8 | | utf16_esperanto_ci | utf16 | 118 | | Yes | 8 | | utf16_hungarian_ci | utf16 | 119 | | Yes | 8 | | utf16_sinhala_ci | utf16 | 120 | | Yes | 8 | | utf16_german2_ci | utf16 | 121 | | Yes | 8 | | utf16_croatian_ci | utf16 | 122 | | Yes | 8 | | utf16_unicode_520_ci | utf16 | 123 | | Yes | 8 | | utf16_vietnamese_ci | utf16 | 124 | | Yes | 8 | | utf16le_general_ci | utf16le | 56 | Yes | Yes | 1 | | utf16le_bin | utf16le | 62 | | Yes | 1 | | cp1256_general_ci | cp1256 | 57 | Yes | Yes | 1 | | cp1256_bin | cp1256 | 67 | | Yes | 1 | | cp1257_lithuanian_ci | cp1257 | 29 | | Yes | 1 | | cp1257_bin | cp1257 | 58 | | Yes | 1 | | cp1257_general_ci | cp1257 | 59 | Yes | Yes | 1 | | utf32_general_ci | utf32 | 60 | Yes | Yes | 1 | | utf32_bin | utf32 | 61 | | Yes | 1 | | utf32_unicode_ci | utf32 | 160 | | Yes | 8 | | utf32_icelandic_ci | utf32 | 161 | | Yes | 8 | | utf32_latvian_ci | utf32 | 162 | | Yes | 8 | | utf32_romanian_ci | utf32 | 163 | | Yes | 8 | | utf32_slovenian_ci | utf32 | 164 | | Yes | 8 | | utf32_polish_ci | utf32 | 165 | | Yes | 8 | | utf32_estonian_ci | utf32 | 166 | | Yes | 8 | | utf32_spanish_ci | utf32 | 167 | | Yes | 8 | | utf32_swedish_ci | utf32 | 168 | | Yes | 8 | | utf32_turkish_ci | utf32 | 169 | | Yes | 8 | | utf32_czech_ci | utf32 | 170 | | Yes | 8 | | utf32_danish_ci | utf32 | 171 | | Yes | 8 | | utf32_lithuanian_ci | utf32 | 172 | | Yes | 8 | | utf32_slovak_ci | utf32 | 173 | | Yes | 8 | | utf32_spanish2_ci | utf32 | 174 | | Yes | 8 | | utf32_roman_ci | utf32 | 175 | | Yes | 8 | | utf32_persian_ci | utf32 | 176 | | Yes | 8 | | utf32_esperanto_ci | utf32 | 177 | | Yes | 8 | | utf32_hungarian_ci | utf32 | 178 | | Yes | 8 | | utf32_sinhala_ci | utf32 | 179 | | Yes | 8 | | utf32_german2_ci | utf32 | 180 | | Yes | 8 | | utf32_croatian_ci | utf32 | 181 | | Yes | 8 | | utf32_unicode_520_ci | utf32 | 182 | | Yes | 8 | | utf32_vietnamese_ci | utf32 | 183 | | Yes | 8 | | binary | binary | 63 | Yes | Yes | 1 | | geostd8_general_ci | geostd8 | 92 | Yes | Yes | 1 | | geostd8_bin | geostd8 | 93 | | Yes | 1 | | cp932_japanese_ci | cp932 | 95 | Yes | Yes | 1 | | cp932_bin | cp932 | 96 | | Yes | 1 | | eucjpms_japanese_ci | eucjpms | 97 | Yes | Yes | 1 | | eucjpms_bin | eucjpms | 98 | | Yes | 1 | | gb18030_chinese_ci | gb18030 | 248 | Yes | Yes | 2 | | gb18030_bin | gb18030 | 249 | | Yes | 1 | | gb18030_unicode_520_ci | gb18030 | 250 | | Yes | 8 | +--------------------------+----------+-----+---------+----------+---------+ 222 rows in set (0.01 sec) 6.字符集设置 mysql有4个级别的字符集 1.服务器级别(操作系统级别) 2.数据库级别 3.表级别 4.列级别 6.1服务器级别 1.操作系统级别 #centOS7 [root@hwyun ~]# cat /etc/locale.conf LANG=en_US.UTF-8 #centOS6 [root@test1 ~]# cat /etc/sysconfig/i18n LANG=\"en_US.UTF-8\" SYSFONT=\"latarcyrheb-sun16\" [root@test1 ~]# echo $LANG en_US.UTF-8 2.操作系统客户端级别 ssh连接工具设置 3.mysql实例级别 方法1：在编译安装时候就指定如下服务器端字符集。 cmake . -DDEFAULT_CHARSET=utf8 \\ -DDEFAULT_COLLATION=utf8_general_ci \\ -DWITH_EXTRA_CHARSETS=all \\ 方法2：在配置文件中设置字符集 [mysqld] character-set-server=utf8 6.2数据库级别 mysql> create database 数据库名 charset utf8 default collate = utf8_general_ci; 6.3表级别 mysql> CREATE TABLE `test` ( `id` int(4) NOT NULL AUTO_INCREMENT, `name` char(20) NOT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=13 DEFAULT CHARSET=utf8; 6.4列级别 类型为CHAR、VARCHAR、TEXT的列，可以指定字符集/校验规则 create table t1(id int,address char(30) character set utf8); 7.生产环境更改数据库(含数据)字符集的方法 mysql> alter database 数据库名 CHARACTER SET utf8 collate utf8_general_ci; mysql> alter table t1 CHARACTER SET utf8; 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mysql/mysql基础/15.mysql日志.html":{"url":"db/mysql/mysql基础/15.mysql日志.html","title":"10.mysql日志","keywords":"","body":"mysql日志 1.错误日志 1.1yum安装默认路径 /var/log/mysqld.log mysql> show variables like \"%log_error%\"; +---------------+---------------------+ | Variable_name | Value | +---------------+---------------------+ | log_error | /var/log/mysqld.log | +---------------+---------------------+ 1 row in set (0.01 sec) 1.2二进制安装、编译安装路径 $MYSQL_HOME/data/主机名.err //编辑配置文件 [root@db01 ~]# vim /etc/my.cnf [mysqld] log_error=/usr/local/mysql/data/error.log //查看方式 mysql> show variables like 'log_error'; +---------------+---------------------------------+ | Variable_name | Value | +---------------+---------------------------------+ | log_error | /usr/local/mysql/data/error.log | +---------------+---------------------------------+ 1 row in set (0.00 sec) 2.二进制日志 2.1含义 binlog日志，记录对mysql的所有更新的操作，插入的操作(增删改操作) 2.2作用 恢复数据，MySQL AB复制，记录所有对数据库发生修改的操作 2.3二进制日志模式 statement：语句模式，上图中将update语句进行记录（默认模式） 优点 简单明了，容易被看懂，就是sql语句，记录时不需要太多的磁盘空间 缺点 记录不够严谨 row：行模式，即数据行的变化过程，上图中Age=19修改成Age=20的过程事件。 mixed：以上两者的混合模式。 企业推荐使用row模式 优点 记录更加严谨 缺点 有可能会需要更多的磁盘空间，不太容易被读懂 2.4开启方式 //开启二进制日志 [root@db01 data]# vim /etc/my.cnf [mysqld] log-bin=mysql-bin binlog_format=row //注意:在mysql5.7中开启binlog必须要加上server-id。 [root@db01 data]# vim /etc/my.cnf [mysqld] log-bin=mysql-bin binlog_format=row server_id=1 2.5二进制日志的操作 //物理查看 [root@db01 data]# ll /usr/local/mysql/data/ -rw-rw---- 1 mysql mysql 285 Mar 6 2017 mysql-bin.000001 //命令行查看 mysql> show binary logs; +------------------+-----------+ | Log_name | File_size | +------------------+-----------+ | mysql-bin.000001 | 120 | +------------------+-----------+ 1 row in set (0.00 sec) mysql> show master status; +------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +------------------+----------+--------------+------------------+-------------------+ | mysql-bin.000001 | 120 | | | | +------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) //查看binlog事件 mysql> show binlog events in 'mysql-bin.000001'; +------------------+-----+-------------+-----------+-------------+---------------------------------------+ | Log_name | Pos | Event_type | Server_id | End_log_pos | Info | +------------------+-----+-------------+-----------+-------------+---------------------------------------+ | mysql-bin.000001 | 4 | Format_desc | 1 | 120 | Server ver: 5.6.40-log, Binlog ver: 4 | +------------------+-----+-------------+-----------+-------------+---------------------------------------+ 1 row in set (0.01 sec) 2.6事件 2.6.1事件含义 1.在binlog中最小的记录单元为event 2.一个事务会被拆分成多个事件（event） 2.6.2事件特性 1.每个event都有一个开始位置（start position）和结束位置（stop position） 2.所谓的位置就是event对整个二进制的文件的相对位置 3.对于一个二进制日志中，前120个position是文件格式信息预留空间 4.MySQL第一个记录的事件，都是从120开始的 2.6.3利用二进制日志恢复数据示例 1.修改mysql二进制日志为row模式 [root@db01 data]# vim /etc/my.cnf [mysqld] log-bin=mysql-bin binlog_format=row 2.查看二进制日志格式 mysql> show variables like 'binlog_format'; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | binlog_format | ROW | +---------------+-------+ 1 row in set (0.01 sec) 3.查看binlog信息 mysql> show master status; +------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +------------------+----------+--------------+------------------+-------------------+ | mysql-bin.000001 | 120 | | | | +------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.05 sec) 4.先刷新，然后再查看binlog信息，此时位置为120 mysql> flush logs; Query OK, 0 rows affected (0.01 sec) mysql> show master status; +------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +------------------+----------+--------------+------------------+-------------------+ | mysql-bin.000002 | 120 | | | | +------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 5.创建一个binlog库 mysql> create database binlog; Query OK, 1 row affected (0.01 sec) 6.创建一个表binlog_table mysql> use binlog; Database changed mysql> create table binlog_table(id int); Query OK, 0 rows affected (0.03 sec) 7.创建库和表后查看binlog信息，此时binlog位置为331 mysql> show master status; +------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +------------------+----------+--------------+------------------+-------------------+ | mysql-bin.000003 | 331 | | | | +------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 8.向表中插入一条数据并查看binlog信息，此时binlog位置为533 mysql> insert into binlog_table values(1); Query OK, 1 row affected (0.01 sec) mysql> show master status; +------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +------------------+----------+--------------+------------------+-------------------+ | mysql-bin.000003 | 533 | | | | +------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 9.向表中插入2条数据并查看binlog信息，此时binlog位置为937 mysql> insert into binlog_table values(2); Query OK, 1 row affected (0.00 sec) mysql> insert into binlog_table values(3); Query OK, 1 row affected (0.01 sec) mysql> show master status; +------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +------------------+----------+--------------+------------------+-------------------+ | mysql-bin.000002 | 937 | | | | +------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 10.删除一条数据、然后删除表、库 mysql> select * from binlog_table; +------+ | id | +------+ | 1 | | 2 | | 3 | +------+ 3 rows in set (0.00 sec) mysql> delete from binlog_table where id=1; Query OK, 1 row affected (0.02 sec) mysql> drop table binlog_table; Query OK, 0 rows affected (0.01 sec) mysql> drop database binlog; Query OK, 0 rows affected (0.01 sec) 11.开始查找要截取的段，这里要恢复删除的数据库 mysqlbinlog --base64-output=decode-rows -vvv /usr/local/mysql/data/mysql-bin.000002 [root@db02 data]# mysqlbinlog --base64-output=decode-rows -vvv /usr/local/mysql/data/mysql-bin.000002 12.开始恢复，恢复前一定要临时关闭二进制日志，否则二进制日志会多记录 #临时关闭二进制日志 mysql> set sql_log_bin=0; Query OK, 0 rows affected (0.01 sec) #截取并写入到一个文件中 [root@db02 data]# mysqlbinlog --start-position=120 --stop-position=1011 /usr/local/mysql/data/mysql-bin.000002 >/tmp/binlog.sql #开始恢复 [root@db02 data]# mysql -uroot -p show databases; +--------------------+ | Database | +--------------------+ | information_schema | | binlog | | mysql | | performance_schema | | test | +--------------------+ 5 rows in set (0.00 sec) mysql> use binlog; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed mysql> show tables; +------------------+ | Tables_in_binlog | +------------------+ | binlog_table | +------------------+ 1 row in set (0.00 sec) mysql> select * from binlog_table; +------+ | id | +------+ | 1 | | 2 | | 3 | +------+ 3 rows in set (0.00 sec) 3.通用查询日志 /var/run/mysqld/mysqld.log #对MySQL所有增删改查都会记录，默认关闭 mysql> show variables like \"%general%\"; +------------------+----------------------------+ | Variable_name | Value | +------------------+----------------------------+ | general_log | OFF | | general_log_file | /var/run/mysqld/mysqld.log | +------------------+----------------------------+ 2 rows in set (0.00 sec) #开启通用查询日志后才会有文件/var/run/mysqld/mysqld.log mysql> set global general_log=on; Query OK, 0 rows affected (0.00 sec) 4.慢查询日志 /var/run/mysqld/mysqld-slow.log #记录查询时间长的语句，用来优化，默认10s为慢查询 mysql> show variables like \"%slow%\"; +---------------------+---------------------------------+ | Variable_name | Value | +---------------------+---------------------------------+ | log_slow_queries | OFF | | slow_launch_time | 2 | | slow_query_log | OFF | | slow_query_log_file | /var/run/mysqld/mysqld-slow.log | +---------------------+---------------------------------+ 4 rows in set (0.00 sec) #设置慢查询日志存放路径 mysql>set global slow_query_log_file=路径 #开启慢查询 mysql> set global slow_query_log=on; Query OK, 0 rows affected (0.00 sec) #设置慢查询超时时间 mysql> set long_query_time=2; Query OK, 0 rows affected (0.00 sec) #模拟慢查询时间为5s mysql> select sleep(5); +----------+ | sleep(5) | +----------+ | 0 | +----------+ 1 row in set (5.00 sec) #此时查看MySQL慢查询日志就可以看到超时的语句 [root@mysql ~]# less /var/run/mysqld/mysqld-slow.log /usr/libexec/mysqld, Version: 5.1.73 (Source distribution). started with: Tcp port: 3306 Unix socket: /var/lib/mysql/mysql.sock Time Id Command Argument # Time: 171123 9:58:55 # User@Host: root[root] @ mysql [] # Query_time: 5.001586 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 0 use DB1; SET timestamp=1511402335; select sleep(5); 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mysql/mysql基础/16.mysql设置密码及忘记密码如何解决.html":{"url":"db/mysql/mysql基础/16.mysql设置密码及忘记密码如何解决.html","title":"11.mysql修改密码及忘记密码如何解决","keywords":"","body":"mysql设置密码及忘记密码如何解决 mysql5.6 方法一 mysqladmin 修改指定用户密码 mysqladmin -u用户名 -p旧密码 password 新密码 示例：使用mysqladmin命令给root设置密码 mysql5.7和mysql8中在命令行使用命令mysqladmin会有警告信息，mysql5.6没有 $ mysqladmin -uroot -p password Enter password: New password: Confirm new password: Warning: Since password will be sent to server in plain text, use ssl connection to ensure password safety. 方法二 set password 修改指定用户密码 set password for 用户名@localhost = password('新密码'); 默认修改root密码 set password='新密码' 或 set password=password('新密码'); 方法三 update更新user表 ⚠️mysql5.6中user表中密码的字段是password ⚠️mysql5.7和8中user表中密码的字段是authentication_string ⚠️mysql8中user表中密码的字段authentication_string后边直接跟字符串即可，不能写password mysql5.6 update mysql.user set password=password('新密码') where user='root' and host='localhost'; mysql5.7 update mysql.user set authentication_string=password('新密码') where user='root' and host='localhost'; mysql8 update mysql.user set authentication_string='新密码' where user='root' and host='localhost'; mysql5.7 方法一 mysqladmin 修改指定用户密码 mysqladmin -u用户名 -p旧密码 password 新密码 示例：使用mysqladmin命令给root设置密码 mysql5.7和mysql8中在命令行使用命令mysqladmin会有警告信息，mysql5.6没有 $ mysqladmin -uroot -p password Enter password: New password: Confirm new password: Warning: Since password will be sent to server in plain text, use ssl connection to ensure password safety. 方法二 set password 修改指定用户密码 set password for 用户名@localhost = password('新密码'); 默认修改root密码 set password='新密码' 或 set password=password('新密码'); 方法三 update更新user表 ⚠️mysql5.6中user表中密码的字段是password ⚠️mysql5.7和8中user表中密码的字段是authentication_string ⚠️mysql8中user表中密码的字段authentication_string后边直接跟字符串即可，不能写password mysql5.6 update mysql.user set password=password('新密码') where user='root' and host='localhost'; mysql5.7 update mysql.user set authentication_string=password('新密码') where user='root' and host='localhost'; mysql8 update mysql.user set authentication_string='新密码' where user='root' and host='localhost'; mysql8.0 方法一 修改指定用户密码 mysqladmin -u用户名 -p旧密码 password 新密码 示例：使用mysqladmin命令给root设置密码 mysql5.7和mysql8中在命令行使用命令mysqladmin会有警告信息，mysql5.6没有 $ mysqladmin -uroot -p password Enter password: New password: Confirm new password: Warning: Since password will be sent to server in plain text, use ssl connection to ensure password safety. 方法二 set password ⚠️mysql8中以下两种方式不可用 set password=password('新密码'); set password for root@localhost = password('新密码'); 只能用如下方法 set password='新密码' 方法三 update更新user表 ⚠️mysql5.6中user表中密码的字段是password ⚠️mysql5.7和8中user表中密码的字段是authentication_string ⚠️mysql8中user表中密码的字段authentication_string后边直接跟字符串即可，不能写password mysql5.6 update mysql.user set password=password('新密码') where user='root' and host='localhost'; mysql5.7 update mysql.user set authentication_string=password('新密码') where user='root' and host='localhost'; mysql8 update mysql.user set authentication_string='新密码' where user='root' and host='localhost'; mysql忘记密码 第一步、停止mysql数据库 第二步、编辑mysql配置文件my.cnf，在[mysqld]下加参数skip-grant-tables 第三步、启动mysql数据库，进入数据库修改密码，修改完成之后把配置文件中的参数skip-grant-tables注释或者删除 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mysql/mysql基础/17.mysql逻辑备份 mysqldump.html":{"url":"db/mysql/mysql基础/17.mysql逻辑备份 mysqldump.html","title":"12.mysql逻辑备份 mysqldump","keywords":"","body":"mysql逻辑备份 mysqldump mysql5.7官方手册 mysql5.7备份和恢复官方文档 一、mysql备份 1.1 为什么要备份 ①防止数据丢失 ②恢复数据，误操作最多 1.2 数据的备份类型 ①完全备份-->备份整个数据库 ②部分备份-->备份部分数据库，例如只备份一个库、一张表 ③增量备份-->备份自上一次备份以来(增量或完全)以来变化的数据 特点: 节约空间、还原麻烦 ④差异备份-->备份自上一次完全备份以来变化的数据 特点: 浪费空间、还原比增量备份简单 1.3 备份方式 热备份 热备份指的是当数据库进行备份时, 数据库的读写操作均不是受影响 温备份 温备份指的是当数据库进行备份时, 数据库的读操作可以执行, 但是不能执行写操作 冷备份 冷备份指的是当数据库进行备份时, 数据库不能进行读写操作, 即数据库要下线 MySQL中进行不同方式的备份还要考虑存储引擎是否支持 MyISAM 热备 × 温备 √ 冷备 √ InnoDB 热备 √ 温备 √ 冷备 √ 1.4 备份命令 mysqldump（逻辑） mysql原生自带很好用的逻辑备份工具 mysqlbinlog（逻辑） 实现binlog备份的原生态命令 xtrabackup（物理） precona公司开发的性能很高的物理备份工具 1.5 mysql备份方式总结 备份方法 备份速度 恢复速度 便捷性 功能 一般用于 cp 快 快 一般、灵活性低 很弱 少量数据备份 mysqldump 慢 慢 一般、可无视存储引擎的差异 一般 中小型数据量的备份 lvm2快照 快 快 一般、支持几乎热备、速度快 一般 中小型数据量的备份 xtrabackup 较快 较快 实现innodb热备、对存储引擎有要求 强大 较大规模的备份 二、mysqldump备份 2.0 利用存储过程生成大量数据 #1.创建数据库 mysql> create database db1; Query OK, 1 row affected (0.00 sec) #2.创建表 mysql> use db1; Database changed mysql> create table db1_t1( id int, name varchar(20), gender char(6), email varchar(50), first_name char(10), last_name char(10) ); Query OK, 0 rows affected (0.01 sec) #3.创建存储过程 mysql> delimiter $$ #声明存储过程的结束符号为$$ mysql> create procedure auto_insert1() BEGIN declare i int default 1; while(i delimiter ; #重新声明分号为结束符号，注意有空格 #4.查看存储过程 show create procedure auto_insert1\\G #5.调用存储过程 call auto_insert1(); #6.查看数据 mysql> select count(*) from s1; +----------+ | count(*) | +----------+ | 100000 | +----------+ 1 row in set (0.04 sec) mysql> select * from s1 limit 10; +------+--------+--------+-------------+------------+-----------+ | id | name | gender | email | first_name | last_name | +------+--------+--------+-------------+------------+-----------+ | 1 | xboyww | man | xboyww1@qq | a1 | b1 | | 2 | xboyww | man | xboyww2@qq | a2 | b2 | | 3 | xboyww | man | xboyww3@qq | a3 | b3 | | 4 | xboyww | man | xboyww4@qq | a4 | b4 | | 5 | xboyww | man | xboyww5@qq | a5 | b5 | | 6 | xboyww | man | xboyww6@qq | a6 | b6 | | 7 | xboyww | man | xboyww7@qq | a7 | b7 | | 8 | xboyww | man | xboyww8@qq | a8 | b8 | | 9 | xboyww | man | xboyww9@qq | a9 | b9 | | 10 | xboyww | man | xboyww10@qq | a10 | b10 | +------+--------+--------+-------------+------------+-----------+ 10 rows in set (0.00 sec) #删除存储过程 DROP PROCEDURE auto_insert1; 生成的数据库和表 db1 db1_t1 10万条数据 db1_t2 10万条数据 db2 db2_t1 10万条数据 db2_t2 10万条数据 mysqldump连接服务端参数 -u 指定用户 -p 指定密码 -S 指定套接字文件 -h 指定主机 -P 指定端口 mysqldump的三种语法 shell> mysqldump [options] db_name [tbl_name ...] shell> mysqldump [options] --databases db_name ... shell> mysqldump [options] --all-databases 2.1 全库备份 -A,--all-databases mysqldump -uroot -p -A >all.sql 2.2 单库、多库备份 -B,--databases 单库备份，可以不加选项-B mysqldump -uroot -p -B db1 > db1.sql 或者 mysqldump -uroot -p db1 > db1.sql 多库备份，必须加参数-B mysqldump -uroot -p -B db1 db2 > db1_db2.sql 2.3 单表、多表备份 不需要参数 单表备份 mysqldump -uroot -p db1 db1_t1 > db1.db1_t1.sql 多表备份 mysqldump -uroot -p db1 db1_t1 db1_t2 > db1.db1_t1_t2.sql 2.4 备份的一些选项 2.4.1 --master-data 备份时加入change master语句，需要开启binlog日志 有3个参数 0 没有 1 不注释 2 注释 当参数=0时，备份的文件中是没有change master to语句的 mysqldump -uroot -p -B db1 --master-data=0 > db1.sql 当参数=1时，备份的文件中就会有change master to语句，并且没有注释 mysqldump -uroot -p -B db1 --master-data=1 > db1.sql #备份的sql文件中会有change master to语句，并且没有注释 $ grep 'CHANGE MASTER' db1.sql CHANGE MASTER TO MASTER_LOG_FILE='binlog.000004', MASTER_LOG_POS=154; 当参数=2时，备份的文件中就会有change master to语句，并且是注释的 mysqldump -uroot -p -B db1 --master-data=2 > db1.sql #备份的sql文件中会有change master to语句，并且是注释的 $ grep 'CHANGE MASTER' db1.sql -- CHANGE MASTER TO MASTER_LOG_FILE='binlog.000004', MASTER_LOG_POS=154; 2.4.2 -R, --routines 备份存储过程和函数数据 mysqldump -uroot -A -R --master-data=2 > all.sql 2.4.3 --triggers 备份触发器数据 默认启用，使用选项--skip-triggers禁用 mysqldump -uroot -A --triggers --master-data=2 > all.sql 2.4.4 --single-transaction 快照备份，仅对InnoDB引擎生效 此选项将事务隔离模式设置为， REPEATABLE READ并START TRANSACTION mysqldump -uroot -A --single-transaction --master-data=2 > all.sql 2.4.5 --lock-all-tables，-x 锁表备份 锁定所有数据库中的所有表，此选项将自动关闭 --single-transaction和 --lock-tables mysqldump -uroot -A -x --master-data=2 > all.sql 三、mysqldump恢复 #先不记录二进制日志 mysql> set sql_log_bin=0; #库内恢复操作 mysql> source /backup/all.sql #库外恢复操作 mysql -uroot -p mysqldump恢复特点 mysqldump在备份和恢复时都需要MySQL实例启动为前提 一般数据量级100G以内，大约15-30分钟可以恢复（PB、EB就需要考虑别的方式） mysqldump是以覆盖的形式恢复数据的 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mysql/mysql基础/18.mysql物理备份 xtrabackup.html":{"url":"db/mysql/mysql基础/18.mysql物理备份 xtrabackup.html","title":"13.mysql物理备份 xtrabackup","keywords":"","body":"mysql物理备份 xtrabackup xtrabackup github地址 xtrabackup2.4官方文档 xtrabackup8.0官方文档 xtrabackup2.4官方下载地址 xtrabackup8.0官方下载地址 xtrabackup备份方式（物理备份） 对于非innodb表（比如myisam）是直接锁表cp数据文件，属于一种温备 对于innodb的表（支持事务），不锁表，cp数据页最终以数据文件方式保存下来，并且把redo和undo一并备走，属于热备方式 备份时读取配置文件/etc/my.cnf 一、安装xtrabackup 1.1 下载软件包并安装 wget https://www.percona.com/downloads/Percona-XtraBackup-2.4/Percona-XtraBackup-2.4.20/binary/redhat/7/x86_64/percona-xtrabackup-24-2.4.20-1.el7.x86_64.rpm yum -y localinstall percona-xtrabackup-24-2.4.20-1.el7.x86_64.rpm 1.2 查看版本 $ xtrabackup -v xtrabackup: recognized server arguments: --datadir=/usr/local/mysql/data --server-id=1 --log_bin=binlog xtrabackup version 2.4.20 based on MySQL server 5.7.26 Linux (x86_64) (revision id: c8b4056) 二、xtrabackup全备 xtrabackup xtrabackup可以在不加锁的情况下备份innodb数据表，不过此工具不能操作myisam。 innobackupex innobackupex是一个封装了xtrabackup的脚本，能同时处理innodb和myisam，但在处理myisam时需要加一个读锁。 利用存储过程生成大量数据 db1、db2每个库中有两张表，每张表10万条数据 #1.创建数据库 mysql> create database db1; Query OK, 1 row affected (0.00 sec) #2.创建表 mysql> use db1; Database changed mysql> create table db1_t1( id int, name varchar(20), gender char(6), email varchar(50), first_name char(10), last_name char(10) ); Query OK, 0 rows affected (0.01 sec) #3.创建存储过程 mysql> delimiter $$ #声明存储过程的结束符号为$$ mysql> create procedure auto_insert1() BEGIN declare i int default 1; while(i delimiter ; #重新声明分号为结束符号，注意有空格 #4.查看存储过程 show create procedure auto_insert1\\G #5.调用存储过程 call auto_insert1(); #6.查看数据 mysql> select count(*) from s1; +----------+ | count(*) | +----------+ | 100000 | +----------+ 1 row in set (0.04 sec) mysql> select * from s1 limit 10; +------+--------+--------+-------------+------------+-----------+ | id | name | gender | email | first_name | last_name | +------+--------+--------+-------------+------------+-----------+ | 1 | xboyww | man | xboyww1@qq | a1 | b1 | | 2 | xboyww | man | xboyww2@qq | a2 | b2 | | 3 | xboyww | man | xboyww3@qq | a3 | b3 | | 4 | xboyww | man | xboyww4@qq | a4 | b4 | | 5 | xboyww | man | xboyww5@qq | a5 | b5 | | 6 | xboyww | man | xboyww6@qq | a6 | b6 | | 7 | xboyww | man | xboyww7@qq | a7 | b7 | | 8 | xboyww | man | xboyww8@qq | a8 | b8 | | 9 | xboyww | man | xboyww9@qq | a9 | b9 | | 10 | xboyww | man | xboyww10@qq | a10 | b10 | +------+--------+--------+-------------+------------+-----------+ 10 rows in set (0.00 sec) #删除存储过程 DROP PROCEDURE auto_insert1; db3，一张表，两条数据 mysql> create database db3; Query OK, 1 row affected (0.00 sec) mysql> create table t3(id int,name char(10)) engine=myisam; Query OK, 0 rows affected (0.01 sec) mysql> insert into t3 values(1,'xiaoming'),(2,'xiaohong'); Query OK, 2 rows affected (0.00 sec) Records: 2 Duplicates: 0 Warnings: 0 mysql> select * from t3; +------+----------+ | id | name | +------+----------+ | 1 | xiaoming | | 2 | xiaohong | +------+----------+ 2 rows in set (0.00 sec) 2.1 全备 2.1.1 备份方法一 xtrabackup --backup xtrabackup2.4 xtrabackup选项 执行备份命令 xtrabackup -uroot -p --backup --target-dir=/data/backups/ /data/backups备份目录下的内容 $ ll 总用量 12340 -rw-r----- 1 root root 487 7月 2 22:43 backup-my.cnf drwxr-x--- 2 root root 92 7月 2 22:43 db1 drwxr-x--- 2 root root 92 7月 2 22:43 db2 drwxr-x--- 2 root root 62 7月 2 22:43 db3 -rw-r----- 1 root root 646 7月 2 22:43 ib_buffer_pool -rw-r----- 1 root root 12582912 7月 2 22:43 ibdata1 drwxr-x--- 2 root root 4096 7月 2 22:43 mysql drwxr-x--- 2 root root 8192 7月 2 22:43 performance_schema drwxr-x--- 2 root root 8192 7月 2 22:43 sys -rw-r----- 1 root root 19 7月 2 22:43 xtrabackup_binlog_info -rw-r----- 1 root root 141 7月 2 22:43 xtrabackup_checkpoints -rw-r----- 1 root root 474 7月 2 22:43 xtrabackup_info -rw-r----- 1 root root 2560 7月 2 22:43 xtrabackup_logfile 2.1.2 备份方法二 innobackupex xtrabackup2.4 innobackupex选项 执行备份命令 -S /var/lib/mysql/mysql.sock -S选项可以不加，会从mysql配置文件/etc/my.cnf中读取sock文件位置 innobackupex -uroot -p1 /backup 备份完成后会在/backup目录下生成一个以时间命令并精确到秒的目录 $ ls 2020-07-02_22-57-09 $ cd 2020-07-02_22-57-09/ $ ll 总用量 12340 -rw-r----- 1 root root 487 7月 2 22:57 backup-my.cnf drwxr-x--- 2 root root 92 7月 2 22:57 db1 drwxr-x--- 2 root root 92 7月 2 22:57 db2 drwxr-x--- 2 root root 62 7月 2 22:57 db3 -rw-r----- 1 root root 646 7月 2 22:57 ib_buffer_pool -rw-r----- 1 root root 12582912 7月 2 22:57 ibdata1 drwxr-x--- 2 root root 4096 7月 2 22:57 mysql drwxr-x--- 2 root root 8192 7月 2 22:57 performance_schema drwxr-x--- 2 root root 8192 7月 2 22:57 sys -rw-r----- 1 root root 19 7月 2 22:57 xtrabackup_binlog_info -rw-r----- 1 root root 141 7月 2 22:57 xtrabackup_checkpoints -rw-r----- 1 root root 494 7月 2 22:57 xtrabackup_info -rw-r----- 1 root root 2560 7月 2 22:57 xtrabackup_logfile 如果想要自主命名备份目录的话，需要加参数--no-timestamp innobackupex -uroot -p1 --no-timestamp /backup/bak 在备份目录下会有一个文件xtrabackup_binlog_info，这个文件记录了binlog文件名和binlog的位置点 $ cat xtrabackup_binlog_info binlog.000009 1061 在备份目录会有一个文件xtrabackup_info，这个文件记录了备份信息汇总 $ cat xtrabackup_info uuid = c47c158f-bc74-11ea-82fa-001c42f33c78 name = tool_name = innobackupex tool_command = --user=root --password=... --no-timestamp /backup/bak tool_version = 2.4.20 ibbackup_version = 2.4.20 server_version = 5.7.28-log start_time = 2020-07-02 23:00:27 end_time = 2020-07-02 23:00:28 lock_time = 0 binlog_pos = filename 'binlog.000009', position '1061' innodb_from_lsn = 0 innodb_to_lsn = 332706000 partial = N incremental = N format = file compact = N compressed = N encrypted = N 在备份目录下会有一个文件xtrabackup_logfile，这个文件是备份的redo_log文件 $ ll xtrabackup_logfile -rw-r----- 1 root root 2560 7月 2 23:00 xtrabackup_logfile 2.2 全备恢复 2.2.1 查看原有数据库 有3个库(db1，db2，db3)， mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | db1 | | db2 | | db3 | | mysql | | performance_schema | | sys | +--------------------+ 7 rows in set (0.00 sec) 2.2.2 原有数据库中的表 #db1，有两张表，每张表中有10万条数据 mysql> use db1; mysql> show tables; +---------------+ | Tables_in_db1 | +---------------+ | db1_t1 | | db1_t2 | +---------------+ 2 rows in set (0.00 sec) mysql> select count(*) from db1_t1; +----------+ | count(*) | +----------+ | 100000 | +----------+ 1 row in set (0.04 sec) mysql> select count(*) from db1_t2; +----------+ | count(*) | +----------+ | 100000 | +----------+ 1 row in set (0.04 sec) #db2，有两张表，每张表中有10万条数据 mysql> use db1; mysql> show tables; +---------------+ | Tables_in_db2 | +---------------+ | db2_t1 | | db2_t2 | +---------------+ 2 rows in set (0.00 sec) mysql> select count(*) from db2_t1; +----------+ | count(*) | +----------+ | 100000 | +----------+ 1 row in set (0.04 sec) mysql> select count(*) from db2_t2; +----------+ | count(*) | +----------+ | 100000 | +----------+ 1 row in set (0.03 sec) #db3，有1张表，表中2行数据 mysql> use db3; mysql> show tables; +---------------+ | Tables_in_db3 | +---------------+ | t3 | +---------------+ 1 row in set (0.00 sec) mysql> select count(*) from t3; +----------+ | count(*) | +----------+ | 2 | +----------+ 1 row in set (0.00 sec) 2.2.3 进行全库备份 innobackupex -uroot -p1 --no-timestamp /backup/bak 2.2.4 删除db1-3数据库 mysql> drop database db1; Query OK, 2 rows affected (0.00 sec) mysql> drop database db2; Query OK, 2 rows affected (0.01 sec) mysql> drop database db3; Query OK, 1 row affected (0.00 sec) mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | +--------------------+ 4 rows in set (0.00 sec) 2.2.5 将redo进行重做，已提交的写到数据文件，未提交的使用undo回滚，模拟CSR的过程 --apply-log参数的作用是应用 BACKUP-DIR 中的 xtrabackup_logfile 事务日志文件。一般情况下，在备份完成后，数据尚且不能用于恢复操作，因为备份的数据中可能会包含尚未提交的事务或已经提交但尚未同步至数据文件中的事务。因此，此时数据文件仍处于不一致状态。\"准备\"的主要作用正是通过回滚未提交的事务及同步已经提交的事务至数据文件使得数据文件处于一致性状态。 innobackupex -uroot -p1 --apply-log /backup/bak 2.2.6 停止mysql，删除原先数据目录 停止mysql $ /etc/init.d/mysqld stop Shutting down MySQL.... SUCCESS! 2.2.7 删除原先数据目录或者修改名称 ⚠️恢复数据之前需要保证数据目录是空的状态 mysql安装的数据目录为/usr/local/mysql/data #如果做删除操作，最好先备份然后再删除，虽然数据已经丢失一部分，这里选择修改目录名称 mv /usr/local/mysql/data{,-bak} 2.2.8 进行数据恢复 这里要注意，恢复的时候mysql配置文件[mysqld]下一定要指定mysql data目录 innobackupex -uroot -p1 --copy-back /backup/bak 或 xtrabackup -uroot p1 --copy-back --target-dir=/backup/bak 2.2.9 给恢复的目录重新授权所有者为mysql chown -R mysql.mysql /usr/local/mysql/data 2.2.10 启动mysql $ /etc/init.d/mysqld start Starting MySQL.Logging to '/usr/local/mysql/data/error.log'. . SUCCESS! 2.2.11 验证数据恢复 验证数据库是否还原 mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | db1 | | db2 | | db3 | | mysql | | performance_schema | | sys | +--------------------+ 7 rows in set (0.00 sec) 验证表中的数据是否还原 #db1，有两张表，每张表中有10万条数据 mysql> use db1; mysql> show tables; +---------------+ | Tables_in_db1 | +---------------+ | db1_t1 | | db1_t2 | +---------------+ 2 rows in set (0.00 sec) mysql> select count(*) from db1_t1; +----------+ | count(*) | +----------+ | 100000 | +----------+ 1 row in set (0.04 sec) mysql> select count(*) from db1_t2; +----------+ | count(*) | +----------+ | 100000 | +----------+ 1 row in set (0.04 sec) #db2，有两张表，每张表中有10万条数据 mysql> use db1; mysql> show tables; +---------------+ | Tables_in_db2 | +---------------+ | db2_t1 | | db2_t2 | +---------------+ 2 rows in set (0.00 sec) mysql> select count(*) from db2_t1; +----------+ | count(*) | +----------+ | 100000 | +----------+ 1 row in set (0.04 sec) mysql> select count(*) from db2_t2; +----------+ | count(*) | +----------+ | 100000 | +----------+ 1 row in set (0.03 sec) #db3，有1张表，表中2行数据 mysql> use db3; mysql> show tables; +---------------+ | Tables_in_db3 | +---------------+ | t3 | +---------------+ 1 row in set (0.00 sec) mysql> select count(*) from t3; +----------+ | count(*) | +----------+ | 2 | +----------+ 1 row in set (0.00 sec) 三、xtrabackup增量备份 xtrabackup2.4 增量备份官方文档 3.1 做全备 db1、db2、db3数据库及表数据说明 $ tree db1 db2 db3 db1 #两张表，每张表中10万条数据 ├── db1_t1.frm ├── db1_t1.ibd ├── db1_t2.frm ├── db1_t2.ibd └── db.opt db2 #两张表，每张表中10万条数据 ├── db2_t1.frm ├── db2_t1.ibd ├── db2_t2.frm ├── db2_t2.ibd └── db.opt db3 #一张表，2条数据 ├── db.opt ├── t3.frm ├── t3.MYD └── t3.MYI 删除之前的全备，重新做全备 innobackupex -uroot -p1 --no-timestamp /backup/bak 或 xtrabackup -uroot -p --backup --target-dir=/backup/bak 在备份目录/backup/bak中有一个文件xtrabackup_checkpoints，这个文件记录了备份类型、lsn(日志序列号) $ cat xtrabackup_checkpoints backup_type = full-backuped from_lsn = 0 to_lsn = 332706875 last_lsn = 332706884 compact = 0 recover_binlog_info = 0 flushed_lsn = 332706884 3.2 开始增量备份 3.2.1 基于全备的的增备 开始第一次增备，只要全备和多个增备的LSN号连续，那么就可以逐个进行恢复。可以在备份目录xtrabackup_checkpoints文件中看到，其中全备的from_lsn=0,增备的from_lsn应该等于上一个增备或者全备的to_lsn $ cat xtrabackup_checkpoints backup_type = full-backuped from_lsn = 0 to_lsn = 332706875 last_lsn = 332706884 compact = 0 recover_binlog_info = 0 flushed_lsn = 332706884 3.2.1.1 插入数据 db1、db2、db3每个数据库中的表都插入一条数据 #db1 mysql> insert into db1_t1 values(100001,'xboyww','man',concat( 'xboyww',100001,'@qq'),concat('a',100001),concat('b',100001)); Query OK, 1 row affected (0.00 sec) mysql> insert into db1_t2 values(100001,'xboyww','man',concat( 'xboyww',100001,'@qq'),concat('a',100001),concat('b',100001)); Query OK, 1 row affected (0.00 sec) #db2 mysql> insert into db2_t1 values(100001,'xboyww','man',concat( 'xboyww',100001,'@qq'),concat('a',100001),concat('b',100001)); Query OK, 1 row affected (0.01 sec) mysql> insert into db2_t2 values(100001,'xboyww','man',concat( 'xboyww',100001,'@qq'),concat('a',100001),concat('b',100001)); Query OK, 1 row affected (0.00 sec) #db3 mysql> insert into t3 values(3,'dabai'); Query OK, 1 row affected (0.00 sec) 查看每张表的数据 每张表都在原先的基础上增加了一行数据 #db1的两张表 mysql> select count(*) from db1_t1; +----------+ | count(*) | +----------+ | 100001 | +----------+ 1 row in set (0.03 sec) mysql> select count(*) from db1_t2; +----------+ | count(*) | +----------+ | 100001 | +----------+ 1 row in set (0.04 sec) #db2的两张表 mysql> select count(*) from db2_t1; +----------+ | count(*) | +----------+ | 100001 | +----------+ 1 row in set (0.04 sec) mysql> select count(*) from db2_t2; +----------+ | count(*) | +----------+ | 100001 | +----------+ 1 row in set (0.04 sec) #db3的一张表 mysql> select count(*) from t3; +----------+ | count(*) | +----------+ | 3 | +----------+ 1 row in set (0.00 sec) 3.2.1.2 执行增备命令 增备就是在全备的命令基础上加一个参数--incremental-basedir=指定增备的目录 innobackupex -uroot -p1 --no-timestamp --incremental /backup/bak_incr1 --incremental-basedir=/backup/bak 或 xtrabackup -uroot -p1 --backup --target-dir=/backup/bak_incr1 --incremental-basedir=/backup/bak 说明： --incremental-basedir是上次全备或者增备出来的文件夹。当第一次增备的时候，一般填上次全备，第二次增备的时候，如果--incremental-basedir填上次全备，那么本次增备就会包含上次全备到现在变化的内容，相当于oracle依次做1级，2级，3级。。。增备如果--incremental-basedir填第一次增备的目录，那么该次增备只包含第一次增备到现在的变化，文件会更小，相当于oracle rman里面每次都做1级增备。 3.2.1.3 增备完成查看备份的数据目录大小 $ pwd /backup $ du -sh * 90M bak 3.2M bak_incr1 #全备的数据大小 $ du -sh * 4.0K backup-my.cnf 33M db1 33M db2 24K db3 4.0K ib_buffer_pool 12M ibdata1 12M mysql 1.1M performance_schema 680K sys 4.0K xtrabackup_binlog_info 4.0K xtrabackup_checkpoints 4.0K xtrabackup_info 4.0K xtrabackup_logfile #增备的数据大小 $ du -sh * 4.0K backup-my.cnf 100K db1 100K db2 24K db3 4.0K ib_buffer_pool 176K ibdata1.delta 4.0K ibdata1.meta 1.2M mysql 1.1M performance_schema 604K sys 4.0K xtrabackup_binlog_info 4.0K xtrabackup_checkpoints 4.0K xtrabackup_info 4.0K xtrabackup_logfile 3.2.1.4 全备的xtrabackup_checkpoints与增备的xtrabackup_checkpoints文件对比 可以看到增备中的from_lsn = 332706875与全备中的to_lsn = 332706875是相同的 #全备 $ cat xtrabackup_checkpoints backup_type = full-backuped from_lsn = 0 to_lsn = 332706875 last_lsn = 332706884 compact = 0 recover_binlog_info = 0 flushed_lsn = 332706884 #增备 $ cat xtrabackup_checkpoints backup_type = incremental from_lsn = 332706875 to_lsn = 332708551 last_lsn = 332708560 compact = 0 recover_binlog_info = 0 flushed_lsn = 332708560 3.2.2 基于增备的增备 3.2.2.1 插入数据 db1、db2、db3每个数据库中的表都插入一条数据 #db1 mysql> insert into db1_t1 values(100002,'xboyww','man',concat( 'xboyww',100002,'@qq'),concat('a',100002),concat('b',100002)); Query OK, 1 row affected (0.00 sec) mysql> insert into db1_t2 values(100002,'xboyww','man',concat( 'xboyww',100002,'@qq'),concat('a',100002),concat('b',100002)); Query OK, 1 row affected (0.00 sec) #db2 mysql> insert into db2_t1 values(100002,'xboyww','man',concat( 'xboyww',100002,'@qq'),concat('a',100002),concat('b',100002)); Query OK, 1 row affected (0.01 sec) mysql> insert into db2_t2 values(100002,'xboyww','man',concat( 'xboyww',100002,'@qq'),concat('a',100002),concat('b',100002)); Query OK, 1 row affected (0.00 sec) #db3 mysql> insert into t3 values(4,'xixixi'); Query OK, 1 row affected (0.00 sec) 查看每张表的数据 每张表都在原先的基础上增加了一行数据 #db1的两张表 mysql> select count(*) from db1_t1; +----------+ | count(*) | +----------+ | 100002 | +----------+ 1 row in set (0.03 sec) mysql> select count(*) from db1_t2; +----------+ | count(*) | +----------+ | 100002 | +----------+ 1 row in set (0.04 sec) #db2的两张表 mysql> select count(*) from db2_t1; +----------+ | count(*) | +----------+ | 100002 | +----------+ 1 row in set (0.04 sec) mysql> select count(*) from db2_t2; +----------+ | count(*) | +----------+ | 100002 | +----------+ 1 row in set (0.04 sec) #db3的一张表 mysql> select count(*) from t3; +----------+ | count(*) | +----------+ | 4 | +----------+ 1 row in set (0.00 sec) 3.2.2.2 执行增备命令 innobackupex -uroot -p1 --no-timestamp --incremental /backup/bak_incr2 --incremental-basedir=/backup/bak_incr1 或 xtrabackup -uroot -p1 --backup --target-dir=/backup/bak_incr2 --incremental-basedir=/backup/bak_incr1 3.2.2.3 增备完成查看备份的数据目录大小 $ pwd /backup $ du -sh * 90M bak 3.2M bak_incr1 3.2M bak_incr2 #第一次增备的数据大小 $ du -sh * 4.0K backup-my.cnf 100K db1 100K db2 24K db3 4.0K ib_buffer_pool 176K ibdata1.delta 4.0K ibdata1.meta 1.2M mysql 1.1M performance_schema 604K sys 4.0K xtrabackup_binlog_info 4.0K xtrabackup_checkpoints 4.0K xtrabackup_info 4.0K xtrabackup_logfile #基于增备的数据大小 du -sh * 4.0K backup-my.cnf 100K db1 100K db2 24K db3 4.0K ib_buffer_pool 144K ibdata1.delta 4.0K ibdata1.meta 1.2M mysql 1.1M performance_schema 604K sys 4.0K xtrabackup_binlog_info 4.0K xtrabackup_checkpoints 4.0K xtrabackup_info 4.0K xtrabackup_logfile 3.2.2.4 基于增备的xtrabackup_checkpoints与增备的xtrabackup_checkpoints文件对比 之前增备中的from_lsn = 332706875与全备中的to_lsn = 332706875是相同的 基于增备的增备from_lsn = 332708551与基于全备的增备中的to_lsn = 332708551是相同的 #基于全备的增备 $ cat xtrabackup_checkpoints backup_type = incremental from_lsn = 332706875 to_lsn = 332708551 last_lsn = 332708560 compact = 0 recover_binlog_info = 0 flushed_lsn = 332708560 #基于增备的增备份 $ cat xtrabackup_checkpoints backup_type = incremental from_lsn = 332708551 to_lsn = 332710179 last_lsn = 332710188 compact = 0 recover_binlog_info = 0 flushed_lsn = 332710188 3.3 增备恢复 3.3.1 先准备一个全备 innobackupex -uroot -p1 --apply-log --redo-only /backup/bak 或 xtrabackup -uroot -p --backup --target-dir=/backup/bak 3.3.2 将增备1应用到全备份 增备1就是基于全备的增备，也就是第一次增备⚠️这里要加--redo-only参数 这次要加入--redo-only参数，因为在每个备份过程中，都会碰到一些事务进来执行，而备份结束时可能有些事务并没有执行完毕，所以在默认prepare中这些事务就会被回滚（rollback），而加入了--redo-only就不会回滚这些事务，而是等待prepare下次增备。 innobackupex -uroot -p1 --apply-log --redo-only /backup/bak --incremental-dir=/backup/bak_incr1 或 xtrabackup -uroot -p1 --prepare --apply-log-only --target-dir=/backup/bak --incremental-dir=/backup/bak_incr1 3.3.3 将增备2应用到全备 增备2就是基于增备的增备，⚠️这里不要加--redo-only参数 innobackupex -uroot -p1 --apply-log /backup/bak --incremental-dir=/backup/bak_incr2 或 xtrabackup -uroot -p1 --prepare --target-dir=/backup/bak --incremental-dir=/backup/bak_incr2 3.3.4 把所有合在一起的完全备份整体进行一次apply操作，回滚未提交的数据 innobackupex -uroot -p1 --apply-log /backup/bak 或 xtrabackup --prepare --apply-log --target-dir=/backup/bak 3.3.5 删除db1-3数据库 mysql> drop database db1; Query OK, 2 rows affected (0.00 sec) mysql> drop database db2; Query OK, 2 rows affected (0.01 sec) mysql> drop database db3; Query OK, 1 row affected (0.00 sec) mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | +--------------------+ 4 rows in set (0.00 sec) 3.3.6 停止mysql，删除原先数据目录 停止mysql $ /etc/init.d/mysqld stop Shutting down MySQL.... SUCCESS! 3.3.7 删除原先数据目录或者修改名称 ⚠️恢复数据之前需要保证数据目录是空的状态 mysql安装的数据目录为/usr/local/mysql/data #如果做删除操作，最好先备份然后再删除，虽然数据已经丢失一部分，这里选择修改目录名称 mv /usr/local/mysql/data{,-bak} 3.3.8 进行数据恢复 这里要注意，恢复的时候mysql配置文件[mysqld]下一定要指定mysql data目录 innobackupex -uroot -p1 --copy-back /backup/bak 或 xtrabackup -uroot p1 --copy-back --target-dir=/backup/bak 3.3.9 给恢复的目录重新授权所有者为mysql chown -R mysql.mysql /usr/local/mysql/data 3.3.10 启动mysql $ /etc/init.d/mysqld start Starting MySQL.Logging to '/usr/local/mysql/data/error.log'. . SUCCESS! 3.3.11 验证数据恢复 验证数据库是否还原 mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | db1 | | db2 | | db3 | | mysql | | performance_schema | | sys | +--------------------+ 7 rows in set (0.00 sec) 验证表中的数据是否还原 #db1，有两张表，每张表中有10万零2条数据 mysql> use db1; mysql> show tables; +---------------+ | Tables_in_db1 | +---------------+ | db1_t1 | | db1_t2 | +---------------+ 2 rows in set (0.00 sec) mysql> select count(*) from db1_t1; +----------+ | count(*) | +----------+ | 100002 | +----------+ 1 row in set (0.04 sec) mysql> select count(*) from db1_t2; +----------+ | count(*) | +----------+ | 100002 | +----------+ 1 row in set (0.04 sec) #db2，有两张表，每张表中有10万零2条数据 mysql> use db1; mysql> show tables; +---------------+ | Tables_in_db2 | +---------------+ | db2_t1 | | db2_t2 | +---------------+ 2 rows in set (0.00 sec) mysql> select count(*) from db2_t1; +----------+ | count(*) | +----------+ | 100002 | +----------+ 1 row in set (0.04 sec) mysql> select count(*) from db2_t2; +----------+ | count(*) | +----------+ | 100002 | +----------+ 1 row in set (0.03 sec) #db3，有1张表，表中4行数据 mysql> use db3; mysql> show tables; +---------------+ | Tables_in_db3 | +---------------+ | t3 | +---------------+ 1 row in set (0.00 sec) mysql> select count(*) from t3; +----------+ | count(*) | +----------+ | 4 | +----------+ 1 row in set (0.00 sec) innobackupex命令与xtrabackup命令的区别 #全备 innobackupex --user=root --password=1 backup xtrabackup -uroot -p --backup --target-dir=/data/backups/ #增备 innobackupex -uroot -p1 --no-timestamp --incremental /backup/bak_incr2 --incremental-basedir=/backup/bak_incr1 xtrabackup -uroot -p1 --backup --target-dir=/backup/bak_incr2 --incremental-basedir=/backup/bak_incr1 需要注意的点 xtrabackup --apply-log-only合并除最后一个以外的所有增量时使用 增量备份的步骤与完全备份的步骤不同。在完全备份中，执行两种类型的操作以使数据库保持一致：已提交的事务相对于数据文件从日志文件中重放，未提交的事务被回滚。准备增量备份时，必须跳过未提交事务的回滚，因为在备份时未提交的事务可能正在进行中，并且很有可能将在下一次增量备份中提交。您应该使用该 选项来防止回滚阶段。xtrabackup --apply-log-only ⚠️如果不使用该选项xtrabackup --apply-log-only阻止回滚阶段，则增量备份将无用。事务回滚后，不能再应用增量备份 四、备份脚本 授权 CREATE USER 'bkpuser'@'localhost' IDENTIFIED BY 'bkpuser@1234'; GRANT RELOAD, LOCK TABLES, PROCESS, REPLICATION CLIENT,super ON *.* TO 'bkpuser'@'localhost'; FLUSH PRIVILEGES; 全备脚本 #!/bin/bash local_ip=\"$(/sbin/ifconfig ens160|grep 'inet'|grep -v '::'| awk '{print $2}')\" user='bkpuser' passwd='bkpuser@1234' config='/etc/my.cnf' backup_path='/tmsdata/xtrabackup_full' backup_date=`date +\"%Y%m%d_%H%M%S\"` backup_dir=\"$backup_path/$backup_date/\" backup_log=\"$backup_path/log\" #邮件设置 title1='percona xtrabackup information(success)' title2='percona xtrabackup information(failed)' content1='Server_name:'$(hostname)' \\n Server_ip:'$local_ip' \\n '$(date +\"%y-%m-%d %H:%M:%S\")' \\n mysql full backup Success!' content2='Server_name:'$(hostname)' \\n Server_ip:'$local_ip' \\n '$(date +\"%y-%m-%d %H:%M:%S\")' \\n mysql full backup Faild!' #判断备份目录是否存在 if [ ! -d \"$backup_dir\" ] && [ ! -d \"$backup_log\" ];then mkdir -p $backup_dir && mkdir -p $backup_log fi #[[ -d $backup_dir ]] || mkdir -p $backup_dir #[[ -d $backup_log ]] || mkdir -p $backup_log echo \"=========================================Start to backup at $(date +%Y%m%d-%H:%M:%S)=========================================\" >> $backup_log/$backup_date.log #开始备份 xtrabackup --defaults-file=$config --user=$user --password=\"$passwd\" --backup --target-dir=$backup_dir &>> $backup_log/$backup_date.log if [ $? -eq 0 ];then echo \"Backup is success! at $(date +%Y%m%d%H%M)\" echo \"Server_name:$(hostname) Server_ip:$local_ip $(date +\"%y-%m-%d %H:%M:%S\") mysql full backup Success!\" >> $backup_log/$backup_date.log echo \"$content1\" | mail -s \"$title1\" huangwb@fslgz.com else echo \"Backup is Fail! at $(date +%Y%m%d%H%M)\" echo \"Server_name:$(hostname) Server_ip:$local_ip $(date +\"%y-%m-%d %H:%M:%S\") mysql full backup Fail!\" >> $backup_log/$backup_date.log echo \"$content2\" | mail -s \"$title2\" huangwb@fslgz.com fi sleep 3 #xtrabackup从该文件读取最近一次的全备路径 egrep \".* Backup created in directory .*\" $backup_log/$backup_date.log >> $backup_path/complete.info #清除超过14天的备份 find $backup_path -mtime +14 -type d -exec rm -rf {} \\; echo \"Backup Process Done\" 增备脚本 #!/bin/bash local_ip=\"$(/sbin/ifconfig ens160|grep 'inet'|grep -v '::'| awk '{print $2}')\" user='bkpuser' passwd='bkpuser@1234' config='/etc/my.cnf' backup_full='/tmsdata/xtrabackup_full' backup_path='/tmsdata/xtrabackup_incr' backup_date=`date +\"%Y%m%d_%H%M%S\"` backup_dir=\"$backup_path/$backup_date/\" backup_log=\"$backup_path/log\" FULL_BASE_DIR=$(tail -1 $backup_full/complete.info | cut -d\\' -f2) #判断备份目录是否存在 if [ ! -d \"$backup_dir\" ] && [ ! -d \"$backup_log\" ];then mkdir -p $backup_dir && mkdir -p $backup_log fi #[[ -d $backup_dir ]] || mkdir -p $backup_dir #[[ -d $backup_log ]] || mkdir -p $backup_log echo \"========================================xtrabackup根据$FULL_BASE_DIR目录开始增备=========================================\" >> $backup_log/$backup_date.log #邮件设置 title1='percona xtrabackup information(success)' title2='percona xtrabackup information(failed)' content1='Server_name:'$(hostname)' Server_ip:'$local_ip' '$(date +\"%y-%m-%d %H:%M:%S\")' mysql increment backup Success!' content2='Server_name:'$(hostname)' Server_ip:'$local_ip' '$(date +\"%y-%m-%d %H:%M:%S\")' mysql increment backup Faild!' echo \"=========================================Start to backup at $(date +%Y%m%d-%H:%M:%S)=========================================\" >> $backup_log/$backup_date.log #开始备份 xtrabackup --defaults-file=$config --user=$user --password=\"$passwd\" --backup --target-dir=$backup_dir --incremental-basedir=$FULL_BASE_DIR &>> $backup_log/$backup_date.log if [ $? -eq 0 ];then echo \"Backup is success! at $(date +%Y%m%d%H%M)\" echo \"Server_name:$(hostname) Server_ip:$local_ip $(date +\"%y-%m-%d %H:%M:%S\") mysql full backup Success!\" >> $backup_log/$backup_date.log echo \"$content1\" | mail -s \"$title1\" huangwb@fslgz.com else echo \"Backup is Fail! at $(date +%Y%m%d%H%M)\" echo \"Server_name:$(hostname) Server_ip:$local_ip $(date +\"%y-%m-%d %H:%M:%S\") mysql full backup Fail!\" >> $backup_log/$backup_date.log echo \"$content2\" | mail -s \"$title2\" huangwb@fslgz.com fi #清除超过14天的备份 find $backup_path -mtime +14 -type d -exec rm -rf {} \\; echo \"Backup Process Done\" 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mysql/mysql进阶/1.mysql多实例-5.6.40.html":{"url":"db/mysql/mysql进阶/1.mysql多实例-5.6.40.html","title":"5.6.40","keywords":"","body":"mysql多实例-5.6.40 1.mysql多实例介绍 1.1什么是MySQL多实例 MySQL多实例就是在一台机器上开启多个不同的服务端口（如：3306,3307），运行多个MySQL服务进程，通过不同的socket监听不同的服务端口来提供各自的服务 1.2MySQL多实例的特点有以下几点 1：有效利用服务器资源，当单个服务器资源有剩余时，可以充分利用剩余的资源提供更多的服务 2：节约服务器资源 3：资源互相抢占问题，当某个服务实例服务并发很高时或者开启慢查询时，会消耗更多的内存、CPU、磁盘IO资源，导致服务器上的其他实例提供服务的质量下降 1.3部署mysql多实例的两种方式 第一种是使用多个配置文件启动不同的进程来实现多实例，这种方式的优势逻辑简单，配置简单，缺点是管理起来不太方便 第二种是通过官方自带的mysqld_multi使用单独的配置文件来实现多实例，这种方式定制每个实例的配置不太方面，优点是管理起来很方便，集中管理 1.4同一开发环境下安装两个数据库，必须处理以下问题 配置文件安装路径不能相同 数据库目录不能相同 启动脚本不能同名 端口不能相同 socket文件的生成路径不能相同 2.mysql多实例安装路径说明 mysql安装路径 第一个实例：/data/mysql3306 第二个实例：/data/mysql3307 第三个实例：/data/mysql3308 3.安装部署过程 3.1安装依赖包 yum -y install gcc gcc-c++ autoconf bison-devel ncurses-devel libaio-devel 3.2创建mysql用户和组 groupadd mysql && useradd -g mysql -s /sbin/nologin mysql 3.3下载mysql-5.6.40二进制包 wget https://downloads.mysql.com/archives/get/file/mysql-5.6.40-linux-glibc2.12-x86_64.tar.gz 3.4解压缩并修改目录名称 tar xf mysql-5.6.40-linux-glibc2.12-x86_64.tar.gz && \\ mv mysql-5.6.40-linux-glibc2.12-x86_64/ mysql-5.6.40 3.5修改目录所有者为mysql chown -R mysql.mysql mysql-5.6.40 3.6创建3个mysql安装目录 mkdir -p /data/mysql330{6..8} 3.7将mysql包分别拷贝到3个安装目录 for i in {6..8};do cp -rp mysql-5.6.40 /data/mysql330$i ;done 3.8做软连接 for i in {6..8};do ln -s /data/mysql330$i/mysql-5.6.40 /data/mysql330$i/mysql;done 3.9编辑配置文件 basedir、datadir、log-error、port、socket文件位置不同，如果要做主从，serverid要不同 //备份原有/etc/my.cnf mv /etc/my.cnf /etc/my.cnf.old //编辑第一个实例配置文件 cat >/etc/my-3306.cnf/etc/my-3307.cnf/etc/my-3308.cnf 3.10拷贝启动脚本 //分别拷贝3个实例启动脚本 for i in {6..8};do cp mysql-5.6.40/support-files/mysql.server /etc/init.d/mysqld330$i ;done //修改文件 sed -i.bak 's#/usr/local#/data/mysql3306#g' /etc/init.d/mysqld3306 /data/mysql3306/mysql/bin/mysqld_safe sed -i.bak 's#/usr/local#/data/mysql3307#g' /etc/init.d/mysqld3307 /data/mysql3307/mysql/bin/mysqld_safe sed -i.bak 's#/usr/local#/data/mysql3308#g' /etc/init.d/mysqld3308 /data/mysql3308/mysql/bin/mysqld_safe 3.11初始化mysql //初始化第一个实例 /data/mysql3306/mysql/scripts/mysql_install_db --user=mysql --basedir=/data/mysql3306/mysql --datadir=/data/mysql3306/mysql/data //初始化第二个实例 /data/mysql3307/mysql/scripts/mysql_install_db --user=mysql --basedir=/data/mysql3307/mysql --datadir=/data/mysql3307/mysql/data //初始化第三个实例 /data/mysql3308/mysql/scripts/mysql_install_db --user=mysql --basedir=/data/mysql3308/mysql --datadir=/data/mysql3308/mysql/data 3.12添加mysql命令环境变量 //这里只需要导出一个即可 echo \"export PATH=/data/mysql3306/mysql/bin:$PATH\" > /etc/profile.d/mysql.sh source /etc/profile 3.13配置systemd管理mysql //配置第一个实例 cat >/etc/systemd/system/mysqld3306.service/etc/systemd/system/mysqld3307.service/etc/systemd/system/mysqld3308.service 3.14启动mysql、检查启动 //启动mysql systemctl start mysqld3306 ; systemctl enable mysqld3306 systemctl start mysqld3307 ; systemctl enable mysqld3307 systemctl start mysqld3308 ; systemctl enable mysqld3308 //检查启动 netstat -ntpl|grep 330* tcp6 0 0 :::3306 :::* LISTEN 16413/mysqld tcp6 0 0 :::3307 :::* LISTEN 16422/mysqld tcp6 0 0 :::3308 :::* LISTEN 16463/mysqld 3.15进入mysql，设置密码 //设置第一个实例密码 mysql -S /data/mysql3306/mysql/mysql.sock mysql> set password=password('3306'); mysql> flush privileges; //设置第二个实例密码 mysql -S /data/mysql3307/mysql/mysql.sock mysql> set password=password('3307'); mysql> flush privileges; //设置第三个实例密码 mysql -S /data/mysql3308/mysql/mysql.sock mysql> set password=password('3308'); mysql> flush privileges; 3.16设置快捷登陆 //原有登陆方式，需要指定mysql用户名密码和套接字文件 mysql -uroot -p3306 -S /data/mysql3306/mysql/mysql.sock 设置快捷登陆 //设置第一个实例 cat >/usr/bin/mysql3306/usr/bin/mysql3307/usr/bin/mysql3308 到此，mysql多实例配置完成！！！ 扩展：基于以上多实例实现mysql主从复制 3306为主 3307、3308为从 1.编辑主库3306（master）配置文件/etc/my-3306.cnf vim /etc/my-3306.cnf #[mysqld]下方增加以下3行 server_id=3306 log_bin=binlog log_bin_index=binlog.index //重启mysql systemctl restart mysqld3306 2.创建专用复制用户 mysql3306 mysql> grant replication slave on *.* to 'backup'@'10.0.0.%' identified by '3306'; Query OK, 0 rows affected (0.01 sec) 3.查看master状态 mysql> show master status; +---------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +---------------+----------+--------------+------------------+-------------------+ | binlog.000001 | 327 | | | | +---------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 4.编辑从库配置文件 //编辑3307配置文件 [root@mysql ~]# vim /etc/my-3307.cnf #[mysqld]下方增加以下3行 server_id=3307 relay_log=/data/mysql3307/mysql/relay_log relay_log_index=/data/mysql3307/mysql/relay_log.index //编辑3308配置文件 [root@mysql ~]# vim /etc/my-3308.cnf #[mysqld]下方增加以下3行 server_id=3308 relay_log=/data/mysql3308/mysql/relay_log relay_log_index=/data/mysql3308/mysql/relay_log.index //重启mysql [root@mysql ~]# systemctl restart mysqld3307 && systemctl restart mysqld3308 5.设置slave从master拉取binlog及拉取的位置 //3307 mysql> change master to master_host='10.0.0.55',master_port=3306,master_user='backup',master_password='123',master_log_file='binlog.000001',master_log_pos=327; Query OK, 0 rows affected, 2 warnings (0.06 sec) //启动slave mysql> start slave; Query OK, 0 rows affected (0.01 sec) //查看slave状态 mysql> show slave status\\G #IO线程和SQL线程都必须为YES Slave_IO_Running: Yes Slave_SQL_Running: Yes ------------------------------------------------------------------------------ //3308 mysql> change master to master_host='10.0.0.55',master_port=3306,master_user='backup',master_password='123',master_log_file='binlog.000001',master_log_pos=327; Query OK, 0 rows affected, 2 warnings (0.02 sec) //启动slave mysql> start slave; Query OK, 0 rows affected (0.00 sec) //查看slave状态 mysql> show slave status\\G #IO线程和SQL线程都必须为YES Slave_IO_Running: Yes Slave_SQL_Running: Yes 6.验证，在3306中创建一个数据库，看3307和3308是否会同步 //3306中创建一个数据库 mysql> create database bxb; Query OK, 1 row affected (0.00 sec) mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | DB3306 | | bxb | | mysql | | performance_schema | | test | +--------------------+ 6 rows in set (0.00 sec) //3307中查看数据库 mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | DB3307 | | bxb | | mysql | | performance_schema | | test | +--------------------+ 6 rows in set (0.00 sec) //3308中查看数据库 mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | DB3308 | | bxb | | mysql | | performance_schema | | test | +--------------------+ 6 rows in set (0.01 sec) 到此，mysql基于多实例实现主从复制完成！！！ 实验过程中遇到的错误 在3308（第二个实例）上启动slave报错 //启动slave报错，从存储库初始化中继日志信息结构失败 mysql> start slave; ERROR 1872 (HY000): Slave failed to initialize relay log info structure from the repository 解决方法：先重置slave,然后停止slvae再重新change master mysql> reset slave all; Query OK, 0 rows affected (0.02 sec) mysql> stop slave; 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mysql/mysql进阶/2.mysql多实例-5.7.23.html":{"url":"db/mysql/mysql进阶/2.mysql多实例-5.7.23.html","title":"5.7.23","keywords":"","body":"mysql多实例-5.7.23 1.mysql多实例介绍 1.1什么是MySQL多实例 MySQL多实例就是在一台机器上开启多个不同的服务端口（如：3306,3307），运行多个MySQL服务进程，通过不同的socket监听不同的服务端口来提供各自的服务 1.2MySQL多实例的特点有以下几点 1：有效利用服务器资源，当单个服务器资源有剩余时，可以充分利用剩余的资源提供更多的服务 2：节约服务器资源 3：资源互相抢占问题，当某个服务实例服务并发很高时或者开启慢查询时，会消耗更多的内存、CPU、磁盘IO资源，导致服务器上的其他实例提供服务的质量下降 1.3部署mysql多实例的两种方式 第一种是使用多个配置文件启动不同的进程来实现多实例，这种方式的优势逻辑简单，配置简单，缺点是管理起来不太方便 第二种是通过官方自带的mysqld_multi使用单独的配置文件来实现多实例，这种方式定制每个实例的配置不太方面，优点是管理起来很方便，集中管理 1.4同一开发环境下安装两个数据库，必须处理以下问题 配置文件安装路径不能相同 数据库目录不能相同 启动脚本不能同名 端口不能相同 socket文件的生成路径不能相同 2.mysql多实例安装路径说明 mysql安装路径 第一个实例：/data/mysql3306 第二个实例：/data/mysql3307 第三个实例：/data/mysql3308 3.安装部署过程 3.1安装依赖包 yum -y install gcc gcc-c++ autoconf bison-devel ncurses-devel libaio-devel 3.2创建mysql用户和组 groupadd mysql && useradd -g mysql -s /sbin/nologin mysql 3.3下载mysql-5.7.23二进制包 wget https://downloads.mysql.com/archives/get/file/mysql-5.7.23-linux-glibc2.12-x86_64.tar.gz 3.4解压缩并修改目录名称 tar xf mysql-5.7.23-linux-glibc2.12-x86_64.tar.gz && \\ mv mysql-5.7.23-linux-glibc2.12-x86_64/ mysql-5.7.23 3.5修改目录所有者为mysql chown -R mysql.mysql mysql-5.7.23 3.6创建3个mysql安装目录 mkdir -p /data/mysql330{6..8} 3.7将mysql包分别拷贝到3个安装目录 for i in {6..8};do cp -rp mysql-5.7.23 /data/mysql330$i ;done 3.8做软连接 for i in {6..8};do ln -s /data/mysql330$i/mysql-5.7.23 /data/mysql330$i/mysql;done 3.9编辑配置文件 basedir、datadir、log-error、port、socket文件位置不同，如果要做主从，serverid要不同 //备份原有/etc/my.cnf mv /etc/my.cnf /etc/my.cnf.old //编辑第一个实例配置文件 cat >/etc/my-3306.cnf/etc/my-3307.cnf/etc/my-3308.cnf 3.10拷贝启动脚本 //分别拷贝3个实例启动脚本 for i in {6..8};do cp mysql-5.7.23/support-files/mysql.server /etc/init.d/mysqld330$i ;done //修改文件 sed -i.bak 's#/usr/local#/data/mysql3306#g' /etc/init.d/mysqld3306 /data/mysql3306/mysql/bin/mysqld_safe sed -i.bak 's#/usr/local#/data/mysql3307#g' /etc/init.d/mysqld3307 /data/mysql3307/mysql/bin/mysqld_safe sed -i.bak 's#/usr/local#/data/mysql3308#g' /etc/init.d/mysqld3308 /data/mysql3308/mysql/bin/mysqld_safe 3.11初始化mysql //初始化第一个实例 /data/mysql3306/bin/mysqld --initialize-insecure --user=mysql --basedir=/data/mysql3306 --datadir=/data/mysql3306/data //初始化第二个实例 /data/mysql3306/bin/mysqld --initialize-insecure --user=mysql --basedir=/data/mysql3306 --datadir=/data/mysql3306/data //初始化第三个实例 /data/mysql3306/bin/mysqld --initialize-insecure --user=mysql --basedir=/data/mysql3306 --datadir=/data/mysql3306/data 3.12添加mysql命令环境变量 //这里只需要导出一个即可 echo \"export PATH=/data/mysql3306/mysql/bin:$PATH\" > /etc/profile.d/mysql.sh source /etc/profile 3.13配置systemd管理mysql //配置第一个实例 cat >/etc/systemd/system/mysqld3306.service/etc/systemd/system/mysqld3307.service/etc/systemd/system/mysqld3308.service 3.14启动mysql、检查启动 //启动mysql systemctl start mysqld3306 ; systemctl enable mysqld3306 systemctl start mysqld3307 ; systemctl enable mysqld3307 systemctl start mysqld3308 ; systemctl enable mysqld3308 //检查启动 netstat -ntpl|grep 330* tcp6 0 0 :::3306 :::* LISTEN 16413/mysqld tcp6 0 0 :::3307 :::* LISTEN 16422/mysqld tcp6 0 0 :::3308 :::* LISTEN 16463/mysqld 3.15进入mysql，设置密码 //设置第一个实例密码 mysql -S /data/mysql3306/mysql/mysql.sock mysql> set password=password('3306'); mysql> flush privileges; //设置第二个实例密码 mysql -S /data/mysql3307/mysql/mysql.sock mysql> set password=password('3307'); mysql> flush privileges; //设置第三个实例密码 mysql -S /data/mysql3308/mysql/mysql.sock mysql> set password=password('3308'); mysql> flush privileges; 3.16设置快捷登陆 //原有登陆方式，需要指定mysql用户名密码和套接字文件 mysql -uroot -p3306 -S /data/mysql3306/mysql/mysql.sock 设置快捷登陆 //设置第一个实例 cat >/usr/bin/mysql3306/usr/bin/mysql3307/usr/bin/mysql3308 到此，mysql多实例配置完成！！！ 扩展：基于以上多实例实现mysql主从复制 3306为主 3307、3308为从 1.编辑主库3306（master）配置文件/etc/my-3306.cnf vim /etc/my-3306.cnf #[mysqld]下方增加以下3行 server_id=3306 log_bin=binlog log_bin_index=binlog.index //重启mysql systemctl restart mysqld3306 2.创建专用复制用户 mysql3306 mysql> grant replication slave on *.* to 'backup'@'10.0.0.%' identified by '3306'; Query OK, 0 rows affected (0.01 sec) 3.查看master状态 mysql> show master status; +---------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +---------------+----------+--------------+------------------+-------------------+ | binlog.000001 | 327 | | | | +---------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 4.编辑从库配置文件 //编辑3307配置文件 [root@mysql ~]# vim /etc/my-3307.cnf #[mysqld]下方增加以下3行 server_id=3307 relay_log=/data/mysql3307/mysql/relay_log relay_log_index=/data/mysql3307/mysql/relay_log.index //编辑3308配置文件 [root@mysql ~]# vim /etc/my-3308.cnf #[mysqld]下方增加以下3行 server_id=3308 relay_log=/data/mysql3308/mysql/relay_log relay_log_index=/data/mysql3308/mysql/relay_log.index //重启mysql [root@mysql ~]# systemctl restart mysqld3307 && systemctl restart mysqld3308 5.设置slave从master拉取binlog及拉取的位置 //3307 mysql> change master to master_host='10.0.0.55',master_port=3306,master_user='backup',master_password='123',master_log_file='binlog.000001',master_log_pos=327; Query OK, 0 rows affected, 2 warnings (0.06 sec) //启动slave mysql> start slave; Query OK, 0 rows affected (0.01 sec) //查看slave状态 mysql> show slave status\\G #IO线程和SQL线程都必须为YES Slave_IO_Running: Yes Slave_SQL_Running: Yes ------------------------------------------------------------------------------ //3308 mysql> change master to master_host='10.0.0.55',master_port=3306,master_user='backup',master_password='123',master_log_file='binlog.000001',master_log_pos=327; Query OK, 0 rows affected, 2 warnings (0.02 sec) //启动slave mysql> start slave; Query OK, 0 rows affected (0.00 sec) //查看slave状态 mysql> show slave status\\G #IO线程和SQL线程都必须为YES Slave_IO_Running: Yes Slave_SQL_Running: Yes 6.验证，在3306中创建一个数据库，看3307和3308是否会同步 //3306中创建一个数据库 mysql> create database bxb; Query OK, 1 row affected (0.00 sec) mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | DB3306 | | bxb | | mysql | | performance_schema | | test | +--------------------+ 6 rows in set (0.00 sec) //3307中查看数据库 mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | DB3307 | | bxb | | mysql | | performance_schema | | test | +--------------------+ 6 rows in set (0.00 sec) //3308中查看数据库 mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | DB3308 | | bxb | | mysql | | performance_schema | | test | +--------------------+ 6 rows in set (0.01 sec) 到此，mysql基于多实例实现主从复制完成！！！ 实验过程中遇到的错误 在3308（第二个实例）上启动slave报错 //启动slave报错，从存储库初始化中继日志信息结构失败 mysql> start slave; ERROR 1872 (HY000): Slave failed to initialize relay log info structure from the repository 解决方法：先重置slave,然后停止slvae再重新change master mysql> reset slave all; Query OK, 0 rows affected (0.02 sec) mysql> stop slave; 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mysql/mysql进阶/3.mysql普通主从复制.html":{"url":"db/mysql/mysql进阶/3.mysql普通主从复制.html","title":"普通主从复制","keywords":"","body":"mysql普通主从复制 1.mysql主从复制过程 1.master开启binlog（二进制）日志、授权slave复制用户，slave开启relay-log（中继）日志 2.slave IO线程会通过在master上已经授权的复制用户权限请求连接master服务器，带着change master to信息（user、host、password、binlog、binlog_pos、port）去问master dump线程有没有slave指定的binlog、binlog_pos,有则拉取binlog 3.IO线程拉取binlog后会先写入到TCP/IP缓存，TCP/IP缓存完成后会给IO线程返回ACK，告知IO线程缓存完成，然后再写入到relay-log中，relay-log写入完成后缓存就会清空，同时会把这一次拉取的binlog文件、binlog_pos记录到master.info中，以便于下一次去拉取的时候知道上一次拉取的位置 4.SQL线程会从relay-log中读取binlog解析成sql语句执行，同时会把上一次读取的relay-log位置记录到relay-log.info，以便于下一次读取的时候知道从什么位置读取，因为SQL线程从relay-log中读取binlog并不是一次全部读完的 官方示意图 2.实验环境 角色 IP 主机名 mysql版本 master 10.0.0.100 db01 5.7.22 slave 10.0.0.101 db02 5.7.22 3.实验过程 master10.0.0.100操作 1.master编辑/etc/my.cnf，指定serverid，并开启binlog和binlog索引 [root@db01 ~]# vim /etc/my.cnf #在[mysqld]下方写入以下3行 server_id=1 #指定serverid，越小优先级越大 log_bin=binlog #开启binlog日志 log_bin_index=binlog.index #开启binlog日志索引 #重启mysql [root@db01 ~]# systemctl restart mysqld 2.创建专用复制用户，允许从slave上连接过来的复制用户 mysql> grant replication slave on *.* to backup@'10.0.0.%' identified by '123'; 3.查看master当前的binlog日志及位置信息 mysql> show master status; +---------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +---------------+----------+--------------+------------------+-------------------+ | binlog.000001 | 154 | | | | +---------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) slave10.0.0.101操作 1.slave编辑配置文件/etc/my.cnf，指定serverid，并开启中继日志 [root@db02 ~]# vim /etc/my.cnf #在[mysqld]下放写入以下3行 server_id=2 #指定serverid，要比mysql-master大 relay_log=/var/lib/mysql/relay_log #开启中继日志 relay_log_index=/var/lib/mysql/relay_log.index #开启中继日志索引 #重启mysql [root@db02 ~]# systemctl restart mysqld 2.设置slave从master拉取binlog，及拉取的位置 mysql> change master to master_host='10.0.0.100', \\ master_port=3306, \\ master_user='backup', \\ master_password='123', \\ master_log_file='binlog.000001', \\ master_log_pos=155; Query OK, 0 rows affected, 2 warnings (0.02 sec) mysql> show warnings; #会有警告，但不影响 | Note | 1759 | Sending passwords in plain text without SSL/TLS is extremely insecure. | Note | 1760 | Storing MySQL user name or password information in the master info repository is not secure and is therefore not recommended. Please consider using the USER and PASSWORD connection options for START SLAVE; see the 'START SLAVE Syntax' in the MySQL Manual for more information. | 没有SSL/TLS的纯文本发送密码是非常不安全的 在主信息存储库中存储MySQL用户名或密码信息是不安全的，因此不建议这样做。请考虑使用用户和密码连接选项启动从;有关更多信息，请参阅MySQL手册中的“开始从属语法”。 语句说明 change master to master_host='10.0.0.100', #mysql-master主机IP地址 master_port=3306, #mysql-master端口 master_user='backup', #slave拉取的用户 master_password='123456', #slave拉去的用户的密码 master_log_file='binlog.000001', #mysql-master的binlog文件，在master中show master status查看 master_log_pos=155; 3.启动slave并查看slave状态 //启动slave mysql> start slave; //查看slave状态，IO线程、SQL线程都为yes才算正确 mysql> show slave status\\G Slave_IO_Running: Yes Slave_SQL_Running: Yes 4.验证，在master上创建数据库和表，然后在slave上看是否可以同步 //master操作 mysql> show databases; #此时mysql-master上有4个库 +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | +--------------------+ 4 rows in set (0.01 sec) mysql> create database DB1; #创建一个数据库DB1 Query OK, 1 row affected (0.01 sec) //slave验证 mysql> show databases; #可以看到，在master上创建的数据库DB1已经同步至slave +--------------------+ | Database | +--------------------+ | information_schema | | DB1 | | mysql | | performance_schema | | sys | +--------------------+ 5 rows in set (0.01 sec) 4.延时从库 4.1延时从库优点 1.误删除时，能更快恢复数据。 有时候手抖了，把线上数据给误删除了，或者误删除库、表、其他对象，或不加WHERE条件的更新、删除，都可以让延迟从库在误操作前的时间点停下，然后进行恢复。 2.把延迟从库作为专用的备份节点。虽然有一定的延迟，但并不影响利用该节点作为备份角色，也不影响生产节点数据库库。 3.还可以把延迟从库当做一些问题、案例研究的对象。个别时候，可能有些binlog event在普通从库上会有问题（例如早期版本中无主键会导致从库更新非常慢的经典问题），这时就有时间在延迟从库上慢慢琢磨研究了。 普通主从最大的缺点：主库误删除数据后从库上的数据也会被同步删除 4.2配置延时从库 从库10.0.0.101操作 //停止主从 mysql>stop slave; //设置延时为60秒 mysql>change master to master_delay = 60; //开启主从 mysql>start slave; //查看状态 mysql> show slave status \\G SQL_Delay: 60 #延时从库停止方法 //停止主从 mysql> stop slave; //设置延时为0 mysql> CHANGE MASTER TO MASTER_DELAY = 0; //开启主从 mysql> start slave; 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mysql/mysql进阶/4.mysql-5.6.40 GTID主从复制.html":{"url":"db/mysql/mysql进阶/4.mysql-5.6.40 GTID主从复制.html","title":"GTID主从复制","keywords":"","body":"mysql-5.6.40 GTID主从复制 1.GTID主从复制简介 1.1GTID主从复制概念 基于GTID的复制是从Mysql5.6开始支持的一种新的复制方式，此方式与传统基于日志的方式存在很大的差异，在原来的基于日志的复制中，从服务器连接到主服务器并告诉主服务器要从哪个二进制日志的偏移量开始执行增量同步，这时我们如果指定的日志偏移量不对，这可能造成主从数据的不一致，而基于GTID的复制会避免这种情况 1.2GTID工作过程 ①首先从服务器会告诉主服务器已经在从服务器执行完了哪些事务的GTID值 ②主库会把所有没有在从库上执行的事务，发送到从库上进行执行，并且使用GTID的复制可以保证同一个事务只在指定的从库上执行一次，这样可以避免由于偏移量的问题造成数据不一致 1.3GTID含义 全局事务ID，其保证为每一个在主服务器上提交的事务在复制集群中可以生成一个唯一的ID 1.4GTID组成 UUID+TID UUID：是在mysql服务首次启动生成的，保存在数据库的数据目录中，在数据目录中有一个auto.conf文件，这个文件保存了UUDI值 TID：事务ID则是从1开始自增的序列，表示这个事务是在主库上执行的第几个事务，Mysql会保证这个事务和GTID是一比一的关系 2.实验环境 服务器角色 ip 主机名 master 10.0.0.10 db01 slave1 10.0.0.11 db02 slave2 10.0.0.12 db03 3.基于GTID主从前提条件 先决条件 1.主库和从库都要开启binlog 2.主库和从库server-id不同 3.要有主从复制用户 4.实验过程 主库10.0.0.10操作 1.修改配置文件 //编辑主库配置文件/etc/my.cnf，在[mysqld]下添加以下几行 [root@db01 ~]# vim /etc/my.cnf server_id=1 log_bin=mysql-bin gtid_mode=ON enforce_gtid_consistency log-slave-updates skip_name_resolve //重启mysql [root@db01 ~]# systemctl restart mysqld //主库查看git开启情况，enforce_gtid_consistency与gtid_mode都为on即为正确 mysql> show global variables like '%gtid%'; +---------------------------------+----------------------------------------+ | Variable_name | Value | +---------------------------------+----------------------------------------+ | binlog_gtid_simple_recovery | OFF | | enforce_gtid_consistency | ON | | gtid_executed | e257d15f-ed9f-11e8-ab08-000c29b62ed9:1 | | gtid_mode | ON | | gtid_owned | | | gtid_purged | | | simplified_binlog_gtid_recovery | OFF | +---------------------------------+----------------------------------------+ 7 rows in set (0.01 sec) #参数说明 server_id=1 #server id主库和从库要不一样 log_bin=mysql-bin #开启binlog gtid_mode=ON #开启gtid enforce_gtid_consistency #执行GTID一致 log-slave-updates #通常情况，从服务器从主服务器接收到的更新不记入它的二进制日志。 该选项告诉从服务器将其SQL线程执行的更新记入到从服务器自己的二进制日志，mysql-5.6必须加这个参数， 5.7可以不加 skip_name_resolve #跳过mysql域名解析 2.主库创建主从复制用户 mysql> grant replication slave on *.* to backup@'10.0.0.%' identified by '123'; Query OK, 0 rows affected (0.02 sec) 从库10.0.0.11、10.0.0.12操作 1.修改配置文件 //从库10.0.0.11修改配置文件/etc/my.cnf，server id要与主库不同 [mysqld] server_id=2 log-bin=mysql-bin gtid_mode=ON enforce_gtid_consistency log-slave-updates skip_name_resolve //重启mysql [root@db02 ~]# systemctl restart mysqld //查看gtid开启状态 mysql> show variables like '%gtid%'; +---------------------------------+-----------+ | Variable_name | Value | +---------------------------------+-----------+ | binlog_gtid_simple_recovery | OFF | | enforce_gtid_consistency | ON | | gtid_executed | | | gtid_mode | ON | | gtid_next | AUTOMATIC | | gtid_owned | | | gtid_purged | | | simplified_binlog_gtid_recovery | OFF | +---------------------------------+-----------+ 8 rows in set (0.00 sec) ------------------------------------------------------- //从库10.0.0.12修改配置文件/etc/my.cnf，server id要与主库不同 [mysqld] server_id=3 log-bin=mysql-bin gtid_mode=ON enforce_gtid_consistency log-slave-updates skip_name_resolve //重启mysql [root@db03 ~]# systemctl restart mysqld //查看gtid开启状态 mysql> show variables like '%gtid%'; +---------------------------------+-----------+ | Variable_name | Value | +---------------------------------+-----------+ | binlog_gtid_simple_recovery | OFF | | enforce_gtid_consistency | ON | | gtid_executed | | | gtid_mode | ON | | gtid_next | AUTOMATIC | | gtid_owned | | | gtid_purged | | | simplified_binlog_gtid_recovery | OFF | +---------------------------------+-----------+ 8 rows in set (0.00 sec) 2.从库拉取 //从库10.0.0.11执行拉取语句 mysql> change master to master_host='10.0.0.10', master_user='backup', master_password='123', master_auto_position=1; Query OK, 0 rows affected, 2 warnings (0.02 sec) //启动IO、SQL线程 mysql> start slave; //查看slave状态，IO、SQL线程都为yes，auto_position为yes即为成功 mysql> show slave status\\G Slave_IO_Running: Yes Slave_SQL_Running: Yes #以下为事务ID，1-3表明从库从主库同步了3次 Retrieved_Gtid_Set: e257d15f-ed9f-11e8-ab08-000c29b62ed9:1-3 Executed_Gtid_Set: e257d15f-ed9f-11e8-ab08-000c29b62ed9:1-3 ------------------------------------------------------------ //从库10.0.0.12执行拉取语句 mysql> change master to master_host='10.0.0.10', master_user='backup', master_password='123', master_auto_position=1; Query OK, 0 rows affected, 2 warnings (0.02 sec) //启动IO、SQL线程 mysql> start slave; //查看slave状态，IO、SQL线程都为yes，auto_position为yes即为成功 mysql> show slave status\\G Slave_IO_Running: YesSlave_SQL_Running: Yes Auto_Position: 1 #以下为事务ID，1-3表明从库从主库同步了3次 Retrieved_Gtid_Set: e257d15f-ed9f-11e8-ab08-000c29b62ed9:1-3 Executed_Gtid_Set: e257d15f-ed9f-11e8-ab08-000c29b62ed9:1-3 3.验证主从同步 //主库创建数据库 mysql> create database GTID; Query OK, 1 row affected (0.00 sec) //从库查看是否同步，可以看到GTID库已经同步过来 mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | GTID | | mysql | | performance_schema | | test | +--------------------+ 5 rows in set (0.00 sec) 以上过程同样适用于mysql-5.7 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mysql/mysql进阶/5.mysql5.7半同步复制.html":{"url":"db/mysql/mysql进阶/5.mysql5.7半同步复制.html","title":"半同步复制","keywords":"","body":"mysql5.7半同步复制 一、复制架构衍生史 在谈这个特性之前，我们先来看看MySQL的复制架构衍生史。 在2000年，MySQL 3.23.15版本引入了Replication。Replication作为一种准实时同步方式，得到广泛应用。这个时候的Replicaton的实现涉及到两个线程，一个在Master，一个在Slave。Slave的I/O和SQL功能是作为一个线程，从Master获取到event后直接apply，没有relay log。这种方式使得读取event的速度会被Slave replay速度拖慢，当主备存在较大延迟时候，会导致大量binary log没有备份到Slave端。 在2002年，MySQL 4.0.2版本将Slave端event读取和执行独立成两个线程（IO线程和SQL线程），同时引入了relay log。IO线程读取event后写入relay log，SQL线程从relay log中读取event然后执行。这样即使SQL线程执行慢，Master的binary log也会尽可能的同步到Slave。当Master宕机，切换到Slave，不会出现大量数据丢失。 在2010年MySQL 5.5版本之前，一直采用的是这种异步复制的方式。主库的事务执行不会管备库的同步进度，如果备库落后，主库不幸crash，那么就会导致数据丢失。于是在MySQL在5.5中就顺其自然地引入了半同步复制，主库在应答客户端提交的事务前需要保证至少一个从库接收并写到relay log中。那么半同步复制是否可以做到不丢失数据呢？下面分析。 在2016年，MySQL在5.7.17中引入了一个全新的技术，称之为InnoDB Group Replication。目前官方MySQL 5.7.17基于Group replication的全同步技术已经问世，全同步技术带来了更多的数据一致性保障。相信是未来同步技术一个重要方向，值得期待。MySQL 5.7 Group Replication 根据上面提到的这几种复制协议，分别对应MySQL几种复制类型，分别是异步、半同步、全同步。 对于异步复制，主库将事务Binlog事件写入到Binlog文件中，此时主库只会通知一下Dump线程发送这些新的Binlog，然后主库就会继续处理提交操作，而此时不会保证这些Binlog传到任何一个从库节点上。 对于全同步复制，当主库提交事务之后，所有的从库节点必须收到，APPLY并且提交这些事务，然后主库线程才能继续做后续操作。这里面有一个很明显的缺点就是，主库完成一个事务的时间被拉长，性能降低。 对于半同步复制，是介于全同步复制和异步复制之间的一种，主库只需要等待至少一个从库节点收到并且Flush Binlog到Relay Log文件即可，主库不需要等待所有从库给主库反馈。同时，这里只是一个收到的反馈，而不是已经完全执行并且提交的反馈，这样就节省了很多时间。 二、半同步复制技术 我们今天谈论第二种架构。我们知道，普通的replication，即MySQL的异步复制，依靠MySQL二进制日志也即binary log进行数据复制。比如两台机器，一台主机（master），另外一台是从机（slave）。 1）正常的复制为：事务一（t1）写入binlog buffer；dumper线程通知slave有新的事务t1；binlog buffer进行checkpoint；slave的io线程接收到t1并写入到自己的的relay log；slave的sql线程写入到本地数据库。 这时，master和slave都能看到这条新的事务，即使master挂了，slave可以提升为新的master。 2）异常的复制为：事务一（t1）写入binlog buffer；dumper线程通知slave有新的事务t1；binlog buffer进行checkpoint；slave因为网络不稳定，一直没有收到t1；master挂掉，slave提升为新的master，t1丢失。 3）很大的问题是：主机和从机事务更新的不同步，就算是没有网络或者其他系统的异常，当业务并发上来时，slave因为要顺序执行master批量事务，导致很大的延迟。 为了弥补以上几种场景的不足，MySQL从5.5开始推出了半同步复制。相比异步复制，半同步复制提高了数据完整性，因为很明确知道，在一个事务提交成功之后，这个事务就至少会存在于两个地方。即在master的dumper线程通知slave后，增加了一个ack（消息确认），即是否成功收到t1的标志码，也就是dumper线程除了发送t1到slave，还承担了接收slave的ack工作。如果出现异常，没有收到ack，那么将自动降级为普通的复制，直到异常修复后又会自动变为半同步复制。 半同步复制具体特性： 从库会在连接到主库时告诉主库，它是不是配置了半同步。 如果半同步复制在主库端是开启了的，并且至少有一个半同步复制的从库节点，那么此时主库的事务线程在提交时会被阻塞并等待，结果有两种可能，要么至少一个从库节点通知它已经收到了所有这个事务的Binlog事件，要么一直等待直到超过配置的某一个时间点为止，而此时，半同步复制将自动关闭，转换为异步复制。 从库节点只有在接收到某一个事务的所有Binlog，将其写入并Flush到Relay Log文件之后，才会通知对应主库上面的等待线程。 如果在等待过程中，等待时间已经超过了配置的超时时间，没有任何一个从节点通知当前事务，那么此时主库会自动转换为异步复制，当至少一个半同步从节点赶上来时，主库便会自动转换为半同步方式的复制。 半同步复制必须是在主库和从库两端都开启时才行，如果在主库上没打开，或者在主库上开启了而在从库上没有开启，主库都会使用异步方式复制。 半同步复制潜在问题： 先看一下半同步复制原理图，如下： master将每个事务写入binlog（sync_binlog=1），传递到slave刷新到磁盘(sync_relay=1)，同时主库提交事务（commit）。master等待slave反馈收到relay log，只有收到ACK后master才将commit OK结果反馈给客户端。 在MySQL 5.5~5.6使用after_commit的模式下，客户端事务在存储引擎层提交后，在得到从库确认的过程中，主库宕机了。此时，即主库在等待Slave ACK的时候，虽然没有返回当前客户端，但事务已经提交，其他客户端会读取到已提交事务。如果Slave端还没有读到该事务的events，同时主库发生了crash，然后切换到备库。那么之前读到的事务就不见了，出现了幻读。如下图所示，图片引自Loss-less Semi-Synchronous Replication on MySQL 5.7.2。 如果主库永远启动不了，那么实际上在主库已经成功提交的事务，在从库上是找不到的，也就是数据丢失了，这是MySQL不愿意看到的。所以在MySQL 5.7版本中增加了after_sync（无损复制）参数，并将其设置为默认半同步方式，解决了数据丢失的问题 三、MySQL 5.6半同步复制配置 半同步复制的前提是已经做好了普通的主从复制 Master配置 3.1master安装半同步模块并启动 此模块就在/usr/local/mysql/lib/plugin/semisync_master.so 1.安装半同步模块 mysql> install plugin rpl_semi_sync_master soname 'semisync_master.so'; Query OK, 0 rows affected (0.00 sec) 2.启动插件 mysql> set global rpl_semi_sync_master_enabled = 1; Query OK, 0 rows affected (0.00 sec) 3.设置超时时间，单位是毫秒，默认为10000毫秒即10秒 mysql> set global rpl_semi_sync_master_timeout = 2000; Query OK, 0 rows affected (0.00 sec) 4.查看配置 mysql> show global variables like '%semi%'; +------------------------------------+-------+ | Variable_name | Value | +------------------------------------+-------+ | rpl_semi_sync_master_enabled | ON | #半同步开启 | rpl_semi_sync_master_timeout | 2000 | #超时时间为2秒 | rpl_semi_sync_master_trace_level | 32 | | rpl_semi_sync_master_wait_no_slave | ON | +------------------------------------+-------+ 4 rows in set (0.00 sec) 5.写入mysql配置文件，永久生效，在[mysqld]下写入以下两行内容 rpl_semi_sync_master_enabled = 1; rpl_semi_sync_master_timeout = 2000; 安装后启动和定制主从连接错误的超时时间默认是10s，可改为2s，一旦有一次超时自动降级为异步 slave配置 3.2slave安装半同步模块并启动 1.安装半同步模块 mysql> install plugin rpl_semi_sync_slave soname 'semisync_slave.so'; Query OK, 0 rows affected (0.01 sec) 2.启动插件 mysql> set global rpl_semi_sync_slave_enabled = 1; Query OK, 0 rows affected (0.00 sec) 3.重启IO线程 mysql> stop slave io_thread; Query OK, 0 rows affected (0.00 sec) mysql> start slave io_thread; Query OK, 0 rows affected (0.00 sec) 4.在master上查看是否启用了半同步 mysql> show global status like 'rpl%'; +--------------------------------------------+-------+ | Variable_name | Value | +--------------------------------------------+-------+ | Rpl_semi_sync_master_clients | 1 | #为1表明开启 | Rpl_semi_sync_master_net_avg_wait_time | 0 | | Rpl_semi_sync_master_net_wait_time | 0 | | Rpl_semi_sync_master_net_waits | 0 | | Rpl_semi_sync_master_no_times | 0 | | Rpl_semi_sync_master_no_tx | 0 | | Rpl_semi_sync_master_status | ON | #为ON表明开启 | Rpl_semi_sync_master_timefunc_failures | 0 | | Rpl_semi_sync_master_tx_avg_wait_time | 0 | | Rpl_semi_sync_master_tx_wait_time | 0 | | Rpl_semi_sync_master_tx_waits | 0 | | Rpl_semi_sync_master_wait_pos_backtraverse | 0 | | Rpl_semi_sync_master_wait_sessions | 0 | | Rpl_semi_sync_master_yes_tx | 0 | +--------------------------------------------+-------+ 14 rows in set (0.00 sec) 现在半同步已经正常工作了，主要看Rpl_semi_sync_master_clients是否不为0，Rpl_semi_sync_master_status是否为ON。如果Rpl_semi_sync_master_status为OFF，说明出现了网络延迟或Slave IO线程延迟。 3.3验证半同步超时 slave上关闭半同步并重启IO线程 mysql> set global rpl_semi_sync_slave_enabled = 0 ; Query OK, 0 rows affected (0.00 sec) mysql> stop slave io_thread; Query OK, 0 rows affected (0.00 sec) mysql> start slave io_thread; Query OK, 0 rows affected (0.00 sec) master上创建数据库验证 //master创建数据库 mysql> create database dbtest; Query OK, 1 row affected (2.00 sec) mysql> create database dbtest01; Query OK, 1 row affected (0.00 sec) 创建第一个数据库花了2.00秒，而我们前面设置的超时时间是2秒，而创建第二个数据库花了0.00秒，由此得出结论是超时转换为异步传送。 可以在Master上查看半同步相关的参数值Rpl_semi_sync_master_clients和Rpl_semi_sync_master_status是否正常。 mysql> show global status like '%semi%'; +--------------------------------------------+-------+ | Variable_name | Value | +--------------------------------------------+-------+ | Rpl_semi_sync_master_clients | 0 | #为0表示关闭半同步 | Rpl_semi_sync_master_net_avg_wait_time | 0 | | Rpl_semi_sync_master_net_wait_time | 0 | | Rpl_semi_sync_master_net_waits | 0 | | Rpl_semi_sync_master_no_times | 1 | | Rpl_semi_sync_master_no_tx | 2 | | Rpl_semi_sync_master_status | OFF | #OFF表示关闭半同步 | Rpl_semi_sync_master_timefunc_failures | 0 | | Rpl_semi_sync_master_tx_avg_wait_time | 0 | | Rpl_semi_sync_master_tx_wait_time | 0 | | Rpl_semi_sync_master_tx_waits | 0 | | Rpl_semi_sync_master_wait_pos_backtraverse | 0 | | Rpl_semi_sync_master_wait_sessions | 0 | | Rpl_semi_sync_master_yes_tx | 0 | +--------------------------------------------+-------+ 14 rows in set (0.00 sec) 可以看到都自动关闭了，需要注意一点的是，当Slave开启半同步后，或者当主从之间网络延迟恢复正常的时候，半同步复制会自动从异步复制又转为半同步复制，还是相当智能的。 另外个人在实际使用中还碰到一种情况从库IO线程有延迟时，主库会自动把半同步复制降为异步复制；当从库IO延迟没有时，主库又会把异步复制升级为半同步复制。可以进行压测模拟，但是此时查看Master的状态跟上面直接关闭Slave半同步有些不同，会发现Rpl_semi_sync_master_clients仍然等于1，而Rpl_semi_sync_master_status等于OFF。 随着MySQL 5.7版本的发布，半同步复制技术升级为全新的Loss-less Semi-Synchronous Replication架构，其成熟度、数据一致性与执行效率得到显著的提升。 四、MySQL 5.7半同步复制的改进 现在我们已经知道，在半同步环境下，主库是在事务提交之后等待Slave ACK，所以才会有数据不一致问题。所以这个Slave ACK在什么时间去等待，也是一个很关键的问题了。因此MySQL针对半同步复制的问题，在5.7.2引入了Loss-less Semi-Synchronous，在调用binlog sync之后，engine层commit之前等待Slave ACK。这样只有在确认Slave收到事务events后，事务才会提交。在commit之前等待Slave ACK，同时可以堆积事务，利于group commit，有利于提升性能。 4.1master安装半同步模块并启动 master配置 1.安装插件 mysql> install plugin rpl_semi_sync_master soname 'semisync_master.so'; Query OK, 0 rows affected (0.00 sec) 2.查看半同步信息，可以看到默认为10000毫秒即10秒 mysql> show global variables like '%semi%'; +-------------------------------------------+------------+ | Variable_name | Value | +-------------------------------------------+------------+ | rpl_semi_sync_master_enabled | OFF | | rpl_semi_sync_master_timeout | 10000 | | rpl_semi_sync_master_trace_level | 32 | | rpl_semi_sync_master_wait_for_slave_count | 1 | | rpl_semi_sync_master_wait_no_slave | ON | | rpl_semi_sync_master_wait_point | AFTER_SYNC | +-------------------------------------------+------------+ 6 rows in set (0.00 sec) 3.启动插件 mysql> set global rpl_semi_sync_master_enabled = 1; Query OK, 0 rows affected (0.00 sec) 4.设置超时时间为1秒 mysql> set global rpl_semi_sync_master_timeout = 1000; Query OK, 0 rows affected (0.00 sec) 5.查看配置 mysql> show global variables like '%semi%'; +-------------------------------------------+------------+ | Variable_name | Value | +-------------------------------------------+------------+ | rpl_semi_sync_master_enabled | ON | | rpl_semi_sync_master_timeout | 1000 | | rpl_semi_sync_master_trace_level | 32 | | rpl_semi_sync_master_wait_for_slave_count | 1 | | rpl_semi_sync_master_wait_no_slave | ON | | rpl_semi_sync_master_wait_point | AFTER_SYNC | +-------------------------------------------+------------+ 6 rows in set (0.00 sec) 6.写入mysql配置文件，永久生效，在[mysqld]下写入以下两行内容 rpl_semi_sync_master_enabled = 1; rpl_semi_sync_master_timeout = 1000; 4.2slave安装半同步模块并启动 1.安装半同步模块 mysql> install plugin rpl_semi_sync_slave soname 'semisync_slave.so'; Query OK, 0 rows affected (0.01 sec) 2.启动插件 mysql> set global rpl_semi_sync_slave_enabled = 1; Query OK, 0 rows affected (0.00 sec) 3.重启IO线程 mysql> stop slave io_thread; Query OK, 0 rows affected (0.00 sec) mysql> start slave io_thread; Query OK, 0 rows affected (0.00 sec) 4.在master上查看是否启用了半同步 mysql> show global status like 'rpl%'; +----------------------------+-------+ | Variable_name | Value | +----------------------------+-------+ | Rpl_semi_sync_slave_status | ON | +----------------------------+-------+ 1 row in set (0.00 sec) 4.3验证半同步超时 slave上关闭半同步并重启IO线程 mysql> set global rpl_semi_sync_slave_enabled = 0 ; Query OK, 0 rows affected (0.00 sec) mysql> stop slave io_thread; Query OK, 0 rows affected (0.00 sec) mysql> start slave io_thread; Query OK, 0 rows affected (0.00 sec) master上创建数据库验证 //master创建数据库 mysql> create database dbtest; Query OK, 1 row affected (1.00 sec) mysql> create database dbtest01; Query OK, 1 row affected (0.00 sec) 创建第一个数据库花了1.00秒，而我们前面设置的超时时间是1秒，而创建第二个数据库花了0.00秒，由此得出结论是超时转换为异步传送。 可以在Master上查看半同步相关的参数值Rpl_semi_sync_master_clients和Rpl_semi_sync_master_status是否正常。 mysql> show global status like '%semi%'; +--------------------------------------------+-------+ | Variable_name | Value | +--------------------------------------------+-------+ | Rpl_semi_sync_master_clients | 0 | #为0表示关闭半同步 | Rpl_semi_sync_master_net_avg_wait_time | 0 | | Rpl_semi_sync_master_net_wait_time | 0 | | Rpl_semi_sync_master_net_waits | 0 | | Rpl_semi_sync_master_no_times | 1 | | Rpl_semi_sync_master_no_tx | 2 | | Rpl_semi_sync_master_status | OFF | #OFF表示关闭半同步 | Rpl_semi_sync_master_timefunc_failures | 0 | | Rpl_semi_sync_master_tx_avg_wait_time | 0 | | Rpl_semi_sync_master_tx_wait_time | 0 | | Rpl_semi_sync_master_tx_waits | 0 | | Rpl_semi_sync_master_wait_pos_backtraverse | 0 | | Rpl_semi_sync_master_wait_sessions | 0 | | Rpl_semi_sync_master_yes_tx | 0 | +--------------------------------------------+-------+ 14 rows in set (0.00 sec) 可以看到都自动关闭了 4.4支持无损复制(Loss-less Semi-Synchronous) 在Loss-less Semi-Synchronous模式下，master在调用binlog sync之后，engine层commit之前等待Slave ACK（需要收到至少一个Slave节点回复的ACK后）。这样只有在确认Slave收到事务events后，master事务才会提交，然后把结果返回给客户端。此时此事务才对其他事务可见。在这种模式下解决了after_commit模式带来的幻读和数据丢失问题，因为主库没有提交事务。但也会有个问题，假设主库在存储引擎提交之前挂了，那么很明显这个事务是不成功的，但由于对应的Binlog已经做了Sync操作，从库已经收到了这些Binlog，并且执行成功，相当于在从库上多了数据，也算是有问题的，但多了数据，问题一般不算严重。这个问题可以这样理解，作为MySQL，在没办法解决分布式数据一致性问题的情况下，它能保证的是不丢数据，多了数据总比丢数据要好。 无损复制其实就是对semi sync增加了rpl_semi_sync_master_wait_point参数，来控制半同步模式下主库在返回给会话事务成功之前提交事务的方式。rpl_semi_sync_master_wait_point该参数有两个值：AFTER_COMMIT和AFTER_SYNC 4.4.1第一个值：AFTER_COMMIT（5.6默认值） master将每个事务写入binlog（sync_binlog=1），传递到slave刷新到磁盘(sync_relay=1)，同时主库提交事务。master等待slave反馈收到relay log，只有收到ACK后master才将commit OK结果反馈给客户端。 第二个值：AFTER_SYNC（5.7默认值，但5.6中无此模式） master将每个事务写入binlog , 传递到slave刷新到磁盘(relay log)。master等待slave反馈接收到relay log的ack之后，再提交事务并且返回commit OK结果给客户端。 即使主库crash，所有在主库上已经提交的事务都能保证已经同步到slave的relay log中。 4.5半同步复制与无损复制的对比 4.5.1 ACK的时间点不同 半同步复制在InnoDB层的Commit Log后等待ACK，主从切换会有数据丢失风险。 无损复制在MySQL Server层的Write binlog后等待ACK，主从切换会有数据变多风险。 4.5.2 主从数据一致性 半同步复制意味着在Master节点上，这个刚刚提交的事物对数据库的修改，对其他事物是可见的。因此，如果在等待Slave ACK的时候crash了，那么会对其他事务出现幻读，数据丢失。 无损复制在write binlog完成后，就传输binlog，但还没有去写commit log，意味着当前这个事物对数据库的修改，其他事物也是不可见的。因此，不会出现幻读，数据丢失风险。 因此5.7引入了无损复制（after_sync）模式，带来的主要收益是解决after_commit导致的master crash后数据丢失问题，因此在引入after_sync模式后，所有提交的数据已经都被复制，故障切换时数据一致性将得到提升。 性能提升，支持发送binlog和接受ack的异步化 旧版本的semi sync受限于dump thread ，原因是dump thread承担了两份不同且又十分频繁的任务：传送binlog给slave ，还需要等待slave反馈信息，而且这两个任务是串行的，dump thread必须等待slave返回之后才会传送下一个events事务。dump thread已然成为整个半同步提高性能的瓶颈。在高并发业务场景下，这样的机制会影响数据库整体的TPS 。 为了解决上述问题，在5.7版本的semi sync框架中，独立出一个Ack Receiver线程 ，专门用于接收slave返回的ack请求，这将之前dump线程的发送和接受工作分为了两个线程来处理。这样master上有两个线程独立工作，可以同时发送binlog到slave，和接收slave的ack信息。因此半同步复制得到了极大的性能提升。这也是MySQL 5.7发布时号称的Faster semi-sync replication。 但是在MySQL 5.7.17之前，这个Ack Receiver线程采用了select机制来监听slave返回的结果，然而select机制监控的文件句柄只能是0-1024，当超过1024时，用户在MySQL的错误日志中或许会收到类似如下的报错，更有甚者会导致MySQL发生宕机。 semi-sync master failed on net_flush() before waiting for slave reply. MySQL 5.7.17版本开始，官方修复了这个bug，开始使用poll机制来替换原来的select机制，从而可以避免上面的问题。其实poll调用本质上和select没有区别，只是在I/O句柄数理论上没有上限了，原因是它是基于链表来存储的。但是同样有缺点：比如大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义。poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。 其实在高性能软件中都是用另外一种调用机制，名为epoll，高性能的代表，比如Nginx，haproxy等都是使用epoll。可能poll的复杂性比epoll低，另外对于ack receiver线程来说可能poll足矣。 性能提升，控制主库接收slave写事务成功反馈数量 MySQL 5.7新增了rpl_semi_sync_master_wait_slave_count参数，可以用来控制主库接受多少个slave写事务成功反馈，给高可用架构切换提供了灵活性。如图所示，当count值为2时，master需等待两个slave的ack。 性能提升，Binlog互斥锁改进 旧版本半同步复制在主提交binlog的写会话和dump thread读binlog的操作都会对binlog添加互斥锁，导致binlog文件的读写是串行化的，存在并发度的问题。 MySQL 5.7对binlog lock进行了以下两方面优化: 1.移除了dump thread对binlog的互斥锁。 2.加入了安全边际保证binlog的读安全。 可以看到从replication功能引入后，官方MySQL一直在不停的完善，前进。同时我们可以发现当前原生的MySQL主备复制实现实际上很难在满足数据一致性的前提下做到高可用、高性能。 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mysql/mysql进阶/6.MHA基于普通主从复制高可用.html":{"url":"db/mysql/mysql进阶/6.MHA基于普通主从复制高可用.html","title":"MHA基于普通主从复制高可用","keywords":"","body":"MHA基于普通主从复制高可用 MHA gIthub地址 MHA github wiki地址 一、MHA简介 MHA通常在10到30秒内以最少的停机时间执行自动的主故障转移和从升级。MHA可以防止复制一致性问题，并节省了必须购买其他服务器的费用。所有这些都具有零性能下降，无复杂性（易于安装）并且无需更改现有部署的情况。 MHA还提供了计划的在线主设备切换，可以在停机（仅阻止写入）的几秒钟（0.5-2秒）内将当前正在运行的主设备安全地更改为新的主设备。 MHA提供以下功能，在需要高可用性，数据完整性和近乎不间断的主维护的许多部署中很有用。 自动化的主站监视和故障转移 MHA可以监视现有复制环境中的MySQL主服务器，并在检测到主服务器故障时执行自动主服务器故障转移。MHA通过识别来自最新从站的差分中继日志事件并将其应用于所有其他从站，包括那些尚未收到最新中继日志事件的从站，来保证所有从站的一致性。MHA通常可以在几秒钟内执行故障转移：9到12秒钟用于检测主设备故障，可选地7到10秒钟用于关闭主计算机电源，以避免脑部分裂；几秒钟的时间将差分中继日志应用于新的主设备。总停机时间通常为10-30秒。可以在配置文件中将特定从站指定为候选主站（设置优先级）。由于MHA维护从站之间的一致性，任何奴隶都可以晋升为新主人。通常不会导致突然的复制失败的一致性问题将不会发生。 交互式（手动启动）主故障转移 可以将MHA配置为手动启动（非自动），交互式故障转移，而无需监视主服务器。 非交互式主服务器故障转移 还支持不监视主服务器的非交互式自动主服务器故障转移。当已经使用MySQL主软件监视时，此功能特别有用。例如，您可以使用Pacemaker（Heartbeat）检测主服务器故障和虚拟IP地址接管，而使用MHA进行主服务器故障转移和从属升级。 在线将主服务器切换到其他主机 通常有必要将现有的主服务器迁移到另一台计算机上，例如当前主服务器存在硬件RAID控制器或RAM问题，或者要用速度更快的计算机替换它等时，这不是主服务器崩溃，但需要定期进行主维护。计划的主机维护应尽快完成，因为这会导致部分停机（禁用主机写入）。另一方面，您应该非常仔细地阻止/杀死当前正在运行的会话，因为不同的master之间可能会发生一致性问题（即“更新master1，更新master 2，提交master1，在提交master 2时出错”会导致数据不一致）。快速主开关和平稳阻止写入都是必需的。 MHA在写入器阻塞后的0.5-2秒内提供正常的主设备切换。通常可以接受0.5-2秒的写入器停机时间，因此即使不分配计划的维护时段，您也可以切换主机。升级到更高版本，更快的计算机等操作变得更加容易。 二、MHA架构 MHA架构官方文档 正常工作时架构 主库down机时架构 该软件由两部分组成：MHA Manager（管理节点）和MHA Node（数据节点）。 MHA Manager可以单独部署在一台独立的机器上管理多个master-slave集群，也可以部署在一台slave节点上。 MHA Node运行在每台MySQL服务器上，MHA Manager会定时探测集群中的master节点，当master出现故障时，它可以自动将最新数据的slave提升为新的master，然后将所有其他的slave重新指向新的master。整个故障转移过程对应用程序完全透明。 在MHA自动故障切换过程中，MHA试图从宕机的主服务器上保存二进制日志，最大程度的保证数据的不丢失(配合mysql半同步复制效果更佳)，但这并不总是可行的。例如，如果主服务器硬件故障或无法通过ssh访问，MHA没法保存二进制日志，只进行故障转移而丢失了最新的数据。使用MySQL 5.5的半同步复制，可以大大降低数据丢失的风险。MHA可以与半同步复制结合起来。如果只有一个slave已经收到了最新的二进制日志，MHA可以将最新的二进制日志应用于其他所有的slave服务器上，因此可以保证所有节点的数据一致性。 注意：目前MHA主要支持一主多从的架构，要搭建MHA,要求一个复制集群中必须最少有三台数据库服务器，一主二从，即一台充当master，一台充当备用master，另外一台充当从库，因为至少需要三台服务器。 工作过程：manager节点定时检测复制集群中的每一个node,如果master宕机会选出数据与master最接近的一台slave来作为新master，去到旧master中拷贝binlog到新master中并应用binlog以保证新master与旧master数据一致，然后将剩余的slave重新changer master to,将slave的主切换为新master 三、部署过程 实验环境 角色 IP 主机名 系统 机器配置 mysql版本 manager 10.0.0.130 mha centos7.8 2c4g 5.7.28 mysql-master 10.0.0.133 mysql01 centos7.8 2c4g 5.7.28 mysql-slave1 10.0.0.134 mysql02 centos7.8 2c4g 5.7.28 mysql-slave2 10.0.0.135 mysql03 centos7.8 2c4g 5.7.28 3.1 下载安装包 MHA manager0.58下载地址 MHA node0.58下载地址 MHA 0.56 下载地址 Manager工具包主要包括以下几个工具： 名称 含义 masterha_check_ssh 检查MHA的SSH配置状况 masterha_check_repl 检查MySQL复制状况 masterha_manger 启动MHA masterha_check_status 检测当前MHA运行状态 masterha_master_monitor 检测master是否宕机 masterha_master_switch 控制故障转移（自动或者手动） masterha_conf_host 添加或删除配置的server信息 Node工具包（这些工具通常由MHA Manager的脚本触发，无需人为操作）主要包括以下几个工具： 名称 含义 save_binary_logs 保存和复制master的二进制日志 apply_diff_relay_logs 识别差异的中继日志事件并将其差异的事件应用于其他的slave filter_mysqlbinlog 去除不必要的ROLLBACK事件（MHA已不再使用这个工具） purge_relay_logs 清除中继日志（不会阻塞SQL线程） 3.2 所有机器做相互免密钥配置 ⚠️复制集群中的每个节点都有可能成为master，都得开启binlog和ssh密钥认证，因为当旧master宕机后，mha要拷贝binlog到所有node节点上，而且所有节点都有可能成为master，故每个节点都要彼此密钥认证 lowB脚本运行一下 #!/bin/bash file_path=/root file_name=host.txt file=$file_path/$file_name user=root pwd=1 ssh_file=~/.ssh/id_rsa yum -y install expect &> /dev/null #生成密钥 [ -f \"$ssh_file\" ] || ssh-keygen -q -N \"\" -f ~/.ssh/id_rsa read -p \"请输入开始数值: \" start_num read -p \"请输入结束数值: \" end_num read -p \"请输入网段(类似格式：10.0.0.)：\" sub_net seq $start_num $end_num >$file #在文件开头加上网段，在文件末尾加上用户名和密码 sed -i 's/^/'$sub_net'/g' $file sed -i 's/$/ '$user' '$pwd'/g' $file echo -e \"执行成功，文件内容如下:\\n`cat $file`\" while read line;do ip=`echo $line | awk '{print $1}'` username=`echo $line | awk '{print $2}'` password=`echo $line | awk '{print $3}'` expect 3.3 mysql主从配置 这里是把10.0.0.133(mysql01)、10.0.0.134(mysql02)、10.0.0.135(mysql03)搭建为ABB，即一主两从，其中mysql01是主库，其余两个节点是从库 master操作(mysql01 10.0.0.133) 3.3.1 编辑/etc/my.cnf，指定serverid，并开启binlog #指定serverid，越小优先级越大 server_id=1 #开启binlog日志，位置在mysql数据目录data下 log_bin=binlog #开启binlog日志索引，位置在mysql数据目录data下 log_bin_index=binlog.index #开启半同步复制 log_slave_updates=1 重启mysql systemctl restart mysqld 3.3.2 创建专用复制用户和设置监控用户 允许从slave上连接过来的复制用户，3台mysql服务器都要创建复制用户和监控用户！！！ ⚠️复制用户名称为repl，否在在后续检测mysql集群连接情况会报错，也可以在配置文件中修改复制用户 创建专用复制用户 mysql> grant replication slave on *.* to 'repl'@'10.0.0.%' identified by 'Bxb123.com'; Query OK, 0 rows affected, 1 warning (0.00 sec) 设置监控用户 ⚠️所有节点进行授权 mysql> grant all privileges on *.* to 'mha'@'10.0.0.%' identified by 'Bxb123.com'; Query OK, 0 rows affected, 1 warning (0.00 sec) mysql5.7会默认加载validate_password 模块，是来控制密码长度和规则的，可以在配置文件里面关闭该模块加上validate_password = off，或者在mysql命令行执行set global validate_password_policy=0;来临时取消密码规则 禁用自动删除relay log功能 set global relay_log_purge=0; 查看master当前的binlog日志及位置信息 mysql> show master status; +---------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +---------------+----------+--------------+------------------+-------------------+ | binlog.000001 | 155 | | | | +---------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) slave操作(mysql02、03 10.0.0.134、135) set global read_only=1; Query OK, 0 rows affected (0.00 sec) //禁用自动删除relay log set global relay_log_purge=0; //拉取binlog change master to master_host='10.0.0.133', \\ master_port=3306, \\ master_user='repl', \\ master_password='Bxb123.com', \\ master_log_file='binlog.000001', \\ master_log_pos=155; Query OK, 0 rows affected, 2 warnings (0.01 sec) ``` **启动slave并查看slave状态** ```python //启动slave mysql> start slave; Query OK, 0 rows affected (0.00 sec) //查看slave状态，SQL和IO线程都为Yes即为正确 Slave_IO_Running: Yes Slave_SQL_Running: Yes #这个值是主从延迟，即slave落后master的秒数，也是一个比较重要的查看主从是否正常的标准值 Seconds_Behind_Master: 0 ``` ### 3.3.5 验证主从同步 **master操作** ```python //在主库上创建一个数据库db1 mysql> create database db1; Query OK, 1 row affected (0.00 sec) ``` **slave操作** 查看主库上创建的数据库是否已经同步过来，同步完成即为成功 ```python mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | db1 | | mysql | | performance_schema | | sys | +--------------------+ 5 rows in set (0.00 sec) ``` ## 3.4 部署MHA node **所有节点执行** ```python #下载包 wget https://github.com/yoshinorim/mha4mysql-node/releases/download/v0.58/mha4mysql-node-0.58.tar.gz #编译安装 $ cd mha4mysql-node-0.58 $ ls AUTHORS bin COPYING debian inc lib Makefile.PL MANIFEST META.yml README rpm t $ perl Makefile.PL $ make && make install ``` **安装完成后拷贝`mha4mysql-node-0.58/bin`下的所有可执行文件到`/usr/local/bin`** > **apply_diff_relay_logs #识别差异日志并应用于其他slave** > **save_binary_logs #保存和复制二进制日志** > **filter_mysqlbinlog #去除不必要的ROLLBACK事件（MHA已不再使用这个工具）** > **purge_relay_logs #清除中继日志** ## 3.5 部署MHA Manager manager操作(mha 10.0.0.130) 3.5.1 增加epel源 wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo 3.5.2 安装依赖包 yum -y install perl-DBD-MySQL perl-Config-Tiny perl-Log-Dispatch perl-Parallel-ForkManager perl-ExtUtils-CBuilder perl-ExtUtils-MakeMaker perl-ExtUtils-Embed perl-CPAN 3.5.3 安装manager #下载包 wget https://github.com/yoshinorim/mha4mysql-manager/releases/download/v0.58/mha4mysql-manager-0.58.tar.gz #编译安装 $ cd cd mha4mysql-manager-0.58 $ ls AUTHORS bin COPYING debian inc lib Makefile.PL MANIFEST META.yml README rpm samples t tests $ perl Makefile.PL $ make && make install 安装完成后会拷贝mha4mysql-manager-0.58/bin下的所有可执行文件到/usr/local/bin masterha_manager #在主服务器关闭的情况下，主服务器自动监视和运行故障转移 masterha_master_switch #手动或非交互式主故障转移或在线主库 masterha_master_monitor #MHA Manager监控程序 masterha_stop #停止MHA Manager masterha_check_repl #检查MySQL复制运行状况 masterha_check_status #检查Manager是否正确监视MySQL master masterha_check_ssh #检查ssh配置 masterha_conf_host #一个帮助程序脚本，用于从配置文件添加/删除主机条目 masterha_secondary_check #MHA Manager二次检查 3.5.4 mysql主库节点配置eth0:0网卡，用作VIP，这里设置为10.0.0.200 这一步在mysql主库上(10.0.0.133)执行 $ ifconfig eth0:0 10.0.0.200 $ ip a s eth0 eth0: mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:1c:42:62:a8:c1 brd ff:ff:ff:ff:ff:ff inet 10.0.0.133/24 brd 10.0.0.255 scope global eth0 valid_lft forever preferred_lft forever inet 10.0.0.200/8 brd 10.255.255.255 scope global eth0:0 valid_lft forever preferred_lft forever inet6 fe80::21c:42ff:fe62:a8c1/64 scope link valid_lft forever preferred_lft forever 3.5.5 使用脚本管理vip ⚠️需要修改的是VIP的地址和网卡的名称 VIP是绑定在主库上的，这样当主库宕机后VIP才会漂移到新主库上 cat > /usr/local/bin/master_ip_failover 'all'; use Getopt::Long; my ( $command, $ssh_user, $orig_master_host, $orig_master_ip, $orig_master_port, $new_master_host, $new_master_ip, $new_master_port ); #这里需要注意一下 eth1:$key的意思是 vip必须绑定在 eth0:0上 my $vip = '10.0.0.200/24'; #此处为你要设置的虚拟ip my $key = '0'; my $ssh_start_vip = \"/usr//sbin/ifconfig eth0:$key $vip\"; #此处改为你的网卡名称 my $ssh_stop_vip = \"/usr/sbin/ifconfig eth0:$key down\"; GetOptions( 'command=s' => \\$command, 'ssh_user=s' => \\$ssh_user, 'orig_master_host=s' => \\$orig_master_host, 'orig_master_ip=s' => \\$orig_master_ip, 'orig_master_port=i' => \\$orig_master_port, 'new_master_host=s' => \\$new_master_host, 'new_master_ip=s' => \\$new_master_ip, 'new_master_port=i' => \\$new_master_port, ); exit &main(); sub main { print \"\\n\\nIN SCRIPT TEST====$ssh_stop_vip==$ssh_start_vip===\\n\\n\"; if ( $command eq \"stop\" || $command eq \"stopssh\" ) { my $exit_code = 1; eval { print \"Disabling the VIP on old master: $orig_master_host \\n\"; &stop_vip(); $exit_code = 0; }; if ($@) { warn \"Got Error: $@\\n\"; exit $exit_code; } exit $exit_code; } elsif ( $command eq \"start\" ) { my $exit_code = 10; eval { print \"Enabling the VIP - $vip on the new master - $new_master_host \\n\"; &start_vip(); $exit_code = 0; }; if ($@) { warn $@; exit $exit_code; } exit $exit_code; } elsif ( $command eq \"status\" ) { print \"Checking the Status of the script.. OK \\n\"; exit 0; } else { &usage(); exit 1; } } sub start_vip() { `ssh $ssh_user\\@$new_master_host \\\" $ssh_start_vip \\\"`; } sub stop_vip() { return 0 unless ($ssh_user); `ssh $ssh_user\\@$orig_master_host \\\" $ssh_stop_vip \\\"`; } sub usage { print \"Usage: master_ip_failover --command=start|stop|stopssh|status --orig_master_host=host --orig_master_ip=ip --orig_master_port=port --new_master_host=host --new_master_ip=ip --new_master_port=port\\n\"; } EOF 给脚本赋予执行权限 chmod +x /usr/local/bin/master_ip_failover 3.5.6 配置mha配置文件 创建mha配置文件目录及日志目录 mkdir /etc/masterha mkdir -p /var/log/masterha/app1 编辑mha配置文件/etc/masterha/app1.conf mha4mysql-manager-0.58/samples/conf/app1.conf是mha的默认配置文件 cat > /etc/masterha/app1.cnf 编辑发生切换后发送报警的脚本，需要自行配置邮箱设置 cat > /etc/mha/send_report 'all'; use Mail::Sender; use Getopt::Long; #new_master_host and new_slave_hosts are set only when recovering master succeeded my ( $dead_master_host, $new_master_host, $new_slave_hosts, $subject, $body ); my $smtp='smtp服务器地址'; my $mail_from='发件人邮箱'; my $mail_user='邮箱登陆用户名'; my $mail_pass='邮箱登陆密码'; my $mail_to=['收件人地址']; GetOptions( 'orig_master_host=s' => \\$dead_master_host, 'new_master_host=s' => \\$new_master_host, 'new_slave_hosts=s' => \\$new_slave_hosts, 'subject=s' => \\$subject, 'body=s' => \\$body, ); mailToContacts($smtp,$mail_from,$mail_user,$mail_pass,$mail_to,$subject,$body); sub mailToContacts { my ( $smtp, $mail_from, $user, $passwd, $mail_to, $subject, $msg ) = @_; open my $DEBUG, \"> /tmp/monitormail.log\" or die \"Can't open the debug file:$!\\n\"; my $sender = new Mail::Sender { ctype => 'text/plain; charset=utf-8', encoding => 'utf-8', smtp => $smtp, from => $mail_from, auth => 'LOGIN', TLS_allowed => '0', authid => $user, authpwd => $passwd, to => $mail_to, subject => $subject, debug => $DEBUG }; $sender->MailMsg( { msg => $msg, debug => $DEBUG } ) or print $Mail::Sender::Error; return 1; } # Do whatever you want here exit 0; EOF 3.5.7 测试MHA Manager 3.5.7.1 测试ssh连接 $ masterha_check_ssh --conf=/etc/masterha/app1.cnf Sat Jun 6 10:27:32 2020 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping. Sat Jun 6 10:27:32 2020 - [info] Reading application default configuration from /etc/mha/mha.conf.. Sat Jun 6 10:27:32 2020 - [info] Reading server configuration from /etc/mha/mha.conf.. Sat Jun 6 10:27:32 2020 - [info] Starting SSH connection tests.. Sat Jun 6 10:27:33 2020 - [debug] Sat Jun 6 10:27:32 2020 - [debug] Connecting via SSH from root@10.0.0.133(10.0.0.133:22) to root@10.0.0.134(10.0.0.134:22).. Sat Jun 6 10:27:32 2020 - [debug] ok. Sat Jun 6 10:27:32 2020 - [debug] Connecting via SSH from root@10.0.0.133(10.0.0.133:22) to root@10.0.0.135(10.0.0.135:22).. Sat Jun 6 10:27:33 2020 - [debug] ok. Sat Jun 6 10:27:33 2020 - [debug] Sat Jun 6 10:27:32 2020 - [debug] Connecting via SSH from root@10.0.0.134(10.0.0.134:22) to root@10.0.0.133(10.0.0.133:22).. Sat Jun 6 10:27:33 2020 - [debug] ok. Sat Jun 6 10:27:33 2020 - [debug] Connecting via SSH from root@10.0.0.134(10.0.0.134:22) to root@10.0.0.135(10.0.0.135:22).. Sat Jun 6 10:27:33 2020 - [debug] ok. Sat Jun 6 10:27:34 2020 - [debug] Sat Jun 6 10:27:33 2020 - [debug] Connecting via SSH from root@10.0.0.135(10.0.0.135:22) to root@10.0.0.133(10.0.0.133:22).. Sat Jun 6 10:27:33 2020 - [debug] ok. Sat Jun 6 10:27:33 2020 - [debug] Connecting via SSH from root@10.0.0.135(10.0.0.135:22) to root@10.0.0.134(10.0.0.134:22).. Sat Jun 6 10:27:33 2020 - [debug] ok. Sat Jun 6 10:27:34 2020 - [info] All SSH connection tests passed successfully. 3.5.7.2 测试mysql集群连接情况 $ masterha_check_repl --conf=/etc/masterha/app1.cnf Sat Jun 6 12:45:42 2020 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping. Sat Jun 6 12:45:42 2020 - [info] Reading application default configuration from /etc/masterha/app1.cnf.. Sat Jun 6 12:45:42 2020 - [info] Reading server configuration from /etc/masterha/app1.cnf.. Sat Jun 6 12:45:42 2020 - [info] MHA::MasterMonitor version 0.58. Sat Jun 6 12:45:43 2020 - [info] GTID failover mode = 0 Sat Jun 6 12:45:43 2020 - [info] Dead Servers: Sat Jun 6 12:45:43 2020 - [info] Alive Servers: Sat Jun 6 12:45:43 2020 - [info] 10.0.0.133(10.0.0.133:3306) Sat Jun 6 12:45:43 2020 - [info] 10.0.0.134(10.0.0.134:3306) Sat Jun 6 12:45:43 2020 - [info] 10.0.0.135(10.0.0.135:3306) Sat Jun 6 12:45:43 2020 - [info] Alive Slaves: Sat Jun 6 12:45:43 2020 - [info] 10.0.0.134(10.0.0.134:3306) Version=5.7.28-log (oldest major version between slaves) log-bin:enabled Sat Jun 6 12:45:43 2020 - [info] Replicating from 10.0.0.133(10.0.0.133:3306) Sat Jun 6 12:45:43 2020 - [info] Primary candidate for the new Master (candidate_master is set) Sat Jun 6 12:45:43 2020 - [info] 10.0.0.135(10.0.0.135:3306) Version=5.7.28-log (oldest major version between slaves) log-bin:enabled Sat Jun 6 12:45:43 2020 - [info] Replicating from 10.0.0.133(10.0.0.133:3306) Sat Jun 6 12:45:43 2020 - [info] Current Alive Master: 10.0.0.133(10.0.0.133:3306) Sat Jun 6 12:45:43 2020 - [info] Checking slave configurations.. Sat Jun 6 12:45:43 2020 - [info] read_only=1 is not set on slave 10.0.0.134(10.0.0.134:3306). Sat Jun 6 12:45:43 2020 - [warning] relay_log_purge=0 is not set on slave 10.0.0.134(10.0.0.134:3306). Sat Jun 6 12:45:43 2020 - [info] read_only=1 is not set on slave 10.0.0.135(10.0.0.135:3306). Sat Jun 6 12:45:43 2020 - [warning] relay_log_purge=0 is not set on slave 10.0.0.135(10.0.0.135:3306). Sat Jun 6 12:45:43 2020 - [info] Checking replication filtering settings.. Sat Jun 6 12:45:43 2020 - [info] binlog_do_db= , binlog_ignore_db= Sat Jun 6 12:45:43 2020 - [info] Replication filtering check ok. Sat Jun 6 12:45:43 2020 - [info] GTID (with auto-pos) is not supported Sat Jun 6 12:45:43 2020 - [info] Starting SSH connection tests.. Sat Jun 6 12:45:50 2020 - [info] All SSH connection tests passed successfully. Sat Jun 6 12:45:50 2020 - [info] Checking MHA Node version.. Sat Jun 6 12:45:51 2020 - [info] Version check ok. Sat Jun 6 12:45:51 2020 - [info] Checking SSH publickey authentication settings on the current master.. Sat Jun 6 12:45:51 2020 - [info] HealthCheck: SSH to 10.0.0.133 is reachable. Sat Jun 6 12:45:51 2020 - [info] Master MHA Node version is 0.58. Sat Jun 6 12:45:51 2020 - [info] Checking recovery script configurations on 10.0.0.133(10.0.0.133:3306).. Sat Jun 6 12:45:51 2020 - [info] Executing command: save_binary_logs --command=test --start_pos=4 --binlog_dir=/usr/local/mysql/data --output_file=/tmp/save_binary_logs_test --manager_version=0.58 --start_file=binlog.000001 Sat Jun 6 12:45:51 2020 - [info] Connecting to root@10.0.0.133(10.0.0.133:22).. Creating /tmp if not exists.. ok. Checking output directory is accessible or not.. ok. Binlog found at /usr/local/mysql/data, up to binlog.000001 Sat Jun 6 12:45:51 2020 - [info] Binlog setting check done. Sat Jun 6 12:45:51 2020 - [info] Checking SSH publickey authentication and checking recovery script configurations on all alive slave servers.. Sat Jun 6 12:45:51 2020 - [info] Executing command : apply_diff_relay_logs --command=test --slave_user='root' --slave_host=10.0.0.134 --slave_ip=10.0.0.134 --slave_port=3306 --workdir=/tmp --target_version=5.7.28-log --manager_version=0.58 --relay_log_info=/usr/local/mysql/data/relay-log.info --relay_dir=/usr/local/mysql/data/ --slave_pass=xxx Sat Jun 6 12:45:51 2020 - [info] Connecting to root@10.0.0.134(10.0.0.134:22).. Checking slave recovery environment settings.. Opening /usr/local/mysql/data/relay-log.info ... ok. Relay log found at /usr/local/mysql/data, up to mysql02-relay-bin.000002 Temporary relay log file is /usr/local/mysql/data/mysql02-relay-bin.000002 Checking if super_read_only is defined and turned on.. not present or turned off, ignoring. Testing mysql connection and privileges.. mysql: [Warning] Using a password on the command line interface can be insecure. done. Testing mysqlbinlog output.. done. Cleaning up test file(s).. done. Sat Jun 6 12:45:51 2020 - [info] Executing command : apply_diff_relay_logs --command=test --slave_user='root' --slave_host=10.0.0.135 --slave_ip=10.0.0.135 --slave_port=3306 --workdir=/tmp --target_version=5.7.28-log --manager_version=0.58 --relay_log_info=/usr/local/mysql/data/relay-log.info --relay_dir=/usr/local/mysql/data/ --slave_pass=xxx Sat Jun 6 12:45:51 2020 - [info] Connecting to root@10.0.0.135(10.0.0.135:22).. Checking slave recovery environment settings.. Opening /usr/local/mysql/data/relay-log.info ... ok. Relay log found at /usr/local/mysql/data, up to mysql03-relay-bin.000002 Temporary relay log file is /usr/local/mysql/data/mysql03-relay-bin.000002 Checking if super_read_only is defined and turned on.. not present or turned off, ignoring. Testing mysql connection and privileges.. mysql: [Warning] Using a password on the command line interface can be insecure. done. Testing mysqlbinlog output.. done. Cleaning up test file(s).. done. Sat Jun 6 12:45:52 2020 - [info] Slaves settings check done. Sat Jun 6 12:45:52 2020 - [info] 10.0.0.133(10.0.0.133:3306) (current master) +--10.0.0.134(10.0.0.134:3306) +--10.0.0.135(10.0.0.135:3306) Sat Jun 6 12:45:52 2020 - [info] Checking replication health on 10.0.0.134.. Sat Jun 6 12:45:52 2020 - [info] ok. Sat Jun 6 12:45:52 2020 - [info] Checking replication health on 10.0.0.135.. Sat Jun 6 12:45:52 2020 - [info] ok. Sat Jun 6 12:45:52 2020 - [info] Checking master_ip_failover_script status: Sat Jun 6 12:45:52 2020 - [info] /usr/local/bin/master_ip_failover --command=status --ssh_user=root --orig_master_host=10.0.0.133 --orig_master_ip=10.0.0.133 --orig_master_port=3306 IN SCRIPT TEST====/usr/sbin/ifconfig eth1:1 down==/usr//sbin/ifconfig eth1:1 10.0.0.200/24=== Checking the Status of the script.. OK Sat Jun 6 12:45:52 2020 - [info] OK. Sat Jun 6 12:45:52 2020 - [warning] shutdown_script is not defined. Sat Jun 6 12:45:52 2020 - [info] Got exit code 0 (Not master dead). MySQL Replication Health is OK. 3.5.8 启动mha 启动mha nohup masterha_manager --conf=/etc/masterha/app1.cnf --remove_dead_master_conf --ignore_last_failover /var/log/masterha/app1/manager.log 2>&1 & 启动参数说明 --remove_dead_master_conf 该参数代表当发生主从切换后，老的主库的ip将会从配置文件中移除。 --manger_log 日志存放位置 --ignore_last_failover 在缺省情况下，如果MHA检测到连续发生宕机，且两次宕机间隔不足8小时的话，则不会进行Failover，之所以这样限制是为了避免ping-pong效应。该参数代表忽略上次MHA触发切换产生的文件，默认情况下，MHA发生切换后会在日志目录，也就是上面我设置的/data产生app1.failover.complete文件，下次再次切换的时候如果发现该目录下存在该文件将不允许触发切换，除非在第一次切换后收到删除该文件，为了方便，这里设置为--ignore_last_failover 测试mha状态 $ masterha_check_status --conf=/etc/masterha/app1.cnf app1 (pid:2262) is running(0:PING_OK), master:10.0.0.133 停止mha $ masterha_stop --conf=/etc/masterha/app1.cnf Stopped app1 successfully. [1]+ Exit 1 nohup masterha_manager --conf=/etc/masterha/app1.cnf --remove_dead_master_conf --ignore_last_failover /var/log/masterha/app1/manager.log 2>&1 重启mha masterha_stop --conf=/etc/masterha/app1.cnf && nohup masterha_manager --conf=/etc/masterha/app1.cnf --remove_dead_master_conf --ignore_last_failover /var/log/masterha/app1/manager.log 2>&1 & 到此，MHA部署完成！ 3.6 测试MHA 3.6.1 手动关闭主库，模拟宕机 10.0.0.133 mysql01操作 systemctl stop mysqld 3.6.2 验证slave1，即10.0.0.134 因为在mha配置文件/etc/masterha/app1.conf中定义了参数candidate_master=1，即设置为候选master，如果设置该参数以后，发生主从切换以后将会将此从库提升为主库，即使这个主库不是集群中事件最新的slave，因此，当主库挂掉时，slave1 10.0.0.134会成为新的主库 10.0.0.135 mysql02操作 可以看到，当主库10.0.0.133宕机后，10.0.0.134成为了新的主库 $ show slave status\\G *************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 10.0.0.134 Master_User: repl Master_Port: 3306 Connect_Retry: 60 Master_Log_File: binlog.000002 Read_Master_Log_Pos: 1331 Relay_Log_File: mysql03-relay-bin.000002 Relay_Log_Pos: 317 Relay_Master_Log_File: binlog.000002 Slave_IO_Running: Yes Slave_SQL_Running: Yes 。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。 验证VIP是否已经漂移 在新主库上能够看到VIP即为成功 $ ip a s eth0 2: eth0: mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:1c:42:09:c2:b1 brd ff:ff:ff:ff:ff:ff inet 10.0.0.134/24 brd 10.0.0.255 scope global eth0 valid_lft forever preferred_lft forever inet 10.0.0.200/24 brd 10.0.0.255 scope global secondary eth0:0 valid_lft forever preferred_lft forever inet6 fe80::21c:42ff:fe09:c2b1/64 scope link valid_lft forever preferred_lft forever 四、MHA常用命令总结 1、检查mha的ssh免密登录状态 masterha_check_ssh --conf=/etc/masterha/app1.cnf 2、检查mha的运行状态 masterha_check_status --conf=/etc/masterha/app1.cnf 3、检查主备库的复制情况 masterha_check_repl --conf=/etc/masterha/app1.cnf 4、停止mha masterha_stop --conf=/etc/masterha/app1.cnf 5、启动mha nohup masterha_manager --conf=/etc/masterha/app1.cnf --remove_dead_master_conf --ignore_last_failover /var/log/masterha/app1/manager.log 2>&1 & 6、mha手动切换主库 masterha_master_switch --conf=/etc/masterha/app1.cnf --master_state=alive --new_master_host=10.0.0.135 --new_master_port=3106 --orig_master_is_new_slave 7、mha重新绑定数据库实例 master_ip_failover --command=status --ssh_user=root --orig_master_host=10.0.0.133 --orig_master_ip=10.0.0.200 --orig_master_port=3306 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mysql/mysql进阶/7.MHA基于GTID主从复制高可用.html":{"url":"db/mysql/mysql进阶/7.MHA基于GTID主从复制高可用.html","title":"MHA基于GTID主从复制高可用","keywords":"","body":"MHA基于GTID主从复制高可用 MHA gIthub地址 MHA github wiki地址 一、MHA简介 MHA通常在10到30秒内以最少的停机时间执行自动的主故障转移和从升级。MHA可以防止复制一致性问题，并节省了必须购买其他服务器的费用。所有这些都具有零性能下降，无复杂性（易于安装）并且无需更改现有部署的情况。 MHA还提供了计划的在线主设备切换，可以在停机（仅阻止写入）的几秒钟（0.5-2秒）内将当前正在运行的主设备安全地更改为新的主设备。 MHA提供以下功能，在需要高可用性，数据完整性和近乎不间断的主维护的许多部署中很有用。 自动化的主站监视和故障转移 MHA可以监视现有复制环境中的MySQL主服务器，并在检测到主服务器故障时执行自动主服务器故障转移。MHA通过识别来自最新从站的差分中继日志事件并将其应用于所有其他从站，包括那些尚未收到最新中继日志事件的从站，来保证所有从站的一致性。MHA通常可以在几秒钟内执行故障转移：9到12秒钟用于检测主设备故障，可选地7到10秒钟用于关闭主计算机电源，以避免脑部分裂；几秒钟的时间将差分中继日志应用于新的主设备。总停机时间通常为10-30秒。可以在配置文件中将特定从站指定为候选主站（设置优先级）。由于MHA维护从站之间的一致性，任何奴隶都可以晋升为新主人。通常不会导致突然的复制失败的一致性问题将不会发生。 交互式（手动启动）主故障转移 可以将MHA配置为手动启动（非自动），交互式故障转移，而无需监视主服务器。 非交互式主服务器故障转移 还支持不监视主服务器的非交互式自动主服务器故障转移。当已经使用MySQL主软件监视时，此功能特别有用。例如，您可以使用Pacemaker（Heartbeat）检测主服务器故障和虚拟IP地址接管，而使用MHA进行主服务器故障转移和从属升级。 在线将主服务器切换到其他主机 通常有必要将现有的主服务器迁移到另一台计算机上，例如当前主服务器存在硬件RAID控制器或RAM问题，或者要用速度更快的计算机替换它等时，这不是主服务器崩溃，但需要定期进行主维护。计划的主机维护应尽快完成，因为这会导致部分停机（禁用主机写入）。另一方面，您应该非常仔细地阻止/杀死当前正在运行的会话，因为不同的master之间可能会发生一致性问题（即“更新master1，更新master 2，提交master1，在提交master 2时出错”会导致数据不一致）。快速主开关和平稳阻止写入都是必需的。 MHA在写入器阻塞后的0.5-2秒内提供正常的主设备切换。通常可以接受0.5-2秒的写入器停机时间，因此即使不分配计划的维护时段，您也可以切换主机。升级到更高版本，更快的计算机等操作变得更加容易。 二、MHA架构 MHA架构官方文档 正常工作时架构 主库down机时架构 该软件由两部分组成：MHA Manager（管理节点）和MHA Node（数据节点）。 MHA Manager可以单独部署在一台独立的机器上管理多个master-slave集群，也可以部署在一台slave节点上。 MHA Node运行在每台MySQL服务器上，MHA Manager会定时探测集群中的master节点，当master出现故障时，它可以自动将最新数据的slave提升为新的master，然后将所有其他的slave重新指向新的master。整个故障转移过程对应用程序完全透明。 在MHA自动故障切换过程中，MHA试图从宕机的主服务器上保存二进制日志，最大程度的保证数据的不丢失(配合mysql半同步复制效果更佳)，但这并不总是可行的。例如，如果主服务器硬件故障或无法通过ssh访问，MHA没法保存二进制日志，只进行故障转移而丢失了最新的数据。使用MySQL 5.5的半同步复制，可以大大降低数据丢失的风险。MHA可以与半同步复制结合起来。如果只有一个slave已经收到了最新的二进制日志，MHA可以将最新的二进制日志应用于其他所有的slave服务器上，因此可以保证所有节点的数据一致性。 注意：目前MHA主要支持一主多从的架构，要搭建MHA,要求一个复制集群中必须最少有三台数据库服务器，一主二从，即一台充当master，一台充当备用master，另外一台充当从库，因为至少需要三台服务器。 工作过程：manager节点定时检测复制集群中的每一个node,如果master宕机会选出数据与master最接近的一台slave来作为新master，去到旧master中拷贝binlog到新master中并应用binlog以保证新master与旧master数据一致，然后将剩余的slave重新changer master to,将slave的主切换为新master 三、部署过程 实验环境 角色 IP 主机名 系统 机器配置 mysql版本 manager 10.0.0.130 mha centos7.8 2c4g 5.7.28 mysql-master 10.0.0.133 mysql01 centos7.8 2c4g 5.7.28 mysql-slave1 10.0.0.134 mysql02 centos7.8 2c4g 5.7.28 mysql-slave2 10.0.0.135 mysql03 centos7.8 2c4g 5.7.28 3.1 下载安装包 MHA manager0.58下载地址 MHA node0.58下载地址 MHA 0.56 下载地址 Manager工具包主要包括以下几个工具： 名称 含义 masterha_check_ssh 检查MHA的SSH配置状况 masterha_check_repl 检查MySQL复制状况 masterha_manger 启动MHA masterha_check_status 检测当前MHA运行状态 masterha_master_monitor 检测master是否宕机 masterha_master_switch 控制故障转移（自动或者手动） masterha_conf_host 添加或删除配置的server信息 Node工具包（这些工具通常由MHA Manager的脚本触发，无需人为操作）主要包括以下几个工具： 名称 含义 save_binary_logs 保存和复制master的二进制日志 apply_diff_relay_logs 识别差异的中继日志事件并将其差异的事件应用于其他的slave filter_mysqlbinlog 去除不必要的ROLLBACK事件（MHA已不再使用这个工具） purge_relay_logs 清除中继日志（不会阻塞SQL线程） 3.2 所有机器做相互免密钥配置 ⚠️复制集群中的每个节点都有可能成为master，都得开启binlog和ssh密钥认证，因为当旧master宕机后，mha要拷贝binlog到所有node节点上，而且所有节点都有可能成为master，故每个节点都要彼此密钥认证 lowB脚本运行一下 #!/bin/bash file_path=/root file_name=host.txt file=$file_path/$file_name user=root pwd=1 ssh_file=~/.ssh/id_rsa yum -y install expect &> /dev/null #生成密钥 [ -f \"$ssh_file\" ] || ssh-keygen -q -N \"\" -f ~/.ssh/id_rsa read -p \"请输入开始数值: \" start_num read -p \"请输入结束数值: \" end_num read -p \"请输入网段(类似格式：10.0.0.)：\" sub_net seq $start_num $end_num >$file #在文件开头加上网段，在文件末尾加上用户名和密码 sed -i 's/^/'$sub_net'/g' $file sed -i 's/$/ '$user' '$pwd'/g' $file echo -e \"执行成功，文件内容如下:\\n`cat $file`\" while read line;do ip=`echo $line | awk '{print $1}'` username=`echo $line | awk '{print $2}'` password=`echo $line | awk '{print $3}'` expect 3.3 mysql主从配置-GTID 这里是把10.0.0.133(mysql01)、10.0.0.134(mysql02)、10.0.0.135(mysql03)搭建为ABB，即一主两从，其中mysql01是主库，其余两个节点是从库 master操作(mysql01 10.0.0.133) 3.3.1 编辑/etc/my.cnf，指定serverid，并开启binlog #指定server id server_id=1 #开启binlog日志，位置在mysql数据目录data下 log_bin=binlog #开启binlog日志索引，位置在mysql数据目录data下 log_bin_index=binlog.index #开启GTID gtid_mode=ON #开启GTID的一些安全限制 执行GTID一致 enforce_gtid_consistency #通常情况，从服务器从主服务器接收到的更新不记入它的二进制日志。该选项告诉从服务器将其SQL线程执行的更新记入到从服务器自己的二进制日志，mysql-5.6必须加这个参数，5.7可以不加 log-slave-updates #禁止mysql域名解析 skip_name_resolve 重启mysql systemctl restart mysqld 查看git开启情况，enforce_gtid_consistency与gtid_mode都为on即为正确 mysql> show global variables like '%gtid%'; +----------------------------------+-------+ | Variable_name | Value | +----------------------------------+-------+ | binlog_gtid_simple_recovery | ON | | enforce_gtid_consistency | ON | | gtid_executed | | | gtid_executed_compression_period | 1000 | | gtid_mode | ON | | gtid_owned | | | gtid_purged | | | session_track_gtids | OFF | +----------------------------------+-------+ 8 rows in set (0.00 sec) 3.3.2 创建专用复制用户和设置监控用户 允许从slave上连接过来的复制用户，3台mysql服务器都要创建复制用户和监控用户！！！ ⚠️复制用户名称为repl，也可以在MHA配置文件中修改复制用户 创建专用复制用户 mysql> grant replication slave on *.* to 'repl'@'10.0.0.%' identified by 'Bxb123.com'; Query OK, 0 rows affected, 1 warning (0.00 sec) 设置监控用户 ⚠️所有节点进行授权 mysql> grant all privileges on *.* to 'mha'@'10.0.0.%' identified by 'Bxb123.com'; Query OK, 0 rows affected, 1 warning (0.00 sec) mysql5.7会默认加载validate_password 模块，是来控制密码长度和规则的，可以在配置文件里面关闭该模块加上validate_password = off，或者在mysql命令行执行set global validate_password_policy=0;来临时取消密码规则 禁用自动删除relay log功能 set global relay_log_purge=0; slave操作(mysql02、03 10.0.0.134、135) show variables like '%gtid%'; +----------------------------------+-----------+ | Variable_name | Value | +----------------------------------+-----------+ | binlog_gtid_simple_recovery | ON | | enforce_gtid_consistency | ON | | gtid_executed_compression_period | 1000 | | gtid_mode | ON | | gtid_next | AUTOMATIC | | gtid_owned | | | gtid_purged | | | session_track_gtids | OFF | +----------------------------------+-----------+ 8 rows in set (0.00 sec) ``` ### 3.3.4 从库拉取 ```python //设置只读，不要在配置文件里写 mysql> set global read_only=1; Query OK, 0 rows affected (0.00 sec) //禁用自动删除relay log set global relay_log_purge=0; //拉取 change master to \\ master_host='10.0.0.133', \\ master_user='repl', \\ master_password='Bxb123.com', \\ master_auto_position=1; Query OK, 0 rows affected, 2 warnings (0.00 sec) ``` **启动slave并查看slave状态** ```python //启动slave mysql> start slave; Query OK, 0 rows affected (0.00 sec) //查看slave状态，SQL和IO线程都为Yes并且Auto_Position为1即为正确 Slave_IO_Running: Yes Slave_SQL_Running: Yes Auto_Position: 1 #这个值是主从延迟，即slave落后master的秒数，也是一个比较重要的查看主从是否正常的标准值 Seconds_Behind_Master: 0 ``` ### 3.3.5 验证主从同步 **master操作** ```python //在主库上创建一个数据库db1 mysql> create database db1; Query OK, 1 row affected (0.00 sec) ``` **slave操作** 查看主库上创建的数据库是否已经同步过来，同步完成即为成功 ```python mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | db1 | | mysql | | performance_schema | | sys | +--------------------+ 5 rows in set (0.00 sec) ``` ## 3.4 部署MHA node **所有节点执行** ```python #下载包 wget https://github.com/yoshinorim/mha4mysql-node/releases/download/v0.58/mha4mysql-node-0.58.tar.gz #编译安装 $ cd mha4mysql-node-0.58 $ ls AUTHORS bin COPYING debian inc lib Makefile.PL MANIFEST META.yml README rpm t $ perl Makefile.PL $ make && make install ``` **安装完成后拷贝`mha4mysql-node-0.58/bin`下的所有可执行文件到`/usr/local/bin`** > **apply_diff_relay_logs #识别差异日志并应用于其他slave** > **save_binary_logs #保存和复制二进制日志** > **filter_mysqlbinlog #去除不必要的ROLLBACK事件（MHA已不再使用这个工具）** > **purge_relay_logs #清除中继日志** ## 3.5 部署MHA Manager manager操作(mha 10.0.0.130) 3.5.1 增加epel源 wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo 3.5.2 安装依赖包 yum -y install perl-DBD-MySQL perl-Config-Tiny perl-Log-Dispatch perl-Parallel-ForkManager perl-ExtUtils-CBuilder perl-ExtUtils-MakeMaker perl-ExtUtils-Embed perl-CPAN 3.5.3 安装manager #下载包 wget https://github.com/yoshinorim/mha4mysql-manager/releases/download/v0.58/mha4mysql-manager-0.58.tar.gz #编译安装 $ cd cd mha4mysql-manager-0.58 $ ls AUTHORS bin COPYING debian inc lib Makefile.PL MANIFEST META.yml README rpm samples t tests $ perl Makefile.PL $ make && make install 安装完成后会拷贝mha4mysql-manager-0.58/bin下的所有可执行文件到/usr/local/bin masterha_manager #在主服务器关闭的情况下，主服务器自动监视和运行故障转移 masterha_master_switch #手动或非交互式主故障转移或在线主库 masterha_master_monitor #MHA Manager监控程序 masterha_stop #停止MHA Manager masterha_check_repl #检查MySQL复制运行状况 masterha_check_status #检查Manager是否正确监视MySQL master masterha_check_ssh #检查ssh配置 masterha_conf_host #一个帮助程序脚本，用于从配置文件添加/删除主机条目 masterha_secondary_check #MHA Manager二次检查 3.5.4 mysql主库节点配置eth0:0网卡，用作VIP，这里设置为10.0.0.200 这一步在mysql主库上(10.0.0.133)执行 $ ifconfig eth0:0 10.0.0.200 $ ip a s eth0 eth0: mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:1c:42:62:a8:c1 brd ff:ff:ff:ff:ff:ff inet 10.0.0.133/24 brd 10.0.0.255 scope global eth0 valid_lft forever preferred_lft forever inet 10.0.0.200/8 brd 10.255.255.255 scope global eth0:0 valid_lft forever preferred_lft forever inet6 fe80::21c:42ff:fe62:a8c1/64 scope link valid_lft forever preferred_lft forever 3.5.5 使用脚本管理vip ⚠️需要修改的是VIP的地址和网卡的名称 VIP是绑定在主库上的，这样当主库宕机后VIP才会漂移到新主库上 cat > /usr/local/bin/master_ip_failover 'all'; use Getopt::Long; my ( $command, $ssh_user, $orig_master_host, $orig_master_ip, $orig_master_port, $new_master_host, $new_master_ip, $new_master_port ); #这里需要注意一下 eth1:$key的意思是 vip必须绑定在 eth0:0上 my $vip = '10.0.0.200/24'; #此处为你要设置的虚拟ip my $key = '0'; my $ssh_start_vip = \"/usr//sbin/ifconfig eth0:$key $vip\"; #此处改为你的网卡名称 my $ssh_stop_vip = \"/usr/sbin/ifconfig eth0:$key down\"; GetOptions( 'command=s' => \\$command, 'ssh_user=s' => \\$ssh_user, 'orig_master_host=s' => \\$orig_master_host, 'orig_master_ip=s' => \\$orig_master_ip, 'orig_master_port=i' => \\$orig_master_port, 'new_master_host=s' => \\$new_master_host, 'new_master_ip=s' => \\$new_master_ip, 'new_master_port=i' => \\$new_master_port, ); exit &main(); sub main { print \"\\n\\nIN SCRIPT TEST====$ssh_stop_vip==$ssh_start_vip===\\n\\n\"; if ( $command eq \"stop\" || $command eq \"stopssh\" ) { my $exit_code = 1; eval { print \"Disabling the VIP on old master: $orig_master_host \\n\"; &stop_vip(); $exit_code = 0; }; if ($@) { warn \"Got Error: $@\\n\"; exit $exit_code; } exit $exit_code; } elsif ( $command eq \"start\" ) { my $exit_code = 10; eval { print \"Enabling the VIP - $vip on the new master - $new_master_host \\n\"; &start_vip(); $exit_code = 0; }; if ($@) { warn $@; exit $exit_code; } exit $exit_code; } elsif ( $command eq \"status\" ) { print \"Checking the Status of the script.. OK \\n\"; exit 0; } else { &usage(); exit 1; } } sub start_vip() { `ssh $ssh_user\\@$new_master_host \\\" $ssh_start_vip \\\"`; } sub stop_vip() { return 0 unless ($ssh_user); `ssh $ssh_user\\@$orig_master_host \\\" $ssh_stop_vip \\\"`; } sub usage { print \"Usage: master_ip_failover --command=start|stop|stopssh|status --orig_master_host=host --orig_master_ip=ip --orig_master_port=port --new_master_host=host --new_master_ip=ip --new_master_port=port\\n\"; } EOF 给脚本赋予执行权限 chmod +x /usr/local/bin/master_ip_failover 3.5.6 配置mha配置文件 创建mha配置文件目录及日志目录 mkdir /etc/masterha mkdir -p /var/log/masterha/app1 编辑mha配置文件/etc/masterha/app1.conf mha4mysql-manager-0.58/samples/conf/app1.conf是mha的默认配置文件 cat > /etc/masterha/app1.cnf 编辑发生切换后发送报警的脚本，需要自行配置邮箱设置 cat > /etc/masterha/send_report 'all'; use Mail::Sender; use Getopt::Long; #new_master_host and new_slave_hosts are set only when recovering master succeeded my ( $dead_master_host, $new_master_host, $new_slave_hosts, $subject, $body ); my $smtp='smtp服务器地址'; my $mail_from='发件人邮箱'; my $mail_user='邮箱登陆用户名'; my $mail_pass='邮箱登陆密码'; my $mail_to=['收件人地址']; GetOptions( 'orig_master_host=s' => \\$dead_master_host, 'new_master_host=s' => \\$new_master_host, 'new_slave_hosts=s' => \\$new_slave_hosts, 'subject=s' => \\$subject, 'body=s' => \\$body, ); mailToContacts($smtp,$mail_from,$mail_user,$mail_pass,$mail_to,$subject,$body); sub mailToContacts { my ( $smtp, $mail_from, $user, $passwd, $mail_to, $subject, $msg ) = @_; open my $DEBUG, \"> /tmp/monitormail.log\" or die \"Can't open the debug file:$!\\n\"; my $sender = new Mail::Sender { ctype => 'text/plain; charset=utf-8', encoding => 'utf-8', smtp => $smtp, from => $mail_from, auth => 'LOGIN', TLS_allowed => '0', authid => $user, authpwd => $passwd, to => $mail_to, subject => $subject, debug => $DEBUG }; $sender->MailMsg( { msg => $msg, debug => $DEBUG } ) or print $Mail::Sender::Error; return 1; } # Do whatever you want here exit 0; EOF 3.5.7 测试MHA Manager 3.5.7.1 测试ssh连接 $ masterha_check_ssh --conf=/etc/masterha/app1.cnf Sat Jun 6 10:27:32 2020 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping. Sat Jun 6 10:27:32 2020 - [info] Reading application default configuration from /etc/mha/mha.conf.. Sat Jun 6 10:27:32 2020 - [info] Reading server configuration from /etc/mha/mha.conf.. Sat Jun 6 10:27:32 2020 - [info] Starting SSH connection tests.. Sat Jun 6 10:27:33 2020 - [debug] Sat Jun 6 10:27:32 2020 - [debug] Connecting via SSH from root@10.0.0.133(10.0.0.133:22) to root@10.0.0.134(10.0.0.134:22).. Sat Jun 6 10:27:32 2020 - [debug] ok. Sat Jun 6 10:27:32 2020 - [debug] Connecting via SSH from root@10.0.0.133(10.0.0.133:22) to root@10.0.0.135(10.0.0.135:22).. Sat Jun 6 10:27:33 2020 - [debug] ok. Sat Jun 6 10:27:33 2020 - [debug] Sat Jun 6 10:27:32 2020 - [debug] Connecting via SSH from root@10.0.0.134(10.0.0.134:22) to root@10.0.0.133(10.0.0.133:22).. Sat Jun 6 10:27:33 2020 - [debug] ok. Sat Jun 6 10:27:33 2020 - [debug] Connecting via SSH from root@10.0.0.134(10.0.0.134:22) to root@10.0.0.135(10.0.0.135:22).. Sat Jun 6 10:27:33 2020 - [debug] ok. Sat Jun 6 10:27:34 2020 - [debug] Sat Jun 6 10:27:33 2020 - [debug] Connecting via SSH from root@10.0.0.135(10.0.0.135:22) to root@10.0.0.133(10.0.0.133:22).. Sat Jun 6 10:27:33 2020 - [debug] ok. Sat Jun 6 10:27:33 2020 - [debug] Connecting via SSH from root@10.0.0.135(10.0.0.135:22) to root@10.0.0.134(10.0.0.134:22).. Sat Jun 6 10:27:33 2020 - [debug] ok. Sat Jun 6 10:27:34 2020 - [info] All SSH connection tests passed successfully. 3.5.7.2 测试mysql集群连接情况 $ masterha_check_repl --conf=/etc/masterha/app1.cnf Sat Jun 6 12:45:42 2020 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping. Sat Jun 6 12:45:42 2020 - [info] Reading application default configuration from /etc/masterha/app1.cnf.. Sat Jun 6 12:45:42 2020 - [info] Reading server configuration from /etc/masterha/app1.cnf.. Sat Jun 6 12:45:42 2020 - [info] MHA::MasterMonitor version 0.58. Sat Jun 6 12:45:43 2020 - [info] GTID failover mode = 0 Sat Jun 6 12:45:43 2020 - [info] Dead Servers: Sat Jun 6 12:45:43 2020 - [info] Alive Servers: Sat Jun 6 12:45:43 2020 - [info] 10.0.0.133(10.0.0.133:3306) Sat Jun 6 12:45:43 2020 - [info] 10.0.0.134(10.0.0.134:3306) Sat Jun 6 12:45:43 2020 - [info] 10.0.0.135(10.0.0.135:3306) Sat Jun 6 12:45:43 2020 - [info] Alive Slaves: Sat Jun 6 12:45:43 2020 - [info] 10.0.0.134(10.0.0.134:3306) Version=5.7.28-log (oldest major version between slaves) log-bin:enabled Sat Jun 6 12:45:43 2020 - [info] Replicating from 10.0.0.133(10.0.0.133:3306) Sat Jun 6 12:45:43 2020 - [info] Primary candidate for the new Master (candidate_master is set) Sat Jun 6 12:45:43 2020 - [info] 10.0.0.135(10.0.0.135:3306) Version=5.7.28-log (oldest major version between slaves) log-bin:enabled Sat Jun 6 12:45:43 2020 - [info] Replicating from 10.0.0.133(10.0.0.133:3306) Sat Jun 6 12:45:43 2020 - [info] Current Alive Master: 10.0.0.133(10.0.0.133:3306) Sat Jun 6 12:45:43 2020 - [info] Checking slave configurations.. Sat Jun 6 12:45:43 2020 - [info] read_only=1 is not set on slave 10.0.0.134(10.0.0.134:3306). Sat Jun 6 12:45:43 2020 - [warning] relay_log_purge=0 is not set on slave 10.0.0.134(10.0.0.134:3306). Sat Jun 6 12:45:43 2020 - [info] read_only=1 is not set on slave 10.0.0.135(10.0.0.135:3306). Sat Jun 6 12:45:43 2020 - [warning] relay_log_purge=0 is not set on slave 10.0.0.135(10.0.0.135:3306). Sat Jun 6 12:45:43 2020 - [info] Checking replication filtering settings.. Sat Jun 6 12:45:43 2020 - [info] binlog_do_db= , binlog_ignore_db= Sat Jun 6 12:45:43 2020 - [info] Replication filtering check ok. Sat Jun 6 12:45:43 2020 - [info] GTID (with auto-pos) is not supported Sat Jun 6 12:45:43 2020 - [info] Starting SSH connection tests.. Sat Jun 6 12:45:50 2020 - [info] All SSH connection tests passed successfully. Sat Jun 6 12:45:50 2020 - [info] Checking MHA Node version.. Sat Jun 6 12:45:51 2020 - [info] Version check ok. Sat Jun 6 12:45:51 2020 - [info] Checking SSH publickey authentication settings on the current master.. Sat Jun 6 12:45:51 2020 - [info] HealthCheck: SSH to 10.0.0.133 is reachable. Sat Jun 6 12:45:51 2020 - [info] Master MHA Node version is 0.58. Sat Jun 6 12:45:51 2020 - [info] Checking recovery script configurations on 10.0.0.133(10.0.0.133:3306).. Sat Jun 6 12:45:51 2020 - [info] Executing command: save_binary_logs --command=test --start_pos=4 --binlog_dir=/usr/local/mysql/data --output_file=/tmp/save_binary_logs_test --manager_version=0.58 --start_file=binlog.000001 Sat Jun 6 12:45:51 2020 - [info] Connecting to root@10.0.0.133(10.0.0.133:22).. Creating /tmp if not exists.. ok. Checking output directory is accessible or not.. ok. Binlog found at /usr/local/mysql/data, up to binlog.000001 Sat Jun 6 12:45:51 2020 - [info] Binlog setting check done. Sat Jun 6 12:45:51 2020 - [info] Checking SSH publickey authentication and checking recovery script configurations on all alive slave servers.. Sat Jun 6 12:45:51 2020 - [info] Executing command : apply_diff_relay_logs --command=test --slave_user='root' --slave_host=10.0.0.134 --slave_ip=10.0.0.134 --slave_port=3306 --workdir=/tmp --target_version=5.7.28-log --manager_version=0.58 --relay_log_info=/usr/local/mysql/data/relay-log.info --relay_dir=/usr/local/mysql/data/ --slave_pass=xxx Sat Jun 6 12:45:51 2020 - [info] Connecting to root@10.0.0.134(10.0.0.134:22).. Checking slave recovery environment settings.. Opening /usr/local/mysql/data/relay-log.info ... ok. Relay log found at /usr/local/mysql/data, up to mysql02-relay-bin.000002 Temporary relay log file is /usr/local/mysql/data/mysql02-relay-bin.000002 Checking if super_read_only is defined and turned on.. not present or turned off, ignoring. Testing mysql connection and privileges.. mysql: [Warning] Using a password on the command line interface can be insecure. done. Testing mysqlbinlog output.. done. Cleaning up test file(s).. done. Sat Jun 6 12:45:51 2020 - [info] Executing command : apply_diff_relay_logs --command=test --slave_user='root' --slave_host=10.0.0.135 --slave_ip=10.0.0.135 --slave_port=3306 --workdir=/tmp --target_version=5.7.28-log --manager_version=0.58 --relay_log_info=/usr/local/mysql/data/relay-log.info --relay_dir=/usr/local/mysql/data/ --slave_pass=xxx Sat Jun 6 12:45:51 2020 - [info] Connecting to root@10.0.0.135(10.0.0.135:22).. Checking slave recovery environment settings.. Opening /usr/local/mysql/data/relay-log.info ... ok. Relay log found at /usr/local/mysql/data, up to mysql03-relay-bin.000002 Temporary relay log file is /usr/local/mysql/data/mysql03-relay-bin.000002 Checking if super_read_only is defined and turned on.. not present or turned off, ignoring. Testing mysql connection and privileges.. mysql: [Warning] Using a password on the command line interface can be insecure. done. Testing mysqlbinlog output.. done. Cleaning up test file(s).. done. Sat Jun 6 12:45:52 2020 - [info] Slaves settings check done. Sat Jun 6 12:45:52 2020 - [info] 10.0.0.133(10.0.0.133:3306) (current master) +--10.0.0.134(10.0.0.134:3306) +--10.0.0.135(10.0.0.135:3306) Sat Jun 6 12:45:52 2020 - [info] Checking replication health on 10.0.0.134.. Sat Jun 6 12:45:52 2020 - [info] ok. Sat Jun 6 12:45:52 2020 - [info] Checking replication health on 10.0.0.135.. Sat Jun 6 12:45:52 2020 - [info] ok. Sat Jun 6 12:45:52 2020 - [info] Checking master_ip_failover_script status: Sat Jun 6 12:45:52 2020 - [info] /usr/local/bin/master_ip_failover --command=status --ssh_user=root --orig_master_host=10.0.0.133 --orig_master_ip=10.0.0.133 --orig_master_port=3306 IN SCRIPT TEST====/usr/sbin/ifconfig eth1:1 down==/usr//sbin/ifconfig eth1:1 10.0.0.200/24=== Checking the Status of the script.. OK Sat Jun 6 12:45:52 2020 - [info] OK. Sat Jun 6 12:45:52 2020 - [warning] shutdown_script is not defined. Sat Jun 6 12:45:52 2020 - [info] Got exit code 0 (Not master dead). MySQL Replication Health is OK. 3.5.8 启动mha 启动mha nohup masterha_manager --conf=/etc/masterha/app1.cnf --remove_dead_master_conf --ignore_last_failover /var/log/masterha/app1/manager.log 2>&1 & 启动参数说明 --remove_dead_master_conf 该参数代表当发生主从切换后，老的主库的ip将会从配置文件中移除。 /var/log/masterha/app1/manager.log 2>&1 & 打印日志 --ignore_last_failover 在缺省情况下，如果MHA检测到连续发生宕机，且两次宕机间隔不足8小时的话，则不会进行Failover，之所以这样限制是为了避免ping-pong效应。该参数代表忽略上次MHA触发切换产生的文件，默认情况下，MHA发生切换后会在日志目录，也就是上面我设置的/data产生app1.failover.complete文件，下次再次切换的时候如果发现该目录下存在该文件将不允许触发切换，除非在第一次切换后收到删除该文件，为了方便，这里设置为--ignore_last_failover MHA切换机制 1、切换后会生成一个临时文件，在MHA的工作目录下 2、下一次切换之前先监测是否存在这个临时文件 3、如果存在，则不做切换 4、如果不存在，则切换 5、该临时文件存在时间8小时 测试mha状态 $ masterha_check_status --conf=/etc/masterha/app1.cnf app1 (pid:2262) is running(0:PING_OK), master:10.0.0.133 停止mha $ masterha_stop --conf=/etc/masterha/app1.cnf Stopped app1 successfully. [1]+ Exit 1 nohup masterha_manager --conf=/etc/masterha/app1.cnf --remove_dead_master_conf --ignore_last_failover /var/log/masterha/app1/manager.log 2>&1 重启mha masterha_stop --conf=/etc/masterha/app1.cnf && nohup masterha_manager --conf=/etc/masterha/app1.cnf --remove_dead_master_conf --ignore_last_failover /var/log/masterha/app1/manager.log 2>&1 & 到此，MHA部署完成！ 3.6 测试MHA 3.6.1 手动关闭主库，模拟宕机 10.0.0.133 mysql01操作 systemctl stop mysqld 3.6.2 验证slave1，即10.0.0.134 因为在mha配置文件/etc/masterha/app1.conf中定义了参数candidate_master=1，即设置为候选master，如果设置该参数以后，发生主从切换以后将会将此从库提升为主库，即使这个主库不是集群中事件最新的slave，因此，当主库挂掉时，slave1 10.0.0.134会成为新的主库 10.0.0.135 mysql02操作 可以看到，当主库10.0.0.133宕机后，10.0.0.134成为了新的主库 $ show slave status\\G *************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 10.0.0.134 Master_User: repl Master_Port: 3306 Connect_Retry: 60 Master_Log_File: binlog.000002 Read_Master_Log_Pos: 1331 Relay_Log_File: mysql03-relay-bin.000002 Relay_Log_Pos: 317 Relay_Master_Log_File: binlog.000002 Slave_IO_Running: Yes Slave_SQL_Running: Yes 。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。 验证VIP是否已经漂移 在新主库上能够看到VIP即为成功 $ ip a s eth0 2: eth0: mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:1c:42:09:c2:b1 brd ff:ff:ff:ff:ff:ff inet 10.0.0.134/24 brd 10.0.0.255 scope global eth0 valid_lft forever preferred_lft forever inet 10.0.0.200/24 brd 10.0.0.255 scope global secondary eth0:0 valid_lft forever preferred_lft forever inet6 fe80::21c:42ff:fe09:c2b1/64 scope link valid_lft forever preferred_lft forever 3.7 修复宕机主库步骤 第一步、修复宕机主库 用各种方法把宕掉的旧主库成功启动 第二步、从MHA配置文件/etc/masterha/app1.conf中的[server default]标签下定义的manager_log=/var/log/masterha/app1/manager.log日志文件中找到change master to语句，修改从库复制用户的密码，并且指定主库为新主库 MHA节点操作 $ grep -i 'change master to' /var/log/masterha/app1/manager.log Sun Jun 7 13:17:49 2020 - [info] All other slaves should start replication from here. Statement should be: CHANGE MASTER TO MASTER_HOST='10.0.0.134', MASTER_PORT=3306, MASTER_AUTO_POSITION=1, MASTER_USER='repl', MASTER_PASSWORD='xxx'; 第三步、连接旧主库，执行上一步找到的change master to语句并打开IO、SQL线程 10.0.0.133 mysql01(旧主库)操作 #执行change master to mysql> CHANGE MASTER TO \\ MASTER_HOST='10.0.0.134', \\ MASTER_PORT=3306, \\ MASTER_AUTO_POSITION=1, \\ MASTER_USER='repl', \\ MASTER_PASSWORD='Bxb123.com'; Query OK, 0 rows affected, 2 warnings (0.01 sec) #启动IO、SQL线程 mysql> start slave; Query OK, 0 rows affected (0.01 sec) 第四步、把旧主库的server标签在MHA配置文件中添加回来，MHA执行切换后，会把down机的主机server标签删除 编辑MHA配置文件/etc/masterha/app1.cnf添加server1标签 [server1] hostname=10.0.0.133 port=3306 第五步、启动MHA nohup masterha_manager --conf=/etc/masterha/app1.cnf --remove_dead_master_conf --ignore_last_failover /var/log/masterha/app1/manager.log 2>&1 & 四、配置binlog-server mysql5.7官方binlog-server文档 MHA官方对于binlog-server的简单说明 从MHA版本0.56开始，MHA支持new部分[binlogN]。在binlog部分，您可以定义mysqlbinlog流服务器。当MHA进行基于GTID的故障转移时，MHA会检查binlog服务器，并且如果binlog服务器在其他从服务器之前，则MHA会在恢复之前将差分binlog事件应用于新的主服务器。当MHA进行基于非GTID的（传统）故障转移时，MHA将忽略二进制日志服务器。 作用: 防止master断电或其他原因导致binlog缺失 前提: mysql主从必须为GTID模式 配置好GTID主从后执行以下步骤 4.1 MHA配置文件/etc/masterha/app1.cnf加入binlog-server配置 这里把mysql03 10.0.0.135当作binlog-server [binlog1] #不让这个机器当主库 no_master=1 hostname=10.0.0.135 master_binlog_dir=/data/mysql/binlog 创建binlog备份目录 mkdir -p /data/mysql/binlog && chown mysql.mysql /data/mysql/binlog 4.2 手动备份binlog ⚠️备份binlog，--host后的IP一定要填写VIP地址 ⚠️一定要注意写对mysql binlog文件的名称 #进入binlog备份目录 cd /data/mysql/binlog #手动备份 mysqlbinlog -R --host=10.0.0.200 --user=mha --password=Bxb123.com --raw --stop-never binlog.000001 & 4.3 启动MHA nohup masterha_manager --conf=/etc/masterha/app1.cnf --remove_dead_master_conf --ignore_last_failover /var/log/masterha/app1/manager.log 2>&1 & 4.4 验证 mysql master节点执行命令flush logs刷新binlog master刷新binlog，多执行几次 mysql> flush logs; Query OK, 0 rows affected (0.01 sec) mysql03 10.0.0.135节点/data/mysql/binlog查看binlog，会同步master上的binlog $ pwd /data/mysql/binlog $ ls binlog.000001 binlog.000002 binlog.000003 五、MHA常用命令总结 1、检查mha的ssh免密登录状态 masterha_check_ssh --conf=/etc/masterha/app1.cnf 2、检查mha的运行状态 masterha_check_status --conf=/etc/masterha/app1.cnf 3、检查主备库的复制情况 masterha_check_repl --conf=/etc/masterha/app1.cnf 4、停止mha masterha_stop --conf=/etc/masterha/app1.cnf 5、启动mha nohup masterha_manager --conf=/etc/masterha/app1.cnf --remove_dead_master_conf --ignore_last_failover /var/log/masterha/app1/manager.log 2>&1 & 6、mha手动切换主库 masterha_master_switch --conf=/etc/masterha/app1.cnf --master_state=alive --new_master_host=10.0.0.135 --new_master_port=3106 --orig_master_is_new_slave 7、mha重新绑定数据库实例 master_ip_failover --command=status --ssh_user=root --orig_master_host=10.0.0.133 --orig_master_ip=10.0.0.200 --orig_master_port=3306 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mysql/mysql知识点/mysql事务隔离级别.html":{"url":"db/mysql/mysql知识点/mysql事务隔离级别.html","title":"mysql事务隔离级别","keywords":"","body":"mysql事务隔离级别 mysql事务 一般来说，事务是必须满足4个条件（ACID）：：原子性（Atomicity，或称不可分割性）、一致性（Consistency）、隔离性（Isolation，又称独立性）、持久性（Durability）。 原子性：一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。 一致性：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作。 隔离性：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。 持久性：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 mysql 4种事务隔离级别 级别 symbol 对应值 含义 存在问题 读未提交 READ-UNCOMMITTED 0 一个事务可以读到另一个事务未提交的数据 存在脏读、不可重复读、幻读的问题 读已提交 READ-COMMITTED 1 一个事务能读到另一个事务已提交的数据 解决脏读的问题，存在不可重复读、幻读的问题 可重复读 REPEATABLE-READ 2 同一事务的多个实例在并发读取数据时，会看到同样的数据行 mysql默认级别，解决脏读、不可重复读的问题，存在幻读的问题。使用 MMVC机制 实现可重复读 串行化 SERIALIZABLE 3 强制事务排序，使之不可能相互冲突 解决脏读、不可重复读、幻读，可保证事务安全，但完全串行执行，性能最低 关于mysql事务的一些知识点 最开始的时候，5.1.5之前的版本binlog format只支持stament，并没有row模式，在RC一些场景下会造成主从数据不一致，所以选择RR才能最大限度保证主从数据一致性 之后的mysql直接使用RC+row是完全没有问题的 mysql5.7表的默认存储引擎是InnoDB mysql> show create table t1; +-------+---------------------------------------------------------------------------------------------------------------------------------------+ | Table | Create Table | +-------+---------------------------------------------------------------------------------------------------------------------------------------+ | t1 | CREATE TABLE `t1` ( `id` int(3) NOT NULL, `name` char(30) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 | +-------+---------------------------------------------------------------------------------------------------------------------------------------+ 1 row in set (0.05 sec) mysql5.7 InnoDB存储引擎默认的事务隔离级别，全局和当前会话都是REPEATABLE-READ(可重复读) RR的并发性没有RC好 #mysql5.7.22 mysql> SELECT @@global.tx_isolation, @@tx_isolation; +-----------------------+-----------------+ | @@global.tx_isolation | @@tx_isolation | +-----------------------+-----------------+ | REPEATABLE-READ | REPEATABLE-READ | +-----------------------+-----------------+ 1 row in set (0.02 sec) 设置事务隔离级别 #配置文件修改，可选参数 READ-UNCOMMITTED、READ-COMMITTED、REPEATABLE-READ、 SERIALIZABLE [mysqld] transaction-isolation = REPEATABLE-READ #设置全局 SET @@global.tx_isolation = 0; SET @@global.tx_isolation = 'READ-UNCOMMITTED'; SET @@global.tx_isolation = 1; SET @@global.tx_isolation = 'READ-COMMITTED'; SET @@global.tx_isolation = 2; SET @@global.tx_isolation = 'REPEATABLE-READ'; SET @@global.tx_isolation = 3; SET @@global.tx_isolation = 'SERIALIZABLE'; #设置会话 SET @@session.tx_isolation = 0; SET @@session.tx_isolation = 'READ-UNCOMMITTED'; SET @@session.tx_isolation = 1; SET @@session.tx_isolation = 'READ-COMMITTED'; SET @@session.tx_isolation = 2; SET @@session.tx_isolation = 'REPEATABLE-READ'; SET @@session.tx_isolation = 3; SET @@session.tx_isolation = 'SERIALIZABLE'; mysql查看/设置自动提交 //查看自动提交是否开启，默认开启 #方法一 mysql> select @@autocommit; +--------------+ | @@autocommit | +--------------+ | 1 | +--------------+ 1 row in set (0.07 sec) #方法二 mysql> show variables like 'autocommit'; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | autocommit | ON | +---------------+-------+ 1 row in set (0.09 sec) //关闭自动提交 mysql> set autocommit = 0; Query OK, 0 rows affected (0.11 sec) 以下所有示例都基于mysql5.7.22 先创建一张示例表t1 mysql> select version(); +-----------+ | version() | +-----------+ | 5.7.22 | +-----------+ mysql> create table t1(id int(3) primary key,name char(30)); mysql> insert into t1 values(1,'xiaoming'); mysql> select * from t1; +----+----------+ | id | name | +----+----------+ | 1 | xiaoming | +----+----------+ 1 读未提交 Read Uncommitted 含义：一个事务可以读到另一个事务未提交的数据！ 示例： 1.mysql默认的事务隔离级别是RR 可用值2来设置 mysql> SELECT @@global.tx_isolation, @@tx_isolation; +-----------------------+-----------------+ | @@global.tx_isolation | @@tx_isolation | +-----------------------+-----------------+ | REPEATABLE-READ | REPEATABLE-READ | +-----------------------+-----------------+ 1 row in set, 2 warnings (0.00 sec) 2.手动修改当前会话为RU mysql> SET @@session.tx_isolation = 0; Query OK, 0 rows affected, 1 warning (0.12 sec) mysql> SELECT @@tx_isolation; +------------------+ | @@tx_isolation | +------------------+ | READ-UNCOMMITTED | +------------------+ 1 row in set, 1 warning (0.04 sec) 3.关闭自动提交 mysql> set autocommit = 0; Query OK, 0 rows affected (0.08 sec) 如图所示，一个事务检索的数据被另一个未提交的事务给修改了。 官网对脏读定义的地址 其内容为 dirty read An operation that retrieves unreliable data, data that was updated by another transaction but not yet committed. 翻译过来就是 检索操作出来的数据是不可靠的，是可以被另一个未提交的事务修改的！ 你会发现，我们的演示结果和官网对脏读的定义一致。根据我们最开始的推理，如果存在脏读，那么不可重复读和幻读一定是存在的。 2 读提交 Read Committed 含义：一个事务能读到另一个事务已提交的数据 示例： 1.mysql默认的事务隔离级别是RR 可用值2来设置 mysql> SELECT @@global.tx_isolation, @@tx_isolation; +-----------------------+-----------------+ | @@global.tx_isolation | @@tx_isolation | +-----------------------+-----------------+ | REPEATABLE-READ | REPEATABLE-READ | +-----------------------+-----------------+ 1 row in set, 2 warnings (0.00 sec) 2.手动修改当前会话为RC mysql> SET @@session.tx_isolation = 1; Query OK, 0 rows affected, 1 warning (0.12 sec) mysql> select @@tx_isolation; +----------------+ | @@tx_isolation | +----------------+ | READ-COMMITTED | +----------------+ 1 row in set, 1 warning (0.04 sec) 3.关闭自动提交 mysql> set autocommit = 0; Query OK, 0 rows affected (0.08 sec) 如图所示，一个事务检索的数据只能被另一个已提交的事务修改。 官网对不可重复读定义的地址 其内容为 non-repeatable read The situation when a query retrieves data, and a later query within the same transaction retrieves what should be the same data, but the queries return different results (changed by another transaction committing in the meantime). 翻译过来就是 一个查询语句检索数据，随后又有一个查询语句在同一个事务中检索数据，两个数据应该是一样的，但是实际情况返回了不同的结果。！ ps:作者注，这里的不同结果，指的是在行不变的情况下(专业点说，主键索引没变)，主键索引指向的磁盘上的数据内容变了。如果主键索引变了，比如新增一条数据或者删除一条数据，就不是不可重复读。 显然，我们这个现象符合不可重复读的定义。下面，大家做一个思考: 这个不可重复读的定义，放到脏读的现象里是不是也可以说的通。显然脏读的现象，也就是读未提交(READ_UNCOMMITTED)的那个例子，是不是也符合在同一个事务中返回了不同结果！ 但是反过来就不一定通了，一个事务A中查询两次的结果在被另一个事务B改变的情况下，如果事务B未提交就改变了事务A的结果，就属于脏读，也属于不可重复读。如果该事务B提交了才改变事务A的结果，就不属于脏读，但属于不可重复读。 3 可重复读 Repeatable Read 官网对幻读定义的地址 phantom A row that appears in the result set of a query, but not in the result set of an earlier query. For example, if a query is run twice within a transaction, and in the meantime, another transaction commits after inserting a new row or updating a row so that it matches the WHERE clause of the query. 翻译过来就是 在一次查询的结果集里出现了某一行数据，但是该数据并未出现在更早的查询结果集里。例如，在一次事务里进行了两次查询，同时另一个事务插入某一行或更新某一行数据后(该数据符合查询语句里where后的条件)，并提交了！ 幻读(Phantom Read)说明 原因：事务A根据相同条件第二次查询，虽然查询不到事务B提交的新增数据，但是会影响事务A之后的一些操作，比如：事务A进行了一次select * from t1表查询，查询出id为1的数据，同时事务B进行了一次insert into t1 values(2,'xx')，也就是此时表中有了id为2的数据，但是在事务A中再次进行查询的时候，根本就查不到id为2的数据，但是当事务A进行insert into t1 values(2,'xx')，也想插入id为2的数据的时候，发现报错了，但是事务A怎么查也查不到有id为2的数据，这就让事务A的使用者出现了幻觉，what happend！。如果不想出现幻读问题，那么自己在查询语句中手动加锁 for update，如果查询的是id为2的数据，即便是现在没有id为2的数据，其他事务也无法对id为2的索引位置进行数据的处理。 含义：同一事务的多个实例在并发读取数据时，会看到同样的数据行 示例： 1.mysql默认的事务隔离级别是RR 可用值2来设置 mysql> SELECT @@global.tx_isolation, @@tx_isolation; +-----------------------+-----------------+ | @@global.tx_isolation | @@tx_isolation | +-----------------------+-----------------+ | REPEATABLE-READ | REPEATABLE-READ | +-----------------------+-----------------+ 1 row in set, 2 warnings (0.00 sec) 显然，该现象是符合幻读的定义的。即同一事务的两次相同查询出现不同行。 官网对解决幻读方法的地址 原文内容如下 By default, InnoDB operates in REPEATABLE READ transaction isolation level. In this case, InnoDB uses next-key locks for searches and index scans, which prevents phantom rows (see Section 14.7.4, “Phantom Rows”). 翻译过来就是 InnoDB默认用了REPEATABLE READ。在这种情况下，使用next-key locks解决幻读问题！ 以下两步均在session2中执行，正确结果是id为1的数据name已经改为abc 不加next-key locks是快照读，根本不能解决幻读问题 mysql> select * from t1; +----+----------+ | id | name | +----+----------+ | 1 | xiaoming | | 2 | hehe | +----+----------+ 2 rows in set (0.09 sec) 加上next-key locks就能解决幻读问题 mysql> select * from t1 lock in share mode; +----+------+ | id | name | +----+------+ | 1 | abc | | 2 | hehe | +----+------+ 2 rows in set (0.05 sec) 4 串行化 Serializable Read 在该隔离级别下，所有的select语句后都自动加上lock in share mode。因此，在该隔离级别下，无论你如何进行查询，都会使用next-key locks。所有的select操作均为当前读! 含义：强制事务排序，使之不可能相互冲突 示例： 1.mysql默认的事务隔离级别是RR 可用值2来设置 mysql> SELECT @@global.tx_isolation, @@tx_isolation; +-----------------------+-----------------+ | @@global.tx_isolation | @@tx_isolation | +-----------------------+-----------------+ | REPEATABLE-READ | REPEATABLE-READ | +-----------------------+-----------------+ 1 row in set, 2 warnings (0.00 sec) 2.手动修改当前会话为串行读 mysql> SET @@session.tx_isolation = 3; Query OK, 0 rows affected, 1 warning (0.12 sec) mysql> select @@tx_isolation; +----------------+ | @@tx_isolation | +----------------+ | READ-COMMITTED | +----------------+ 1 row in set, 1 warning (0.04 sec) 3.关闭自动提交 mysql> set autocommit = 0; Query OK, 0 rows affected (0.08 sec) OK,注意看上表红色部分！就是因为使用了next-key locks,innodb将PiD=1这条索引记录，和(1,++∞)这个间隙锁住了。其他事务要在这个间隙上插数据，就会阻塞，从而防止幻读发生! 有的人会说，你这第二次查询的结果，也变了啊，明显和第一次查询结果不一样啊？但是这是被自己的事务改的，不是被其他事物修改的。这不算是幻读，也不是不可重复读。 脏读、不可重复度、幻读 根据事务的隔离级别不同，会有三种情况发生，即脏读、不可重复度、幻读，这三种情况有如下包含关系 对上图解释 如果发生了脏读，那么不可重复读和幻读是一定发生的。因为拿脏读的现象，用不可重复读，幻读的定义也能解释的通。但是反过来，拿不可重复读的现象，用脏读的定义就不一定解释的通了！ mysql事务隔离级别对应的现象 隔离级别 对应值 脏读 不可重复读 幻读 READ-UNCOMMITTED（读未提交） 0 √ √ √ READ-COMMITTED（读提交） 1 × √ √ REPEATABLE-READ（可重复读） 2 × × √ SERIALIZABLE （可串行化） 3 × × × 脏读 定义 官网对脏读定义的地址 其内容为 dirty read An operation that retrieves unreliable data, data that was updated by another transaction but not yet committed. 翻译过来就是 检索操作出来的数据是不可靠的，是可以被另一个未提交的事务修改的！ 根据我们最开始的推理，如果存在脏读，那么不可重复读和幻读一定是存在的。 示例 新建一张表，并且隔离级别设置为读未提交 READ-UNCOMMITTED 1.新建表t1 mysql> create table t1(id int primary key,name char(30),money double); Query OK, 0 rows affected (0.01 sec) 2.插入数据 mysql> insert into t1 values(1,'xiaoming',100); Query OK, 1 row affected (0.00 sec) 3.设置当前会话事务隔离级别为读未提交 READ-UNCOMMITTED mysql> SET @@session.tx_isolation = 'READ-UNCOMMITTED'; Query OK, 0 rows affected, 1 warning (0.00 sec) 4.查看事务隔离级别 global是全局 session是会话 mysql> SELECT @@global.tx_isolation, @@tx_isolation; +-----------------------+------------------+ | @@global.tx_isolation | @@tx_isolation | +-----------------------+------------------+ | REPEATABLE-READ | READ-UNCOMMITTED | +-----------------------+------------------+ 1 row in set, 2 warnings (0.00 sec) 5.关闭自动提交 mysql> set @@autocommit = 0; Query OK, 0 rows affected (0.00 sec) 6.查看自动提交是否关闭，1为开启，0为关闭 mysql> select @@autocommit; +--------------+ | @@autocommit | +--------------+ | 0 | +--------------+ 1 row in set (0.00 sec) 脏读定义 检索操作出来的数据是不可靠的，是可以被另一个未提交的事务修改的！ 上图中的示例session2中查询的数据是不可靠的，被未提交的事物session1修改了，这就是脏读 举个例子描述一下这个过程，财务(session1)给小明(session2)发了100元工资，然后小明查询自己的账户，果然是多了100元，变成了200元，但是财务发现操作有误，选择了事务回滚，这个时候当小明再查询自己账户的时候，发现账户变成了100元 不可重复读 定义 官网对不可重复读定义的地址 其内容为 non-repeatable read The situation when a query retrieves data, and a later query within the same transaction retrieves what should be the same data, but the queries return different results (changed by another transaction committing in the meantime). 翻译过来就是 一个查询语句检索数据，随后又有一个查询语句在同一个事务中检索数据，两个数据应该是一样的，但是实际情况返回了不同的结果。！ ps:作者注，这里的不同结果，指的是在行不变的情况下(专业点说，主键索引没变)，主键索引指向的磁盘上的数据内容变了。如果主键索引变了，比如新增一条数据或者删除一条数据，就不是不可重复读。 显然，我们这个现象符合不可重复读的定义。下面，大家做一个思考: 这个不可重复读的定义，放到脏读的现象里是不是也可以说的通。显然脏读的现象，也就是读未提交(READ_UNCOMMITTED)的那个例子，是不是也符合在同一个事务中返回了不同结果！ 但是反过来就不一定通了，一个事务A中查询两次的结果在被另一个事务B改变的情况下，如果事务B未提交就改变了事务A的结果，就属于脏读，也属于不可重复读。如果该事务B提交了才改变事务A的结果，就不属于脏读，但属于不可重复读。 示例-读提交 新建一张表，并且隔离级别设置为读提交 READ-COMMITTED 1.新建表t1 mysql> create table t1(id int primary key,name char(30),money double); Query OK, 0 rows affected (0.01 sec) 2.插入数据 mysql> insert into t1 values(1,'xiaoming',100); Query OK, 1 row affected (0.00 sec) 3.设置当前会话事务隔离级别为读提交 READ-COMMITTED mysql> SET @@session.tx_isolation = 'READ-COMMITTED'; Query OK, 0 rows affected, 1 warning (0.00 sec) 4.查看事务隔离级别 global是全局 session是会话 mysql> SELECT @@global.tx_isolation, @@tx_isolation; +-----------------------+----------------+ | @@global.tx_isolation | @@tx_isolation | +-----------------------+----------------+ | REPEATABLE-READ | READ-COMMITTED | +-----------------------+----------------+ 1 row in set, 2 warnings (0.00 sec) 5.关闭自动提交 mysql> set @@autocommit = 0; Query OK, 0 rows affected (0.00 sec) 6.查看自动提交是否关闭，1为开启，0为关闭 mysql> select @@autocommit; +--------------+ | @@autocommit | +--------------+ | 0 | +--------------+ 1 row in set (0.00 sec) 不可重复读是指在事务1内，读取了一个数据，事务1还没有结束时，事务2也访问了这个数据，修改了这个数据，并提交。紧接着，事务1又读这个数据。由于事务2的修改，那么事务1两次读到的的数据可能是不一样的，因此称为是不可重复读。 示例-可重复读 新建一张表，并且隔离级别设置为可重复读 REPEATABLE-READ 1.新建表t1 mysql> create table t1(id int primary key,name char(30),money double); Query OK, 0 rows affected (0.01 sec) 2.插入数据 mysql> insert into t1 values(1,'xiaoming',100); Query OK, 1 row affected (0.00 sec) 3.设置当前会话事务隔离级别为可重复读 REPEATABLE-READ mysql> SET @@session.tx_isolation = 'REPEATABLE-READ'; Query OK, 0 rows affected, 1 warning (0.00 sec) 4.查看事务隔离级别 global是全局 session是会话 mysql> SELECT @@global.tx_isolation, @@tx_isolation; +-----------------------+-----------------+ | @@global.tx_isolation | @@tx_isolation | +-----------------------+-----------------+ | REPEATABLE-READ | REPEATABLE-READ | +-----------------------+-----------------+ 1 row in set, 2 warnings (0.00 sec) 5.关闭自动提交 mysql> set @@autocommit = 0; Query OK, 0 rows affected (0.00 sec) 6.查看自动提交是否关闭，1为开启，0为关闭 mysql> select @@autocommit; +--------------+ | @@autocommit | +--------------+ | 0 | +--------------+ 1 row in set (0.00 sec) 上述示例说明当我们将当前会话的隔离级别设置为可重复读的时候，当前会话可以重复读，就是每次读取的结果集都相同，而不管其他事务有没有提交。 当session1 commit的时候，才能看到最终的正确结果，这会产生幻读 幻读 定义 官网对幻读定义的地址 phantom A row that appears in the result set of a query, but not in the result set of an earlier query. For example, if a query is run twice within a transaction, and in the meantime, another transaction commits after inserting a new row or updating a row so that it matches the WHERE clause of the query. 翻译过来就是 在一次查询的结果集里出现了某一行数据，但是该数据并未出现在更早的查询结果集里。例如，在一次事务里进行了两次查询，同时另一个事务插入某一行或更新某一行数据后(该数据符合查询语句里where后的条件)，并提交了！ 大白话说明一下 所谓幻读，指的是当某个事务在读取某个范围内的记录时，另外一个事务又在该范围内插入了新的记录，当之前的事务再次读取该范围的记录时，会产生幻读 就是事务1查询id 幻读(Phantom Read)原因 原因：事务A根据相同条件第二次查询，虽然查询不到事务B提交的新增数据，但是会影响事务A之后的一些操作，比如：事务A进行了一次select * from t1表查询，查询出id为1的数据，同时事务B进行了一次insert into t1 values(2,'xx')，也就是此时表中有了id为2的数据，但是在事务A中再次进行查询的时候，根本就查不到id为2的数据，但是当事务A进行insert into t1 values(2,'xx')，也想插入id为2的数据的时候，发现报错了，但是事务A怎么查也查不到有id为2的数据，这就让事务A的使用者出现了幻觉，what happend！。如果不想出现幻读问题，那么自己在查询语句中手动加锁 for update，如果查询的是id为2的数据，即便是现在没有id为2的数据，其他事务也无法对id为2的索引位置进行数据的处理。 官网对解决幻读方法的地址 原文内容如下 By default, InnoDB operates in REPEATABLE READ transaction isolation level. In this case, InnoDB uses next-key locks for searches and index scans, which prevents phantom rows (see Section 14.7.4, “Phantom Rows”). 翻译过来就是 InnoDB默认用了REPEATABLE READ。在这种情况下，使用next-key locks解决幻读问题！ 示例 新建一张表，并且隔离级别设置为可重复读 REPEATABLE-READ 1.新建表t1 mysql> create table t1(id int primary key,name char(30),money double); Query OK, 0 rows affected (0.01 sec) 2.插入数据 mysql> insert into t1 values(1,'xiaoming',100); Query OK, 1 row affected (0.00 sec) 3.设置当前会话事务隔离级别为可重复读 REPEATABLE-READ mysql> SET @@session.tx_isolation = 'REPEATABLE-READ'; Query OK, 0 rows affected, 1 warning (0.00 sec) 4.查看事务隔离级别 global是全局 session是会话 mysql> SELECT @@global.tx_isolation, @@tx_isolation; +-----------------------+-----------------+ | @@global.tx_isolation | @@tx_isolation | +-----------------------+-----------------+ | REPEATABLE-READ | REPEATABLE-READ | +-----------------------+-----------------+ 1 row in set, 2 warnings (0.00 sec) 5.关闭自动提交 mysql> set @@autocommit = 0; Query OK, 0 rows affected (0.00 sec) 6.查看自动提交是否关闭，1为开启，0为关闭 mysql> select @@autocommit; +--------------+ | @@autocommit | +--------------+ | 0 | +--------------+ 1 row in set (0.00 sec) 不加next-key locks是快照读，根本不能解决幻读问题 mysql> select * from t1; +----+----------+-------+ | id | name | money | +----+----------+-------+ | 1 | xiaoming | 100 | +----+----------+-------+ 1 row in set (0.00 sec) 加上next-key locks就能解决幻读问题 mysql> select * from t1 lock in share mode; +----+----------+-------+ | id | name | money | +----+----------+-------+ | 1 | xiaoming | 100 | | 2 | dahong | 500 | +----+----------+-------+ 2 rows in set (0.00 sec) mysql> select * from t1 for update; +----+----------+-------+ | id | name | money | +----+----------+-------+ | 1 | xiaoming | 100 | | 2 | dahong | 500 | +----+----------+-------+ 2 rows in set (0.00 sec) 很多人容易搞混不可重复读和幻读，确实这两者有些相似。但不可重复读重点在于update和delete，而幻读的重点在于insert。 总的来说幻读就是事务A对数据进行操作，事务B还是可以用insert插入数据的，因为使用的是行锁，这样导致的各种奇葩问题就是幻读 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/redis/1.CentOS7.5安装redis-5.0.7.html":{"url":"db/redis/1.CentOS7.5安装redis-5.0.7.html","title":"redis安装","keywords":"","body":"CentOS7.5安装redis-5.0.7 redis官网 官网下载地址 一、下载redis wget http://download.redis.io/releases/redis-5.0.7.tar.gz 二、编译安装redis //将下载的redis包解压到/usr/local tar xf redis-5.0.7.tar.gz -C /usr/local //进入解压后的redis目录进行编译安装 cd /usr/local/redis-5.0.7 make //添加环境变量 cat >/etc/profile.d/redis.sh 三、配置redis //创建redis工作目录 mkdir -p /etc/redis/6379 mkdir -p /var/log/redis/6379 mkdir -p /var/run/redis/6379 //创建redis配置文件 cat >/etc/redis/6379/redis.conf 四、使用systemd管理redis ⚠️#使用redis二进制命令启动redis /usr/local/redis-5.0.7/src/redis-server & //编辑文件 cat >/usr/lib/systemd/system/redis.service 这边并没有使用 ExecStop=/bin/kill -s QUIT $MAINPID 这样的命令来停止redis, 因为使用这个语句在运行systemctl stop redis后, redis并未执行关闭动作, 而是直接退出. 这时候用 systemctl status redis 查看状态是failed. 只有用ExecStop=/install_path/bin/redis-cli -p 16379 shutdown 才能正确停止redis 五、使用systemd管理redis遇到的问题 问题一：重载系统服务后启动redis卡住不动 解决方法 注释/usr/lib/systemd/system/redis.serviceType=forking一项 网上解释原因 If set to forking, it is expected that the process configured with ExecStart= will call fork() as part of its start-up. The parent process is expected to exit when start-up is complete and all communication channels are set up. The child continues to run as the main daemon process. This is the behavior of traditional UNIX daemons. If this setting is used, it is recommended to also use the PIDFile= option, so that systemd can identify the main process of the daemon. systemd will proceed with starting follow-up units as soon as the parent process exits. 如果设置为fork，则使用ExecStart=配置的进程将调用fork()作为启动的一部分。启动完成并设置好所有通信通道后，父进程将退出。子进程继续作为主守护进程运行。这是传统UNIX守护进程的行为。如果使用了该设置，建议还使用PIDFile=选项，以便systemd能够识别守护进程的主进程。一旦父进程退出，systemd将开始启动后续单元。 问题二：pid原先路径为/var/run/redis_6379.pid，报错Failed at step EXEC spawning /usr/local/redis-5.0.7/src: Permission denied 解决方法： 将pid路径改为/var/run/redis/redis_6379.pid就可以了，原因未知 六、redis安全配置 protected-mode 保护模式，是否只允许本地访问，默认是yes protected-mode no bind 指定IP进行监听 bind 127.0.0.1 requirepass 增加密码 requirepass 1 #连接方式1 $ redis-cli 127.0.0.1:6379> set name xiaoming (error) NOAUTH Authentication required. 127.0.0.1:6379> AUTH 1 OK 127.0.0.1:6379> set name xiaoming OK #连接方式2 $ redis-cli -a 1 Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe. 127.0.0.1:6379> set name xiaoliang OK 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/redis/redis持久化.html":{"url":"db/redis/redis持久化.html","title":"redis持久化","keywords":"","body":"redis持久化 一、什么是持久化？ 持久化：就是将内存中的数据，写入到磁盘上，并且永久存在 二、redis持久化类型 RDB AOF RDB和AOF对比 定义对比 优缺点对比 工作方式对比 2.1RDB持久化 2.1.1 RDB持久化介绍 可以在指定的时间间隔内生成数据集的时间点快照（point-in-time snapshot） 2.1.2 RDB持久化优点 RDB是一种表示某个即时点的Redis数据的紧凑文件。RDB文件适合用于备份。例如，你可能想要每小时归档最近24小时的RDB文件，每天保存近30天的RDB快照。这允许你很容易的恢复不同版本的数据集以容灾 RDB非常适合于灾难恢复，作为一个紧凑的单一文件，可以被传输到远程的数据中心 RDB最大化了Redis的性能，因为Redis父进程持久化时唯一需要做的是启动(fork)一个子进程，由子进程完成所有剩余工作。父进程实例不需要执行像磁盘IO这样的操作 RDB在重启保存了大数据集的实例时比AOF要快 2.1.3 RDB持久化缺点 当你需要在Redis停止工作(例如停电)时最小化数据丢失，RDB可能不太好。你可以配置不同的保存点(save point)来保存RDB文件(例如，至少5分钟和对数据集100次写之后，但是你可以有多个保存点)。然而，你通常每隔5分钟或更久创建一个RDB快照，所以一旦Redis因为任何原因没有正确关闭而停止工作，你就得做好最近几分钟数据丢失的准备了 RDB需要经常调用fork()子进程来持久化到磁盘。如果数据集很大的话，fork()比较耗时，结果就是，当数据集非常大并且CPU性能不够强大的话，Redis会停止服务客户端几毫秒甚至一秒。AOF也需要fork()，但是你可以调整多久频率重写日志而不会有损(trade-off)持久性(durability) 2.1.4 RDB持久化优缺点总结 优点：速度快，适合于用作备份，主从复制也是基于RDB持久化功能实现的 缺点：会有数据丢失、导致服务停止几秒 2.1.5 RDB持久化配置参数 RDB持久化核心配置参数 #持久化数据文件存储位置 dir /etc/redis/6379 #rdb持久化数据文件名 dbfilename dump.rdb #900秒（15分钟）内有1个更改 save 900 1 #300秒（5分钟）内有10个更改 save 300 10 #60秒（1分钟）内有10000个更改 save 60 10000 配置RDB持久化 ⚠️save这里这是做演示，还是要根据实际使用情况进行修改，例如我们线上主流的配置是 7200 10 1.编辑配置文件 cat > /etc/redis/6379/redis.conf SHUTDOWN not connected> #指定配置文件启动 redis-server /etc/redis/6379/redis.conf 3.写入数据 #连接redis，如果设置了密码，使用-a参数 redis-cli 127.0.0.1:6379> set a 1 OK 127.0.0.1:6379> set b 2 OK 4.手动保存RDB持久化 127.0.0.1:6379> BGSAVE Background saving started 5.查看RDB持久化文件 dump.rdb就是RDB持久化文件 $ ll total 16 -rw-r--r-- 1 root root 92 Dec 10 19:31 dump.rdb -rw-r--r-- 1 root root 410 Dec 10 19:22 redis.conf -rw-r--r-- 1 root root 4314 Dec 10 19:31 redis.log 2.2AOF持久化 2.2.1 AOF持久化介绍 AOF（append only file）只追加文件，记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。 AOF 文件中的命令全部以 Redis 协议的格式来保存，新命令会被追加到文件的末尾 AOF持久化原理 2.2.2 AOF持久化优点 使用AOF Redis会更具有可持久性(durable)：你可以有很多不同的fsync策略：没有fsync，每秒fsync，每次请求时fsync。使用默认的每秒fsync策略，写性能也仍然很不错(fsync是由后台线程完成的，主线程继续努力地执行写请求)，即便你也就仅仅只损失一秒钟的写数据 AOF日志是一个追加文件，所以不需要定位，在断电时也没有损坏问题。即使由于某种原因文件末尾是一个写到一半的命令(磁盘满或者其他原因),redis-check-aof工具也可以很轻易的修复 当AOF文件变得很大时，Redis会自动在后台进行重写。重写是绝对安全的，因为Redis继续往旧的文件中追加，使用创建当前数据集所需的最小操作集合来创建一个全新的文件，一旦第二个文件创建完毕，Redis就会切换这两个文件，并开始往新文件追加 AOF文件里面包含一个接一个的操作，以易于理解和解析的格式存储。你也可以轻易的导出一个AOF文件。例如，即使你不小心错误地使用FLUSHALL命令清空一切，如果此时并没有执行重写，你仍然可以保存你的数据集，你只要停止服务器，删除最后一条命令，然后重启Redis就可以 2.2.3 AOF持久化缺点 对同样的数据集，AOF文件通常要大于等价的RDB文件 AOF可能比RDB慢，这取决于准确的fsync策略。通常fsync设置为每秒一次的话性能仍然很高，如果关闭fsync，即使在很高的负载下也和RDB一样的快。不过，即使在很大的写负载情况下，RDB还是能提供能好的最大延迟保证 在过去，我们经历了一些针对特殊命令(例如，像BRPOPLPUSH这样的阻塞命令)的罕见bug，导致在数据加载时无法恢复到保存时的样子。这些bug很罕见，我们也在测试套件中进行了测试，自动随机创造复杂的数据集，然后加载它们以检查一切是否正常，但是，这类bug几乎不可能出现在RDB持久化中。为了说得更清楚一点：Redis AOF是通过递增地更新一个已经存在的状态，像MySQL或者MongoDB一样，而RDB快照是一次又一次地从头开始创造一切，概念上更健壮。但是，要注意Redis每次重写AOF时都是以当前数据集中的真实数据从头开始，相对于一直追加的AOF文件(或者一次重写读取老的AOF文件而不是读内存中的数据)对bug的免疫力更强。我们还没有收到一份用户在真实世界中检测到崩溃的报告 2.2.4 AOF持久化优缺点总结 优点：可以最大程度保证数据不丢失 缺点：日志记录量级比较大 2.2.5 AOF持久化配置参数 AOF持久化核心配置参数 #是否打开AOF日志功能 appendonly yes/no 以下三种方法只能同时打开一种 #每一条命令都立即同步到AOF appendfsync always #每秒写一次 appendfsync everysec #写入工作交给操作系统,由操作系统判断缓冲区大小,统一写入到AOF appendfsync no 配置AOF持久化 1.编辑配置文件 cat >/etc/redis/6379/redis.conf SHUTDOWN not connected> #指定配置文件启动 redis-server /etc/redis/6379/redis.conf 3.写入数据 #连接redis，如果设置了密码，使用-a参数 redis-cli 127.0.0.1:6379> set name hehe OK 4.查看AOF文件 appendonly.aof就是AOF持久化日志文件 $ ll /etc/redis/6379/ total 20 -rw-r--r-- 1 root root 56 Dec 10 19:49 appendonly.aof -rw-r--r-- 1 root root 92 Dec 10 19:49 dump.rdb -rw-r--r-- 1 root root 182 Dec 10 19:49 redis.conf -rw-r--r-- 1 root root 6358 Dec 10 19:49 redis.log 5.AOF文件内容 $ cat /etc/redis/6379/appendonly.aof *2 $6 SELECT $1 0 *3 $3 set $4 name $4 hehe *3 $3 set $4 test $4 test 三、如何选择RDB和AOF 1.一般来说,如果想达到足以媲美 PostgreSQL 的数据安全性， 你应该同时使用两种持久化功能 2.如果你非常关心你的数据,但仍然可以承受数分钟以内的数据丢失， 那么你可以只使用 RDB 持久化 3.有很多用户单独使用AOF，但是我们并不鼓励这样，因为时常进行RDB快照非常方便于数据库备份，启动速度也较之快，还避免了AOF引擎的bug 4.在企业中，通常都使用RDB来做持久化，因为一般redis是在做MySQL的缓存，就算缓存数据丢失，真实的数据还是在MySQL中，之所以用缓存是为了速度，性能而考虑，所以还是建议使用RDB持久化，相对来说会好一些，除非专门用redis来做一个key:value的数据库，而且数据很重要，那么可以考虑使用AOF 注意：基于这些原因，将来我们可能会统一AOF和RDB为一种单一的持久化模型(长远计划) RDB和AOF持久化对比 四、RDB与AOF工作方式 4.1 RDB 4.1.1 RDB快照工作方式 1.默认情况下，Redis保存数据集快照到磁盘，名为dump.rdb的二进制文件。你可以设置让Redis在N秒内至少有M次数据集改动时保存数据集，或者你也可以手动调用SAVE或者BGSAVE命令 2.在上文中我们已经在配置文件中做过对应的配置： 例如，这个配置会让Redis在每个60秒内至少有1000次键改动时自动转储数据集到磁盘： save 60 1000 3.当 Redis 需要保存 dump.rdb 文件时，服务器执行以下操作： Redis 调用 fork() ，同时拥有父进程和子进程 子进程将数据集写入到一个临时的 RDB 文件中。当子进程完成对新 RDB 文件的写入时， Redis 用新RDB 文件替换原来的 RDB 文件，并删除旧的 RDB 文件 4.这种方式使得 Redis 可以从写时复制机制中获益 RDB是先将数据集写入到一个临时文件，当临时文件全部写完时，再覆盖dump.rdb文件 4.1.2 RDB持久化方式 save、bgsave、自动化 save 该命令会阻塞当前Redis服务器，执行save命令期间，Redis不能处理其他命令，直到RDB过程完成为止。具体流程如下： bgsave 执行该命令时，Redis会在后台异步进行快照操作，快照同时还可以响应客户端请求。具体流程如下： 自动化 自动触发是由我们的配置文件来完成的。在redis.conf配置文件中，里面有如下配置，我们可以去设置： ①save：这里是用来配置触发 Redis的 RDB 持久化条件，也就是什么时候将内存中的数据保存到硬盘。比如save m n。表示m秒内数据集存在n次修改时，自动触发bgsave。 默认如下配置： save 900 1 表示900 秒内如果至少有 1 个 key 的值变化，则保存save 900 1 save 300 10 表示300 秒内如果至少有 10 个 key 的值变化，则保存save 300 10 save 60 10000 表示60 秒内如果至少有 10000 个 key 的值变化，则保存save 60 10000 不需要持久化，那么你可以注释掉所有的 save 行来停用保存功能。 ②stop-writes-on-bgsave-error ：默认值为yes。当启用了RDB且最后一次后台保存数据失败，Redis是否停止接收数据。这会让用户意识到数据没有正确持久化到磁盘上，否则没有人会注意到灾难（disaster）发生了。如果Redis重启了，那么又可以重新开始接收数据了 ③rdbcompression ；默认值是yes。对于存储到磁盘中的快照，可以设置是否进行压缩存储。 ④rdbchecksum ：默认值是yes。在存储快照后，我们还可以让redis使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。 ⑤dbfilename ：设置快照的文件名，默认是 dump.rdb ⑥dir：设置快照文件的存放路径，这个配置项一定是个目录，而不能是文件名。 save于bgsave对比 4.2 AOF 4.2.1 AOF重写功能 1.因为 AOF 的运作方式是不断地将命令追加到文件的末尾，所以随着写入命令的不断增加， AOF 文件的体积也变得越来越大。举个例子，如果你对一个计数器调用了 100 次 INCR ，那么仅仅是为了保存这个计数器的当前值， AOF 文件就需要使用 100 条记录。然而在实际上，只使用一条 SET 命令已经足以保存计数器的当前值了，其余 99 条记录实际上都是多余的 2.为了处理这种情况， Redis 支持一种有趣的特性：可以在不断服务客户端的情况下，对 AOF 文件进行重建。执行 BGREWRITEAOF 命令， Redis 将生产一个新的 AOF 文件，这个文件包含重建当前数据集所需的最少命令 AOF重写原理 4.2.2 AOF有多持久 你可以配置 Redis 多久才将数据 fsync 到磁盘一次。 有三个选项： always：每次有新命令追加到 AOF 文件时就执行一次 fsync ：非常慢，也非常安全。 everysec：每秒 fsync 一次：足够快（和使用 RDB 持久化差不多，）并且在故障时只会丢失1秒钟的数据。 no：从不 fsync，将数据交给操作系统来处理。更快，也更不安全的选择。 推荐（并且也是默认）的措施为每秒 fsync 一次，这种 fsync 策略可以兼顾速度和安全性。 总之fsync 的策略在实际使用中非常慢，即使在 Redis2.0 对相关的程序进行了改进之后仍是如此。频繁调用 fsync 注定了这种策略不可能快得起来。 4.2.3 AOF文件出错解决方法 服务器可能在程序正在对AOF文件进行写入时停机，如果停机造成了AOF文件出错，那么 Redis 在重启时会拒绝载入这个 AOF 文件，从而确保数据的一致性不会被破坏 当发生 AOF 文件出错时，可以用以下方法来修复出错的 AOF 文件： 1.为现有的 AOF 文件创建一个备份 2.使用 Redis 附带的 redis-check-aof 程序，对原来的AOF文件进行修复。redis-check-aof --fix 3.使用 diff -u 对比修复后的 AOF 文件和原始 AOF 文件的备份，查看两个文件之间的不同之处 4.重启 Redis 服务器，等待服务器载入修复后的 AOF 文件，并进行数据恢复 4.3 RDB和AOF之间的相互作用 在版本号大于等于 2.4 的 Redis 中， BGSAVE 执行的过程中，不可以执行 BGREWRITEAOF 。 反过来说，在 BGREWRITEAOF 执行的过程中，也不可以执行 BGSAVE 这可以防止两个 Redis 后台进程同时对磁盘进行大量的 I/O 操作。如果 BGSAVE 正在执行，并且用户显示地调用 BGREWRITEAOF 命令，那么服务器将向用户回复一个 OK 状态，并告知用户， BGREWRITEAOF 已经被预定执行； 一旦 BGSAVE 执行完毕， BGREWRITEAOF 就会正式开始 当 Redis 启动时，如果 RDB 持久化和 AOF 持久化都被打开了，那么程序会优先使用 AOF 文件来恢复数据集，因为 AOF 文件所保存的数据通常是最完整的 五、redis备份 5.1 备份策略 1.Redis 对于数据备份是非常友好的，因为你可以在服务器运行的时候对 RDB 文件进行复制： RDB 文件一旦被创建，就不会进行任何修改 2.当服务器要创建一个新的 RDB 文件时，它先将文件的内容保存在一个临时文件里面，当临时文件写入完毕时，程序才使用临时文件替换原来的 RDB 文件 3.这也就是说，无论何时， 复制 RDB 文件都是绝对安全的 以下是我们的建议： 创建一个定期任务（cron job）， 每小时将一个 RDB 文件备份到一个文件夹， 并且每天将一个 RDB 文件备份到另一个文件夹 确保快照的备份都带有相应的日期和时间信息， 每次执行定期任务脚本时， 使用 find 命令来删除过期的快照： 比如说， 你可以保留最近 48 小时内的每小时快照， 还可以保留最近一两个月的每日快照 至少每天一次， 将 RDB 备份到你的数据中心之外， 或者至少是备份到你运行 Redis 服务器的物理机器之外 5.2 redis备份、恢复 redis持久化就是redis备份 将备份文件 (dump.rdb) 移动到 redis 安装目录并启动服务即可，使用CONFIG GET dir命令获取redis目录 六、redis持久化高级配置 RDB持久化高级配置 #后台备份进程出错时,主进程停不停止写入? 主进程不停止容易造成数据不一致 stop-writes-on-bgsave-error yes #导出的rdb文件是否压缩 如果rdb的大小很大的话建议这么做 rdbcompression yes #导入rbd恢复数据时,要不要检验rdb的完整性 验证版本是不是一致 rdbchecksum yes AOF持久化高级配置 #正在导出rdb快照的过程中,要不要停止同步aof no-appendfsync-on-rewrite yes/no #aof文件大小比起上次重写时的大小,增长率100%时重写,缺点:业务开始的时候，会重复重写多次 auto-aof-rewrite-percentage 100 #aof文件,至少超过64M时,重写 auto-aof-rewrite-min-size 64mb 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/redis/redis命令.html":{"url":"db/redis/redis命令.html","title":"redis命令","keywords":"","body":"redis命令 redis命令官方文档 ⚠️ keys * 命令不要在生产环境中使用！！！ 这里仅仅是为了实验使用这个命令 redis-cli 语法 redis-cli 选项 -h 指定连接的redis服务端IP地址，不写默认本机 -p 指定端口 -a 指定密码 示例 redis没有配置密码 $ redis-cli 127.0.0.1:6379> redis配置了密码 redis-cli -h 127.0.0.1 -p 6379 -a \"mypass\" redis设置密码 #方法一 配置文件 在redis的配置文件中写入以下一行即为设置redis密码 requirepass password #方法二 命令行设置密码，如果需要取消密码则设置为空即可 CONFIG set requirepass \"password\" 命令行设置redis密码后通过redis-cli命令进入redis就需要输入auth命令进行验证 redis-server 示例：指定配置文件启动redis redis-server /etc/redis/6379/redis.conf keys命令 del key 含义：该命令用于在key存在时删除 key 示例： 127.0.0.1:6379> get str \"6abc\" 127.0.0.1:6379> DEL str (integer) 1 127.0.0.1:6379> get str (nil) dump key 含义：序列化key，并返回被序列化的值 示例： 127.0.0.1:6379> GET str \"abc\" 127.0.0.1:6379> DUMP str \"\\x00\\x03abc\\a\\x00&\\x9e\\xe5\\xceI\\xb8w\\xf8\" exists key 含义：检查指定key是否存在，存在返回1，不存在返回0 示例： 127.0.0.1:6379> EXISTS str (integer) 1 127.0.0.1:6379> EXISTS str1 (integer) 0 expire key seconds 含义：为给定key设置过期时间，以秒为单位 示例： 127.0.0.1:6379> GET str \"abc\" 127.0.0.1:6379> EXPIRE str 5 (integer) 1 127.0.0.1:6379> GET str \"abc\" 127.0.0.1:6379> GET str \"abc\" 127.0.0.1:6379> GET str (nil) expireat key timestamp 含义：EXPIREAT 的作用和 EXPIRE 类似，都用于为key设置过期时间。 不同在于 EXPIREAT 命令接受的时间参数是 UNIX 时间戳(unix timestamp) 示例： 127.0.0.1:6379> EXPIREAT str 1688666880 (integer) 0 1688666880是unix时间戳秒，对应的时间是 2023/7/7 2:8:0 pexpire key milliseconds 含义：设置key的过期时间以毫秒计 示例： 127.0.0.1:6379> PEXPIRE str 3000 (integer) 1 127.0.0.1:6379> GET str \"abc\" 127.0.0.1:6379> GET str (nil) pexpireat key milliseconds-timestamp 含义：设置key过期时间的时间戳(unix timestamp) 以毫秒计 示例： 127.0.0.1:6379> PEXPIREAT str 1655555555005 (integer) 1 1655555555005是unix时间戳毫秒，对应的时间是 2022/6/18 20:32:35 keys pattern 含义：查找所有符合给定模式( pattern)的 key 示例： 127.0.0.1:6379> SET str1 aaa OK 127.0.0.1:6379> SET str2 bbb OK 127.0.0.1:6379> SET str3 ccc OK #查找以str开头的key 127.0.0.1:6379> KEYS str* 1) \"str1\" 2) \"str3\" 3) \"str2\" move key db 含义：将当前数据库的key移动到给定的数据库db当中 示例： ⚠️当从一个数据库移动一个不存在的key到另一个数据库时会失败 ⚠️当两个数据库存在相同的key时，则无法移动 #redis默认使用数据库0，这里再显示指定一次 127.0.0.1:6379> SELECT 0 OK 127.0.0.1:6379> SET str aaa OK #把str移动到数据库1 127.0.0.1:6379> MOVE str 1 (integer) 1 #在数据库0检查str是否存在，返回0表示不存在 127.0.0.1:6379> EXISTS str (integer) 0 #切换到库1，然后检查str是否存在 127.0.0.1:6379> SELECT 1 OK 127.0.0.1:6379[1]> EXISTS str (integer) 1 persist key 含义：移除key的过期时间，key将持久保持 示例： #设置过期时间为10秒 127.0.0.1:6379> EXPIRE str 10 (integer) 1 #取消过期时间，返回值为1表示取消成功 127.0.0.1:6379> PERSIST str (integer) 1 pttl key 含义：以毫秒为单位返回key的剩余的过期时间 示例： #设置过期时间 127.0.0.1:6379> EXPIRE str 10 (integer) 1 #返回结果为还有7109毫秒过期 127.0.0.1:6379> PTTL str (integer) 7109 ttl key 含义：以秒为单位，返回给定 key 的剩余生存时间(TTL, time to live) 示例： 127.0.0.1:6379> EXPIRE str 10 (integer) 1 127.0.0.1:6379> TTL str (integer) 8 randomkey 含义：从当前数据库中随机返回一个 key 示例： 127.0.0.1:6379> MSET str1 a str2 b str3 c OK 127.0.0.1:6379> RANDOMKEY \"str1\" 127.0.0.1:6379> RANDOMKEY \"str2\" 127.0.0.1:6379> RANDOMKEY \"str1\" 127.0.0.1:6379> RANDOMKEY \"str2\" 127.0.0.1:6379> RANDOMKEY \"str1\" 127.0.0.1:6379> RANDOMKEY \"str1\" 127.0.0.1:6379> RANDOMKEY \"str3\" pename key newkey 含义：修改key的名称 示例： 127.0.0.1:6379> GET str \"aaa\" 127.0.0.1:6379> RENAME str str1 OK 127.0.0.1:6379> KEYS * 1) \"str1\" renamenx key newkey 含义：仅当newkey不存在时，将key改名为newkey 示例： 127.0.0.1:6379> KEYS * 1) \"str2\" 127.0.0.1:6379> RENAMENX str2 str3 (integer) 1 127.0.0.1:6379> KEYS * 1) \"str3\" type key 含义：返回key所存储值的类型 示例： 127.0.0.1:6379> type str3 string 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/redis/redis危险命令.html":{"url":"db/redis/redis危险命令.html","title":"redis危险命令","keywords":"","body":"redis危险命令 keys * 虽然其模糊匹配功能使用非常方便也很强大，在小数据量情况下使用没什么问题，数据量大会导致 Redis 锁住及 CPU 飙升，在生产环境建议禁用或者重命名！ flushdb 删除Redis中当前所在数据库中的所有记录，并且该命令是原子性的，不会终止执行，一旦执行，将不会执行失败。 flushall 删除Redis中所有数据库中的所有记录，并且该命令是原子性的，不会终止执行，一旦执行，将不会执行失败。 config 修改redis配置命令，一般在redis配置文件中做配置 禁用redis危险命令 编辑redis配置文件，引号中内容为空则为禁用命令，有内容则为给命令起别名 rename-command KEYS \"\" rename-command FLUSHALL \"\" rename-command FLUSHDB \"\" rename-command CONFIG \"\" 示例 #禁用keys * 127.0.0.1:6379> KEYS * (error) ERR unknown command 'KEYS' #使用命令别名，keys命令别名设置为了hehe 127.0.0.1:6379> hehe * 1) \"str2\" 2) \"str1\" 3) \"str3\" 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/redis/redis数据类型/1.redis数据类型-string字符串.html":{"url":"db/redis/redis数据类型/1.redis数据类型-string字符串.html","title":"string 字符串","keywords":"","body":"redis数据类型 string 字符串 redis命令官方文档 string(字符串) 简介： 字符串 可以存储的值： 字符串，整数或者浮点数，还有jpg图片或者序列化对象 操作： 对整个字符串或者字符串的其中一部分执行操作，对整数和浮点数执行自增或者自减操作 应用场景： 做简单的键值对缓存 使用示例： 127.0.0.1:6379> set a 1 OK 127.0.0.1:6379> get a \"1\" 127.0.0.1:6379> del a (integer) 1 127.0.0.1:6379> get a (nil) redis字符串常用命令 set key value 含义：设置指定key的值 示例： 127.0.0.1:6379> SET str a OK get key 含义：获取指定key的值 示例： 127.0.0.1:6379> GET str \"a\" setrange key offset value 含义：用value参数覆写给定key所储存的字符串值，从偏移量offset开始 示例： 127.0.0.1:6379> GET str \"abc\" 127.0.0.1:6379> SETRANGE str 1 123 (integer) 4 127.0.0.1:6379> GET str \"a123\" getrange key start end 含义：返回key中字符串值的子字符 示例： 127.0.0.1:6379> GET str \"abcdef\" 127.0.0.1:6379> GETRANGE str 0 3 \"abcd\" getset key value 含义：将给定key的值设为value ，并返回key的旧值(old value) 示例： 127.0.0.1:6379> GET str \"abcdef\" 127.0.0.1:6379> GETSET str 123 \"abcdef\" 127.0.0.1:6379> GET str \"123\" getbit key offset 含义：对key所储存的字符串值，获取指定偏移量上的位(bit) 示例： 127.0.0.1:6379> GET str \"abcd\" 127.0.0.1:6379> GETBIT str 0 (integer) 0 127.0.0.1:6379> GETBIT str 1 (integer) 1 127.0.0.1:6379> GETBIT str 2 (integer) 1 127.0.0.1:6379> GETBIT str 3 (integer) 0 setbit key offset value 含义：对key所储存的字符串值，设置或清除指定偏移量上的位(bit) 示例： 27.0.0.1:6379> GET str \"abcd\" 127.0.0.1:6379> GETBIT str 0 (integer) 0 127.0.0.1:6379> GETBIT str 1 (integer) 1 127.0.0.1:6379> GETBIT str 2 (integer) 1 127.0.0.1:6379> GETBIT str 3 (integer) 0 127.0.0.1:6379> SETBIT str 0 1 (integer) 0 127.0.0.1:6379> GETBIT str 0 (integer) 1 mset key value [key value] 含义：同时设置一个或多个key-value对 示例： 127.0.0.1:6379> MSET str1 aaa str2 bbb OK mget key1 [key2] 含义：获取所有(一个或多个)给定key的值 示例： 127.0.0.1:6379> MGET str1 str2 1) \"a\" 2) \"b\" setex key seconds value 含义：将值value关联到key ，并将key的过期时间设为seconds (以秒为单位) 示例： 127.0.0.1:6379> SETEX str 10 abc OK #10秒后str的值失效 127.0.0.1:6379> GEt str (nil) setnx key value 含义：只有在key不存在时设置key的值 示例： 127.0.0.1:6379> GET str \"abc\" 127.0.0.1:6379> SETNX str 123 (integer) 0 127.0.0.1:6379> GET str \"abc\" 127.0.0.1:6379> SETNX str2 123 (integer) 1 127.0.0.1:6379> GET str2 \"123\" msetnx key value [key value] 含义：同时设置一个或多个key-value对，当且仅当所有给定key都不存在，如果key存在则不改变 示例： 127.0.0.1:6379> MSETNX str5 5 str6 6 (integer) 1 127.0.0.1:6379> MGET str5 str6 1) \"5\" 2) \"6\" psetex key milliseconds value 含义：这个命令和 SETEX 命令相似，但它以毫秒为单位设置key的生存时间，而不是像 SETEX 命令那样，以秒为单位 示例： 127.0.0.1:6379> PSETEX str 3000 a123 OK #str 3000毫秒(3秒)后失效 127.0.0.1:6379> GET str (nil) incr key 含义：将key中储存的数字值增一 示例： 127.0.0.1:6379> GET str \"10\" 127.0.0.1:6379> INCR str (integer) 11 127.0.0.1:6379> GET str \"11\" incrby key increment 含义：将key所储存的值加上给定的增量值（increment） 示例： 127.0.0.1:6379> GET str \"11\" 127.0.0.1:6379> INCRBY str 2 (integer) 13 127.0.0.1:6379> GET str \"13\" incrbyfloat key increment 含义：将key所储存的值加上给定的浮点增量值（increment） 示例： 127.0.0.1:6379> GET str \"13\" 127.0.0.1:6379> INCRBYFLOAT str 0.5 \"13.5\" 127.0.0.1:6379> GET str \"13.5\" decr key 含义：将key中储存的数字值减一 示例： 127.0.0.1:6379> GET str \"10\" 127.0.0.1:6379> DECR str (integer) 9 127.0.0.1:6379> GET str \"9\" decrby key decrement 含义：key所储存的值减去给定的减量值（decrement） 示例： 127.0.0.1:6379> GET str \"9\" 127.0.0.1:6379> DECRBY str 3 (integer) 6 127.0.0.1:6379> GET str \"6\" append key value 含义：如果key已经存在并且是一个字符串， APPEND 命令将指定的value追加到该key原来值（value）的末尾 示例： 127.0.0.1:6379> GET str \"6\" 127.0.0.1:6379> APPEND str abc (integer) 4 127.0.0.1:6379> GET str \"6abc\" strlen key 含义：返回key所储存的字符串值的长度 示例： 127.0.0.1:6379> GET str \"6abc\" 127.0.0.1:6379> STRLEN str (integer) 4 在生产环境中使用``keys *`` 这个命令之后会有意想不到的结果 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/redis/redis数据类型/2.redis数据类型-list列表.html":{"url":"db/redis/redis数据类型/2.redis数据类型-list列表.html","title":"list 列表","keywords":"","body":"redis数据类型 list 列表 list(列表) 简介： 链表（双向链表） 可以存储的值： 列表 操作： 从两端压入或者弹出元素，对单个或者多个元素进行修改，只保留一个范围内的元素 应用场景：最新消息排行；消息队列 范围：一个列表最多可以包含 2^32 - 1 个元素 (4294967295, 每个列表超过40亿个元素) 使用示例： 127.0.0.1:6379> LPUSH test a (integer) 1 127.0.0.1:6379> LPUSH test b (integer) 2 127.0.0.1:6379> LPUSH test c (integer) 3 127.0.0.1:6379> LRANGE test 0 -1 1) \"c\" 2) \"b\" 3) \"a\" 127.0.0.1:6379> LPOP test \"c\" redis列表常用命令 lpush/rpush key value1 [value2] 含义：从左/从右向列表中添加一个或多个值 示例： lpush 从左边开始插入值，先插入的值在后边 127.0.0.1:6379> LPUSH lst a (integer) 1 127.0.0.1:6379> LPUSH lst b (integer) 2 127.0.0.1:6379> LPUSH lst c (integer) 3 127.0.0.1:6379> LRANGE lst 0 -1 1) \"c\" 2) \"b\" 3) \"a\" rpush 从右边开始插入值，先插入的值在前边 127.0.0.1:6379> RPUSH l a (integer) 1 127.0.0.1:6379> RPUSH l b (integer) 2 127.0.0.1:6379> RPUSH l c (integer) 3 127.0.0.1:6379> LRANGE l 0 -1 1) \"a\" 2) \"b\" 3) \"c\" blpop key1 [key2] timeout 含义：移出并获取列表的第一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止 示例： 127.0.0.1:6379> LPUSH lst a b c (integer) 3 127.0.0.1:6379> BLPOP lst 3 1) \"lst\" 2) \"c\" brpoplpush source destination timeout 含义：从列表中弹出一个值，将弹出的元素插入到另外一个列表中并返回它； 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止 示例： #从列表lst中弹出一个值插入到lst1中，并且返回lst中的这个值 127.0.0.1:6379> BRPOPLPUSH lst lst1 3 \"a\" #弹出lst1中的值 127.0.0.1:6379> LPOP lst1 \"a\" 127.0.0.1:6379> LPOP lst1 (nil) lindex key index 含义：通过索引获取列表中的元素 示例： 127.0.0.1:6379> LPUSH lst a b c (integer) 3 127.0.0.1:6379> LINDEX lst 0 \"c\" linsert key befor|after pivot value 含义：在列表的元素前或者后插入元素 示例： #向列表lst中插入3个值，因为是lpush，所以第一个元素是c 127.0.0.1:6379> LPUSH lst a b c (integer) 3 #在元素c之前插入d 127.0.0.1:6379> LINSERT lst before c d (integer) 4 #原先c是第一个元素，现在第一个元素是d 127.0.0.1:6379> LINDEX lst 0 \"d\" llen key 含义：获取列表长度 示例： 127.0.0.1:6379> LLEN lst (integer) 4 lpop key 含义：移出并获取列表的第一个元素 示例： 127.0.0.1:6379> RPUSH lst a b c d e f (integer) 6 127.0.0.1:6379> LPOP lst \"a\" rpop key 含义：移除列表的最后一个元素，返回值为移除的元素 示例： 127.0.0.1:6379> RPUSH lst a b c d e f (integer) 6 127.0.0.1:6379> RPOP lst \"f\" lpush key value1 [value2] 含义：将一个或多个值插入到列表头部 示例： 127.0.0.1:6379> LPUSH lst aaa bbb (integer) 5 lpushx key value 含义：将一个值插入到已存在的列表头部 示例： 127.0.0.1:6379> LPUSHX lst 123 (integer) 6 #插入一个不存在的列表，返回值为0 127.0.0.1:6379> LPUSHX lst1 123 (integer) 0 lrange key start stop 含义：获取列表指定范围内的元素，下标从0开始 示例： 127.0.0.1:6379> LRANGE lst 1 3 1) \"bbb\" 2) \"aaa\" 3) \"c\" 127.0.0.1:6379> LRANGE lst 0 3 1) \"123\" 2) \"bbb\" 3) \"aaa\" 4) \"c\" lrem key count value 含义：移除列表元素 count的值 count > 0 : 从表头开始向表尾搜索，移除与 VALUE 相等的元素，数量为 COUNT 。 count count = 0 : 移除表中所有与 VALUE 相等的值。 示例： #rpush插入元素，因此元素从左往右为a b c a b c 127.0.0.1:6379> RPUSH lst a b c a b c (integer) 6 #从表头开始向表尾搜索，移除2个与a相等的元素，所以列表中剩下的元素是b c b c 127.0.0.1:6379> LREM lst 2 a (integer) 2 127.0.0.1:6379> LRANGE lst 0 -1 1) \"b\" 2) \"c\" 3) \"b\" 4) \"c\" lset key index value 含义：通过索引设置列表元素的值 示例： 127.0.0.1:6379> RPUSH lst a b c a b c (integer) 6 127.0.0.1:6379> LSET lst 0 hehe OK 127.0.0.1:6379> LRANGE lst 0 -1 1) \"hehe\" 2) \"b\" 3) \"c\" 4) \"a\" 5) \"b\" 6) \"c\" ltrim key start stop 含义：对一个列表进行修剪(trim)，就是说，让列表只保留指定区间内的元素，不在指定区间之内的元素都将被删除 示例： #插入元素 127.0.0.1:6379> RPUSH lst a b c d e f (integer) 6 #保留从下标1开始到结尾，即把下标为0的第一个元素删除 127.0.0.1:6379> LTRIM lst 1 -1 OK #下标为0的元素被删除 127.0.0.1:6379> LRANGE lst 0 -1 1) \"b\" 2) \"c\" 3) \"d\" 4) \"e\" 5) \"f\" RPOPLPUSH source destination 含义：移除列表的最后一个元素，并将该元素添加到另一个列表并返回 示例： 127.0.0.1:6379> RPUSH lst1 aaa (integer) 1 127.0.0.1:6379> RPUSH lst2 bbb ccc (integer) 2 127.0.0.1:6379> RPOPLPUSH lst1 lst2 \"aaa\" 127.0.0.1:6379> LRANGE lst2 0 -1 1) \"aaa\" 2) \"bbb\" 3) \"ccc\" rpushx key value 含义：为已存在的列表添加值，每次只能添加一个值 示例： 127.0.0.1:6379> RPUSH lst a b c (integer) 3 127.0.0.1:6379> RPUSHX lst d (integer) 4 127.0.0.1:6379> LRANGE lst 0 -1 1) \"a\" 2) \"b\" 3) \"c\" 4) \"d\" 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/redis/redis数据类型/3.redis数据类型-hash字典.html":{"url":"db/redis/redis数据类型/3.redis数据类型-hash字典.html","title":"hash 字典","keywords":"","body":"redis数据类型 hash 字典 hash(字典) 简介： 键值对集合，即编程语言中的map类型 可以存储的值： 适合存储对象，并且可以像数据库中的update一样，只修改某一项的属性值 操作： 添加、获取、移除单个键值对，获取所有键值对，检查某个键是否存在 应用场景： 存储、读取、修改用户属性 范围：Redis 中每个 hash 可以存储 2^32 - 1 键值对（40多亿） 使用示例: #定义一个哈希man，有名字、年龄、体重描述信息 127.0.0.1:6379> HMSET man name \"xiaoming\" age 18 weight \"60kg\" OK 127.0.0.1:6379> HGETALL man 1) \"name\" 2) \"xiaoming\" 3) \"age\" 4) \"18\" 5) \"weight\" 6) \"60kg\" redis哈希常用命令 hdel key field1 [field2] 含义：删除一个或多个哈希表字段 示例： 127.0.0.1:6379> HMSET man name \"xiaoming\" age 18 weight \"60kg\" OK 127.0.0.1:6379> HGETALL man 1) \"name\" 2) \"xiaoming\" 3) \"age\" 4) \"18\" 5) \"weight\" 6) \"60kg\" #删除哈希中的weight字段 127.0.0.1:6379> HDEL man weight (integer) 1 127.0.0.1:6379> HGETALL man 1) \"name\" 2) \"xiaoming\" 3) \"age\" 4) \"18\" hexists key field 含义：查看哈希表key中，指定的字段是否存在 示例： 127.0.0.1:6379> HMSET man name \"xiaoming\" age 18 weight \"60kg\" OK 127.0.0.1:6379> HEXISTS man name (integer) 1 127.0.0.1:6379> HEXISTS man sex (integer) 0 hget key fidle 含义：获取存储在哈希表中指定字段的值 示例： 127.0.0.1:6379> HMSET man name \"xiaoming\" age 18 weight \"60kg\" OK 127.0.0.1:6379> HGET man name \"xiaoming\" hincrby key fidle increment 含义：为哈希表key中的指定字段的整数值加上增量 increment 示例： 127.0.0.1:6379> HMSET man name \"xiaoming\" age 18 weight \"60kg\" OK 127.0.0.1:6379> HINCRBY man age 2 (integer) 20 127.0.0.1:6379> HGET man age \"20\" hincrbyfloat key field increment 含义：为哈希表key中的指定字段的浮点数值加上增量 increment 示例： 127.0.0.1:6379> HMSET man name \"xiaoming\" age 18 weight \"60kg\" OK 127.0.0.1:6379> HINCRBYFLOAT man age 0.5 \"18.5\" 127.0.0.1:6379> HGET man age \"18.5\" hkeys key 含义：获取所有哈希表中的字段 示例： 127.0.0.1:6379> HMSET man name \"xiaoming\" age 18 weight \"60kg\" OK 127.0.0.1:6379> HKEYS man 1) \"name\" 2) \"age\" 3) \"weight\" hvals key 含义：获取哈希表中所有值 示例： 127.0.0.1:6379> HMSET man name \"xiaoming\" age 18 weight \"60kg\" OK 127.0.0.1:6379> HVALS man 1) \"xiaoming\" 2) \"18\" 3) \"60kg\" hlen key 含义：获取哈希表中字段的数量 示例： 127.0.0.1:6379> HMSET man name \"xiaoming\" age 18 weight \"60kg\" OK 127.0.0.1:6379> HLEN man (integer) 3 hmget key field1 [field2] 含义：获取所有给定字段的值 示例： 127.0.0.1:6379> HMSET man name \"xiaoming\" age 18 weight \"60kg\" OK 127.0.0.1:6379> HMGET man name age 1) \"xiaoming\" 2) \"18\" hmset key field1 value1 [field2 value2] 含义：同时将多个field-value (域-值)对设置到哈希表key中 示例： 127.0.0.1:6379> HMSET man name \"xiaoming\" age 18 weight \"60kg\" OK hset key field value 含义：将哈希表key中的字段field的值设为 value 示例： 127.0.0.1:6379> HSET man name \"xiaoming\" (integer) 1 hsetnx key field value 含义：只有在字段field不存在时，设置哈希表字段的值 示例： 127.0.0.1:6379> HSETNX hehe name \"hehe\" (integer) 1 scan、sscan、hscan、zscan SSCAN 命令、 HSCAN 命令和 ZSCAN 命令的第一个参数总是一个数据库键。 而 SCAN 命令则不需要在第一个参数提供任何数据库键 —— 因为它迭代的是当前数据库中的所有数据库键。 scan cursor [MATCH pattern] [COUNT count] 含义：用于迭代当前数据库中的数据库键 示例： sscan 含义：用于迭代集合键中的元素 示例： hscan 含义：用于迭代哈希键中的键值对 示例： zscan 含义：用于迭代有序集合中的元素（包括元素成员和元素分值） 示例： 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/redis/redis数据类型/4.redis数据类型-set集合.html":{"url":"db/redis/redis数据类型/4.redis数据类型-set集合.html","title":"set 集合","keywords":"","body":"redis数据类型 set 集合 简介： hash表实现，元素不重复 可以存储的值： 无序集合 操作： 添加、获取、移除单个元素，检查一个元素是否已经存在于集合中，计算交集、并集、差集从集合里面随机获取元素 应用场景： 共同好友；利用唯一性，统计访问网站的所有IP 范围：集合中最大的成员数为 2^32 - 1 (4294967295, 每个集合可存储40多亿个成员) 使用示例： 127.0.0.1:6379> SADD s a (integer) 1 127.0.0.1:6379> SADD s b (integer) 1 127.0.0.1:6379> SADD s c (integer) 1 127.0.0.1:6379> SMEMBERS s 1) \"b\" 2) \"c\" 3) \"a\" redis集合常用命令 sadd key member1 [member2] 含义：向集合添加一个或多个成员 示例： 127.0.0.1:6379> SADD s aaa bbb ccc (integer) 3 scard key 含义：获取集合的成员数 示例： 127.0.0.1:6379> SADD s aaa bbb ccc (integer) 3 127.0.0.1:6379> SCARD s (integer) 3 sdiff key1 [key2] 含义：返回给定所有集合的差集，⚠️返回的差集来自第一个key，而不是后边的key 示例： 127.0.0.1:6379> SADD s aaa bbb ccc (integer) 3 127.0.0.1:6379> SADD s1 aaa ccc ddd eee fff (integer) 5 127.0.0.1:6379> SDIFF s s1 1) \"bbb\" #差集结果是bbb，s在s1中有的元素是aaa ccc，没有bbb，因为差集结果来自第一个key，也就是s，即aaa bbb ccc，肯定是这3个元素中的某一个或者多个或者没有 127.0.0.1:6379> SDIFF s s1 1) \"bbb\" sdiffstore destination key1 [key2] 含义：返回给定所有集合的差集并存储在 destination 中 示例： #向集合s1、s2中插入元素 127.0.0.1:6379> SADD s1 aaa bbb ccc (integer) 3 127.0.0.1:6379> SADD s2 aaa ccc ddd (integer) 3 #把s1和s2的差集存储在s3中 127.0.0.1:6379> SDIFFSTORE s3 s1 s2 (integer) 1 127.0.0.1:6379> SMEMBERS s3 1) \"bbb\" sinter key1 [key2] 含义：返回给定所有集合的交集 示例： 127.0.0.1:6379> SADD s1 aaa bbb ccc (integer) 3 127.0.0.1:6379> SADD s2 bbb ddd fff (integer) 3 127.0.0.1:6379> SADD s3 ggg bbb kkk (integer) 3 127.0.0.1:6379> SINTER s1 s2 s3 1) \"bbb\" sinterstore destination key1 含义：返回给定所有集合的交集并存储在 destination 中 示例： 27.0.0.1:6379> SADD s1 aaa bbb ccc (integer) 3 127.0.0.1:6379> SADD s2 bbb ddd fff (integer) 3 127.0.0.1:6379> SADD s3 ggg bbb kkk (integer) 3 127.0.0.1:6379> SINTERSTORE s4 s1 s2 s3 (integer) 1 127.0.0.1:6379> SMEMBERS s4 1) \"bbb\" sismember key member 含义：判断member元素是否是集合 key 的成员 示例： 127.0.0.1:6379> SADD s1 aaa bbb ccc (integer) 3 127.0.0.1:6379> SISMEMBER s1 bbb (integer) 1 127.0.0.1:6379> SISMEMBER s1 ddd (integer) 0 smembers key 含义：返回集合中的所有成员 示例： 127.0.0.1:6379> SADD s1 aaa bbb ccc (integer) 3 127.0.0.1:6379> SMEMBERS s1 1) \"bbb\" 2) \"ccc\" 3) \"aaa\" smove source destination member 含义：将member元素从source集合移动到destination集合 示例： 127.0.0.1:6379> SADD s1 aaa bbb ccc (integer) 3 127.0.0.1:6379> SMOVE s1 s2 bbb (integer) 1 127.0.0.1:6379> SMEMBERS s1 1) \"ccc\" 2) \"aaa\" 127.0.0.1:6379> SMEMBERS s2 1) \"bbb\" spop key 含义：移除并返回集合中的一个随机元素 示例： 127.0.0.1:6379> SADD s1 aaa bbb ccc (integer) 3 127.0.0.1:6379> SPOP s1 \"bbb\" 127.0.0.1:6379> SPOP s1 \"aaa\" 127.0.0.1:6379> SPOP s1 \"ccc\" 127.0.0.1:6379> SPOP s1 (nil) srandmember key [count] 含义：返回集合中一个或多个随机数，count不写默认返回一个 示例： 127.0.0.1:6379> SRANDMEMBER s1 2 1) \"bbb\" 2) \"ccc\" 127.0.0.1:6379> SRANDMEMBER s1 \"bbb\" srem key member1 [member2] 含义：移除集合中一个或多个成员 示例： 127.0.0.1:6379> SADD s1 aaa bbb ccc (integer) 3 127.0.0.1:6379> SREM s1 aaa (integer) 1 127.0.0.1:6379> SMEMBERS s1 1) \"bbb\" 2) \"ccc\" sunion key1 [key2] 含义：返回所有给定集合的并集 示例： 127.0.0.1:6379> SADD s1 aaa bbb ccc (integer) 3 127.0.0.1:6379> SADD s2 ccc ddd eee (integer) 3 127.0.0.1:6379> SUNION s1 s2 1) \"aaa\" 2) \"ccc\" 3) \"bbb\" 4) \"eee\" 5) \"ddd\" sunionstore destination key1 [key2] 含义：所有给定集合的并集存储在destination集合中 示例： 127.0.0.1:6379> SADD s1 aaa bbb ccc (integer) 3 127.0.0.1:6379> SADD s2 ccc ddd eee (integer) 3 127.0.0.1:6379> SUNIONSTORE s3 s1 s2 (integer) 5 127.0.0.1:6379> SMEMBERS s3 1) \"aaa\" 2) \"ccc\" 3) \"bbb\" 4) \"eee\" 5) \"ddd\" SSCAN key cursor [MATCH pattern] [COUNT count 含义：迭代集合中的元素 示例： 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/redis/redis数据类型/5.redis数据类型-zset有序集合.html":{"url":"db/redis/redis数据类型/5.redis数据类型-zset有序集合.html","title":"zset 有序集合","keywords":"","body":"redis数据类型 zset 有序集合 简介： 将 set 中的元素增加一个权重参数score，元素按score有序排列 可以存储的值： 有序集合 操作： 添加、获取、删除元素，根据分值范围或者成员来获取元素，计算一个键的排名 应用场景： 排行榜；带权重的消息队列 范围：集合中最大的成员数为 2^32 - 1 (4294967295, 每个集合可存储40多亿个成员)。 特点：每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。有序集合的成员是唯一的，但分数(score)却可以重复。 使用示例： 127.0.0.1:6379> ZADD z1 1 aaa (integer) 1 127.0.0.1:6379> ZADD z1 2 bbb (integer) 1 127.0.0.1:6379> ZADD z1 3 ccc (integer) 1 127.0.0.1:6379> ZRANGE z1 0 -1 1) \"aaa\" 2) \"bbb\" 3) \"ccc\" redis有序集合常用命令 zadd key score1 member1 含义：向有序集合添加一个或多个成员，或者更新已存在成员的分数 示例： 127.0.0.1:6379> ZADD z1 1 a 2 b 3 c (integer) 3 127.0.0.1:6379> ZRANGE z1 0 -1 1) \"a\" 2) \"b\" 3) \"c\" zcard key 含义：获取有序集合的成员数 示例： 127.0.0.1:6379> ZADD z1 1 a 2 b 3 c (integer) 3 127.0.0.1:6379> ZCARD z1 (integer) 3 zcount key min max 含义：计算在有序集合中指定区间分数的成员数 示例： 127.0.0.1:6379> ZADD z1 1 aaa (integer) 1 127.0.0.1:6379> ZADD z1 1 bbb (integer) 1 127.0.0.1:6379> ZADD z1 2 ccc (integer) 1 127.0.0.1:6379> ZADD z1 3 ddd (integer) 1 127.0.0.1:6379> ZADD z1 4 eee (integer) 1 127.0.0.1:6379> ZCOUNT z1 1 3 (integer) 4 zincrby key increment member 含义：有序集合中对指定成员的分数加上增量 increment 示例： 127.0.0.1:6379> ZADD z1 1 aaa (integer) 1 127.0.0.1:6379> ZINCRBY z1 5 1 \"5\" zinterstore destination numkeys key [key ...] 含义：计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合 key 中 示例： 127.0.0.1:6379> ZADD z1 1 aaa 2 bbb 3 ccc 4 ddd 5 eee 6 fff (integer) 6 127.0.0.1:6379> ZADD z2 1 aaa 2 bbb 3 ccc 5 hhh 6 ttt 9 wwww (integer) 6 #这里必须要指定一下有序集合的个数 127.0.0.1:6379> ZINTERSTORE z3 2 z1 z2 (integer) 3 127.0.0.1:6379> ZRANGE z3 0 -1 1) \"aaa\" 2) \"bbb\" 3) \"ccc\" zlexcount key min max 含义：在有序集合中计算指定字典区间内成员数量 示例： zrange key start stop [WITHSCORES] 含义：通过索引区间返回有序集合指定区间内的成员 示例： 127.0.0.1:6379> ZADD z1 1 a 2 b 3 c (integer) 3 127.0.0.1:6379> ZRANGE z1 0 -1 1) \"a\" 2) \"b\" 3) \"c\" zrangebylex key min max [LIMIT offset count] 含义：通过字典区间返回有序集合的成员 示例： 127.0.0.1:6379> ZADD z1 1 a 2 b 3 c 4 d 5 e 6 f (integer) 6 127.0.0.1:6379> ZRANGEBYLEX z1 [b [e 1) \"b\" 2) \"c\" 3) \"d\" 4) \"e\" zrangebyscore key min max [WITHSCORES] [LIMIT] 含义：通过分数返回有序集合指定区间内的成员 示例： 127.0.0.1:6379> ZADD z1 1 a 2 b 3 c 4 d 5 e 6 f (integer) 6 127.0.0.1:6379> ZRANGEBYSCORE z1 2 5 1) \"b\" 2) \"c\" 3) \"d\" 4) \"e\" zrank key member 含义：返回有序集合中指定成员的索引 示例： 127.0.0.1:6379> ZADD z1 1 a 2 b 3 c 4 d 5 e 6 f (integer) 6 127.0.0.1:6379> ZRANGE z1 0 3 1) \"a\" 2) \"b\" 3) \"c\" 4) \"d\" zrem key member1 [member2 ...] 含义：移除有序集合中的一个或多个成员 示例： 127.0.0.1:6379> ZADD z1 1 a 2 b 3 c 4 d 5 e 6 f (integer) 6 127.0.0.1:6379> ZREM z1 a c (integer) 2 127.0.0.1:6379> ZRANGE z1 0 -1 1) \"b\" 2) \"d\" 3) \"e\" 4) \"f\" zremrangebylex key min max 含义：移除有序集合中给定的字典区间的所有成员 示例： 127.0.0.1:6379> ZADD z1 1 a 2 b 3 c 4 d 5 e 6 f (integer) 6 127.0.0.1:6379> ZREMRANGEBYLEX z1 [c [e (integer) 3 127.0.0.1:6379> ZRANGE z1 0 -1 1) \"a\" 2) \"b\" 3) \"f\" zremrangebyrank key start stop 含义：移除有序集合中给定的排名区间（下标）的所有成员 示例： 127.0.0.1:6379> ZADD z1 1 a 2 b 3 c 4 d 5 e 6 f (integer) 6 127.0.0.1:6379> ZREMRANGEBYRANK z1 0 3 (integer) 4 127.0.0.1:6379> ZRANGE z1 0 -1 1) \"e\" 2) \"f\" zremrangebyscore key min max 含义：移除有序集合中给定的分数区间的所有成员 示例： 127.0.0.1:6379> ZADD z1 1 a 2 b 3 c 4 d 5 e 6 f (integer) 6 127.0.0.1:6379> ZREMRANGEBYSCORE z1 2 5 (integer) 4 127.0.0.1:6379> ZRANGE z1 0 -1 1) \"a\" 2) \"f\" zrevrange key start stop [WITHSCORES] 含义：返回有序集合中指定区间内的成员，通过索引，分数从高到低，索引为0的元素在最后 示例： 127.0.0.1:6379> ZADD z1 1 a 2 b 3 c 4 d 5 e 6 f (integer) 6 #这里的下标也是从0开始，但是下标为0的元素在最后 127.0.0.1:6379> ZREVRANGE z1 1 3 1) \"e\" 2) \"d\" 3) \"c\" 127.0.0.1:6379> ZREVRANGE z1 0 1 1) \"f\" 2) \"e\" zrevrangebyscore key max min [WITHSCORES] 含义：返回有序集中指定分数区间内的成员，分数从高到低排序 示例： 127.0.0.1:6379> ZADD z1 1 a 2 b 3 c 4 d 5 e 6 f (integer) 6 127.0.0.1:6379> ZREVRANGEBYSCORE z1 3 1 1) \"c\" 2) \"b\" 3) \"a\" zrevrank key member 含义：返回有序集合中指定成员的排名，有序集成员按分数值递减(从大到小)排序 示例： 127.0.0.1:6379> ZADD z1 1 a 2 b 3 c 4 d 5 e 6 f (integer) 6 127.0.0.1:6379> ZREVRANK z1 c (integer) 3 zscore key member 含义：返回有序集中，成员的分数值 示例： 127.0.0.1:6379> ZADD z1 1 a 2 b 3 c 4 d 5 e 6 f (integer) 6 127.0.0.1:6379> ZSCORE z1 f \"6\" zunionstore destination numkeys key1 [key2 ...] 含义：计算给定的一个或多个有序集的并集，并存储在新的 key 中 示例： 127.0.0.1:6379> ZADD z1 1 aaa 2 bbb 3 ccc (integer) 3 127.0.0.1:6379> ZADD z2 1 aaa 2 ttt 3 vvv (integer) 3 127.0.0.1:6379> ZUNIONSTORE z3 2 z1 z2 (integer) 5 127.0.0.1:6379> ZRANGE z3 0 -1 1) \"aaa\" 2) \"bbb\" 3) \"ttt\" 4) \"ccc\" 5) \"vvv\" zscan key cursor [MATCH pattern] [COUNT count] 含义：迭代有序集合中的元素（包括元素成员和元素分值） 示例： 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"db/mongodb/centos7安装mongodb.html":{"url":"db/mongodb/centos7安装mongodb.html","title":"centos7安装mongodb","keywords":"","body":"centos7安装mongodb mongodb官网 mongodb官方文档 mongodb社区版官方下载地址 mongodb github地址 一、yum安装 1.1 添加清华yum源 cat > /etc/yum.repos.d/mongodb.repo yum makecache 1.2 安装社区版mongodb 安装最新版 yum -y install mongodb-org 安装指定版本 yum -y install mongodb-org-4.2.8 mongodb-org-server-4.2.8 mongodb-org-shell-4.2.8 mongodb-org-mongos-4.2.8 mongodb-org-tools-4.2.8 1.3 启动mongodb systemctl enable mongod && systemctl start mongod mongodb监听tcp/27017 $ netstat -ntpl|grep 27017 tcp 0 0 127.0.0.1:27017 0.0.0.0:* LISTEN 17976/mongod mongodb默认以mongod用运行 $ ps aux|grep [m]ongo mongod 17976 0.6 7.8 1552904 78904 ? Sl 22:04 0:00 /usr/bin/mongod -f /etc/mongod.conf 1.4 mongodb相关目录文件 mongodb配置文件/etc/mongod.conf mongodb日志文件/var/log/mongodb/mongod.log mongodb PID文件/run/mongodb/mongod.pid mongodb SOCKET文件/tmp/mongodb-27017.sock mongodb数据目录/var/lib/mongo/ 二、二进制安装 mongodb4.2二进制安装官方文档 2.1 安装依赖包 yum -y install libcurl openssl 2.2 下载二进制包 wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-4.2.8.tgz 2.3 解压缩包 tar xf mongodb-linux-x86_64-rhel70-4.2.8.tgz -C /usr/local/ 2.4 做软连接 ln -s /usr/local/mongodb-linux-x86_64-rhel70-4.2.8/ /usr/local/mongodb-4.2.8 2.5 导出PATH环境变量 echo 'export PATH=/usr/local/mongodb-4.2.8/bin:$PATH' >/etc/profile.d/mongodb.sh && source /etc/profile 2.6 创建相关目录 #创建数据、日志、pid、配置文件目录 mkdir -p /data/db/mongodb/{data,log,pid,conf} 2.7 创建mongod用户 useradd mongod -s /sbin/nologin -M 2.8 编辑mongodb配置文件 cat > /data/db/mongodb/conf/mongod.conf 2.9 设置目录所有者为mongod chown -R mongod:mongod /data/db/mongodb 2.10 使用supervisor管理mongodb cat >/etc/supervisor/config.d/mongodb.ini $ supervisorctl update mongodb mongodb: added process group 2.11 查看mongodb运行状态 查看mongodb进程 $ ps aux|grep [m]ongodb mongod 30352 1.5 2.2 1550840 89140 ? Sl 20:18 0:00 /usr/local/mongodb-4.2.8/bin/mongod -f /data/db/mongodb/conf/mongod.conf mongodb监听TCP/27010端口 $ netstat -ntpl|grep mongod tcp 0 0 10.0.0.31:27010 0.0.0.0:* LISTEN 30352/mongod 2.12 连接mongodb $ mongo 10.0.0.31:27010 MongoDB shell version v4.2.8 connecting to: mongodb://10.0.0.31:27010/test?compressors=disabled&gssapiServiceName=mongodb Implicit session: session { \"id\" : UUID(\"f87cbfff-d5b5-4f72-b378-15547f61fdca\") } MongoDB server version: 4.2.8 Server has startup warnings: 2020-07-01T20:18:05.560+0800 I CONTROL [initandlisten] 2020-07-01T20:18:05.560+0800 I CONTROL [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/enabled is 'always'. 2020-07-01T20:18:05.560+0800 I CONTROL [initandlisten] ** We suggest setting it to 'never' 2020-07-01T20:18:05.560+0800 I CONTROL [initandlisten] 2020-07-01T20:18:05.560+0800 I CONTROL [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/defrag is 'always'. 2020-07-01T20:18:05.560+0800 I CONTROL [initandlisten] ** We suggest setting it to 'never' 2020-07-01T20:18:05.560+0800 I CONTROL [initandlisten] --- Enable MongoDB's free cloud-based monitoring service, which will then receive and display metrics about your deployment (disk utilization, CPU, operation statistics, etc). The monitoring data will be available on a MongoDB website with a unique URL accessible to you and anyone you share the URL with. MongoDB may use this information to make product improvements and to suggest MongoDB products and deployment options to you. To enable free monitoring, run the following command: db.enableFreeMonitoring() To permanently disable this reminder, run the following command: db.disableFreeMonitoring() --- > show databases admin 0.000GB config 0.000GB local 0.000GB 生产环境配置 bind_ip = 172.20.1.40 logpath = /data/db/mongodb/logs/mongod.log logappend = true pidfilepath = /data/db/mongodb/pid/mongod.pid dbpath = /data/db/mongodb/data storageEngine = wiredTiger directoryperdb = true #replSet = replset #rest = true oplogSize = 61440 #fork = true auth = false shardsvr = true port = 27010 journal = true maxConns = 30000 master = true #slave = true #source = 10.31.133.145:27010 #source = 10.47.125.99:27010 autoresync=true 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/shell/1.shell简介.html":{"url":"linux/shell/1.shell简介.html","title":"shell简介","keywords":"","body":"shell简介 一、什么是shell Shell 是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁。Shell 既是一种命令语言，又是一种程序设计语言。 Shell 是指一种应用程序，这个应用程序提供了一个界面，用户通过这个界面访问操作系统内核的服务。 Ken Thompson 的 sh 是第一种 Unix Shell，Windows Explorer 是一个典型的图形界面Shell。 kernel：为软件服务，接收用户或软件指令驱动硬件，完成工作 shell：命令解释器 user：用户接口，对接用户 上图可以看出，shell在操作系统中起到了承接用户和系统内核的作用。那为什么不直接用户对内核呢？ 原因很简单，因为内核处理的都是二进制，而用户处理的都是高级语言。 Shell 脚本 Shell 脚本（shell script），是一种为 shell 编写的脚本程序。 业界所说的 shell 通常都是指 shell 脚本，但是shell 和 shell script 是两个不同的概念。 Shell 环境 Shell 编程跟 JavaScript、php 编程一样，只要有一个能编写代码的文本编辑器和一个能解释执行的脚本解释器就可以了。 Linux 的 Shell 种类众多，常见的有： Bourne Shell（/usr/bin/sh或/bin/sh） Bourne Again Shell（/bin/bash） C Shell（/usr/bin/csh） K Shell（/usr/bin/ksh） Shell for Root（/sbin/sh） …… 在一般情况下，人们并不区分 Bourne Shell 和 Bourne Again Shell，所以，像 #!/bin/sh，它同样也可以改为 #!/bin/bash。 #! 是告诉系统其后路径所指定的程序即是解释此脚本文件的 Shell 程序。 二、shell分类 2.1 交互分类 2.1.1 交互式shell 交互式：顾名思义就是 shell 与用户存在交互， 用户登录后，在终端上输入命令，shell 立即执行用户提交的命令。 当用户退出后，shell 也终止了。 2.1.2 非交互式shell 非交互式：即 shell 与用户不存在交互，而是以 shell script 的方式执行的。 shell 读取存放在文件中的命令, 并且执行它们，类似如下 cat > test.sh 2.2 登陆分类 2.2.1 登陆式shell 登录 shell 是指需要用户名、密码登录后进入的 shell，或者通过 --login 选项生成的 shell su - username 2.2.2 非登陆式shell 非登录式 shell 是指不需要输入用户名和密码即可打开的 shell，比如输入命令 bash或者sh 就能进入一个全新的非登录 shell 图形终端下打开的命令窗口 自动执行的shell脚本 su username 2.2.3 区分登陆式shell和非登陆式shell 区分方法一 可以通过查看 $0 的值，登录式 shell 返回 -bash，而非登录式 shell 返回的是 bash #通过终端输入用户名和密码登录的登陆式shell $ echo $0 -bash #通过su username登陆的非登陆式shell $ su www $ echo $0 bash 区分方法二 执行exit命令和logout命令 执行 exit 命令， 退出的 shell 可以是登录式shell 或者 非登录式 shell ； 执行 logout 命令，则只能退出登录式 shell，不能退出非登录式 shell 执行exit命令 #通过终端输入用户名和密码登录的登陆式shell $ exit 登出 Connection to 10.0.0.10 closed. #通过su username登陆的非登陆式shell $ su www [www@test1 root]$ exit exit 执行logout命令 #通过终端输入用户名和密码登录的登陆式shell $ logout Connection to 10.0.0.10 closed. #通过su username登陆的非登陆式shell $ logout bash: logout: 不是登录shell: 使用 `exit' 三、shell的配置文件 登录式shell 读取配置 文件过程： /etc/profile –> /etc/profile.d/*.sh –> ~ /.bash_profile –> ~ /bashrc –> /etc/bashrc 非登录式shell 读取配置 文件过程： ~ /.bashrc –> /etc/bashrc –> /etc/prodile.d/*.sh 3.1 bash的配置文件 全局配置文件 /etc/profile /etc/profile.d/* /etc/bashrc 个人配置文件 ~/.bash_profile ~/.bashrc profile类文件作用 1.设定环境变量 2.运行命令或脚本（登录时运行的脚本） bashrc类文件配置作用 1.设定本地变量 2.定义命令别名 3.2 各shell读取配置文件过程 3.2.1 bash 1、交互式的登录shell （bash –il test.sh） 载入的信息： /etc/profile ~/.bash_profile（ -> ~/.bashrc -> /etc/bashrc） ~/.bash_login ~/.profile 2、非交互式的登录shell （bash –l test.sh） 载入的信息： /etc/profile ~/.bash_profile （ -> ~/.bashrc -> /etc/bashrc） ~/.bash_login ~/.profile $BASH_ENV 3、交互式的非登录shell （bash –i test.sh） 载入的信息： ~/.bashrc （ -> /etc/bashrc） 4、非交互式的非登录shell （bash test.sh） 载入的信息： $BASH_ENV 3.2.2 sh 1、交互式的登录shell （sh –il test.sh） 载入的信息： /etc/profile ~/.profile 2、非交互式的登录shell （sh –l test.sh） 载入的信息： /etc/profile ~/.profile 3、交互式的非登录shell （sh –i test.sh） 载入的信息： $ENV 4、非交互式的非登录shell （sh test.sh） 载入的信息： nothing 综上可知， 交互/非交互/登录/非登录，这四种 shell 主要区别在于：是否载入相关配置文件！ 这些配置的载入与否，导致了 Linux 很多默认选项的差异。 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/shell/2.1shell变量综述.html":{"url":"linux/shell/2.1shell变量综述.html","title":"shell变量综述","keywords":"","body":"shell变量综述 一、shell变量分类 环境变量（全局变量） 可以在当前shell及子shell中使用 本地变量（局部变量） 只能在子shell中使用 二、shell查看变量 set 输出所有的变量，包括环境变量和本地变量 env 只显示全局变量 declare 输出所有的变量、函数、整数和已经导出的变量 三、设置环境变量 3.1设置临时性环境变量 export 变量名=value 变量名=value;export 变量名 declare -x 变量名=value 3.2 设置永久性环境变量 写入/etc/profile中 然后使用source命令生效 3.3 取消变量 unset 变量名 四、环境变量生效顺序 /etc/profile ~/.bashrc_profile ~/.bashrc /etc/bashrc 五、shell特殊位置环境变量 变量 含义 $0 脚本名称 $n 位置变量，n代表数字，超过10要用{}括起来 $# 参数个数 $*、$@ 列出参数 $? 上一个命令的执行结果返回值 $() 表示先执行里边的内容 ${} \"金庸新著\" 和 \"金庸新\"著 用于区分变量 $! 获取上一个脚本的PID $_ 获取上一个脚本的最后一个参数 $- 显示shell使用的当前选项，与set命令功能相同 $0 当前脚本的文件名，如果执行脚本包含了路径，那么就包括脚本路径 #编辑脚本内容 $ cat >a.sh $n 位置变量，获取当前执行的脚本的第n个参数，n=1..9,如果n大于9，用大括号括起来${10} #编辑脚本内容 $ cat > b.sh $# 获取当前执行脚本后接的参数总个数 #编辑脚本内容 $ cat > c.sh $*和¥@ 列出所有参数 $* 以\"参数1 参数2 参数3 ...\"的形式列出所有参数 $@ 以\"参数1\" \"参数2\" \"参数3\"的形式列出所有参数 不加引号时，$*和$@输出一样 #$* $ set -- a b c $ for i in $*;do echo $i;done a b c #$@ $ set -- a b c $ for i in $@;do echo $i;done a b c 加入引号时，$*和$@输出不一样 #$* $ set -- a b c $ for i in \"$*\";do echo $i;done a b c #$@ $ set -- a b c $ for i in \"$@\";do echo $i;done a b c $? 上一个命令的执行结果返回值 常见返回值 #命令错误，返回值127 $ lp -bash: lp: 未找到命令 $ echo $? 127 #参数不正确或者文件目录不存在 $ ls -e ls：无效选项 -- e Try 'ls --help' for more information. $ echo $? 2 #权限拒绝，不是目录或文件等等 $ touch /opt/txt touch: cannot touch ‘/opt/txt’: Permission denied $ echo $? 1 #命令正确执行 $ ls $ echo $? 0 $() 表示先执行里边的内容 $()等同于`` #脚本中想要把一个命令的输出复值给一个变量 $ ip=$(ip a s eth0|awk -F'[ /]'+ 'NR==3{print $3}') $ echo $ip 10.0.0.10 ${} \"金庸新著\" 和 \"金庸新\"著 用于区分变量 #想要输出你好a，但是因为没有加{}，所以aa就成了最终的变量，但是变量名是a $ a='你好' $ echo $aa 输出内容为空 #用{}解决以上问题 $ a='你好' $ echo ${a}a 你好a $! 获取最后运行的后台进程的PID ⚠️必须是后台进程 #下载nginx官方的一张图片 $ nohup wget nginx.org/nginx.png & $ echo $! 1065 $_ 获取上一个脚本的最后一个参数 #编辑脚本内容 $ cat > b.sh $- 显示shell使用的当前选项，与set命令功能相同 #shell默认选项是himBH $ echo $- himBH # $ set -x ++ printf '\\033]0;%s@%s:%s\\007' root test1 '~' $ echo $- + echo himxBH himxBH ++ printf '\\033]0;%s@%s:%s\\007' root test1 '~' shell默认选项himBH，每个字母都代表了一个 shell 选项 h - hashall i - interactive-comments m - monitor B - braceexpand H- history ⚠️⚠️⚠️注意这里的 \"设置-\" 和 \"取消+\" 是反人类的：设置用 -，关闭反而是用 + h - hashall bash 的 hash 功能，可以实现让某些 command 和 具体路径 绑定在一起 查看默认选项 $ echo $- himBH $ hash -p /tmp/aaadate date $ hash -l |grep aaadate builtin hash -p /tmp/aaadate date #此时再执行命令date，会发现原先的/usr/bin/date变成了/tmpaaadate $ date -bash: /tmp/aaadate: No such file or directory #执行set +h +h表示去掉h，也就是imBH 命令不能和具体路径绑定，因此date命令能正确执行 $ set +h $ echo $- imBH $ date 2020年 06月 24日 星期三 00:26:50 CST #加上h 命令可以和具体路径绑定 $ set -h $ echo $- himBH $ date -bash: /tmp/aaadate: 没有那个文件或目录 #恢复 $ hash -d date $ date 2020年 06月 24日 星期三 00:29:14 CST i - interactive-comments 配置在交互 shell 模式下，是否允许注释 恢复默认选项 $ echo $- himBH 必须使用set +o interactive-comments，set +i不好使，原因未知 #设置命令行不允许注释 $ set +o interactive-comments $ echo $- himBH #在命令行加上# 此时是不被允许的 $ #testcomment -bash: #testcomment: 未找到命令 #取消设置 $ set -o interactive-comments $ echo $- himBH $ #testcomment m - monitor 配置是否打开控制 Job control 功能 恢复默认选项 $ echo $- himBH Job control 是什么？ 即可以控制进程的停止、继续，后台或者前台执行等。 开启 job control 后，如果执行了一个比较耗时的命令，可以按下 CTRL+Z 让它在后台运行： $ sleep 50 ^Z [1]+ 已停止 sleep 50 然后， 可以用 fg 命令将后台运行的任务恢复到前台执行 $ fg 1 sleep 50 如果关闭这个选项，就会失去控制 Job 的能力 $ set +m $ echo $- hiBH #此时使用ctrl+z不管用 $ sleep 50 ^Z^Z^Z^Z^Z^C $ fg -bash: fg: 无任务控制 B - braceexpand 关于大括号使用的flag，打开后可以快捷地实现某些效果 恢复默认选项 $ echo $- himBH 利用大括号输出文件 echo {1..5}.txt 1.txt 2.txt 3.txt 4.txt 5.txt 关闭大括号效果 $ set +B $ echo $- himH 再次执行命令发现{}不生效了 echo {1..5}.txt {1..5}.txt H - histexpand 是否允許用 \"感叹号 ！+ history number\" 来执行历史命令 !! 返回并执行最近的一个历史命令 !n 返回并执行第 n 个历史命令 恢复默认选项 $ echo $- himBH #执行命令 $ ls /tmp/ ks-script-2R8Xnq yum.log #使用!运行上一次以l开头的命令 $ !l ls /tmp/ ks-script-2R8Xnq yum.log #取消!功能 $ set +H #再次执行就会报错 $ !l -bash: !l: 未找到命令 问题 由于 histexpand 打开的时候，\"!\" 带特殊含义； 因此 histexpand 打开状态下，\"!\" 不能出现在双引号中， 否则会报错 -bash: !\": event not found $ echo $- himBH #想要输出hehe!，但是却报错了，原因是命令行下，双引号里面用了!的话，Shell 会以为要执行历史展开，从而导致报错 $ echo \"hehe!\" -bash: !\": event not found 解决方法一 关闭histexpand $ echo $- himBH $ set +H $ echo $- himB $ echo \"hehe!\" hehe! 解决方法二 使用单引号 $ echo $- himBH $ echo 'hehe!' hehe! 六、环境变量总结 变量名通常要大写 变量可以在自身的shell及子shell中使用 常用export来定义环境变量 执行env默认可以显示所有的环境变量名称及对应的值 输出时用\"$变量名\"，取消时用\"unset 变量名\" 书写crond定时任务是要注意，脚本要用到的环境变量最好先在所执行的shell脚本中重新定义 如果希望环境变量永久生效，则可以将其放在用户环境变量文件或全局环境变量文件中 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/shell/2.2shell变量子串.html":{"url":"linux/shell/2.2shell变量子串.html","title":"shell变量子串","keywords":"","body":"shell变量子串 1.返回变量 ${var} 返回变量var的内容 $ a=10 $ echo ${a} 10 2.返回字符长度 ${#var} 返回变量var的长度，按照字符 a=10 $ echo ${#a} 2 3.截取子串 ${var:n} 在变量var中，从位置n(n为数字)之后开始提取子串到结尾 $ a=\"i am boy\" $ echo ${a:3} m boy ${var:n:length} 在变量var中，从位置n之后开始提取长度为length的子串 $ a=\"i am boy\" $ echo ${a:3:3} m b 4.删除子串 4.1 从开头删除 4.1.1 最短匹配 ${var#word} 从变量var开头开始删除最短匹配的word子串 $ a=abc123ABCabc123ABC $ echo ${a#a*b} c123ABCabc123ABC #匹配了ab，最短匹配 $ echo ${a#a*C} abc123ABC #匹配了abc123ABC 4.1.2 最长匹配 ${var##word} 从变量var开头开始删除最长匹配的word子串 $ a=abc123ABCabc123ABC $ echo ${a##a*b} c123ABC #匹配了abc123ABCab，最长匹配 $ echo ${a##a*C} #全部匹配，全部删除 4.2 从结尾删除 4.2.1 最短匹配 ${var%word} 从变量var结尾开始删除最短匹配的word子串 $ a=abc123ABCabc123ABC $ echo ${a%1*C} abc123ABCabc #从结尾开始匹配了123ABC 4.2.2 最长匹配 ${var%%word} 从变量var结尾开始删除最长匹配的word子串 $ a=abc123ABCabc123ABC $ echo ${a%%1*C} abc #从结尾匹配了123ABCabc123ABC 5.替换子串 ${var/A/B} 用B代替第一个匹配的A $ a=abc111 $ echo ${a/1/9} abc911 ${var//A/B} 用B代替所有匹配的A $ a=abc111 $ echo ${a//1/9} abc999 6.特殊扩展变量 6.1 ${var:-word} ${var:-word},冒号可以忽略 如果var的变量值为空或为未赋值，则会返回word字符串并替代变量的值 $ echo $C #变量C没有赋值，所以为空 $ B=${C:-hehe} #如果C没有赋值，则将hehe赋值给B $ echo $B hehe $ A=abc $ B=${A:-haha} #因为变量A有值，所以将变量A的值赋予B $ echo $B abc #冒号可以不写 $ echo $D $ E=${D-hehe} $ echo $E hehe 6.2 ${var:=word} ${var:=word}，冒号可以忽略 如果var的变量值为空或未赋值，则设置这个变量值为word,并返回其值 $ echo $A #变量A没有赋值 $ B=${A=hehe} #如果变量A为空或未赋值，则设置变量A的值为hehe $ echo $A hehe #与var-word不同，变量A也会有值 $ echo $B hehe 6.3 ${var:?word} ${var:?word}，冒号可以忽略 如果var的变量值为空或未赋值，那么word字符串将被作为标准错误输出，否则输出变量的值 $ echo $A #变量A为空或未赋值 $ echo ${A?hehe} -bash: A: hehe #将hehe作为标准错误输出 $ A=abc $ echo ${A?hehe} abc #因为变量A有值，所以输出变量A的值 6.4 ${var:+word} ${vrt:+word}，冒号可以忽略 如果var变量值为空或未赋值，则什么都不做，否则word字符串将替代变量的值 $ echo $A #变量A为空或未赋值 $ echo ${A+hehe} #不做任何操作 $ A=abc $ echo ${A+hehe} hehe #因为变量A有值，所以用hehe替代变量A的值 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/shell/2.3shell变量自增.html":{"url":"linux/shell/2.3shell变量自增.html","title":"shell变量自增","keywords":"","body":"shell变量自增 a++是先执行表达式后再自增，执行表达式时使用的是a的原值 ++a是先自增再执行表达示，执行表达式时使用的是自增后的a a++示例 $ a=1 $ let num=a++ #a++ 先执行表达式，num=a，所以num的值为1，然后a再自增，值为2 $ echo $num 1 $ echo $a 2 ++a示例 $ a=1 $ let num=++a #a先自增，因此a的值为2，然后执行表达式，num=2，所以num的值为2 $ echo $num 2 $ echo $a 2 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/shell/2.4shell特殊位置环境变量.html":{"url":"linux/shell/2.4shell特殊位置环境变量.html","title":"shell特殊位置环境变量","keywords":"","body":"shell特殊位置环境变量 变量 含义 $0 脚本名称 $n 位置变量，n代表数字，超过10要用{}括起来 $# 参数个数 $*、$@ 列出参数 $? 上一个命令的执行结果返回值 $() 表示先执行里边的内容 ${} \"金庸新著\" 和 \"金庸新\"著 用于区分变量 $! 获取上一个脚本的PID $_ 获取上一个脚本的最后一个参数 $- 显示shell使用的当前选项，与set命令功能相同 $0 当前脚本的文件名，如果执行脚本包含了路径，那么就包括脚本路径 #编辑脚本内容 $ cat >a.sh $n 位置变量，获取当前执行的脚本的第n个参数，n=1..9,如果n大于9，用大括号括起来${10} #编辑脚本内容 $ cat > b.sh $# 获取当前执行脚本后接的参数总个数 #编辑脚本内容 $ cat > c.sh $*和¥@ 列出所有参数 $* 以\"参数1 参数2 参数3 ...\"的形式列出所有参数 $@ 以\"参数1\" \"参数2\" \"参数3\"的形式列出所有参数 不加引号时，$*和$@输出一样 #$* $ set -- a b c $ for i in $*;do echo $i;done a b c #$@ $ set -- a b c $ for i in $@;do echo $i;done a b c 加入引号时，$*和$@输出不一样 #$* $ set -- a b c $ for i in \"$*\";do echo $i;done a b c #$@ $ set -- a b c $ for i in \"$@\";do echo $i;done a b c $? 上一个命令的执行结果返回值 常见返回值 #命令错误，返回值127 $ lp -bash: lp: 未找到命令 $ echo $? 127 #参数不正确或者文件目录不存在 $ ls -e ls：无效选项 -- e Try 'ls --help' for more information. $ echo $? 2 #权限拒绝，不是目录或文件等等 $ touch /opt/txt touch: cannot touch ‘/opt/txt’: Permission denied $ echo $? 1 #命令正确执行 $ ls $ echo $? 0 $() 表示先执行里边的内容 $()等同于`` #脚本中想要把一个命令的输出复值给一个变量 $ ip=$(ip a s eth0|awk -F'[ /]'+ 'NR==3{print $3}') $ echo $ip 10.0.0.10 ${} \"金庸新著\" 和 \"金庸新\"著 用于区分变量 #想要输出你好a，但是因为没有加{}，所以aa就成了最终的变量，但是变量名是a $ a='你好' $ echo $aa 输出内容为空 #用{}解决以上问题 $ a='你好' $ echo ${a}a 你好a $! 获取最后运行的后台进程的PID ⚠️必须是后台进程 #下载nginx官方的一张图片 $ nohup wget nginx.org/nginx.png & $ echo $! 1065 $_ 获取上一个脚本的最后一个参数 #编辑脚本内容 $ cat > b.sh $- 显示shell使用的当前选项，与set命令功能相同 #shell默认选项是himBH $ echo $- himBH # $ set -x ++ printf '\\033]0;%s@%s:%s\\007' root test1 '~' $ echo $- + echo himxBH himxBH ++ printf '\\033]0;%s@%s:%s\\007' root test1 '~' shell默认选项himBH，每个字母都代表了一个 shell 选项 h - hashall i - interactive-comments m - monitor B - braceexpand H- history ⚠️⚠️⚠️注意这里的 \"设置-\" 和 \"取消+\" 是反人类的：设置用 -，关闭反而是用 + h - hashall bash 的 hash 功能，可以实现让某些 command 和 具体路径 绑定在一起 查看默认选项 $ echo $- himBH $ hash -p /tmp/aaadate date $ hash -l |grep aaadate builtin hash -p /tmp/aaadate date #此时再执行命令date，会发现原先的/usr/bin/date变成了/tmpaaadate $ date -bash: /tmp/aaadate: No such file or directory #执行set +h +h表示去掉h，也就是imBH 命令不能和具体路径绑定，因此date命令能正确执行 $ set +h $ echo $- imBH $ date 2020年 06月 24日 星期三 00:26:50 CST #加上h 命令可以和具体路径绑定 $ set -h $ echo $- himBH $ date -bash: /tmp/aaadate: 没有那个文件或目录 #恢复 $ hash -d date $ date 2020年 06月 24日 星期三 00:29:14 CST i - interactive-comments 配置在交互 shell 模式下，是否允许注释 恢复默认选项 $ echo $- himBH 必须使用set +o interactive-comments，set +i不好使，原因未知 #设置命令行不允许注释 $ set +o interactive-comments $ echo $- himBH #在命令行加上# 此时是不被允许的 $ #testcomment -bash: #testcomment: 未找到命令 #取消设置 $ set -o interactive-comments $ echo $- himBH $ #testcomment m - monitor 配置是否打开控制 Job control 功能 恢复默认选项 $ echo $- himBH Job control 是什么？ 即可以控制进程的停止、继续，后台或者前台执行等。 开启 job control 后，如果执行了一个比较耗时的命令，可以按下 CTRL+Z 让它在后台运行： $ sleep 50 ^Z [1]+ 已停止 sleep 50 然后， 可以用 fg 命令将后台运行的任务恢复到前台执行 $ fg 1 sleep 50 如果关闭这个选项，就会失去控制 Job 的能力 $ set +m $ echo $- hiBH #此时使用ctrl+z不管用 $ sleep 50 ^Z^Z^Z^Z^Z^C $ fg -bash: fg: 无任务控制 B - braceexpand 关于大括号使用的flag，打开后可以快捷地实现某些效果 恢复默认选项 $ echo $- himBH 利用大括号输出文件 echo {1..5}.txt 1.txt 2.txt 3.txt 4.txt 5.txt 关闭大括号效果 $ set +B $ echo $- himH 再次执行命令发现{}不生效了 echo {1..5}.txt {1..5}.txt H - histexpand 是否允許用 \"感叹号 ！+ history number\" 来执行历史命令 !! 返回并执行最近的一个历史命令 !n 返回并执行第 n 个历史命令 恢复默认选项 $ echo $- himBH #执行命令 $ ls /tmp/ ks-script-2R8Xnq yum.log #使用!运行上一次以l开头的命令 $ !l ls /tmp/ ks-script-2R8Xnq yum.log #取消!功能 $ set +H #再次执行就会报错 $ !l -bash: !l: 未找到命令 问题 由于 histexpand 打开的时候，\"!\" 带特殊含义； 因此 histexpand 打开状态下，\"!\" 不能出现在双引号中， 否则会报错 -bash: !\": event not found $ echo $- himBH #想要输出hehe!，但是却报错了，原因是命令行下，双引号里面用了!的话，Shell 会以为要执行历史展开，从而导致报错 $ echo \"hehe!\" -bash: !\": event not found 解决方法一 关闭histexpand $ echo $- himBH $ set +H $ echo $- himB $ echo \"hehe!\" hehe! 解决方法二 使用单引号 $ echo $- himBH $ echo 'hehe!' hehe! 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/shell/3.1shell产生随机数方法.html":{"url":"linux/shell/3.1shell产生随机数方法.html","title":"shell产生随机数方法","keywords":"","body":"shell产生随机数方法 方法1：通过系统环境变量（$RANDOM）实现 示例 $ echo $RANDOM 9010 $ echo $RANDOM 21762 $ echo $RANDOM 10826 RANDOM的随机数范围为0-32767，因此，加密性不好，可以通过在输出的随机数后增加加密字符串（就是和密码生成有关的一个字符串）的方式解决，最后再一起执行md5sum操作并截取结果的后n位，这样安全性就提高了 $ echo hehe$RANDOM|md5sum a0c30ca1ee50e4ad15a103d18b59bd16 - 方法2：通过openssl产生随机数 -base64 使用-base64位编码格式 后边的数字不知道是什么 $ openssl rand -base64 1 Og== $ openssl rand -base64 2 49U= $ openssl rand -base64 3 ii94 $ openssl rand -base64 4 ZdFgGQ== $ openssl rand -base64 5 g+6lQaw= $ openssl rand -base64 6 6TL7NHBd $ openssl rand -base64 7 vI3vCFMJzA== $ openssl rand -base64 8 dE+LENuXc3Y= $ openssl rand -base64 9 ciL/KwjUQnR5 $ openssl rand -base64 10 nAFsTVLvVBtREw== 方法3：通过date获得随机数 示例 $ date +%N N表示纳秒 519916150 $ date +%N 660161239 $ date +%N 352563239 $ date +%N 198867394 $ date +%N 872287833 $ date +%N 698481118 $ date +%N 988858815 方法4：通过/dev/urandom配合chksum生成随机数 /dev/random设备存储着系统当前运行环境的实时数据，它可以看作系统在某个时候的唯一值，因此可以用作随机数元数据，可以通过文件读取的方式读到里面的数据，/dev/urandom这个设备的数据与random里的一样，只是它是非阻塞的随机数发生器，读取操作不会不会产生阻塞 示例 $ head /dev/urandom | cksum 185767657 2818 $ head /dev/urandom | cksum 2888724895 3156 $ head /dev/urandom | cksum 1734919599 1634 $ head /dev/urandom | cksum 3186002271 2797 $ head /dev/urandom | cksum 3511808856 1282 方法5：通过UUID生成随机数 UUID码全称是通用唯一标识码（Universally Unique Identifier,UUID）,它是一个软件建库的标准，亦为自由软件基金会（Open Software Foundation,OSF）的组织在分布式计算环境（Distributed Computing Enviroment,DCE）领域的一部分，UUID的目的是让分布式系统中的所有元素都能有唯一的的辨识信息，而不需要通过中央控制端来做辨识信息的指定 示例 $ cat /proc/sys/kernel/random/uuid f541c0ee-bbe7-4257-8733-2f58cc0ef27f $ cat /proc/sys/kernel/random/uuid 9a136a5c-5397-40df-bea4-d6cf60db5d78 $ cat /proc/sys/kernel/random/uuid 6548c058-7d40-4013-9ce2-a6503c3010a4 方法6：使用expect附带的mkpasswd生成随机数 mkpasswd依赖于包expect，因此需要先安装expect包 mkpasswd -l 指定密码长度 -d 指定密码中数字的数量 -c 指定密码中小写字母的数量 -C 指定密码中大写字母的数量 -s 指定密码中特殊字符的数量 示例 $ mkpasswd -l 10 -d 2 -c 2 -C 2 -s 2 Ly6Jl7|kq{ $ mkpasswd -l 10 -d 2 -c 2 -C 2 -s 2 raBT2x?4c) $ mkpasswd -l 10 -d 2 -c 2 -C 2 -s 2 Ata$\"P03op 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/shell/3.2shell获取奇数行和偶数行.html":{"url":"linux/shell/3.2shell获取奇数行和偶数行.html","title":"shell获取奇数行和偶数行","keywords":"","body":"shell获取奇数行和偶数行 方法一 awk 文件内容 $ cat test.txt 1 2 3 4 5 6 获取奇数行 方法一 NR为行，每一行与2取模，奇数与2取模结果为1，1为真，所以输出奇数行 $ awk 'NR%2' test.txt 1 3 5 方法二 ++i表示i先自加1，因此i的值为1 $ awk '++i%2' test.txt 1 3 5 方法三 行数与2取模，等于1的就是奇数行 $ awk '{if(NR%2==1)print $0}' test.txt 1 3 5 获取偶数行 方法一 NR为行，每一行与2取模，奇数与2取模结果为1，1为真，所以输出奇数行，取反则输出偶数行 $ awk '!(NR%2)' test.txt 2 4 6 方法二 i++表示先赋值再自加，因此i的值为0 $ awk 'i++%2' test.txt 2 4 6 方法三 行数与2取模，等于0的就是偶数行 $ awk '{if(NR%2==0)print $0}' test.txt 2 4 6 方法二 sed 获取奇数行 n表示换行，此命令为先打印P，然后再换行，会把下一行覆盖，因此为先打印1行，然后换行，覆盖第二行，再打印第3行，覆盖第四行。。。 $ sed -n '1,$p;n' test.txt 1 3 5 获取偶数行 与奇数行相反，先换行，覆盖第一行，再打印，打印第二行，然后再换行，覆盖第三行，然后再打印，打印第四行。。。 $ sed -n '1,$n;p' test.txt 2 4 6 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/shell/3.3shell脚本小操作.html":{"url":"linux/shell/3.3shell脚本小操作.html","title":"shell脚本小操作","keywords":"","body":"shell脚本小操作 一、获取本机公网IP 场景： 云主机使用ip或者ifconfig命令是看不到本机公网IP的，想要获取本机公网IP 获取本地网络公网IP curl ifconfig.me $ curl ifconfig.me 8.8.8.8 curl icanhazip.com $ curl icanhazip.com 8.8.8.8 curl ident.me $ curl ident.me 8.8.8.8 curl ipecho.net/plain $ curl ipecho.net/plain 8.8.8.8 curl whatismyip.akamai.com $ curl whatismyip.akamai.com 8.8.8.8 curl myip.dnsomatic.com $ curl myip.dnsomatic.com 8.8.8.8 curl myip.dnsomatic.com $ curl myip.dnsomatic.com 8.8.8.8 二、获取脚本绝对路径 #编辑脚本 $ cat >/usr/src/test.sh 三、获取脚本执行时间 #编辑脚本 $ cat >/opt/test.sh 四、shell脚本中精准过滤进程 示例：过滤crond进程，会把grep命令同样显示出来 $ ps aux|grep crond root 771 0.0 0.0 126388 1616 ? Ss 08:57 0:00 /usr/sbin/crond -n root 20996 0.0 0.0 112828 980 pts/0 S+ 21:11 0:00 grep --color=auto crond 精准过滤 $ ps aux|grep '[c]rond' root 771 0.0 0.0 126388 1616 ? Ss 08:57 0:00 /usr/sbin/crond -n $ ps aux|grep crond |grep -v grep root 771 0.0 0.0 126388 1616 ? Ss 08:57 0:00 /usr/sbin/crond -n 五、shell显示ok或者faild #编辑脚本 $ cat >test.sh 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/shell/3.4shell脚本执行方法.html":{"url":"linux/shell/3.4shell脚本执行方法.html","title":"shell脚本执行方法","keywords":"","body":"shell脚本执行方法 shell脚本5种执行方法 执行方法 是否需要执行权限 是否在当前进程执行 . 不需要 当前进程 source 不需要 当前进程 ./ 需要 子进程，不能读取当前shell中的变量 sh 不需要 子进程，不能读取当前shell中的变量 bash 不需要 子进程，不能读取当前shell中的变量 脚本内容 cat >test.sh 执行脚本 $ pwd /root $ sh test.sh $ pwd #会发现使用sh执行脚本切换路径未生效 /root 问题：执行脚本后，理应切换到/opt，但是实际并没有 原因：执行脚本的时候，只是在当前的shell下开了一个子进程，切换目录的操作只对该进程中相关后续指令有效，但改变不了父进程的目录 解决方法：使用.或者source执行脚本 脚本的执行方法 . source 脚本可以没有执行权限，会在当前进程中执行 ./ sh bash 执行脚本时，会启动一个子进程来运行脚本，不能读取当前shell中的变量 以上五种方法中，只有./需要脚本有执行权限，其他四种不需要 测试 . 切换目录成功 $ pwd /root $ . test.sh $ pwd /opt source 切换目录成功 $ pwd /root $ source test.sh $ pwd /opt ./ 切换目录失败 $ pwd /root $ ./test.sh $ pwd /root sh 切换目录失败 $ pwd /root $ sh test.sh $ pwd /root bash 切换目录失败 $ pwd /root $ bash test.sh $ pwd /root 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/shell/3.5shell打印字符长度.html":{"url":"linux/shell/3.5shell打印字符长度.html","title":"shell打印字符串长度","keywords":"","body":"shell打印字符长度 编写shell脚本以打印下面语句中字符数小于6的单词。 The hard part isn’t making the decision. It’s living with it. 思路：首先取出所有单词，计算每个单词的长度，然后依次进行判断 计算变量内容的长度，常见的方法有四种： 1.变量自带的获取长度的方法 echo $ $ str=abc $ echo ${#str} 3 2.管道加wc -L方法 $ str=abc #-L 打印行长度 $ echo $str|wc -L 3 3.利用expr自带的length方法 $ str=abc $ expr length $str 3 4.利用awk自带的length函数方法 $ str=abc $ echo $str|awk '{print length ($0)}' 3 结合for循环截取字符串 结合for循环截取字符串，例如截取给定字符串中长度大于某一个值或小于某一个值 例句：The hard part isn't making the decision. It's living with it. 截取例句中单词长度大于5的单词 方法一 $ #编辑脚本 cat >test.sh 方法二 wc -L #编辑脚本 cat >test.sh 方法三 利用expr自带的length方法 #编辑脚本 cat >test.sh 方法四 利用awk自带的length函数方法 #编辑脚本 cat >test.sh 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/shell/4.shell脚本条件测试.html":{"url":"linux/shell/4.shell脚本条件测试.html","title":"shell脚本条件测试","keywords":"","body":"shell脚本条件测试 一、sehll脚本的条件测试 条件测试语法 说明 test 测试表达式 test命令和测试表达式之间至少有一个空格 [ 测试表达式 ] []边界和内容之间至少有一个空格 [[ 测试表达式 ]] [[]]边界和内容之间至少有一个空格 ((测试表达式)) 一般用于if语句里,(())俩边不需要有空格 &&、||、>、等操作符可以应用于[[]]中，但不能应用于[]中，在[]中一般用-a、-o、-gt、-lt代替上述操作 二、文件测试表达式 文件测试操作符 说明 -d (directory) 是否为目录 -f (file) 是否为文件 -e (exist) 文件是否存在 -r (read) 是否只读 -w (write) 是否可写 -x (executable) 是否可执行 -s (size) 文件大小不为0 -L (link) 是否为链接文件 -nt (new than) f1 -nt f2 文件f1是否比f2新 -ot (older than) f1 -ot f2 文件f1是否比f2旧 -r和-w都是判断文件属主是否有权限(root用户下都会返回1)，属组和其他人即使有权限也返回0 -x 普通用户下判断属主是否有执行权限，即使属组和其他人有权限也返回0 -x root用户下只要文件有执行权限就返回1 文件测试表达式示例 判断文件属主是否有读权限 #创建文件 $ touch hehe $ ll hehe -rw-r--r-- 1 root root 0 Nov 22 13:30 hehe #将hehe的权限改为000 $ chmod 000 hehe $ ll hehe ---------- 1 root root 0 Nov 22 13:30 hehe #判断文件是否只读 $ [ -r hehe ] && echo 1 || echo 0 #文件hehe没有任何权限，但是返回了1，因为当前用户是root 1 #切换到普通用户测试 $ su - www $ touch hehe $ chmod 000 hehe $ ll total 0 ---------- 1 www www 0 Jun 25 10:14 hehe #普通用户下，当文件没有读权限的时候返回是0 $ [ -r hehe ] && echo 1 || echo 0 0 判断文件属主是否有写权限 #判断文件是否可写 $ [ -w hehe ] && echo 1 || echo 0 #文件hehe没有任何权限，但是返回了1，因为当前用户是root 1 #切换到普通用户测试 $ su - www $ touch hehe $ chmod 000 hehe $ ll total 0 ---------- 1 www www 0 Jun 25 10:14 hehe #普通用户下，当文件没有写权限的时候返回是0 $ [ -w hehe ] && echo 1 || echo 0 0 判断文件是否有执行权限 #判断文件是否可执行 $ [ -x hehe ] && echo 1 || echo 0 #文件所有者是root的情况下，只有执行权限没有的时候会返回0，读写权限即使没有也会返回1 0 -f示例 $ echo $hehe #变量hehe为空 $ [ -f $hehe ] && echo 1 || echo 0 1 #不加引号返回的结果不正确 $ [ -f \"$hehe\" ] && echo 1 || echo 0 0 #加引号返回才正确 三、字符串测试表达式 字符串测试操作符 说明 -n 字符串 若字符串长度不为0，则为真 no zero -z 字符串 若字符串长度为0，则为真 zero 字符串1=字符串2 若字符串1等于字符串2，则为真 字符串1!=字符串2 若字符串1不等于字符串2，则为真 字符串测试表达式特殊示例 示例1 $ [ \"abc\"=\"1\" ] && echo 1 || echo 0 1 #结果不正确，进行字符串比较时，等号两端如果没有空格则会错误 $ [ \"abc\" = \"1\" ] && echo 1 || echo 0 0 示例2 $ var=\"\" $ echo $var $ [ -n \"$var\" ] && echo 1 || echo 0 0 $ [ -n $var ] && echo 1 || echo 0 1 #结果不正确，因为变量var为空，字符串比较时，如果不加双引号则结果不正确 示例3 (大于号)在[]中使用时，需要用\\转义 $ [ 1 四、整数二元比较操作符 整数二元比较操作符 说明 -eq 相等 equal -ne 不相等 not equal -gt 大于 granter than -ge 大于等于 granter equal -lt 小于 less than -le 小于等于 less equal 五、逻辑操作符 在[]和test中使用的操作符 在[[]]和(())中使用的操作符 说明 -a && and,与 俩端都为真则结果为真 -o **\\ \\ ** or,或 俩端有一个为真则为真 ！ ！ not,非 俩端相反则为真 逻辑运算符示例 -a -o不能用在[[]]中，&& ||等不能用在[]中 #&&不能用在[]中，需要使用-a $ [ -f /etc/hosts && -f /etc/services ] && echo 1 || echo 0 #bash: [: missing `]' 0 $ [ -f /etc/hosts -a -f /etc/services ] && echo 1 || echo 0 1 #-a不能用在[[]]中，需要使用&& $ [[ -f /etc/hosts -a -f /etc/services ]] && echo 1 || echo 0 -bash: syntax error in conditional expression #-bash: syntax error near `-a' $ [[ -f /etc/hosts && -f /etc/services ]] && echo 1 || echo 0 1 六、测试表达式test、[]、[[]]、(())的区别总结 其中[]最为常用 测试表达式符号 边界是否需要空格 逻辑操作符 整数比较操作符 字符串比较操作符 是否支持通配符匹配 test 需要 !、-a、-o -eq、-gt、-lt、ge、-le =、==、!= 不支持 [] 需要 !、-a、-o -eq、-gt、-lt、ge、-le =、==、!= 不支持 [[]] 需要 **!、&&、\\ \\ ** -eq、-gt、-lt、ge、-le或=、>、=、 =、==、!= 支持 (()) 不需要 !、&&、 =、>、=、 =、==、!= 不支持 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/shell/5.shell数值运算.html":{"url":"linux/shell/5.shell数值运算.html","title":"shell数值运算","keywords":"","body":"shell数值运算 一、算术运算符表 算术运算符 含义 + - 加法、减法 * / % 乘法、除法、取模 ** 幂运算 ++ -- 增加、减少 **！ && \\ \\ ** 逻辑非、与、或 >= 小于、小于等于、大于、大于等于 == != = 相等、不相等、对于字符串\"=\"表示相当于 > 向左移位、向右移位 **~ \\ & ^** 按位取反、按位异或、按位与、按位或 = += -= *= /= %= 赋值运算符,例如a+=1相当于a=a+1 二、运算操作符与运算命令 运算操作符与运算命令 含义 (()) 用于整数运算的常用运算符，效率最高 let 用于整数运算,类似于\"(())\" expr 可用于整数运算,但还有很多其他的额外功能 bc linux下的一个计算器程序 $[] 用于整数运算 awk awk既可以用于整数运算,也可以用于小数运算 declare 定义变量值和属性,-i 参数可以用于定义整型变量，做运算 三、双小括号\"(())\"数值运算 示例 $ echo $((1+10)) 11 $ echo $((1-10)) -9 示例1 用(())做数值运算 $ echo $((1+2**3-4%3)) #先乘除后加减，先算2**3=8 4%3=1，最后1+8-1=8 8 $ ((a=1+2**3-4%3)) $ echo $a 8 示例2 在变量前后使用--和++特殊运算符的表达式 $ a=10 $ echo $((a++)) #如果a在运算符++的前面，那么在输出整个表达式时，会输出a的值 10 $ echo $a #执行上面的表达式后，因为有a++，因此a会增加1 11 $ a=10 $ echo $((a--)) #如果a在运算符--的前面，那么在输出整个表达式时，会输出a的值 10 $ echo $a #执行上面的表达式后，因为有a--，因此a会减少1 9 $ a=10 $ echo $((++a)) #如果a在运算符++的后面，那么在输出整个表达式时，先进行自增 11 $ echo $a 11 $ a=10 $ echo $((--a)) #如果a在运算符--的后面，那么在输出整个表达式时，先进行自减 9 $ echo $a 9 示例3 通过(())运算后赋值给变量 $ a=100 $ b=$((a+1)) $ echo $b 101 四、let运算命令的用法 let运算命令语法格式 let 赋值表达式 相当于 ((赋值表达式)) 示例1 用let做数值运算 $ a=1 $ let a=a+8 $ echo $a 9 五、expr命令的用法 expr命令既可以用于整数运算,也可以用于相关字符串长度、匹配等的运算处理 示例 expr命令用于计算 $ expr 2+2 2+2 $ expr 2 + 2 #注意，运算符左右必须有至少一个空格 4 $ expr 2 * 2 expr: syntax error #注意，做乘法运算需要转义* $ expr 2 \\* 2 4 示例2 利用expr判断一个变量值或字符串是否为整数 实现原理:利用expr做计算时变量或字符串必须是整数的原则，把一个变量或字符串和一个已知的整数(非0)相加，看命令返回的值是否为0，如果为0，就认为做加法的变量或字符串为整数，否则就不是 $ i=1 $ expr $i + 1 &>/dev/null $ echo $? 0 #返回0，证明i的值为整数 $ i=hehe $ expr $i + 1 &>/dev/null $ echo $? 2 #返回为非0，证明i的值不是整数 示例3 利用expr判断参数是否为整数 #编辑脚本 cat >expr1.sh /dev/null 2>&1 [ $? -eq 0 ] && echo int || echo chars done EOF #执行脚本 $ sh expr1.sh please input: 1 int please input: 2 int please input: a chars please input: / chars 示例4 利用expr判断文件扩展名是否符合要求 #编辑脚本 cat > string.sh /dev/null;then echo \"you are using $1\" else echo \"please use *.pub file\" fi EOF #执行脚本 $ sh string.sh hehe please use *.pub file $ sh string.sh hehe.pub you are using hehe.pub 示例5 利用expr计算字符串的长度 #当变量有空格时，expr length 后的变量必须加引号 $ char=\"i am a boy\" $ expr length $char expr: syntax error $ expr length \"$char\" 10 #当变量没有空格时，expr length 后的变量可以不加引号 $ char=\"iamboy\" $ expr length $char 6 五、bc命令的用法 示例1 bc交互式用法 $ bc bc 1.06.95 Copyright 1991-1994, 1997, 1998, 2000, 2004, 2006 Free Software Foundation, Inc. This is free software with ABSOLUTELY NO WARRANTY. #For details type `warranty'. scale=5 #表示小数后保留5位 9/5 1.80000 9/1.3 6.92307 1+1 2 9-3 6 示例2 bc用在命令行中 $ echo 3+5 | bc 8 $ echo 9-3 | bc 6 $ echo 9*9 | bc 81 $ echo 9.9+6.6 | bc 16.5 示例3 利用bc通过一条命令计算输出1+2+3+..+10的值 #生成表达式方法一 $ seq -s \"+\" 10 1+2+3+4+5+6+7+8+9+10 $ seq -s \"+\" 10 | bc 55 #生成表达式方法二 $ echo {1..10} | tr \" \" \"+\" 1+2+3+4+5+6+7+8+9+10 $ echo {1..10} | tr \" \" \"+\" | bc 55 六、$[]符号的运算 $[]只能做整数运算 $ echo $[2**3] 8 $ echo $((3%5)) 3 $ echo $[1+1] 2 $ echo $[2*2] 4 $ echo $[10/3] 3 $ echo $[10%3] 1 $ echo $[10**3] 1000 七、用awk实现计算 #方法1 $ echo \"9.9 8.8\" | awk '{print ($1-$2)}' 1.1 $ echo \"358 113\" | awk '{print ($1-3)/$2}' 3.14159 #方法2 $ awk 'BEGIN{print (9.9-8.8)}' 1.1 $ awk 'BEGIN{print (358-3)/113}' 3.14159 八、declare(同typeset)命令用法 使用typeset定义整数变量，直接进行计算，此方法不常用，因为需要定义才能生效 $ declare -i A=10 B=20 $ A=A+B $ echo $A 30 $ typeset -i C=30 D=50 $ C=C+D $ echo $C 80 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/shell/6.1shell流程控制语句之if.html":{"url":"linux/shell/6.1shell流程控制语句之if.html","title":"if","keywords":"","body":"shell流程控制语句之if 一、if单分支 1.1 if单分支语法 #写法一 if 条件表达式;then 命令 fi #写法二 if 条件表达式 then 命令 fi 1.2 示例 if [ 1 -eq 1 ];then echo \"equality\" fi 二、if双分支 2.1 if双分支语法 #写法一 if 条件表达式;then 命令 else 命令 fi #写法二 if 条件表达式 then 命令 else 命令 fi 2.2 示例 if [ 1 -eq 1 ];then echo \"equality\" else echo \"not equality\" fi 三、if多分支 3.1 if多分支语法 elif后面还可以加条件，即elif可以有多个 写法一 if 条件表达式;then 命令 elif 命令 else 命令 fi 写法二 if 条件表达式 then 命令 elif 命令 else 命令 fi 3.2 示例 if [ 1 -eq 1 ];then echo \"equality\" elif [ 2 -eq 1 ];then echo \"equality\" else echo \"not equality\" fi 猜数字脚本示例 系统产生一个随机数，然后用户输入一个数字，与随机数做比较，输入的数字比随机数大则提示输入数字大了，输入的数字比随机数小则提示输入数字小了，猜对提示你猜对了 #!/usr/bin/env bash SJ=`echo $((RANDOM%100+1))` i=1 for ((;;)) do read -p \"please input a num: \" NUM if [[ $NUM =~ ^[0-9]+$ ]];then if [ $NUM -eq $SJ ];then echo -e \"\\033[32myou guess it!!! \\033[0m\" echo -e \"\\033[34mGuess the total is $i times!!!\\033[0m\" exit 0 elif [ $NUM -gt $SJ ];then echo \"Larger than the random number\" else echo \"Smaller than the random number\" fi else echo \"Please enter the correct number: \" fi let i++ done 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/shell/6.2shell流程控制语句之case.html":{"url":"linux/shell/6.2shell流程控制语句之case.html","title":"case","keywords":"","body":"shell流程控制语句之case case语句语法 case 变量名 in 模式1) 命令1 ;; 模式2) 命令2 ;; 模式3) 命令3 ;; *) 其它命令 esac 使用示例 read -p \"请输入一个数字：\" NUM case $NUM in 1) echo \"你输入的是1\" ;; 2) echo \"你输入的是2\" ;; 3) echo \"你输入的是3\" ;; *) echo \"请输入以下数字{1|2|3}\" esac 购物脚本示例 打印本店菜单，然后提示输入商品的编号，购买的数量，并计算消费多少，如果输入不正确则退出 #!/bin/bash echo -e \"\\033[36m这是本店的菜单:\\033[0m \\n\\t\\033[32m1.汉堡/13￥\\033[0m\\n\\t\\033[35m2.>鸡腿/9￥\\033[0m\\n\\t\\033[31m3.可乐/6￥\\033[0m\" xunhuan (){ read -p '请输入要购买的商品编号,按\"q\"退出,按\"y\"打印消费清单: ' menu case \"$menu\" in q) break ;; 1) read -p \"请输入要购买的汉堡数量: \" hb echo -e \"\\033[34m\\n您购买了$hb个汉堡\\n\\033[0m\" ;; 2) read -p \"请输入要购买的鸡腿数量: \" jt echo -e \"\\033[34m\\n您购买了$jt个鸡腿\\n\\033[0m\" ;; 3) read -p \"请输入要购买的可乐数量: \" kl echo -e \"\\033[34m\\n您购买了$kl个可乐\\n\\033[0m\" ;; y) a=$hb*13 b=$jt*9 c=$kl*6 let sum=$a+$b+$c echo -e \"\\033[32m消费清单:\\n\\t商品名称\\t单价\\t数量\\t总价\\n\\t汉堡\\t\\t13￥\\t$hb\\t$a\\n\\t鸡腿\\t\\t9￥\\t$jt\\t$b\\n\\t可乐\\t\\t6￥\\t$kl\\t$c\\n\\n\\t总计:$sum元\\t\\t收银员：李骚峰\\033[0m\" ;; *) echo \"输入不正确,请输入正确的编号{1|2|3}\" esac } while : ;do xunhuan done 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/shell/7.1shell循环控制语句之for.html":{"url":"linux/shell/7.1shell循环控制语句之for.html","title":"for","keywords":"","body":"shell循环控制语句之for 语法 for 变量名 in 取值列表; do 命令 done 示例 #!/bin/bash data='a b c d' IFS=, for i in $data;do echo $i done for循环高并发执行脚本 for循环ping脚本，执行效果很慢，因为会一个一个IP去ping #!/usr/bin/env bash #export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin for i in {1..254} do ping -c1 10.0.0.$i &>/dev/null if [ $? -eq 0 ];then echo \"10.0.0.$i\" >> /root/ping.txt fi done 高并发执行 #!/usr/bin/env bash #export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin for i in {1..254} do { ping -c1 10.0.0.$i &>/dev/null if [ $? -eq 0 ];then echo \"10.0.0.$i\" >> /root/ping.txt fi }& done wait echo -e\"online ip is: \\n`cat /root/ping.txt`\" waite 等待并发全部执行完成才往后执行 for循环高并发 在要执行的命令外加上 {命令}& 即在do跟done之间的命令加{}& 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/shell/7.2shell循环控制语句之while、until.html":{"url":"linux/shell/7.2shell循环控制语句之while、until.html","title":"while、until","keywords":"","body":"shell循环控制语句之while、until 一、while 语法 while 条件表达式 do 命令 done 说明 while循环语句会对紧跟在while命令后的条件表达式进行判断，如果该条件表达式成立，则执行while循环体里的命令，每一次执行到done时就会重新判断while条件表达式是否成立，直到条件表达式不成立时才会跳出while循环体，如果一开始条件表达式就不成立，那么程序就不会进入循环体中执行命令了 示例1 while true表示条件永远为真，因此会一直执行 #!/bin/bash while true do uptime sleep 2 done 执行结果如下 22:15:04 up 11:00, 2 users, load average: 0.00, 0.01, 0.05 22:15:06 up 11:00, 2 users, load average: 0.00, 0.01, 0.05 22:15:08 up 11:00, 2 users, load average: 0.00, 0.01, 0.05 。。。 ctrl+c停止 示例2 while循环竖向打印54321 #!/bin/bash i=5 while ((i>0)) do echo \"$i\" ((i--)) done 二、until 语法 until 条件表达式 do 命令 done 当条件表达式不成立时，进入循环执行命令，条件表达式成立时，终止循环，until应用较少 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/shell/7.3循环控制及状态返回值.html":{"url":"linux/shell/7.3循环控制及状态返回值.html","title":"循环控制及状态返回值","keywords":"","body":"循环控制及状态返回值 一、break、continue、exit、return的区别和对比 break、continue在条件语句及循环语句(for、while)中用于控制程序的走向 exit用于终止所有语句并退出当前脚本，除此之外exit还可以返回上一次程序或命令的执行状态值给当前shell return类似于exit，只不过return仅用于在函数内部返回函数执行的状态值 命令 说明 break [n] 跳出整个循环，n表示跳出循环的层数 continue [n] 跳过本次循环，忽略本次循环的剩余代码，进入下一次循环，n表示退到第n层继续循环 exit [n] 退出当前shell程序，n为上一次程序执行的状态返回值，n也可以省略，在下一个shell里可通过$?接收exit n的n的值 return [n] 退出当前函数，并且在函数里作为函数的返回值，以判断函数执行是否正确，在下一个shell里可通过$?接收return n的n的值 二、break、continue、exit功能执行流程图 2.1 break 2.2.1 while循环中break的功能执行流程图 2.2.2 for循环中break的功能执行流程图 2.2 continue 2.2.1 while循环中continue的功能执行流程图 2.2.2 for循环中continue的功能执行流程图 2.3 exit 2.3.1 while循环中exit的功能执行流程图 2.3.2 for循环中exit的功能执行流程图 三、break、continue、exit、return基础示例 3.1 编辑综合示例脚本 #!/bin/bash if [ $# -ne 1 ];then #如果传入的参数个数不为1，则打印下面的使用提示给用户 echo $\"usage:$0 {break|continue|exit|return}\" exit 1 fi #定义测试函数 test(){ for((i=0; i 3.2 break 含义 跳出整个循环 当参数是break时 当i等于3时，符合条件，执行break，跳出整个循环，之前循环打印的变量i依次为0、1、2，并执行后续的echo，因为没有return所以执行echo \"I am in func.\"和echo \"ok\" $ sh test.sh break 0 1 2 I am in func. ok 3.3 continue 含义 跳过本次循环，忽略本次循环的剩余代码，进入下一次循环，n表示退到第n层继续循环 当参数是continue时 当i等于3时，符合条件，执行continue，跳出本次循环，继续下一次循环，因此打印的变量i没有3，执行后续的echo，因为没有return所以执行echo \"I am in func.\"和echo \"ok\" $ sh test.sh continue 0 1 2 4 5 I am in func. ok 3.4 exit 含义 退出当前shell程序，n为上一次程序执行的状态返回值，n也可以省略，在下一个shell里可通过$?接收exit n的n的值 当参数是exit时 当i等于3时，符合条件，执行exit，退出脚本，所有的echo都不执行，之前循环打印的变量i依次为0、1、2，默认exit的退出码是0，如果指定了则打印指定的exit退出码 $ sh test.sh exit 0 1 2 $ echo $? 0 #手动设置exit返回值是100 $ sh test.sh \"exit 100\" 0 1 2 $ echo $? 100 3.5 return 含义 退出当前函数，并在函数里作为函数的返回值，以判断函数执行是否正确，在下一个shell里可通过$?接收return n的n的值 当参数是return时 当i等于3时，符合条件，执行return，并且返回一个返回值，执行后续的echo，因为是return，所以函数中的echo不执行，最后执行echo \"return's exit status:$func_ret\"和echo \"ok\" $ sh test.sh return 0 1 2 return's exit status:0 ok #手动设置return返回值是100 $ sh test.sh \"return 100\" 0 1 2 return's exit status:100 ok 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/shell/8.shell数组.html":{"url":"linux/shell/8.shell数组.html","title":"shell数组","keywords":"","body":"shell数组 一、shell数组概念 概念 shell数组就是一个元素集合，它把有限个元素(变量或字符组合)用一个名字来命名，然后用编号对他们进行区分，这个名字就称为数组名 数组下标 用于区分不同内容的编号 数组元素 组成数组的各个元素,也称为变量 二、shell数组定义 2.0 shell数组分类 普通数组：数组下标只能是数字 关联数组：数组下标可以是字符，通过declare -A 数组名定义 2.1 普通数组 方法一 用小括号将变量值括起来赋值给数组变量，每个变量之间要用空格进行分隔,常用定义方法 语法 array=(value1 value2 value3 ... ) 使用示例 $ array=(1 2 3) $ echo ${array[*]} 1 2 3 方法二 用小括号将变量值括起来，同时采用键值对的形式复制，不常用 语法 array=( [1]=one [2]=two [3]=three ) 使用示例 $ array=( [1]=one [2]=two [3]=three ) $ echo ${array[*]} one two three $ echo ${array[1]} one $ echo ${array[2]} two $ echo ${array[3]} three 方法三 通过分别定义数组变量的方法来定义，不常用 语法 array[0]=a;array[1]=b;array[2]=c 使用示例 $ array[0]=a;array[1]=b;array[2]=c $ echo ${array[0]} a $ echo ${array[1]} b $ echo ${array[2]} c 方法四 动态的定义数组变量，并使用命令的输出结果作为数组的内容 语法 array=($(命令)) 或 array=(`命令`) 使用示例 $ mkdir /array $ touch /array/{1..3}.txt $ ll /array/ total 0 -rw-r--r-- 1 root root 0 Nov 12 08:37 1.txt -rw-r--r-- 1 root root 0 Nov 12 08:37 2.txt -rw-r--r-- 1 root root 0 Nov 12 08:37 3.txt $ array=($(ls /array)) $ echo ${array[*]} 1.txt 2.txt 3.txt array=(`ls /array`) $ echo ${array[*]} 1.txt 2.txt 3.txt 2.2 关联数组 2.2.1 定义关联数组 普通数组的下标不能为字符 $ array=([a]=hehe [b]=haha [c]=xixi) #输出不正确 $ echo ${array[*]} xixi 定义关联数组，需要提前用declear -A 数组名定义 $ declare -A array $ array=([a]=hehe [b]=haha [c]=xixi) $ echo ${array[*]} hehe haha xixi 关联数组使用示例 #定义了一个关联数组array $ declare -A array #让下标为m的数组元素自增1，此时m为1 $ let array[m]++ #让下标为m的数组元素自增1，此时m为2 $ let array[m]++ #让下标为f的数组元素自增1，此时f为1 $ let array[f]++ #打印下标为m出现的次数 $ echo ${array[m]} 2 #打印下标为f出现的次数 $ echo ${array[f]} 1 2.2.2 关联数组脚本示例 统计/etc/passwd中每个bash出现的次数 思路: 1.将/etc/passwd的最后一列取出来,因为最后一列是bash类型 2.定义关联数组，将取出来的bash类型存放到数组中 3.for循环遍历数组，输出相同下标的数组元素 编辑脚本 #!/usr/bin/env bash #定义一个关联数组 declare -A array #使用while循环从/etc/passwd文件中读取每一行 while read line do #把/etc/passwd中bash类型取出来 PASSWD=`echo $line|awk -F: '{print $NF}'` #让每一行bash自增1,这样最后就会把相同bash相加 let array[$PASSWD]++ done 执行结果如下 /sbin/nologin 21 /bin/sync 1 /bin/bash 2 /sbin/shutdown 1 /sbin/halt 1 2.2.3 关于关联数组的问题 2.2.3.1 关联数组赋值时必须指定下标 #先定义一个关联数组 $ declare -A array #在给数组赋值的时候提示为关联数组赋值时必须使用下标 $ array=(1 2 3) bash: array: 1: must use subscript when assigning associative array bash: array: 2: must use subscript when assigning associative array bash: array: 3: must use subscript when assigning associative array #此时必须给数组元素指定下标 $ array=([1]=1 [2]=2 [3]=3) //查看元素显示 $ echo ${array[*]} 1 2 3 //查看数组下标 $ echo ${!array[*]} 1 2 3 //依据数组下标查看数组元素正确 $ echo ${array[1]} 1 $ echo ${array[2]} 2 $ echo ${array[3]} 3 2.2.3.2 普通数组在只有一个元素的情况下，下标可以是字符串，但是超过2个元素就不可以 第一种情况，指定普通数组的下标是字符串，但是只给数组赋值一个元素 #定义一个普通数组 $ array=([a]=aa) //数组内容可以正常显示 $ echo ${array[*]} aa #依据数组下标查看数组元素正确 $ echo ${array[a]} aa #数组下标也显示正确 $ echo ${!array[*]} 0 第二种情况，指定普通数组的下标是字符串，并给数组赋值2个元素 #定义一个普通数组 $ array=([a]=aa [b]=bb) #此时数组内容显示不正确 $ echo ${array[*]} bb #依据数组下标查看数组元素也不正确 $ echo ${array[a]} bb $ echo ${array[b]} bb #同时数组下标显示也不正确 $ echo ${!array[*]} 0 三、shell数组的打印及输出 3.1 打印数组元素 语法 ${数组名 [下标]} 数组下标从0开始 使用示例 $ array=(1 2 3) $ echo ${array[0]} 1 $ echo ${array[1]} 2 $ echo ${array[2]} 3 #使用*或@打印整个数组内容 $ echo ${array[*]} 1 2 3 #使用*或@打印整个数组内容 $ echo ${array[@]} 1 2 3 3.2 打印数组元素个数 语法 ${#数组名 [*]} 或 ${#数组名 [@]} 使用示例 $ array=(1 2 3) $ echo ${array[*]} 1 2 3 $ echo ${array[@]} 1 2 3 $ echo ${#array[@]} 3 $ echo ${#array[*]} 3 3.3 查看数组下标 语法 ${!数组名[*]} 使用示例 $ array=(1 2 3) $ echo ${!array[*]} 0 1 2 3.4 数组赋值 语法 #如果下标不存在，则会自动添加一个新的数组元素 数组名[下标]=值 使用示例 $ array=(1 2 3) $ echo ${array[*]} 1 2 3 #增加下标为3的数组元素，即增加数组第4个元素 $ array[3]=4 $ echo ${array[*]} 1 2 3 4 $ array[0]=hehe $ echo ${array[*]} hehe 2 3 4 查看数组赋值 命令: declare -a #查看普通数组 declare -A #查看关联数组 使用示例: #创建一个普通数组 $ array=(1 2 3 4 5) $ declare -a | tail -1 declare -a array='([0]=\"1\" [1]=\"2\" [2]=\"3\" [3]=\"4\" [4]=\"5\")' #创建一个关联数组 $ declare -A array $ array=([a]=hehe [b]=haha [c]=xixi) $ declare -A | tail -1 declare -A array='([a]=\"hehe\" [b]=\"haha\" [c]=\"xixi\" )' 3.5 数组及数组元素的删除 语法 #删除相应下标的数组元素 unset 数组[下标] #删除整个数组 unset 数组 使用示例 $ array=(1 2 3) $ echo ${array[*]} 1 2 3 #删除下标为0的数组元素 $ unset array[0] $ echo ${array[*]} 2 3 #删除整个数组 $ unset array $ echo ${array[*]} #数组已经删除，返回为空 数组元素删除扩展示例 $ array=(one one one one one) $ echo ${array[*]} one one one one one #从左边开始匹配最短的数组元素并删除 $ echo ${array[*]#o*} ne ne ne ne ne #从左边开始匹配最长的数组元素并删除 $ echo ${array[*]##o*} #全部匹配并删除 #从右边开始匹配最短的数组元素并删除 $ echo ${array[*]%%e*} on on on on on #从右边开始匹配最长的数组元素并删除 $ echo ${array[*]%e*} on on on on on 3.6 数组内容截取 语法 #数字1:数字2表示截取下标1到下标2的元素 $[array[*]:数字1:数字2] 使用示例 $ array=(1 2 3 4 5 6) $ echo ${array[*]} 1 2 3 4 5 6 #截取下标1到下标3的元素 $ echo ${array[*]:1:3} 2 3 4 $ array=(1 2 3 4 5 6) #这里理解为从下标0开始,截取3个元素 $ echo ${array[*]:0:3} 1 2 3 $ array=(`echo {a..z}`) $ echo ${array[*]} a b c d e f g h i j k l m n o p q r s t u v w x y z 3.7 数组内容替换 语法 $[数组名[*]/要替换掉数组元素/替换为什么] 使用示例 $ array=(1 2 3 4 5 6) #将数组中的1替换为hehe，但不改变原数组内容 $ echo ${array[*]/1/hehe} hehe 2 3 4 5 6 #数组内容并没有改变 $ echo ${array[*]} 1 2 3 4 5 6 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/shell/9.shell函数.html":{"url":"linux/shell/9.shell函数.html","title":"shell函数","keywords":"","body":"shell函数 一、shell函数简介 函数概念 类似于alias别名 函数作用 将程序里多次被调用的相同代码组合起来(函数体)，并为其取一个名字，即函数名，其他所有想重复调用这部分代码的地方都只需要调用这个名字就可以了 函数优势 把相同程序段定义为函数,可以减少整个程序的代码量,提升开发效率 增加程序的可读性,易读性,提升管理效率 可以实现程序功能模块化,使得程序具备通用性 二、shell函数的定义 2.1 标准写法 语法 function 函数名 () { 命令 } 2.2 简化写法 简化写法一 函数名 () { 命令 } 简化写法二 function 函数名 { 命令 } 三、shell函数参数 参数列表 参数 说明 $n 位置参数，第n个参数，n是整数 $# 脚本参数总数 $* 参数列表 $@ 参数列表 四、shell函数的调用 直接在脚本中写函数名即可 #!/usr/bin/env bash #test为函数名称 test (){ echo \"function test\" } #调用函数 test 五、shell函数的执行 1.执行shell函数时，函数名前的function和函数后的小括号都不要带 2.函数的定义必须在要执行的程序前面定义或加载 3.shell执行系统中各种程序的执行顺序为: 系统别名-->函数-->系统命令-->可执行文件 4.在shell函数里面，return命令的功能于exit类似，return的作用是退出函数，而exit是退出脚本文件 5.return语句会返回一个退出值(即返回值)给调用函数的当前程序，而exit会返回一个退出值(即返回值)给执行程序的当前shell 6.如果函数存放在独立的文件中，被脚本加载使用时，需要使用source或\".\"来加载 7.在函数内一般使用local定义局部变量,这些变量离开函数后就会消失 六、shell函数使用示例 6.1 基本使用示例 编辑脚本 #!/usr/bin/env bash test1 (){ echo test1 } test2 (){ echo test2 } test1 test2 执行结果如下 test1 test2 6.2 分离函数体和执行函数的脚本示例 ⚠️这个方法在centOS7中不能用，原因未知!!! 建立函数库脚本，往/etc/init.d/functions文件中追加一个函数 cat >>/etc/init.d/functions 编写脚本，调用刚才往/etc/init.d/functions文件中追加的函数 cat > test-functions.sh 执行结果如下 $ sh test-functions.sh test functions 6.3 函数传参示例 6.3.1 通过脚本传参 编辑脚本 cat > test-functions.sh 执行结果如下 $ sh test-functions.sh 123 you input 123 6.3.2 通过/etc/init.d/functions文件实现 ⚠️这个方法在centOS7中不能用，原因未知!!! 建立函数库脚本，往/etc/init.d/functions文件中追加一个函数 cat >>/etc/init.d/functions 编写脚本，调用刚才往/etc/init.d/functions文件中追加的函数 cat >test-functions.sh 执行结果如下 $ sh test-functions.sh 123 you input 123 七、shell函数脚本使用示例 url检测脚本示例 cat >check_url.sh 执行结果如下 $ sh check_url.sh www.baidu.com www.baidu.com is yes 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"linux/shell/10.expect自动化交互式程序.html":{"url":"linux/shell/10.expect自动化交互式程序.html","title":"expect自动化交互程序","keywords":"","body":"expect自动化交互式程序 一、expect简介 什么是expect expect是一个用来实现自动交互功能的软件套件(expect is a software suite for automating interactive tools)，是基于TCL的脚本编程工具语言，方便学习，功能强大 为什么要使用expect linux中执行系统命令或程序时，系统会以交互式的形式要求输入指定的字符串，之后才能继续执行命令，如果在shell脚本中，这样就不能实现脚本完全自动化执行，因此需要用到expect自动化交互 linux交互式操作的场景 #修改用户密码 $ passwd Changing password for user root. New password: #ssh连接服务器 $ ssh root@10.0.0.10 root@10.0.0.10's password: #生成ssh密钥 ssh-keygen Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): expect自动交互工作流程 spawn启动指定进程--->expect获取期待的关键字--->send向指定进程发送指定字符--->进程执行完毕，退出结束 二、expect简单使用示例 示例：免交互ssh连接服务器 先手动交互ssh连接一台服务器 安装expect yum -y install expect 编辑expect脚本 脚本开头的#!/usr/bin/expect是脚本开头解析器，和shell类似，表示 程序使用expect解析 #扩展名使用.exp代表是expect脚本 cat >test.exp 使用expect命令执行脚本，因为之前已经ssh连接过了，所以这里就能不需要输入yes连接了 $ expect test.exp spawn ssh root@10.0.0.31 uptime root@10.0.0.31's password: 10:29:02 up 44 min, 1 user, load average: 0.00, 0.01, 0.03 这里仅仅是一个简单的不需要输入密码的示例，但是如果没有ssh连接过的话还是需要手动输入第一次连接需要的yes 三、expect程序自动交互的重要命令 3.1 spawn命令 在expect自动交互程序执行的过程中，spawn命令是一个开始就需要使用的命令，通过spawn执行一个命令或程序，之后所有的expect操作都会在这个执行过的命令或程序进程中进行，包括自动交互功能，因此如果没有spawn命令，expect程序将会无法实现自动交互 语法 spawn [选项] [需要自动交互的命令或程序] 示例 在spawn命令的后面，直接挤上要执行的命令或程序 spawn ssh root@10.0.0.100 uptime 使用spawn命令是expect程序实现自动交互工作流程中的第一步，也是最关键的一步 3.2 expect命令 3.2.1 expect命令说明 在expect自动交互程序的执行过程中，当使用spawn命令执行一个命令或者程序之后，会提示某些交互式信息，expect命令的作用就是获取spawn命令执行后的信息，查看是否和其事先自定的相匹配，一旦匹配上指定的内容就执行expect后面的动作，expect命令也有一些选项，相对用的多的是-re，表示使用正则表达式的方式来匹配 语法 expect 表达式 [动作] 示例 ⚠️以下命令不能在命令行中执行，需要放入expect脚本中执行 spawn ssh root@10.0.0.100 uptime expect \"*password\" (send 1\\r) 3.2.2 expect命令实践 3.2.2.1 实践示例1 执行ssh命令远程获取服务器负载值和eth0网卡，并自动输入yes及用户名密码 编辑expect脚本 cat >test.exp 说明 exp_send和send类似，后面的\\r(回车)，和前文的\\n(换行)类似 expect {}，类似多行expect 匹配多个字符串，需要在每次匹配并执行动作后，加上exp_continue 执行脚本 $ expect test.exp spawn ssh root@10.0.0.31 uptime && ip a s eth0 The authenticity of host '10.0.0.31 (10.0.0.31)' can't be established. ECDSA key fingerprint is SHA256:o9tdhhhgM3KPZytcz16k/Wt6gfEkDp1FCD3Q7VmLnoE. ECDSA key fingerprint is MD5:0e:a2:0c:a6:42:e4:95:b4:77:44:14:36:ba:11:2b:d8. #可以看到这里expect会自动输入yes Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added '10.0.0.31' (ECDSA) to the list of known hosts. #expect自动输入密码 root@10.0.0.31's password: 10:32:18 up 8:45, 1 user, load average: 0.08, 0.03, 0.05 2: eth0: mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:1c:42:1b:e4:d7 brd ff:ff:ff:ff:ff:ff inet 10.0.0.31/24 brd 10.0.0.255 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::21c:42ff:fe1b:e4d7/64 scope link valid_lft forever preferred_lft forever 3.2.2.2 实践示例2 利用expect相应shell脚本中的多个read读入 编辑shell脚本 cat > read.sh 编辑expect脚本 ⚠️expect脚本中的exp_send也可以改成send cat > read.exp 执行脚本 $ expect read.exp spawn /bin/sh /root/read.sh please input your username:xiaoming please input your password:1 please input your email:1@qq.com your name is xiaoming,your password is 1,your email is 1@qq.com. 3.3 send命令 send命令和exp_send命令用法类似，即在expect命令后匹配指定的字符串后，发送指定的字符串给系统，这些命令可以支持一些特殊转义符号，例如\\r(回车)、\\n(换行)、\\t(制表符) send命令使用示例 ⚠️expect脚本中的send也可以改成exp_send cat > read.exp send命令参数 -i 指定spawn_id，用来向不同的spawn_id进程发送命令，是进行多程序控制的参数 -s s代表slpwly，即控制发送的速度，使用的时候要与expect中的变量send_slow相关联 3.4 exp_continue命令 exp_continue命令一般处于expect命令中，属于一种动作命令，一般用在匹配多次字符串的动作中，从命令的拼写就可以看出命令的作用，即让expect程序继续匹配的意思 exp_continue命令使用示例 cat > read.exp 如果需要一次性匹配多个字符串，那么不同的匹配之间就要加上exp_continue，否则expect将不会自动输入指定的字符串，最后一个结尾就不需要加上exp_continue了，因为匹配全部完成了 3.5 send_user命令 send_user命令可以用来打印expect脚本信息，类似shell里的echo命令，并且有echo -e的功能，而默认的send、exp_send命令都是将字符串输出到expect程序中去 send_user命令使用示例 编辑expect脚本 cat >send_user.exp 执行脚本 $ expect send_user.exp i am boy. i like play basketbal. 3.6 exit命令 exit命令的功能类似于shell中的exit，即直接退出expect脚本，除了最基本的退出脚本功能外，还可以利用这个命令对脚本做一些关闭前的清理和提示等工作 exit命令使用示例 cat > exit.exp 执行脚本 $ expect exit.exp i am boy. i like play basketbal. goog bye. 3.7 expect常用命令总结 expect命令 作用 spawn spawn命令是一个在expect自动交互程序的开始就需要使用的命令，通过spawn执行一个命令或程序，之后所有的expect操作都在这个执行过的命令或程序进程中进行，包括自动交互功能 expect 在expect自动交互程序的执行过程中，在使用spawn命令执行一个命令或程序之后，会提示某些交互式信息，expect命令的作用就是获取这些信息，查看是否和其事先指定的信息相匹配，一旦匹配上指定的内容，就执行expect后面的动作 send expect中的动作命令，当expect匹配了指定的字符串后，发送指定的的字符串给系统，这些命令可以支持一些特殊的转义符号，例如\\r表示回车、\\n表示换行、\\t表示制表符等，还有一个类似的exp_send命令 exp_continue 属于一种动作命令，在一个expect命令中，用于多次匹配字符串并执行不同的动作中，从命令的拼写格式就可以看出该命令的作用，即让expect程序继续匹配 send_user 用来打印expect脚本信息，类似shell里的echo命令，并且带-e(支持转义)功能 exit 退出expect脚本，以及在退出脚本前做一些关闭前的清理和提示等工作 四、expect程序变量 4.1 普通变量 定义语法 set 变量名 变量值 定义普通变量示例 set pwd 123 打印变量 puts $变量名 使用示例 编辑expect脚本 cat > var.exp 执行脚本 $ expect var.exp 123 password is 123 4.2 特殊参数变量 在expect里也有与shell脚本里的$0、$1、$#等类似的特殊参数变量，用于接收及控制expect脚本传参 在expect中$argv表示参数数组，可以使用[lindex $argv n]接收expect脚本传递参，n从0开始，分别表示第一个[lindex $argv 0]参数、第二个[lindex $argv 1]参数、第三个[lindex $argv 2]参数。。。 定义及输出特殊参数变量 cat >special-var.exp 执行脚本 $ expect special-var.exp access.log 10.0.0.100 /tmp access.log 10.0.0.100 /tmp 文件是: access.log 主机IP是: 10.0.0.100 目录是: /tmp expect接收参数的方式和bash脚本的方式区别 类型 接收传参方式 bash $0...$n expect set 变量名 [lindex $argv 0...n] 除了基本的位置参数外，expect也支持其他的特殊参数，例如$argc表示传参的个数，$argv0表示脚本的名字 使用示例 编辑expect脚本 cat > special-other.exp 执行脚本 $ expect special-other.exp access.log 10.0.0.100 /tmp 文件是: access.log 主机IP是: 10.0.0.100 目录是: /tmp 传参个数是: 3 脚本名是: special-other.exp 五、expect程序中的if条件语句 语法 if关键字后面要有空格，else关键字前后都要有空格，{条件表达式}大括号里边靠近大括号处可以没有空格，将指令括起来的起始大括号\"{\"前要有空格 if {条件表达式} { 命令 } 或 if {条件表达式} { 命令 } else { 命令 } 使用示例 使用if语句判断脚本传参的个数，如果不符合则给予提示 cat > if.exp 执行脚本 未给脚本传参数 $ expect if.exp usage: expect if.exp file ip dir 给脚本传参 $ expect if.exp access.log 10.0.0.100 tmp 文件是: access.log 主机IP是: 10.0.0.100 目录是: tmp 六、expect中的关键字 expect中的特殊关键字用于匹配过程，代表某些特殊的含义或状态，一般只用于expect命令中而不能在expect命令外面单独使用 6.1 eof关键字 eof(end-of-line)关键字用于匹配结束符，即在expect脚本中的最后声明 示例 #!/usr/bin/expect spawn ssh root@10.0.0.100 uptime expect \"*password\" {send \"1\\n\"} #eof关键字用于结束expect脚本 expect eof 6.2 timeout关键字 timeout是expect中的一个控制时间的关键字变量，它是一个全局性的时间控制开关，可以通过为这个变量赋值来规定整个expect操作的时间，注意这个变量是服务于expect全局的，而不是某一条命令，即使命令没有任何错误，到了时间仍然会激活这个变量，此外，到时间后还会激活一个处理及提示信息开关 timeout超时功能使用示例 #timeout语法1 cat >timeout.exp timeout.exp 执行脚本 执行脚本后提示需要输入密码，这里等待5秒后如果没有输入密码则提示请求超时，并退出脚本 $ expect timeout.exp spawn ssh root@10.0.0.31 uptime root@10.0.0.31's password: request timeout 七、expect综合示例 批量分发ssh密钥示例 本地生成密钥对 ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa &>/dev/null 编辑expect脚本 cat >ssh.exp 分发单个主机示例 $ expect ssh.exp ~/.ssh/id_rsa.pub 10.0.0.31 spawn ssh-copy-id -i /root/.ssh/id_rsa.pub -p 22 root@10.0.0.31 /usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: \"/root/.ssh/id_rsa.pub\" The authenticity of host '10.0.0.31 (10.0.0.31)' can't be established. ECDSA key fingerprint is SHA256:o9tdhhhgM3KPZytcz16k/Wt6gfEkDp1FCD3Q7VmLnoE. ECDSA key fingerprint is MD5:0e:a2:0c:a6:42:e4:95:b4:77:44:14:36:ba:11:2b:d8. Are you sure you want to continue connecting (yes/no)? yes /usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed /usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys root@10.0.0.31's password: Number of key(s) added: 1 Now try logging into the machine, with: \"ssh -p '22' 'root@10.0.0.31'\" and check to make sure that only the key(s) you wanted were added. 分发多个主机示例 编辑shell脚本循环执行expect脚 cat > ssh.sh 执行脚本 $ sh ssh.sh spawn ssh-copy-id -i /root/.ssh/id_rsa.pub -p 22 root@10.0.0.31 /usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: \"/root/.ssh/id_rsa.pub\" The authenticity of host '10.0.0.31 (10.0.0.31)' can't be established. ECDSA key fingerprint is SHA256:o9tdhhhgM3KPZytcz16k/Wt6gfEkDp1FCD3Q7VmLnoE. ECDSA key fingerprint is MD5:0e:a2:0c:a6:42:e4:95:b4:77:44:14:36:ba:11:2b:d8. Are you sure you want to continue connecting (yes/no)? yes /usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed /usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys root@10.0.0.31's password: Number of key(s) added: 1 Now try logging into the machine, with: \"ssh -p '22' 'root@10.0.0.31'\" and check to make sure that only the key(s) you wanted were added. spawn ssh-copy-id -i /root/.ssh/id_rsa.pub -p 22 root@10.0.0.52 /usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: \"/root/.ssh/id_rsa.pub\" The authenticity of host '10.0.0.52 (10.0.0.52)' can't be established. ECDSA key fingerprint is SHA256:o9tdhhhgM3KPZytcz16k/Wt6gfEkDp1FCD3Q7VmLnoE. ECDSA key fingerprint is MD5:0e:a2:0c:a6:42:e4:95:b4:77:44:14:36:ba:11:2b:d8. Are you sure you want to continue connecting (yes/no)? yes /usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed /usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys root@10.0.0.52's password: Number of key(s) added: 1 Now try logging into the machine, with: \"ssh -p '22' 'root@10.0.0.52'\" and check to make sure that only the key(s) you wanted were added. 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/1.python基础一 变量、常量、注释.html":{"url":"python/python基础/1.python基础一 变量、常量、注释.html","title":"python基础一 变量、常量、注释","keywords":"","body":"python基础一 变量、常量、注释 1.变量 1.1 定义 ​ 将程序中运行的中间值，临时存储起来，以便再次使用 1.2 命名规范 数字、字母、下划线组成 变量名要具有可描述性 不能以数字开头 禁止使用python中的关键字 ['False', 'None', 'True', 'and', 'as', 'assert', 'break', 'class', 'continue', 'def', 'del', 'elif', 'else', 'except', 'finally', 'for', 'from', 'global', 'if', 'import', 'in', 'is', 'lambda', 'nonlocal', 'not', 'or', 'pass', 'raise', 'return', 'try', 'while', 'with', 'yield'] 驼峰命名法 单词首字母大写 AisMan 下划线命名法 单词之间以下划线分割 a_is_man 2.常量 2.1 定义 变量名大写的就是常量 2.2 说明 python中本没有常量，为了迎合别的语言 python中的常量可以修改，但是不建议修改 2.3 用途 用于配置文件中 3.注释 3.1 定义 给一些晦涩难懂的代码进行标注或者解释 3.2 分类 单行注释 一个#号 多行注释 3个单引号或者3个双引号(推荐) 4.用户输入 4.1 语法 input(提示语句) 4.2 说明 ⚠️python中input输入的内容都是字符串 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/2.python基础二 流程控制语句.html":{"url":"python/python基础/2.python基础二 流程控制语句.html","title":"python基础二 流程控制语句","keywords":"","body":"python基础二 流程控制语句 1. if流程控制语句 1.1 语法 1.1.1 单分支 if 条件: 执行命令 1.1.2 双分支 if 条件: 执行命令 else: 执行命令 1.1.3 多分支 多选一或零 if 条件: 执行命令 elif 条件: 执行命令 elif 条件: 执行命令 。。。 多选一 if 条件: 执行命令 elif 条件: 执行命令 else 条件: 执行命令 2. while循环语句 2.1 语法 #无限循环 while True: 循环体 #有限循环 while 条件: 循环体 2.2 关键字 break 终止当前循环 contiune 跳出本次循环，继续下次循环 ⚠️break和continue下方的代码不会执行 3. for循环语句 3.1 语法 for 变量名 in 条件: 循环体 3.2 for循环删除的坑 #for循环删除列表中的内容，同样循环删除列表也适用于字典 //错误演示 lst = [1,2,3,4,5] for i in lst: lst.remove(i) print(lst) [2, 4] //结果错误，因为for循环删除一个元素后，后边的元素会往前补，当i是0的时候，删除1，此时2补上，2的下标变为了0，下一次for循环，会删除下标为1的，但是此时原本下标为1的元素2已经补前了，所以会删除3，依次类推，会隔空删除元素 //方法1 lst = [1,2,3,4,5] for i in range(len(lst)): lst.pop(0) #列表中的元素删除一个，后边的会继续补上，所以只删除第一个 print(lst) [] //方法2 lst = [1,2,3,4,5] lst1 = lst.copy() #浅拷贝是两个变量各自占不同的内存空间，但是值还是共用 for i in lst1: #因此循环lst1删除值，lst也删除 lst.remove(i) print(lst) [] 3.3 可迭代对象与不可迭代对象说明 #可迭代对象 str -- 字符串 list -- 列表 tuple -- 元祖 set -- 集合 dict -- 字典 range -- 范围 #不可迭代对象 int -- 数字 bool -- 布尔值 3.4 代码示例 #代码示例1，for循环会便利可迭代对象中的每一个字符，然后依次执行print，因为可迭代对象为4个字符，因此打印4行123 for i in \"hehe\" print (123) 打印结果 123 123 123 123 #代码示例2 for i in \"abced\" print (i) 打印结果 a b c d e 3.5 面试题 ⚠️ #for循环面试题1 for i in \"abcde\": pass print (i) 打印结果 e ⚠️for循环中遇到pass，只会打印可迭代对象中的最后一个字符 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/3.python基础三 字符串详解.html":{"url":"python/python基础/3.python基础三 字符串详解.html","title":"python基础三 字符串详解","keywords":"","body":"python基础三 字符串 1. 索引(下标) 1.1 定义 方便查找字符串 1.2 格式说明 变量名[下标] 1.3 代码说明 name = \"abcd\" 计算机从0开始数数 0123 #从左向右 -1-2-3-4 #从右向左 #正向取值 print (name[2]) c #反向取值 print (name[-3]) b 2. 切片 2.1 定义 截取从一个位置到另一个位置 2.2 格式说明 变量名[起始位置:终止位置] ⚠️顾头不顾尾，就是python中的切片从起始位置开始截取，到终止位置结束，不包含终止位置 2.3 代码说明 name = \"hehe_haha_xixi\" #正向打印 要打印hehe print (name[0:4]) #0表示起始位置，4表示结束位置，但是不包含结束位置 #反向 要打印xixi print (name[-4:]) #默认到结束位置 #正向全部打印 print (name[:]) hehe_haha_xixi #反向全部打印 需要用到步长！！！ ⚠️默认从头开始，到结尾 3. 步长 3.1 定义 配合切片使用，表示切片时的规则，例如步长为2，切割完第一个位置后开始截取第3个位置 3.2 格式说明 变量名[切片起始位置:切片终止位置:步长] name[1:5:2] #name为变量名，1表示从字符下标1开始，下标5结束，步长为2 3.3 代码说明 #例如要截取ace name = \"abcde\" print (name[0::2]) ace #例如要截取hgfed name = \"abcdefghi\" print (name[-2:2:-1]) hgfed ⚠️步长默认为1 ⚠️正向取结尾要加1，反向取结尾要减1 #例如要截取bcd name = \"abcde\" #正向取bcd，d的下标为3，正向取，要加1，因此为4 name = \"abcde\" print (name[1:4]) #反向取bcd即dcb，b的下标为1，反向取，要减1，因此为0 name = \"abcde\" print (name[-2:0:-1]) ⚠️⚠️⚠️索引超出最大范围会报错 ⚠️⚠️⚠️切片超出最大范围不会报错 4. 字符串的方法 upper #全部大写 lower #全部小写 startswith #以什么开头 支持切片 endswith #以什么结尾 支持切片 count #统计 strip #去除头尾两端的空格,换行符,制表符,还可指定去除内容 split #分割, 默认以空格,换行符,制表符进行分割,可以指定分割内容, 返回是列表 replace #替换 参数1(旧值),参数2(新值),参数3(次数) 默认全换 # is系列 str.isalnum #判断数字,中文,字母 str.isalpha #判断中文,字母 str.isdigit #判断阿拉伯数字 str.isdecimal #判断十进制 4.1 upper 说明 ​ 全部大写 代码示例 name = \"abc\" print (name.upper()) ABC 4.2 lower 说明 ​ 全部小写 代码示例 name = \"ABC\" print (name.lower()) abc 4.3 startswith 说明 ​ 以。。。开头，支持切片，返回布尔值 代码示例 //无切片示例 name = \"abcdefg\" print (name.startswith(\"a\")) True print (name.startswith(\"b\")) False //有切片示例1 name = \"abcdefg\" print (name[1:3]) bc print (name.startswith(\"a\",1,3)) # 切片结果为bc，不是以a开头，因此结果为False False //有切片示例2 name = \"abcdefg\" print (name[-1:3:-1]) gfe //反向取值无法正确匹配 print (name.startswith(\"g\",-1,3)) False //startswith最多3个参数，第一个参数：匹配内容，第二、三个参数：切片范围 print (name.startswith(\"g\",-1,3,-1)) Traceback (most recent call last): File \"\", line 1, in TypeError: startswith() takes at most 3 arguments (4 given) 4.4 endswith 说明 ​ 以。。。结尾，支持切片，返回布尔值 代码示例 //无切片示例 name = \"abcdefg\" print (name.endswith(\"g\")) True print (name.endswith(\"f\")) False //有切片示例1 name = \"abcdefg\" print (name[1:3]) bc print (name.endswith(\"a\",1,3)) # 切片结果为bc,不是以a结尾，因此结果为False False print (name.endswith(\"c\",1,3)) # 切片结果为bc,以c结尾,因此结果为True True //有切片示例2 name = \"abcdefg\" print (name[-1:3:-1]) gfe //反向取值无法正确匹配 print (name.endswith(\"e\",-1,3)) False 4.5 strip 说明 ​ 去除头尾两端的空格,换行符,制表符,还可指定去除内容 代码示例 //去除头尾两端的空格、换行符、制表符 name = \" ab c\\td a \" print (name.strip()) ab c d a //strip只会去除头尾两端的空格、换行符、制表符，中间的空格、换行符、制表符不会去除 //指定去除内容 name = \"ab c\\td a\" print (name.strip(\"a\")) b c d //指定去除的内容\"a\",strip只会去除开头和结尾的a 4.6 split 说明 ​ 分割, 默认以空格,换行符,制表符进行分割,可以指定分割内容, 返回是列表 代码示例 //默认以空格、换行符、制表符进行分割，返回列表 name = \"hehe haha\" //中间的空格会销毁 print (name.split()) ['hehe', 'haha'] //指定分割内容，返回列表 name = \"hehe:haha\" print (name.split(\":\")) ['hehe', 'haha'] print (name.split(\"h\")) ['', 'e', 'e:', 'a', 'a'] 4.7 replace 说明 ​ 替换 参数1(旧值),参数2(新值),参数3(次数) 默认全换 代码示例 name = \"hehe hehe hehe\" //默认全部替换示例，替换hehe为haha print (name.replace(\"e\",\"a\")) haha haha haha //只替换第一个hehe为haha print (name.replace(\"e\",\"a\",2)) haha hehe hehe 4.8 count 说明 ​ 计算字符出现次数 代码示例 //统计变量name中a出现的次数 name = \"abcdeabcde\" print (name.count(\"a\")) 2 4.9 str.isalnum 说明 ​ 判断是否只包含数字,中文,字母，返回布尔值 代码示例 //只包含数字、中文、字母，返回结果True name = \"123呵呵haha\" print (name.isalnum()) True //包含数字、中文、字母，同时包含特殊符号*，返回结果False name = \"123呵呵haha*\" print (name.isalnum()) False 4.10 str.isalpha 说明 ​ 判断中文,字母,返回布尔值 代码示例 //只包含中文、字母，返回结果为True name = \"呵呵hehe\" print (name.isalpha()) True //包含中文、字母，同时包含数字，返回结果为False name = \"呵呵hehe123\" print (name.isalpha()) False 4.11 str.isdigit 说明 ​ 判断阿拉伯数字,返回布尔值 代码示例 //isdigit有bug，圆圈5也算作是阿拉伯数字，因此用isdecimal做判断更好 name = \"1234⑤\" print (name.isdigit()) True name = \"12345\" print (name.isdigit()) True //赋值方式错误 name = 12345 print (name.isdigit()) Traceback (most recent call last): File \"\", line 1, in AttributeError: 'int' object has no attribute 'isdigit' 4.12 str.isdecimal 说明 ​ 判断十进制，返回布尔值 代码示例 //判断十进制数字 name = \"10\" print (name.isdecimal()) True //用isdecimal判断圆圈数字更准确 name = \"1234⑤\" print (name.isdecimal()) False 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/4.python基础四 格式化.html":{"url":"python/python基础/4.python基础四 格式化.html","title":"python基础四 格式化","keywords":"","body":"python基础四 格式化 1. %占位填位表示法 1.1 说明 占位 %s 字符串占位 ⚠️字符串可以填充数字，后边的补位可以是整型 %d 与%i相同，整型占位 ⚠️后边的补位必须为整型 补位 变量名%(打印的内容) ⚠️补位必须与占位位数相同 1.2 代码示例 #msg中的变量名后的%s表示给对应的变量占位，而在最后的print中%表示取位 name = input(\"name\") age = input(\"age\") sex = input(\"sex\") hobby = input(\"hobby\") msg = \"\"\" ------info------ name:%s age:%s sex:%s hobby:%s -------end------ \"\"\" print(msg%(name,int(age),sex,hobby)) 2. f+{}表示法 python3.6以上支持 2.1 说明 用f表示格式化 msg =f\"myname is {input('name')}\" 2.2 代码示例 msg = f\"my name is {input('请输入姓名：')} I'm {input('请输入年龄: ')} years old\" print (msg) 3. 条件格式化 3.1 按照位置 s = \"a{}b\" s1 = s.format(\"你好\") print (s1) a你好b 3.2 按照索引 s = \"a{1}b\" s1 = s.format(\"你好\",\"呵呵\") print (s1) a呵呵b 3.3 按照关键字 s = \"a{A}b\" s = s.format(A=\"你好\") print (s) a你好b 4.其他格式化 4.1 格式化函数使用示例 def func(a,b): return a + b msg = f\"运行结果:{func(1,2)}\" print(msg) 运行结果:3 4.2 格式化列表、字典使用示例 #f-string支持列表 lst = [1,2,3,4,5,6] msg = f\"运行结果:{lst[0:3]}\" print(msg) [1,2,3] #f-string支持字典 dic = {\"key\":1,\"key1\":22} msg = f\"运行结果:{dic['key1']}\" print(msg) 运行结果:22 4.3 三木运算符使用示例 a = 100 b = 20 msg = f\"{a if a 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/5.python基础五 运算符.html":{"url":"python/python基础/5.python基础五 运算符.html","title":"python基础五 运算符","keywords":"","body":"python基础五 运算符 1. 比较运算符 > 大于 = 大于等于 2. 赋值运算符 = 等于 += 加等于 -= 减等于 *= 乘等于 /= 除等于 //= 整除等于 **= 幂等于 %= 模等于 3. 逻辑运算符 3.1 说明 与 and 或 or 非 not 3.2 优先级和查找顺序 #优先级 () > not > and > or #查找顺序 从左往右 3.3 True和False进行逻辑运算 and: 一真一假,就是假 同真为真,同假为假 or: 一真一假,就是真 同真为真,同假为假 3.4 逻辑运算符与数字运算时的规则 逻辑运算符与数字运算时的规则 # and数字进行逻辑运算时: # 数字不为 0 时和不为 False # and运算选择and后边的内容 # and运算都为假时选择and前的内容 # and 运算一真一假选择假 示例 ⚠️ 任何时候，0都可以看作是False ⚠️ 任何时候，除0外的其余数字都可以看作是True print(1 and 3) 结果：3 原因：数字不为0的时候选择and后边的内容 print(3 and 1) 结果：1 原因：数字不为0的时候选择and后边的内容 print(0 and 8) 结果：0 原因：and运算一真一假选择假 print(8 and 0) 结果：0 原因：and运算一真一假选择假 print(False and 5) 结果：False 原因：为False选择False print(5 and False) 结果：False 原因：and运算符一真一假选择假 print(0 and False) 结果：0 原因：将0看作False，and运算符都为假选择and前边的内容 print(False and 0) 结果：False 原因：and运算符都为假时选择and前的内容 # or 数字进行逻辑运算时: # 数字不为 0 时和不为 False # or运算选择or前边的内容 # or运算都为假时选择or后边的内容 # or 运算一真一假选择真 示例 print(1 or 3) 结果：1 原因：数字不为0的时候选择or前边的内容 print(3 or 1) 结果：3 原因：数字不为0的时候选择or前边的内容 print(0 or 8) 结果：8 原因：or运算一真一假选择真，0为假，8为真，选择8 print(8 or 0) 结果：8 原因：or运算一真一假选择真，0为假，8为真，选择8 print(False or 5) 结果：5 原因：or运算一真一假选择真，0位假，5为真，选择5 print(5 or False) 结果：5 原因：or运算一真一假选择真，0位假，5为真，选择5 print(0 or False) 结果：False 原因：0为假，or运算都为假时选择or后边的内容 print(False or 0) 结果：0 原因：0为假，or运算都为假时选择or后边的内容 4. 成员运算符 4.1 说明 in 在。。。中 not in 不在。。。中 4.2 代码示例 #以下代码，如果用户输入的内容包含hehe即为真 name = \"hehe\" msg = input(\"请输入字符\") if name in msg: print(111) else: print(222) 5. 算术运算符 + 加 - 减 * 乘 / 除 // 整除|地板除（向下取整） 例如 5//3 = 1 ** 幂 % 取余 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/6.python基础六 编码.html":{"url":"python/python基础/6.python基础六 编码.html","title":"python基础六 编码","keywords":"","body":"python基础六 编码 1.编码集 ascii 不支持中文，每一个字符占8位，1个字节 gbk 国标，支持中文，一个字符占16位，2个字节 unicode 中文、英文都是4个字节 utf-8 英文1个字节、欧洲2个字节、亚洲3个字节 2.二次编码 2.1 编码作用 1.存储 -- 文件操作 2.传输 -- 网编 2.2 编码 s = \"呵呵\" s1 = s.encode(\"utf8\") print (s1) b'\\xe5\\x91\\xb5\\xe5\\x91\\xb5' 2.3 解码 s2 = s1.decode(\"utf8\") print (s2) 呵呵 2.4 注意点 ⚠️ 1.python3内存中使用的就是unicode（万国码） 2.硬盘中存储时的编码方式 gbk utf-8 3.用什么编码，就用什么解码 3.单位转换 bit = 1byte 1024byte = 1KB 1024KB = 1MB 1024MB = 1GB 1024GB = 1TB 1024TB = 1PB 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/7.1python基础七 基础数据类型-整型、布尔值.html":{"url":"python/python基础/7.1python基础七 基础数据类型-整型、布尔值.html","title":"整型、布尔值","keywords":"","body":"python基础七 基础数据类型-整型、布尔值 1.整型 1.1 定义 用于计算和比较 1.2 进制转换 1.2.1 10进制 --> 2进制 算法 整除2，获取余数，从下往上读取 #示例 15转换为二进制 15整除2 商 余数 7 1 3 1 1 1 0 1 15转换为二进制 --> 1111 转换关键字 bin() #十进制转换二进制 示例 print (bin(15)) 0b1111 1.2.2 2进制 --> 10进制 算法 从右向左，计算机从0开始 #示例 1010转换为十进制 1010 =0*0**2 + 1*2**1 + 0*2**2 + 1*2**3 =0 + 2 + 0 + 8 =10 转换关键字 int() #二进制转换十进制 示例 print (int(\"1010\"),2) 2表示括号中的数字是二进制 10 1.3 最大位数 bit_length 求十进制最大位数 //示例1 a = 10 print (a.bit_length()) 4 #说明 10转换为2进制为1010 -->4位 //示例2 a = 30 print (a.bit_length()) 5 #说明 30转换为2进制为11110 -->5位 2.布尔值 2.1 作用 判断对错 2.2 说明 只有python的True和False的首字母是大写，其余语言都是小写 2.3 代码示例 print(1>2) print(10>5) False True 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/7.2python基础七 基础数据类型-字符串.html":{"url":"python/python基础/7.2python基础七 基础数据类型-字符串.html","title":"字符串","keywords":"","body":"python基础七 基础数据类型-字符串 1.字符串 1. 字符串的方法 upper #全部大写 lower #全部小写 startswith #以什么开头 支持切片 endswith #以什么结尾 支持切片 count #统计 strip #去除头尾两端的空格,换行符,制表符,还可指定去除内容 split #分割, 默认以空格,换行符,制表符进行分割,可以指定分割内容, 返回是列表 replace #替换 参数1(旧值),参数2(新值),参数3(次数) 默认全换 capitalize #首字母大写 title #每个单词首字母大写 index #根据元素查找索引 查找不到报错 find #根据元素查找索引 查找不到返回-1 join #将列表转换为字符串 split #将字符串转换为列表 center #居中 format #格式化 swapcase #大小写转换 # is系列 str.isalnum #判断数字,中文,字母 str.isalpha #判断中文,字母 str.isdigit #判断阿拉伯数字 str.isdecimal #判断十进制 1.1 upper 全部大写 name = \"abc\" print (name.upper()) ABC 1.2 lower 全部小写 name = \"ABC\" print (name.lower()) abc 1.3 startswith 以。。。开头，支持切片，返回布尔值 //无切片示例 name = \"abcdefg\" print (name.startswith(\"a\")) True print (name.startswith(\"b\")) False //有切片示例1 name = \"abcdefg\" print (name[1:3]) bc print (name.startswith(\"a\",1,3)) # 切片结果为bc，不是以a开头，因此结果为False False //有切片示例2 name = \"abcdefg\" print (name[-1:3:-1]) gfe //反向取值无法正确匹配 print (name.startswith(\"g\",-1,3)) False //startswith最多3个参数，第一个参数：匹配内容，第二、三个参数：切片范围 print (name.startswith(\"g\",-1,3,-1)) Traceback (most recent call last): File \"\", line 1, in TypeError: startswith() takes at most 3 arguments (1 given) 1.4 endswith 以。。。结尾，支持切片，返回布尔值 //无切片示例 name = \"abcdefg\" print (name.endswith(\"g\")) True print (name.endswith(\"f\")) False //有切片示例1 name = \"abcdefg\" print (name[1:3]) bc print (name.endswith(\"a\",1,3)) # 切片结果为bc,不是以a结尾，因此结果为False False print (name.endswith(\"c\",1,3)) # 切片结果为bc,以c结尾,因此结果为True True //有切片示例2 name = \"abcdefg\" print (name[-1:3:-1]) gfe //反向取值无法正确匹配 print (name.endswith(\"e\",-1,3)) False 1.5 strip 去除头尾两端的空格,换行符,制表符,还可指定去除内容 //去除头尾两端的空格、换行符、制表符 name = \" ab c\\td a \" print (name.strip()) ab c d a //strip只会去除头尾两端的空格、换行符、制表符，中间的空格、换行符、制表符不会去除 //指定去除内容 name = \"ab c\\td a\" print (name.strip(\"a\")) b c d //指定去除的内容\"a\",strip只会去除开头和结尾的a 1.6 split 作用1:分割, 默认以空格,换行符,制表符进行分割,可以指定分割内容, 返回是列表 作用2:将字符串转换为列表 1.分割 //默认以空格、换行符、制表符进行分割，返回列表 name = \"hehe haha\" //中间的空格会销毁 print (name.split()) ['hehe', 'haha'] //指定分割内容，返回列表 name = \"hehe:haha\" print (name.split(\":\")) ['hehe', 'haha'] print (name.split(\"h\")) ['', 'e', 'e:', 'a', 'a'] 2.将字符串转换为列表 s = \"hehe\" print (s.split()) ['hehe'] print (type(s.split())) 1.7 replace 替换 参数1(旧值),参数2(新值),参数3(次数) 默认全换 name = \"hehe hehe hehe\" //默认全部替换示例，替换hehe为haha print (name.replace(\"e\",\"a\")) haha haha haha //只替换第一个hehe为haha print (name.replace(\"e\",\"a\",2)) haha hehe hehe 1.8 count 计算字符出现次数 //统计变量name中a出现的次数 name = \"abcdeabcde\" print (name.count(\"a\")) 2 1.9 capitalize 首字母大写 s = \"hehe\" print (s.capitalize()) Hehe 1.10 title 每个单词首字母大写 s = \"hehe,haha\" print (s.title()) Hehe,Haha 1.11 index 根据元素查找索引 查找不到报错 #通过元素查找索引 s = [1,2,3,\"b\"] s = s.index(\"b\") print (s) 3 查找不到报错 s = [1,2,3,\"b\"] s = s.index(\"c\") print (s) ValueError: 'c' is not in list 1.12 find 根据元素查找索引 查找不到返回-1 #列表不支持find s = [1,2,3,\"b\"] s = s.find(\"c\") print (s) AttributeError: 'list' object has no attribute 'find' #查找不到返回-1 s = \"abc\" s = s.find(\"d\") print (s) -1 1.13 join 将列表转换为字符串 //join() 将列表转换为字符串 lst = ['a','b','c'] s = \"_\".join(lst) print (s) a_b_c print (type(s)) 1.14 center 居中 //示例1 s = \"abc\" s = s.center(20) print (s) abc //总长度20 //示例2 s = \"abc\" s.center(20,\"_\") //总长度20 左右两边为_ s = \"abc\" s = s.center(20,\"_\") print (s) ________abc_________ 1.15 format 格式化 1.按照位置格式化 s = \"a{}b\" s1 = s.format(\"你好\") print (s1) a你好b 2.按照索引格式化 s = \"a{1}b\" s1 = s.format(\"你好\",\"呵呵\") print (s1) a呵呵b 3.按照关键字格式化 s = \"a{A}b\" s = s.format(A=\"你好\") print (s) a你好b 1.16 swapcase 大小写转换 s = \"abc\" print (s.swapcase()) ABC s = \"abcD\" print (s.swapcase()) ABCd is系列 1.17 str.isalnum 判断是否只包含数字,中文,字母，返回布尔值 //只包含数字、中文、字母，返回结果True name = \"123呵呵haha\" print (name.isalnum()) True //包含数字、中文、字母，同时包含特殊符号*，返回结果False name = \"123呵呵haha*\" print (name.isalnum()) False 1.18 str.isalpha 判断中文,字母,返回布尔值 //只包含中文、字母，返回结果为True name = \"呵呵hehe\" print (name.isalpha()) True //包含中文、字母，同时包含数字，返回结果为False name = \"呵呵hehe123\" print (name.isalpha()) False 1.19 str.isdigit 判断阿拉伯数字,返回布尔值 //isdigit有bug，圆圈5也算作是阿拉伯数字，因此用isdecimal做判断更好 name = \"1231⑤\" print (name.isdigit()) True name = \"12315\" print (name.isdigit()) True //赋值方式错误 name = 12315 print (name.isdigit()) Traceback (most recent call last): File \"\", line 1, in AttributeError: 'int' object has no attribute 'isdigit' 1.20 str.isdecimal 判断十进制，返回布尔值 //判断十进制数字 name = \"10\" print (name.isdecimal()) True //用isdecimal判断圆圈数字更准确 name = \"1231⑤\" print (name.isdecimal()) False 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/7.3python基础七 基础数据类型-列表.html":{"url":"python/python基础/7.3python基础七 基础数据类型-列表.html","title":"列表","keywords":"","body":"python基础七 基础数据类型-列表 1. 列表 1.1 含义 ​ python中数据结构之一 1.2 关键字 list 1.3 定义 列表名 = [元素1,元素2,元素3,...] #每个元素以逗号分隔 以逗号分隔称为一个元素 1.4 作用 1.存储大量数据 2.存储不同数据类型的数据 1.5 特点 可变、可迭代、有序 1.6 列表增加 lst.append() #追加列表,只能在末尾添加 //代码示例 lst = [\"a\",\"b\"] lst.append(c) print (lst) ['a', 'b', 'c'] 1.7 列表插入 ⚠️⚠️⚠️以后尽量少使用列表插入insert，有性能消耗 lst.insert(下标,插入的内容) #参数1，要插入的位置的下标，参数2，要插入的内容 //代码示例 lst = [\"a\",\"b\"] lst.insert(1,\"c\") //1表示要插入的位置，即下标，c表示要插入的内容 print (lst) ['a', 'c', 'b'] 1.8 列表扩展 迭代添加 ⚠️extend原理是for循环迭代添加 lst.extend() #extend是迭代添加，例如添加\"abc\"，会添加\"a\",\"b\",\"c\" //代码示例 lst = [\"a\",\"b\"] lst.extend(\"hehe\") print (lst) ['a', 'b', 'h', 'e', 'h', 'e'] //for循环代码示例 lst = [\"a\",\"b\"] for i in \"hehe\": lst.append(i) print (lst) ['a', 'b', 'h', 'e', 'h', 'e'] 1.9 列表删除 #方式一 lst.remove() //一次只能删除一个 //通过元素名进行删除 lst = [\"a\",\"b\",\"c\"] lst.remove(\"b\") ['a', 'c'] #方式二 lst.pop() //弹出，默认从列表最后弹出内容，并且有返回值，返回的内容是删除的内容 //代码示例,默认删除 lst = [\"a\",\"b\",\"c\"] lst.pop() 'c' print (lst) ['a', 'b'] //代码示例，通过下标删除 lst = [\"a\",\"b\",\"c\"] lst.pop(0) 'a' print (lst) ['b', 'c'] #方式三 del lst //慎用，删除列表全部 //代码示例,删除列表全部 lst = [\"a\",\"b\",\"c\"] del lst print (lst) Traceback (most recent call last): File \"\", line 1, in NameError: name 'lst' is not defined //代码示例，根据下标删除 lst = [\"a\",\"b\",\"c\"] del lst[0] print (lst) ['b', 'c'] //代码示例，切片删除 lst = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\"] del lst[1:3] print (lst) ['a', 'd', 'e', 'f'] #方式四 clear lst //清除列表 //代码示例 lst = [\"a\",\"b\",\"c\"] lst.clear print (lst) [] 1.10 列表修改 lst[下标] = \"修改为。。。\" #方式一，修改单个元素 //代码示例 lst = [\"a\",\"b\",\"c\"] lst[0] = \"hehe\" print (lst) ['hehe', 'b', 'c'] #方式二，修改多个元素 //代码示例1，超出列表范围添加多个元素 lst = [\"a\",\"b\",\"c\"] lst[1:4] = 1,2,3 print (lst) ['a', 1, 2, 3] //代码示例2，超出列表范围添加一个元素 lst = [\"a\",\"b\",\"c\"] lst[1:4] = 1, //⚠️这里后边必须要加一个逗号，否则会变成不可迭代的数字 print (lst) ['a', 1] ⚠️列表修改元素时，修改的内容必须为可迭代的 lst[1:4] = 1 Traceback (most recent call last): File \"\", line 1, in TypeError: can only assign an iterable #方式三，切片修改多个元素 //代码示例1,将a、c、e修改为A、C、E lst = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\"] lst[0:5:2] = \"A\",\"B\",\"C\" print (lst) ['A', 'b', 'B', 'd', 'C', 'f'] //代码示例2,修改列表中不连续的元素，修改的内容必须一一对应 lst = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\"] lst[0:5:2] = \"A\",\"B\" Traceback (most recent call last): File \"\", line 1, in ValueError: attempt to assign sequence of size 2 to extended slice of size 3 1.10.1列表修改总结 1.使用切片时，获取的内容就是原数据本身，即列表切片后获取的是列表 2.切片获取的内容是连续的，修改内容时可多可少 3.如果切片获取的内容不是连续的，修改的内容必须一一对应 1.11 列表查看 #方法一 for循环 lst = [\"a\",\"b\",\"c\"] for i in lst: print (i) a b c #方法二 索引查询 lst = [\"a\",\"b\",\"c\"] print (lst[0]) a 1.11 列表嵌套 #列表嵌套就是列表中的元素是列表 //代码示例，要打印8 lst = [1,2,3,[4,5,[6,7,8]]] lst1 = lst[3] print (lst1) [4, 5, [6, 7, 8]] lst2 = lst1[2] print (lst2) [6, 7, 8] print (lst2[2]) 8 //代码示例，要打印8 lst = [1,2,3,[4,5,[6,7,8]]] print (lst[3][2][2]) 8 1.12 列表方法 1.12.1 列表倒序 reverse() 将列表倒序显示 #方法1 lst[::-1] //此方式为新开辟内存空间 lst = [1,2,3,4,5,6] print (lst[::-1]) [6, 5, 4, 3, 2, 1] print (id(lst),id(lst[::-1])) 140193101789000 140193101800136 #方法2 lst.reverse() //此方式为原地修改 lst = [1,2,3,4,5,6] lst.reverse() print (lst) [6, 5, 4, 3, 2, 1] //⚠️这样写会返回空 lst = [1,2,3,4,5,6] lst = lst.reverse() print (lst) None 1.12.2 列表排序 #升序 sort() lst = [1,3,2,7,5,6] lst.sort() print (lst) [1, 2, 3, 5, 6, 7] #降序 sort(reverse=True) lst = [1,2,3,7,5,6] lst.sort(reverse=True) print (lst) [7, 6, 5, 3, 2, 1] 1.13 列表总结 1.列表是可变数据类型，可迭代数据类型，列表是有序的 2.列表的作用存储大量数据，并且可以存储不同数据类型 3.列表就是一个容器 1.14 列表面试题 1.列表整合面试题 lst1 = [1,2,3,[4]] lst2 = [5,6,7] lst1和lst2整合 #方法1 extend lst1 = [1,2,3,[4]] lst2 = [5,6,7] lst1.extend(lst2) print (lst1) [1, 2, 3, [4], 5, 6, 7] #方法2 列表相加 lst1 = [1,2,3,[4]] lst2 = [5,6,7] print (lst1 + lst2) [1, 2, 3, [4], 5, 6, 7] 2.列表相乘面试题 ⚠️列表进行乘法时，元素都是共用的 同样的，元组也适用 lst = [1,2,[]] lst1 = lst * 2 lst1[-1].append(8) lst、lst1结果？ ⚠️ lst与lst1中元素相同，因为列表进行乘法时，元素都是共用的，因此当lst1最后一个元素追加了一个8之后，所有的元素变成了1,2,[8] lst = [1,2,[]] lst1 = lst * 2 lst1[-1].append(8) print (lst) [1, 2, [8]] print (lst1) [1, 2, [8], 1, 2, [8]] 3.定义列表 lst = [] lst1 = list() //次方式同样适用于其他数据类型 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/7.4python基础七 基础数据类型-字典.html":{"url":"python/python基础/7.4python基础七 基础数据类型-字典.html","title":"字典","keywords":"","body":"python基础七 基础数据类型-字典 1.字典 1.1 含义 python中的一种数据类型 唯一的一种{} 键值对的数据 1.2 关键字 dict 1.3 定义 dic = {key:value} 1.4 哈希说明 可变数据类型就不可哈希 不可变数据类型就可哈希 1.5 字典说明 字典的键是不可变数据类型，可哈希 字典的键是唯一的，不可重复 字典的值可以是任意的 字典是一个可变数据类型 1.6 字典的增 1.6.1 方式一 dic[键] = 值 dic = {\"key1\":1,\"key2\":2,\"key3\":3} //定义一个字典 print (dic) {'key1': 1, 'key2': 2, 'key3': 3} dic[\"key4\"] = 4 //增加一个键 print (dic) {'key1': 1, 'key2': 2, 'key3': 3, 'key4': 4} 1.6.2 方式二 dic.setdefault(\"键\",值) 参数1是键，参数2是值 dic = {\"key1\":1,\"key2\":2,\"key3\":3} //定义一个字典 dic.setdefault(\"key4\",4) //增加一个键 print (dic) {'key1': 1, 'key2': 2, 'key3': 3, 'key4': 4} #特殊说明1 使用setdefault增加字典值时，如果键值存在就不增加 dic = {\"key1\":1,\"key2\":2,\"key3\":3} //定义一个字典 dic.setdefault(\"key1\",5) //向已有的键key1中插入值 print (dic) {'key1': 1, 'key2': 2, 'key3': 3} //已存在的键不会改变 #特殊说明2 如果键不存在，则返回None dic = {\"key1\":1} print (dic.setdefault(\"key5\")) None #特殊说明3 键和值添加成功后返回的是添加的值 dic = {\"key1\":1} print (dic.setdefault(\"key5\",5)) 5 #特殊说明4 如果键存在，返回的是键的值 dic = {\"key1\":1} print (dic.setdefault(\"key1\")) 1 #setdefault工作流程说明 1.setdefault在字典中先根据键值查找，如果返回的结果为None，在进行第二步 2.将键和值添加到字典中 1.7 字典的删 1.7.1 clear() 清空 dic = {\"key1\":1,\"key2\":2,\"key3\":3} dic.clear() print (dic) {} 1.7.2 pop dic = {\"key1\":1,\"key2\":2,\"key3\":3} dic.pop(\"key1\") print (dic) {'key2': 2, 'key3': 3} 1.7.3 popitem() 随机删除(官方名称，py3.6版本后默认删除最后一个) #随机删除（官方名称）python3.6版本后默认删除最后一个 dic = {\"key1\":1,\"key2\":2,\"key3\":3} dic.popitem() print (dic) {'key1': 1, 'key2': 2} 1.7.4 del 删除字典 #直接删除字典 dic = {\"key1\":1,\"key2\":2,\"key3\":3} del dic sprint (dic) Traceback (most recent call last): File \"\", line 1, in NameError: name 'dic' is not defined #根据键删除,del删除，键只能有一个 dic = {\"key1\":1,\"key2\":2,\"key3\":3} del dic[\"key1\"] print (dic) {'key2': 2, 'key3': 3} 1.8 字典的改 1.8.1 dic[\"key\"] = \"value\" dic = {\"key1\":1,\"key2\":2,\"key3\":3} #修改方式 暴力增加，当键在字典中存在时就修改，不存在就是增加 dic[\"key1\"] = \"5\" //键key1存在，此时为修改 print (dic) {'key1': '5', 'key2': 2, 'key3': 3} dic[\"key6\"] = \"6\" //键key6不存在，此时为增加 print (dic) {'key1': 1, 'key2': 2, 'key3': 3, 'key6': '6'} 1.8.2 update dic = {\"key1\":1,\"key2\":2,\"key3\":3} dic.update({\"key1\":\"hehe\"}) //修改单个值 print (dic) {'key1': 'hehe', 'key2': 2, 'key3': 3} dic = {\"key1\":1,\"key2\":2,\"key3\":3} dic.update({\"key1\":\"hehe\",\"key2\":\"haha\"}) //修改多个值 print (dic) {'key1': 'hehe', 'key2': 'haha', 'key3': 3} 1.9 字典的查 #查找方式1 有键返回值，没有键报错 dic = {\"key1\":1,\"key2\":2,\"key3\":3} print (dic[\"key1\"]) //有键返回值 1 print (dic[\"key1\"]) //没有键报错 KeyError: 'key10' #查找方式2 dic.get(\"key\") dic = {\"key1\":1,\"key2\":2,\"key3\":3} print (dic.get(\"key1\")) //有键返回值 1 print (dic.get(\"key10\")) //没有键返回None None print (dic.get(\"key10\",\"呵呵\")) //没有键还可以返回自定义值 呵呵 #查找方式3 获取字典所有的键、值、键和值 dic = {\"key1\":1,\"key2\":2,\"key3\":3} print (dic.keys()) //返回字典所有的键，高仿列表 dict_keys(['key1', 'key2', 'key3']) for i in dic.keys(): print (i) key1 key2 key3 print (dic.values()) //返回字典所有的值 dict_values([1, 2, 3]) for i in dic.values(): print (i) 1 2 3 print (dic.items()) //返回字典所有的键和值 dict_items([('key1', 1), ('key2', 2), ('key3', 3)]) for i in dic.items(): print (i) ('key1', 1) ('key2', 2) ('key3', 3) 2.解构 2.1 解构示例1 两个变量互换值 a,b = 10,20 print (a,b) #a与b的值互换 a = 10 b = 20 a,b = b,a print (a,b) 20 10 #解构说明1 a,b = \"你好\" //将字符串分别赋值给a和b print (a) print (b) 你 好 a,b = \"你好啊\" //后边的值必须与变量的数量相同 print (a) print (b) 2.2 解构示例2 字典示例 字典本身是无序的，所以不支持索引，python3.6以上版本按照定义的顺序显示 #将字典转换为列表从而可以以索引查询字典的键和值 dic = {\"key1\":1,\"key2\":2,\"key3\":3} lst = list(dic.items()) //将字典所有键和值显示并转换为列表，从而可以取键和值 print (lst[0]) ('key1', 1) print (lst[0][0]) //打印出字典的键和值后再根据索引取键或者值 key1 #进阶，字典中的值比较少的时候可以用转换为列表的方式然后根据索引获取键或者值解决，如果字典中的值比较多，可以用for循环解决 dic = {\"key1\":1,\"key2\":2,\"key3\":3,\"key4\":4,\"key5\":5,\"key6\":6,\"key7\":7,\"key8\":8,\"key9\":9} //获取字典中的键和值 for i in dic.items(): print (i) ('key1', 1) ('key2', 2) ('key3', 3) ('key4', 4) ('key5', 5) ('key6', 6) ('key7', 7) ('key8', 8) ('key9', 9) //分别获取字典中的键和值 for i in dic.items(): print (i[0],i[1]) key1 1 key2 2 key3 3 key4 4 key5 5 key6 6 key7 7 key8 8 key9 9 3.字典的嵌套 字典的嵌套就是字典中还有字典 #示例1 dic = {\"dic1\":1,\"dic2\":2,\"dic3\":3,\"dic4\":4,\"dic5\":{\"dic6\":6,\"dic7\":{\"dic8\":8,\"dic9\":9,\"dic10\":{\"dic11\":11,\"dic12\":12}}}} //要获取dic12的值 print (dic[\"dic5\"][\"dic7\"][\"dic10\"][\"dic12\"]) 12 #示例2 dic = {\"dic1\":1,\"dic2\":2,\"dic3\":3,\"dic4\":4,\"dic5\":{\"dic6\":6,\"dic7\":{\"dic8\":8,\"dic9\":9,\"dic10\":{\"dic11\":\"么么哒\",\"dic12\":\"呵哈嘻\"}}}} //要获取哈 print (dic[\"dic5\"][\"dic7\"][\"dic10\"][\"dic12\"][1]) #获取到字典的键dic12后，值是字符串，因此可以根据索引取值 哈 4.字典骚操作 4.1 字典批量创建键值对 fromkeys fromkeys(参数1，参数2) 参数1:键（可迭代） 参数2:值（共用）批量创建键值对 dic = {} dic = dic.fromkeys(\"abc\",'hehe') print (dic) {'a': 'hehe', 'b': 'hehe', 'c': 'hehe'} 字典批量创建键值对，值必须可迭代！！！ //字典批量创建键值对，值是可变数据类型的坑 dic = {} dic = dic.fromkeys(\"abc\",[]) dic[\"c\"].append(6) print (dic) {'a': [6], 'b': [6], 'c': [6]} 本意是想修改c的值，但是结果却全变了 正确做法 dic = {} dic = dic.fromkeys(\"abc\",[]) dic[\"c\"] = 6 print (dic) {'a': [], 'b': [], 'c': 6} 4.2 字典另类定义方式 //字典另类定义方式1 print (dict(k1=1,k2=2)) {'k1': 1, 'k2': 2} //字典另类定义方式2 print (dict([(1,2),(3,4),(5,6)])) {1: 2, 3: 4, 5: 6} 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/7.5python基础七 基础数据类型-元组.html":{"url":"python/python基础/7.5python基础七 基础数据类型-元组.html","title":"元组","keywords":"","body":"python基础七 基础数据类型-元组 1.元组 1.1 含义 python中的数据类型之一 1.2 关键字 tuple 1.3 定义 tu = () 1.4 作用 通过元素的名称获取元素的索引 1.5 应用场景 1.不可变：为了防止误操作时修改重要数据 2.配置文件中存储数据 1.6 特点 1.元组就是一个不可变的列表 2.元组不能增删改 3.元组是一个有序，可迭代，不可变的数据类型 4.当小括号中没有出现逗号时，数据类型就是括号中数据本身的数据类型 5.列表和元组进行乘法时，元素都是共用的 1.7 使用示例 //定义一个元组 tu = (1,2,3) print (tu) (1, 2, 3) //支持索引 tu = (1,2,3) print (tu[0]) 1 //支持切片 tu = (1,2,3) print (tu[0:1]) (1,) print (tu[0:2]) (1, 2) //统计元组中元素个数 tu.count tu = (1,2,3,1) print (tu.count(1)) 2 //通过元素的名称获取元素的索引 tu.index tu = (1,2,3) print (tu.index(1)) 0 //for循环打印元组中的内容 tu = (1,2,3) for i in tu: print (i) 1 2 3 1.8 元组面试题 a = (10) # 当小括号中没有出现逗号时,数据类型就是括号中数据类型本身 a = (\"abc\") # 当小括号中没有出现逗号时,数据类型就是括号中数据类型本身 a = (\"abc\",) # 这是一个元组 a = () # 这是元组 a = (1,2,3) # 这是元组 //代码示例 a = (10) print (type(a)) a = (\"abc\") print (type(a)) a = (\"abc\",) print (type(a)) a = () print (type(a)) a = (1,2,3) print (type(a)) 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/7.6python基础七 基础数据类型-集合.html":{"url":"python/python基础/7.6python基础七 基础数据类型-集合.html","title":"集合","keywords":"","body":"python基础七 基础数据类型-集合 1.集合 1.1 含义 集合是python中的一种数据类型 1.2 关键字 set 1.3 定义 空集合 set() #定义集合示例 s = {1,2,3} 1.4 特点 1.去重，集合中的元素都是唯一的 2.集合关系 3.集合无序、可变、可迭代 1.5 集合使用示例 1.集合去重 lst = [1,2,3,1,4] print (set(lst)) {1, 2, 3, 4} 1.6 集合面试题示例 一行代码去重 ⚠️需要注意的是原先的数据类型是什么，在做完去重处理后需要转换为原先的数据类型 lst = [1,2,3,5,6,1,5,6,7,8,9,33,1,2,33,66] print (set(lst)) //不完美做法，没有将数据类型转换为原来的列表 print (list(set(lst))) [1, 2, 3, 33, 5, 6, 7, 8, 9, 66] 1.7 集合核心说明 ⚠️集合就是一个没有值的字典 ⚠️集合就是一个没有值的字典 为什么说集合是一个没有值的字典？？？ 字典的值：任意 字典的键：不可变、可哈希 \"\"\"示例说明，列表是可变的 如果集合中能打印列表，那么说明集合中的元素相当于字典中的值,也就是集合是一个没有键的字典 如果集合中不能打印列表，那么说明集合中的元素相当于字典中的键，也就是集合是一个没有值的字典 \"\"\" #打印一个可变类型 s = {1,2,[1,2,3]} print (s) TypeError: unhashable type: 'list' //打印结果报错列表不可哈希 #打印一个不可变类型 s = {1,2,(1,2,3)} print (s) {1, 2, (1, 2, 3)} 1.8 集合的增删改查 1.8.1 集合的增 #方式1 update s = set() s.update('play') print (s) {'l', 'a', 'p', 'y'} //集合中的update会把增加的内容迭代添加 #方式2 add s = set() s.add('play') //add在集合中是常用的 print (s) {'play'} 1.8.2 集合的删 #方式1 pop 随机删除 s = {1,2,3,'呵呵',5} s.pop() //⚠️集合中的pop是随机删除 print (s) {2, 3, 5, '呵呵'} {1, 2, 3, 5} #方式2 remove 通过元素名称删除 s = {1,2,3,'呵呵',5} s.remove(\"呵呵\") print (s) {1, 2, 3, 5} #方式3 clear s = {1,2,3,'呵呵',5} s.clear() print (s) set() //⚠️ 空集合为set() 1.8.3 集合的改 1.先删后加 2.转换数据类型进行修改 1.8.4 集合的查 #for循环 s = {1,2,3,'呵呵',5} for i in s: print (i) 1 2 3 5 呵呵 1.9 集合关系 1.9.1 集合并集 | == or a = {'a','b','c','d','e'} b = {'a','c','e','f'} print (a | b) {'b', 'a', 'c', 'f', 'd', 'e'} 1.9.2 集合交集 & == and a = {'a','b','c','d','e'} b = {'a','c','e','f'} print (a & b) {'a', 'c', 'e'} 1.9.3 集合差集 - #差集就是用自身的元素减去对方的元素，相同的元素消除，但是自身没有的不会出现 a = {'a','b','c','d','e'} b = {'a','c','e','f'} print (a - b) {'b', 'd'} 1.9.4 集合补集、反差集、对称集 ^ #补集就是用自身的元素减去对方的元素，相同的元素消除，同时自身没有的元素会出现 a = {'a','b','c','d','e'} b = {'a','c','e','f'} print (a ^ b) {'b', 'd', 'f'} 1.9.5 超集 就是父集 > a = {'a','b','c','d','e'} b = {'a','c','e'} print (a > b) //判断a是否是b的父集 True 1.9.6 子集 a = {'a','b','c','d','e'} b = {'a','c','e'} print (b 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/8.python基础八 小数据池、代码块.html":{"url":"python/python基础/8.python基础八 小数据池、代码块.html","title":"python基础八 小数据池、代码块","keywords":"","body":"python基础八 小数据池、代码块 1.小数据池、代码块（了解，实际开发中用不到） 1.1 小数据池、代码块含义 小数据池、代码块属于python中的驻留机制，目的用于节省内存空间 代码块：一个py文件、一个函数、一个模块、一个类、交互模式（终端）下的每一行都是一个代码块 小数据池：python中的内存驻留机制，优先级比代码块低 ⚠️先执行代码块然后执行小数据池 1.2 小数据池缓存机制 数字：-5 ～ 256 字符串： 1.定义时内容（不包含中文、特殊符号）长度不限，内容相同，就进行驻留 2.python3.6解释器字符串进行乘法时（不包含中文、特殊符号），总长度不能超过20 3.python3.7解释器字符串进行乘法时（不包含中文、特殊符号），总长度不能超过4096 ⚠️验证小数据池机制必须在终端中，不能在IDE(例如pycharm)中验证，因为IDE中是一个py文件，是一个代码块，会优先执行 1.小数据池数字验证 //-5 ~ 256验证，返回结果为True，驻留，内存空间地址相同 >>> a = -5 >>> b = -5 >>> a is b True >>> print (id(a),id(b)) 4331026288 4331026288 >>> a = 256 >>> b = 256 >>> a is b True >>> print (id(a),id(b)) 4331034640 4331034640 //-5 ~ 256范围外验证，返回结果为False，不驻留，内存空间地址不同 >>> a = -6 >>> b = -6 >>> a is b False >>> print (id(a),id(b)) 140558040632912 140557772390192 >>> a = 257 >>> b = 257 >>> a is b False >>> print (id(a),id(b)) 140558039687984 140557772390256 2.小数据池字符串验证 2.1定义内容验证 //不包含中文、特殊符号,定义时内容相同，驻留，内存空间地址相同 >>> a = \"abc\" >>> b = \"abc\" >>> a is b True >>> print (id(a),id(b)) 140558040616664 140558040616664 //包含中文、特殊符号，定义时内容相同，不驻留，内存空间地址不同 >>> a = \"abc#\" >>> b = \"abc#\" >>> a is b False >>> print (id(a),id(b)) 140557772689168 140557772689112 >>> a = \"abc#你好\" >>> b = \"abc#你好\" >>> a is b False >>> print (id(a),id(b)) 140557772596880 140557772596688 >>> a = \"abc你好\" >>> b = \"abc你好\" >>> a is b False >>> print (id(a),id(b)) 140557772596688 140557772596880 2.1字符串乘法验证(python3.6) //不包含中文和特殊符号，总长度不超过20，驻留，内存空间地址相同 >>> a = \"hehe\" * 3 >>> b = \"hehe\" * 3 >>> print (a is b) True >>> print (id(a),id(b)) 140557772708656 140557772708656 >>> a = \"hehe\" * 5 >>> b = \"hehe\" * 5 >>> print (a is b) True >>> print (id(a),id(b)) 140557772718488 140557772718488 //字符串相乘，等于20时驻留 //不包含中文和特殊符号，总长度超过20，不驻留，内存空间地址不同 >>> a = \"hehe\" * 6 >>> b = \"hehe\" * 6 >>> print (a is b) False >>> print (id(a),id(b)) 140557772714992 140557772714912 //包含中文或者特殊符号，不管总长度是否超过20，都不驻留，内存空间地址不同 >>> a = \"abc#你好\" * 3 >>> b = \"abc#你好\" * 3 >>> print (a is b) False >>> print (id(a),id(b)) 140231892539968 140231893044000 //总长度不超过20，但是内存地址还是不同 >>> a = \"abc#你好\" * 5 >>> b = \"abc#你好\" * 5 >>> print (a is b) False >>> print (id(a),id(b)) 140231893461712 140231893461848 1.3 代码块缓存机制 数字：-5 ～ 正无穷 字符串： 1.定义时内容长度不限，内容相同，就进行驻留 2.字符串进行乘法时（不包含中文和特殊符号），总长度不能超过20 1.代码块数字验证 （pycharm中验证） //-5 ~ 正无穷验证，返回结果为True，驻留，内存空间地址相同 a = -5 b = -5 print (a is b) True print (id(a),id(b)) 4453603184 4453603184 a = 1000000 b = 1000000 print (a is b) True print (id(a),id(b)) 140434424966800 140434424966800 //-5 ~ 正无穷范围外验证，返回结果为False，不驻留，内存空间地址不同 a = -6 b = -6 print (a is b) False print (id(a),id(b)) 140442480390000 140442480390032 2.字符串验证 2.1定义内容验证 //只要内容相同，就驻留，可以包含中文和字符串,小数据池中就不可以 a = \"abc#你好\" b = \"abc#你好\" print (a is b) True print (id(a),id(b)) 140481266762928 140481266762928 2.2字符串乘法验证 //不包含中文、特殊符号，总长度不超过20，驻留，内存空间地址相同，与小数据池相同 a = \"abc\" * 6 b = \"abc\" * 6 print (a is b) True print (id(a),id(b)) 140679911152496 140679911152496 //包含中文、特殊符号，无论总长度是否超过20，都不驻留，内存空间地址不同 a = \"abc#你好\" * 3 b = \"abc#你好\" * 3 print (a is b) False print (id(a),id(b)) 140361947581552 140361947581216 //总长度不超过20，内存空间地址不同 a = \"abc#你好\" * 5 b = \"abc#你好\" * 5 print (a is b) False print (id(a),id(b)) 140438049459712 140437243696104 //总长度超过20，内存空间地址不同 1.4 小数据池和代码块对比 小数据池 代码块 数字 -5 ～ 256 驻留 -5 ～ 正无穷 驻留 字符串定义内容 不能包含中文、特殊符号，长度不限，内容相同就驻留 可以包含中文、特殊符号，长度不限，内容相同就驻留 字符串乘法 不能包含中文、特殊符号，总长度不超过20就驻留 不能包含中文、特殊符号，总长度不超过20就驻留 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/9.python基础九 深浅拷贝.html":{"url":"python/python基础/9.python基础九 深浅拷贝.html","title":"python基础九 深浅拷贝","keywords":"","body":"python基础九 深浅拷贝 1.深浅拷贝（⚠️重要） 1.1 浅拷贝 1.1.1 定义 只拷贝第一层的内存地址 1.1.2 浅拷贝示例 赋值 示意浅拷贝前先说明赋值 1.赋值共用同一块内存空间，一个变量的值改变，另一个赋值的变量同时也改变 2.多个变量名指向同一块内存空间 //列表示例 lst = [1,1,3] lst1 = lst lst1.append(4) //正常思维理解应该是lst1更改后，lst不会改变，但是赋值是多个变量名指向同一个内存 空间，因此只要一个变量改变，另一个变量也改变 print (lst,lst1) [1, 1, 3, 4] [1, 1, 3, 4] //字典示例 dic = {'k1':1,'k1':1} dic1 = dic dic1.update({'k1':111}) print (dic,dic1) {'k1': 1, 'k1': 111} {'k1': 1, 'k1': 111} 赋值示意图 浅拷贝 只拷贝第一层的内存地址 列表中浅拷贝有两种方式 1. lst = [1,1,3] new_lst = lst.copy() 1. lst = [1,1,3] new_lst = lst[:] 浅拷贝只拷贝第一层的内存空间地址,浅拷贝的两个变量是单独的内存空间，不再是共用同一个内存空间地址 //列表示例1 列表中未嵌套第二层元素 lst = [1,1,3] new_lst = lst.copy() new_lst.append(4) print (lst,new_lst) [1, 1, 3] [1, 1, 3, 4] //浅拷贝中lst和new_lst结果不同 print (id(lst),id(new_lst)) 140584614767176 140584614774344 //浅拷贝中lst和new_lst内存空间地址不同 //列表示例1 列表中嵌套了第二层元素 lst = [1,1,[3,4,5]] new_lst = lst.copy() new_lst.append(6) print (lst,new_lst) [1, 1, [3, 4, 5]] [1, 1, [3, 4, 5], 6] print (id(lst),id(new_lst)) 140431875130951 140431874963911 print (id(lst[1]),id(new_lst[1])) //浅拷贝只拷贝第一层内存空间，因此两个列表的第二个嵌套的元素的值内存空间相同 140633470413384 140633470413384 浅拷贝单层元素示意图（增加元素） 浅拷贝多层元素示意图（修改元素） 浅拷贝多层元素示意图（第二层增加元素） 1.1.3 浅拷贝总结 1.浅拷贝只复制第一层内存空间地址 1.浅拷贝，修改第一层元素或者追加元素，都是将旧指向改变为新指向，两个变量互不影响 3.浅拷贝修改第二层及以下元素或者追加元素，修改的是两个变量共用的值，此时修改会影响两个变量 1.1.4 浅拷贝坑 lst = [1,3,[4,5],6] lst1 = lst lst1 = lst[:] lst1[-1] = [8,9] lst1[-1].append([0]) #数字无法进行追加操作 print (lst,lst1,lst1) AttributeError: 'int' object has no attribute 'append' 1.2深拷贝 1.2.1 定义 不可变数据类型共用内存空间，可变数据类型开辟新的内存空间，不管嵌套多少层都是这样的原理 1.2.2 深拷贝语法 Import copy copy.deepcopy() 1.2.3 深拷贝示例 import copy lst = [1,1,[3,4]] new_lst = copy.deepcopy(lst) print (id(lst[0]),id(new_lst[0])) #lst[0]为1，1是整型，是不可变数据类型 --> 共用内存空间地址 4464777164 4464777164 print (id(lst[-1]),id(new_lst[-1])) 140663166316984 140663166494088 #lst[-1]为[3,4]，[3,4]是列表，是可变数据类型 --> 新开辟内存空间地址 1.2.4 深拷贝原理图 1.2.5 深拷贝总结 深拷贝中，不可变数据类型共用内存空间地址，可变数据类型开辟新的内存空间，不管嵌套多少层都是这样 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/10.python基础十 文件操作.html":{"url":"python/python基础/10.python基础十 文件操作.html","title":"python基础十 文件操作","keywords":"","body":"python基础十 文件操作 1.文件操作 1.1 作用 持久化存储 1.2 文件操作总结 f = open(file=\"文件名字或文件路径\",mode=\"操作模式\",encoding=\"编码\") r 只读 w 清空写 a 追加写 rb 只读字节 wb 清空写字节 ab 追加写字节 r+ 读写 w+ 清空写读 a+ 追加写读 1.3 文件操作 1.3.1 只读文件 --> r r: 读文本 f = open(\"test.txt\",mode=\"r\",encoding=\"utf-8\") #参数说明 f 变量名，句柄 open 表示打开文件，通过python向操作系统发送指令 test.txt 表示要操作的文件 mode 指定对文件的操作方式，r表示读取 r 表示读取文件 encoding 指定字符集 ⚠️文件读取时只能读一遍 在py同级目录下创建一个文件txt.txt，并写入以下内容 一只奔跑的草泥马 abc 123 1.全部读取 print(f.read()) f = open(\"txt.txt\",mode=\"r\",encoding=\"utf-8\") print(f.read()) 一只奔跑的草泥马 abc 123 2.r模式下按照字符读取 print(f.read(3)) f = open(\"txt.txt\",mode=\"r\",encoding=\"utf-8\") print(f.read(5)) 一只奔跑的 3.读取一行 print(f.readline().strip()) 读取一行默认最后有换行符，需要去掉 f = open(\"txt.txt\",mode=\"r\",encoding=\"utf-8\") print (f.readline().strip()) 一只奔跑的草泥马 4.读取多行，以列表的形式存储 print(f.readlines()) f = open(\"txt.txt\",mode=\"r\",encoding=\"utf-8\") print (f.readlines()) ['一只奔跑的草泥马\\n', 'abc\\n', '123'] //读取总结 print(f.read()) #全部读取 print(f.read(3)) #模式的r的情况下按照字符读取 print(f.readline().strip()) #读取一行 print(f.readlines()) #读取多行,以列表的形式存储 1.3.2 清空写 --> w w: 清空写文本 f = open(\"txt.txt\",mode=\"w\",encoding=\"utf-8\") 清空写会把要操作的文件先清空，然后再写入 //w模式打开文件后会清空文件内容 f = open(\"txt.txt\",mode=\"w\",encoding=\"utf-8\") print (f) txt.txt文件中的内容会被清空 //写入内容 f = open(\"txt.txt\",mode=\"w\",encoding=\"utf-8\") print (f.write(\"呵呵\\n哈哈\")) 5 txt.txt文件中的内容为如下，并且光标在最开头 呵呵 哈哈 //连续写会从文件最后开始写 f = open(\"txt.txt\",mode=\"w\",encoding=\"utf-8\") print (f.write(\"呵呵\\n哈哈\")) print (f.write(\"嘻嘻\\n嘿嘿\")) 5 5 txt.txt文件中的内容如下，并且光标在最开头 呵呵 哈哈嘻嘻 嘿嘿 //对文件写操作后，需要刷新和关闭文件 f = open(\"txt.txt\",mode=\"w\",encoding=\"utf-8\") print (f.write(\"呵呵\\n哈哈\")) print (f.write(\"嘻嘻\\n嘿嘿\")) print (f.write(\"啦啦\\n吼吼\")) f.flush() f.close() 5 5 5 txt.txt文件中的内容如下，并且光标在最开头 呵呵 哈哈嘻嘻 嘿嘿啦啦 吼吼 1.3.3 追加写 --> a a: 追加写文本 f = open(\"txt.txt\",mode=\"a\",encoding=\"utf-8\") //追加写文本 只会在同一行追加 f = open(\"txt.txt\",mode=\"a\",encoding=\"utf-8\") print (f.write(\"呵呵\")) print (f.write(\"哈哈\")) print (f.write(\"嘿嘿\")) txt.txt文件内容如下，并且光标在最开头 呵呵哈哈嘿嘿 1.3.4 只读字节 --> rb ⚠️二进制方式读取文件不能指定字符集 f = open(\"txt.txt\",mode=\"rb\",encoding=\"utf-8\") print (f.read()) ValueError: binary mode doesn't take an encoding argument //txt.txt文件中的内容为 呵呵哈哈嘿嘿 f = open(\"txt.txt\",mode=\"rb\") print (f.read()) b'\\xe5\\x91\\xb5\\xe5\\x91\\xb5\\xe5\\x93\\x88\\xe5\\x93\\x88\\xe5\\x98\\xbf\\xe5\\x98\\xbf' 以上的字节的内容就是 呵呵哈哈嘿嘿 1.3.5 清空写字节 --> wb 1. 字节内容说明b'\\xe5\\x91\\xb5\\xe5\\x91\\xb5\\xe5\\x93\\x88\\xe5\\x93\\x88\\xe5\\x98\\xbf\\xe5\\x98\\xbf' txt.txt的内容是 呵呵哈哈嘿嘿 2. 清空txt.txt文件 3. f.write()括号中只能写字节 b'\\xxx'⚠️ f = open(\"txt.txt\",mode=\"wb\") f.write(b'\\xe5\\x91\\xb5\\xe5\\x91\\xb5\\xe5\\x93\\x88\\xe5\\x93\\x88\\xe5\\x98\\xbf\\xe5\\x98\\xbf') 4.此时txt.txt文件内容如下 呵呵哈哈嘿嘿 1.3.6 追加写字节 --> ab 1. 字节内容说明b'\\xe5\\x91\\xb5\\xe5\\x91\\xb5\\xe5\\x93\\x88\\xe5\\x93\\x88\\xe5\\x98\\xbf\\xe5\\x98\\xbf' 的内容是 呵呵哈哈嘿嘿 2. txt.txt文件内容是 呵呵哈哈嘿嘿 3. f.write()括号中只能写字节 b'\\xxx'⚠️ f = open(\"txt.txt\",mode=\"ab\") f.write(b'\\xe5\\x91\\xb5\\xe5\\x91\\xb5\\xe5\\x93\\x88\\xe5\\x93\\x88\\xe5\\x98\\xbf\\xe5\\x98\\xbf') 4.此时txt.txt文件内容如下,已成功追加 呵呵哈哈嘿嘿呵呵哈哈嘿嘿 1.3.7 读写 --> r+ txt.txt文件内容为 呵呵哈哈嘿嘿 f = open(\"txt.txt\",\"r+\",encoding=\"utf-8\") a = f.read() f.write(\"这是读写\") 呵呵哈哈嘿嘿 此时txt.txt文件内容为 呵呵哈哈嘿嘿这是读写 1.3.8 清空写读 --> w+ txt.txt文件内容为 呵呵哈哈嘿嘿 f = open(\"txt.txt\",\"w+\",encoding=\"utf-8\") print (f.write(\"清空写读\")) print (f.read()) 4 此时txt.txt文件内容如下，并且光标在最后边 清空写读 1.3.9 追加写读 --> a+ txt.txt文件内容为 呵呵哈哈嘿嘿 f = open(\"txt.txt\",\"a+\",encoding=\"utf-8\") print (f.write(\"追加写读\")) print (f.read()) 此时txt.txt文件内容如下，并且光标在追字前边 呵呵哈哈嘿嘿追加写读 1.4 光标操作 txt.txt内容为 呵呵哈哈嘿嘿 光标操作总结 f = open(\"txt.txt\",\"r\",encoding=\"utf-8\") f.seek(0,0) #移动到文件头部 f.seek(0,1) #移动到光标当前位置 f.seek(0,2) #移动到文件末尾 f.seek(3) #移动3个字节,根据编码不同决定移动的字节大小 print(f.read()) print(f.tell()) #查看光标 返回的是字节 1.5 with open with open 1.自动关闭文件 2.可以同时操作多个文件 3.as 起别名 现在有两个文件 t1 t2，t1内容为t1，t2内容为t2 with open(\"t1\",\"r\",encoding=\"utf-8\") as f1, \\ open(\"t2\",\"r\",encoding=\"utf-8\") as f2: print (f1.read()) print (f2.read()) t1 t2 ⚠️两个open之间必须以逗号分隔，print必须在with的下一级 1.6 修改文件名及文件内容 1.6.1 修改文件名 现在有两个文件 t1 t2，t1内容为t1，t2内容为t2 现在想把两个文件名互换 即t1 --> t2 t2 --> t1 转换思路，将t1改名为临时文件t3，然后把t2改名为t1，最后把t3改名为t1，即 t1 --> t3 t2 --> t1 t3 --> t2 import os # 与操作系统做交互 os.rename(\"t1\",\"t3\") os.rename(\"t2\",\"t1\") os.rename(\"t3\",\"t2\") 此时t1内容为t2，t2内容为t1 1.6.2 修改文件内容 t1的内容如下 abc okm tgb 现在要把t1中的b替换成“呵呵” 替换思路，拷贝t1为t2，⚠️尽量不在原文件修改 ⚠️文本中存储的都是字符串 with open(\"t1\",\"r\",encoding=\"utf-8\")as f,\\ open(\"t2\",\"w\",encoding=\"utf-8\")as f1: for i in f: f1.write(i.replace(\"b\",\"呵呵\")) f1.flush() 此时t2内容如下，已经将t1中的b替换成了呵呵 a呵呵c okm tg呵呵 因为t1是读的，t2才是写的文件，现在的需求是t1中修改，因此还需要转换一下文件名 即把t1与t2的文件名相互替换，这样才能达到需求，同时改名后的源文件t2不要删除 import os # 与操作系统做交互 os.rename(\"t1\",\"t3\") os.rename(\"t2\",\"t1\") os.rename(\"t3\",\"t2\") 此时t1文件内容如下 a呵呵c okm tg呵呵 t2文件内容如下 abc okm tgb #文件替换内容步骤总结 1.不要在原文件操作，需要拷贝一个文件 2.读原文件，改拷贝的文件 3.改完拷贝的文件后再替换文件名 4.保留替换文件名后的原文件 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/11.python基础十一 函数.html":{"url":"python/python基础/11.python基础十一 函数.html","title":"python基础十一 函数","keywords":"","body":"python基础十一 函数 1.函数的作用 封装代码,大量的减少重复代码,重用性高 2.函数的定义 def 函数名(): 函数体 def 是一个关键字，申明要定义一个函数 ():是固定写法 函数体中写的是需要用到的重复代码 3.函数的调用 函数名() 4.函数的返回值 #函数返回值总结 函数体中不写return默认返回None,或者写了return不写值返回的也是None return 能够返回任意数据类型(python中所有对象) return 能够返回多个数据类型,以元组的形式接收 return 能够终止函数,return下方的代码不执行 return 将返回值返回给调用者 //return示例 def func(): a = 10 return a a = func() print(a) 5.函数的参数 5.1位置参数 //函数参数示例 def hehe(app): //形参数 print (\"打开:\",app) //注意必须用逗号隔开 hehe(\"微信\") //实参 执行结果返回如下： 打开: 微信 //位置参数示例 def ball(web, players, age, addr): #形参 print(\"登陆NBA官网\") print(f\"打开{web}\") print(f\"找一位{players},要求年龄:{age},地区:{addr}的人\") print(\"看看视频\") print(\"学学球技\") ball(\"视频专区\", \"球员\", 28, \"洛杉矶\") #实参 按照位置传参 登陆NBA官网 打开视频专区 找一位球员,要求年龄:28,地区:洛杉矶的人 看看视频 学学球技 5.2 默认参数 //默认参数示例 def ball(web, players, age, addr=\"洛杉矶\"): #addr=\"洛杉矶\"表示默认参数 print(\"登陆NBA官网\") print(f\"打开{web}\") print(f\"找一位{players},要求年龄:{age},地区:{addr}的人\") print(\"看看视频\") print(\"学学球技\") ball(\"视频专区\", \"球员\", 28) #实参这里可不写形参中定义的默认值 ball(\"视频专区\",\"球员\",30,\"波士顿\") #实参写内容会覆盖形参中定义的默认参数 登陆NBA官网 打开视频专区 找一位球员,要求年龄:28,地区:洛杉矶的人 看看视频 学学球技 登陆NBA官网 打开视频专区 找一位球员,要求年龄:30,地区:波士顿的人 看看视频 学学球技 5.3 关键字传参 //关键字传参示例 def fun(a,b,c=1,d=2): print (a,b,c,d) fun(1,2,3,4) //结果是1 2 3 4 fun(a=\"呵呵\",b=\"哈哈\") //结果是呵呵 哈哈 1 2 fun(1,2,d=\"呵呵\") //结果是1 2 1 呵呵 5.4 动态参数 *args 5.4.1 动态参数作用 1.能够接受不固定长度的参数 2.位置参数过多时可以使用动态参数 5.4.2 动态参数使用方法 def func(*c): #形参位置上的*是聚合 print(*c) #函数体中的*就是打散 func(1,2,3,4,5,6,7,8,9,0) 结果如下： 1 2 3 4 5 6 7 8 9 0 def func(a,b,*c): # *c就表示动态参数 print (a,b,*c) func(1,2,3,4,5,6,7,8) 1 2 3 4 5 6 7 8 5.5 动态关键字参数 **kwages 5.5.1 动态关键字参数作用 只接收多余的动态位置参数 注意是只接收 5.5.2 动态关键字参数使用方法 //动态关键字使用方法示例1 def func(a,b,**kwargs): print (kwargs) func(a=1,b=2,c=3,d=4,e=5) 结果如下： {'c': 3, 'd': 4, 'e': 5} //动态关键字参数使用方法示例2 dic = {\"key\": 1, \"key2\": 2} def func(**kwargs): #聚合 print(kwargs) #打散 func(**dic) #打散 func(key=1,key2=2) 结果如下： {'key': 1, 'key2': 2} 5.6 函数参数面试题 #万能传参 def func(*args, **kwargs): print(args, kwargs) func(12, 2, 121, 12, 321, 3, a=1, b=2) 结果如下 (12, 2, 121, 12, 321, 3) {'a': 1, 'b': 2} *xargs获取的是一个元组 **kwargs获取的是一个字典 #*args和**kwargs def func(*args, a1=8,**kwargs): #万能传参 print(args, kwargs) #函数体中的*args是将元组打散,*kwargs是将字典的键获取到 func(12, 2, a1=1, b1=2) 结果如下： (12, 2) {'b1': 2} 5.7 函数参数总结 #参数的总结: 1.形参 在定义函数的阶段就是形参 可以单独使用位置参数,也可以单独使用默认参数,也可以混合使用 位置传参:必须一一对应 默认参数:可以不传参,可以传参,传参就是把默认的值给覆盖 混合使用:位置参数,默认参数 2.实参 在调用函数的阶段就是实参 可以单独使用位置参数,也可以单独使用关键字参数,也可以混合使用 位置传参:必须一一对应 关键字参数:指名道姓的方式进行传参 混合使用:位置参数,默认参数 3.参数总结 位置参数,动态位置,默认参数,动态关键字参数 *args 程序员之间约定俗称(可以更换但是不建议更换) **kwargs 程序员之间约定俗称(可以更换但是不建议更换) *args 获取的是一个元组 **kwargs 获取的是一个字典 *args 只接受多余的位置参数 **kwargs 只接受多余的关键字参数 4.函数参数优先级 数参数优先级: 位置参数 > 动态位置参数(可变位置参数) > 默认参数 > 动态关键字参数(可变关键字参数) 6.函数的注释 #注释方法1 def a(a,b): \"\"\" 数字加法运算 :param a: int :param b: int :return: int \"\"\" return a + b print (a(1,2)) #注释方法2 def func(a:int,b:int): #这里的a:int只是做到一个约束，并没有实际作用 \"\"\" 加法运算 :param a: :param b: :return: \"\"\" return a + b print (func(1,2)) //查看函数的注释 func.__doc__ print (func.__doc__) 加法运算 :param a: :param b: :return: //查看函数的名字 a.__name__ 代码在编写过程中会设计到函数名赋值，例如 def func(a,b): return a + b a = func print (a(1,2)) print (a.__name__) func 7.函数的名称空间 7.1函数名称空间分类 1.内置空间 -- 存放pyhton自带一些函数 2.全局空间 -- 当前py文件顶格编写的代码开辟的空间 3.局部空间 -- 函数开辟的空间 程序加载顺序: 内置空间 > 全局空间 > 局部空间 程序取值顺序: 局部空间 > 全局空间 > 内置空间 //代码示例 a = 10 #这里的10是全局变量 def func(): a = 5 #这里的5是局部变量 print (a) print (func()) 5 None 7.2函数的作用域 1.全局作用域: 内置 + 全局 globals() #查看全局作用域 2.局部作用域: 局部 locals() #查看当前作用域(建议查看局部) //代码示例 查看全局 a = 10 b = 20 print (globals()) {'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': , '__spec__': None, '__annotations__': {}, '__builtins__': , '__file__': '/jetBrains/pycharm/python-works/python基础/test.py', '__cached__': None, 'a': 10, 'b': 20} //代码示例 查看局部 def func(): a = 10 print (locals()) func() {'a': 10} 8.函数的第一类对象 8.1总概 1.函数名可以当做值,赋值给一个变量 2.函数名可以当做另一个函数的参数来使用 3.函数名可以当做另一个函数的返回值 4.函数名可以当做元素存储在容器中 8.2 函数名可以当作值，赋值给一个变量 //代码示例 def func(): print(1) a = func #函数名是func，然后赋值给了a，打印a与func的函数内存空间地址一样，并且执行a()相当于执行func() print(func) #函数的内存地址 print(a) #函数的内存地址 a() #结果 1 8.3 函数名可以当作另一个函数的参数来使用 //代码示例 def func(): print(1) def foo(a): #a = func print(a) #func这个函数的内存地址 foo(func) func函数当作了foo函数的参数 8.4 函数名可以当作另一个函数的返回值 //代码示例 def func(): return 1 #print def foo(a): #a = func函数的内存地址 return a #return func函数的内存地址 cc = foo(func) print(cc) #func函数的内存地址 8.5 函数名可以当作元素存储在容器中 容器：字典、元组、列表、集合 //代码示例 def func(): print(1) def foo(): print(2) def f(): print(3) lst = [func,foo,f] ⚠️将函数放在容器中的好处，可以使用for循环批量执行函数，而不是一个一个执行 for i in lst: i() 1 2 3 //代码示例 购物平台 ⚠️整体思路 1.定义5个函数，模拟购物平台注册、登陆 2.将这5个步骤的函数存入字典中 3.让用户选择要执行的操作，然后执行函数完成功能实现 def register(): print(\"注册\") def login(): print(\"登录\") def shopping(): print(\"浏览商品\") def add_shopping_car(): print(\"加入购物车\") def buy_goods(): print(\"购买\") msg = \"\"\" 1.注册 2.登录 3.浏览商品 4.加入购物车 5.购买 请输入您要选择的序号: \"\"\" func_dic = {\"1\": register, \"2\": login, \"3\": shopping, \"4\": add_shopping_car, \"5\": buy_goods} while True: choose = input(msg) if choose in func_dic: func_dic[choose]() else: print(\"退出商城\") 9.函数的嵌套 9.1 分类 1.交叉嵌套 2.嵌套 9.2 交叉嵌套 9.2.1 交叉嵌套示例1 def func(foo): print (1) foo() print (3) def a(): print (1) func(a) 1 1 3 上述代码进一步说明 def func(foo): print(1) v = foo() #第一个功能是调用函数,第二个功能是接收返回值 #v = None #print(v) #None print(3) 1 1 None 3 9.2.2 交叉嵌套示例2 //代码示例 def func(): print(1) print(\"太难\") print(2) def foo(b): print(3) b() print(4) def f(a,b): a(b) f(foo,func) 最终结果 3 1 太难 2 4 9.2.3 交叉嵌套示例3 def func(a,b): def foo(b,a): print(b,a) return foo(a,b) a = func(4,7) print(a) 结果 4 7 None 9.2.4 交叉嵌套示例4 //代码示例1 def func(a,b): a = a + b b = a + 10 def foo(a,d): def f(e,f): print(f,e) return \"呵呵\" f(d,a) foo(b,a) print(func(2,3)) 结果 15 5 None ⚠️return \"呵呵\"返回给了f，f是foo函数的最后一行，默认返回None，foo又是func函数的最后一行，默认返回None //代码示例2 def func(a,b): a = a + b b = a + 10 def foo(a,d): def f(e,f): print(f,e) return \"呵呵\" return f(d,a) return foo(b,a) print(func(2,3)) 结果 15 5 呵呵 10. 函数关键字global与nonlocal 10.1 global global 1.global只修改全局空间中的变量 2.在局部空间中可以使用全局中的变量,但是不能修改,如果要强制修改需要添加global 3.当变量在全局存在时global就是申明我要修改全局的变量,并且会在局部开辟这个变量 4.当变量在全局中不存在时global就是申明要在全局创建一个变量,并且会在局部开辟这个变量 1.函数中加关键字global对全局变量进行修改 //不加global关键字 a = 10 def func(): a += 1 func() print(a) 结果报错 UnboundLocalError: local variable 'a' referenced before assignment 当全局变量a存在时 //使用glboal关键字，global关键字申明变量a是全局变量 a = 10 def func(): global a #申明要修改全局的变量a a += 1 func() print(a) 结果： 11 当全局变量a不存在时 //使用global关键字申明并创建全局变量a def func(): global a a = 10 func() print(a) 结果： 10 当变量在全局存在时globla就是申明我要修改全局变量，并且会在局部开辟同名变量 当变量在全局不存在时global就是申明要在全局创建一个变量 10.2 nonlocal nonlocal 1.nonlocal只修改局部空间中的变量,最外层的一个函数 2.只修改离nonlocal最近的一层,如果这一层没有就往上一层查找,只能在局部 3.nonlocal 不能进行创建 nonlocal只修改局部空间中的变量，最外层的一个函数 只修改离nonlocal最近的一层函数，如果这一层没有就往上一层查找，只能在局部 //代码示例1 def func(): a = 10 def foo(): a = 20 def f(): nonlocal a a += 1 print(a) f() foo() func() 结果： 21 //代码示例2 a = 15 def func(): a = 10 def foo(): def f(): nonlocal a a += 1 print(a) #11 print(a) #10 f() foo() print(a) #11 func() print(a) #15 结果： 10 11 11 15 global与nonlocal结合示例 a = 10 def func(): a = 5 def foo(): a = 3 def f(): nonlocal a a += 1 def aa(): a = 1 def bb(): global a a += 1 print(a) #11 bb() print(a) #1 aa() print(a) #4 f() print(a) #4 foo() print(a) #5 func() print(a) #11 结果： 11 1 4 4 5 11 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/12.python基础十二 迭代器、生成器.html":{"url":"python/python基础/12.python基础十二 迭代器、生成器.html","title":"python基础十二 迭代器、生成器","keywords":"","body":"python基础十二 迭代器、生成器 1.迭代器 1.1 含义 一个一个取值 1.2 可迭代对象 #Python中规定,只要是具有__iter__()方法就是可迭代对象 str.__iter__() list.__iter__() tuple.__iter__() dict.__iter__() set.__iter__() ⚠️可迭代对象能够重复取值 1.3 迭代器使用示例 //使用示例1 将迭代器赋值给一个变量，这样就能重复取值了 可迭代对象能够重复取值 lst = [1,1,2] 将可迭代对象转换成迭代器 l = lst.__iter__() print(l) #结果：，迭代器的内存空间地址 print(l.__next__()) #结果：1 print(l.__next__()) #结果：1 print(l.__next__()) #结果：2 print(1.__next__()) #结果：StopIteration 停止迭代，不能超过元素个数 ⚠️有多少个元素就只能next多少次 //使用示例1 单独执行迭代器，这样每次只能取第一个值 lst = [1,1,2,4,5] ⚠️以下两个lst.__iter__()迭代器内存地址，mac中显示的是一样，win本有的一样，有的不一样！！！ print(lst.__iter__()) # print(lst.__iter__()) # print(lst.__iter__().__next__()) #结果：1 #lst.__iter__() 是一个迭代器1 print(lst.__iter__().__next__()) #结果：1 #lst.__iter__() 是一个迭代器1 ⚠️这里迭代器是多个 1.4 for循环本质 ⚠️⚠️⚠️for循环就是一个迭代器 s = \"hehe\" for i in s: print (i) h e h e s = \"hehe\" s1 = s.__iter__() while True: print (s1.__next__()) 结果会报错如下：停止迭代 StopIteration s = \"hehe\" s1 = s.__iter__() while True: try: #尝试着运行一下缩进体中的内容，如果运行有问题用except接收一下 print (s1.__next__()) except StopIteration: break 结果如下： h e h e 1.5 python3中迭代器用法 //python1和python2中迭代器共同用法 lst = ['a',1,2,4,5] print (iter(lst)) print (iter(lst)) print (iter(lst).__next__()) print (iter(lst).__next__()) 结果如下： a a //python1中支持__iter__()方法 //python1中不支持 __next__()方法 2.生成器 2.1 生成器含义 控制循环迭代行为，一边循环一边计算的特殊程序 例如，创建一个包含100万元素的列表，不仅占空间。而且如果只访问前边几个元素，后续的元素空间就白白浪费了，生成器可以根据规则生成后续元素 2.2 生成器定义 1.基于函数实现的生成器 2.表达式实现生成器 2.3 生成器本质 生成器的本质就是一个迭代器 迭代器：文件句柄，通过数据转换，python自带提供 生成器：程序员自己实现 2.4 生成器使用示例 2.4.1 定义及创建生成器 #定义一个函数 def func(): print (1) return 5 print (func()) 1 5 ⚠️函数题中存在关键字yield就是定义一个生成器 #定义一个生成器 def func(): print (1) yield 5 print (func()) #⚠️这一步才算是创建一个生成器对象 2.4.2 语法及词法 ⚠️代码执行的时候有多个对象在工作 语法检查 词法检查 //示例1 def func(): print (foo) 返回结果为空 原因： 函数没有被调用，因此不报错 //示例1 def func(): if 2 > 1 结果： SyntaxError: invalid syntax 原因： 首先进行语法检查，语法错误 //示例2 def func(): foo() func() 结果： 报错,语法检查没有问题，但是词法检查有问题 2.4.3 生成器使用 2.4.3.1 生成器使用示例1 ⚠️⚠️⚠️生成器最大特点：惰性机制 //示例1 def func(): yield 1 #记录执行位置，当第一次next的时候记录，第二次next的时候就开始从下边取值 yield 1 yield 2 g = func() #获取的是生成器的内存地址 print (next(g)) #取值 1 print (next(g)) #取值 1 print (next(g)) #取值 2 print (next(g)) #取值 会报错 StopIteration 2.4.3.2 生成器使用示例2 //示例1 def func(): yield 1 #记录执行位置，当第一次next的时候记录，第二次next的时候就开始从下边取值 yield 1 yield 2 g = func() g1 = func() g1 = func() print (g) print (g1) print (g1) print (next(func())) #这是一个生成器1 print (next(func())) #这是一个生成器1 print (next(func())) #这是一个生成器2 1 1 1 ⚠️⚠️⚠️yield和return部分功能很像 def func(): yield print(next(func())) None #yeild后边不写内容返回的是None 2.4.3.3 生成器使用示例3 //示例2 def func(): #1 def foo(): #1 print (1) #2 yield foo #4 g = func().__next__() #5 print (g) #结果 .foo at 0x7fdb08082400> print (g()) #结果 1 None print (type(g)) #结果 🐷示例2执行过程 第一步，定义一个函数func()： 第1行 第二步，执行第5行的func()，创建一个生成器 第三步，执行第5行func().__next__()，进行去值，获取的是生成器的内存空间地址 第四步，执行第1、2行的foo函数，只是定义一个foo函数，没有实际调用 第五步，执行第4行的yield foo，yield foo获取的是foo函数的内存空间地址，并且返回给变量g 此时g就是foo函数的内存地址 第六步，print (g)，返回的是foo的函数内存地址 第七步，print (g())，g() == foo()，返回1，函数体中默认返回None 第八步，print (type(g))，返回的是foo函数的类型 2.4.3.4 生成器使用示例4 //示例4 def func(): yield 1,1,2,4,5 print (112) yield 1111 yield 666 g = func() print (next(g)) #结果 (1, 1, 2, 4, 5) print (next(g)) #结果 112 1111 2.5 时间 空间 2.5.1 空间换时间 //概念 例如，一个列表要产生50000个元素，一次性创建，这样就是用了空间换了时间 用一次性生成占用大量空间的元素换取快速读取时间 2.5.2 时间换空间 //概念 例如，还是一个列表创建50000个元素，这次不一次性创建，而是创建一个监控者，用一个元素由监控者取一个，这样就节省了大量内存空间，但是需要读取的时间变长 //代码示例 def func(): for i in range(1,50001): yield i g = func() print (next(g)) #结果1 print (next(g)) #结果1 这样就是需要一个然后读取一个，节省了内存空间地址，但是需要消耗大量时间 2.6 yield from yield from 逐个返回对象 //示例1 将元素整体返回 def func(): yield [1,1,2,4,5] #将元素整体返回 g = func() print (next(g)) [1, 1, 2, 4, 5] //示例1 将元素逐个返回 def func(): yield from [1,1,2,4,5] g = func() print (next(g)) print (next(g)) print (next(g)) 1 1 2 //示例2 多个yield，逐个返回一个yield的元素再返回下一个yield的 def func(): yield from [1,1,2] yield from ['a','b','c','d','e'] g = func() print (next(g)) print (next(g)) print (next(g)) print (next(g)) 1 1 2 a #yield总结 yield 能返回多个,以元组的形式存储 yield 能返回各种数据类型(Python的对象) yield 能够写多个并且都执行 yield 能够记录执行位置 yield 后边不写内容 默认返回None yield 都是将数据一次性返回 3.区分迭代器和生成器及迭代对象说明 #方法1 具有send()方法的就是一个生成器 #方法1 查看内存地址 //示例 lst = [1,1,2] print (lst.__iter__()) #结果 def func(): yield 1 print (func()) #结果 ⚠️⚠️⚠️ 生成器一定是一个迭代器，但是迭代器不一定是一个生成器 //迭代对象 具有__iter__()方法的就是一个可迭代对象 //迭代器: 具有__iter__() 和 __next__()方法就是一个迭代器 //生成器: 基于函数创建的生成器,函数体中必须存在yield 4.迭代器和生成器优缺点总结 #优点 节省空间 #缺点 1.不能直接使用元素 1.不能直观查看元素的个数 2.使用不灵活 4.稍微消耗时间 5.一次性执行，不能逆行执行 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/14.python基础十四 模块.html":{"url":"python/python基础/14.python基础十四 模块.html","title":"python基础十四 模块","keywords":"","body":"python基础十四 模块 重点 ##os模块 #文件夹相关 os.makedirs('dirname1/dirname2') 可生成多层递归目录 *** os.removedirs('dirname1') 若目录为空，则删除，并递归到上一级目录，如若也为空，则删除，依此类推 *** os.mkdir('dirname') 生成单级目录；相当于shell中mkdir dirname *** os.rmdir('dirname') 删除单级空目录，若目录不为空则无法删除，报错；相当于shell中rmdir dirname *** #文件相关 os.remove() 删除一个文件 *** os.rename(\"oldname\",\"newname\") 重命名文件/目录 *** #路径相关 os.path.abspath(path) 返回path规范化的绝对路径 *** os.path.split(path) 将path分割成目录和文件名二元组返回 *** os.path.exists(path) 如果path存在，返回True；如果path不存在，返回False *** os.path.isfile(path) 如果path是一个存在的文件，返回True。否则返回False *** os.path.isdir(path) 如果path是一个存在的目录，则返回True。否则返回False *** os.path.join(path1[, path2[, ...]]) 将多个路径组合后返回，第一个绝对路径之前的参数将被忽略 *** os.path.getsize(path) 返回path的大小 *** #sys模块 sys.path 返回模块的搜索路径，初始化时使用PYTHONPATH环境变量的值 *** 1. 模块介绍 py文件就是一个模块 2. 模块分类 2.1 内置模块 内置模块也叫标准库 2.2 第三方模块 别人写好的功能 2.3 自定义模块 自己写的特定功能 3. 模块作用 1.开发效率高，有大量的内置函数和模块 2.拿来主义，大量的第三方模块，拿来既能用，不需要知道原理 3.减少重复代码，分文件管理，有助于修改和维护 4. 模块使用 4.1 语法 import 模块名 4.2 模块的两种用法 1.当作普通模块执行 2.被当作脚本执行 5. 自定义模块 自定义模块使用示例 //非同级目录示例 1.在当前需要调用模块的py文件test.py的不同路径新建一个文件i.py，一会test.py调用这个文件i.py 2.在/Users/baixuebing/Desktop下创建一个i.py文件，文件内如下 print(\"非同级目录自定义模块路径导入练习\") a = 10 b = 20 3.test.py文件内容如下 import sys #需要导入sys模块 sys.path.append('/Users/baixuebing/Desktop') #这里写要导入的自定义模块的路径 from i import a,b #自定义模块名是i，导入a,b两个功能 print(a,b) #打印功能 非同级目录自定义模块路径导入练习 10 20 //同级目录示例 说明：test.py文件与自定义模块i.py在同一个路径下 from i import a,b print(a,b) 同级目录自定义模块导入练习 10 20 5.1 自定义模块特殊说明 应用场景： 1.现在有一个自定义模块i.py，文件内容如下 def login(): print('登陆') def register(): print('注册') print('自定义模块保留自定义内容不被调用') print(123456) 调用者文件test.py，文件内容如下 import sys from i import login login() 2.导入这个自定义模块并执行，返回结果如下，但是自定义模块中调用函数的123456不想被调用，需要做一下特殊处理，让调用者只能看到 ’自定义模块保留自定义内容不被调用‘、登陆、注册，不能看到123456 自定义模块保留自定义内容不被调用 123456 3.修改自定义模块i.py，在a()和b()的上方加入一行代码 if __name__ == \"__main__\": def a(): print('登陆') def register(): print('注册') print('自定义模块保留自定义内容不被调用') if __name__ == \"__main__\": #不可外传功能 print(123456) 4.调用者再次执行，结果如下，结果123456无法获取 自定义模块保留自定义内容不被调用 登陆 🌟🌟🌟 原因： 在当前文件i.py中执行__name__获取的值是'__main__' 当前文件i.py被当作模块导入时，__name__获取的是当前文件名 6. 模块导入 6.1 模块导入过程 1.将模块存储到当前名称空间中，可以使用globals查看 2.以模块的名字命名，并开辟一个独立空间 3.通过模块名来使用模块中的功能 6.2. 导入说明 6.2.1 全部导入 import 模块名 是将模块中所有的内容全部倒入 6.2.2 导入部分 from 模块名 import 功能1，功能2 从模块中导入部分功能 from 模块名 import 功能1 as 别名 6.3 模块导入注意点⚠️ 1.同一个模块，写多次，只执行一次 6.4 模块导入顺序 内存 --> 内置 --> sys.path 7. 模块路径 模块与py文件在同一路径可以直接调用 模块与py文件不在同一路径，需要导入sys模块及导入模块路径 import sys sys.path.append('路径') 8. 模块查找顺序 内存 --> 内置 --> sys.path 9. time模块 9.1 时间分类 9.1.1 时间戳 用于计算 通常的叫法,时间戳表示的是格林尼治时间是从1970年1月1日00:00:00开始按秒计算的偏移量。这个是实时变化的。我们运行“type(time.time())”，返回的是float类型 #获取时间戳 import time print(time.time()) 1569543159.206561 9.1.2 结构化时间 用于程序员获取数据结构 命名元组 #获取结构化时间 import time t = time.time() #获取时间戳 print(time.localtime(t)) #将时间戳转换为结构化时间 time.struct_time(tm_year=2019, tm_mon=9, tm_mday=27, tm_hour=8, tm_min=22, tm_sec=41, tm_wday=4, tm_yday=270, tm_isdst=0) 9.1.3 字符串时间 给用户查看的 python中时间日期格式化符号： %y 两位数的年份表示（00-99） %Y 四位数的年份表示（000-9999） %m 月份（01-12） %d 月内中的一天（0-31） %H 24小时制小时数（0-23） %I 12小时制小时数（01-12） %M 分钟数（00=59） %S 秒（00-59） %a 本地简化星期名称 %A 本地完整星期名称 %b 本地简化的月份名称 %B 本地完整的月份名称 %c 本地相应的日期表示和时间表示 %j 年内的一天（001-366） %p 本地A.M.或P.M.的等价符 %U 一年中的星期数（00-53）星期天为星期的开始 %w 星期（0-6），星期天为星期的开始 %W 一年中的星期数（00-53）星期一为星期的开始 %x 本地相应的日期表示 %X 本地相应的时间表示 %Z 当前时区的名称 %% %号本身 #获取字符串时间 import time print(time.strftime(\"%Y-%m-%d %X\")) 2017-09-27 08:18:32 9.2 三种时间相互转换 9.2.1 字符串时间结构化时间 import time str_time = \"2019-9-1 12:23:06\" print(time.strptime(str_time,\"%Y-%m-%d %H:%M:%S\")) # 将字符串时间转换成结构化时间 time.struct_time(tm_year=2019, tm_mon=9, tm_mday=1, tm_hour=12, tm_min=23, tm_sec=6, tm_wday=6, tm_yday=244, tm_isdst=-1) t = time.localtime() #先获取结构化时间 print(time.strftime(\"%Y-%m-%d %H:%M:%S\",t)) #将结构化时间转换成字符串时间 9.2.2 时间戳结构化时间 import time t = time.time() #获取时间戳 print(t) 1569543714.778055 print(time.localtime(t)) #将时间戳转成结构化时间 time.struct_time(tm_year=2019, tm_mon=9, tm_mday=27, tm_hour=8, tm_min=22, tm_sec=41, tm_wday=4, tm_yday=270, tm_isdst=0) t = time.localtime() #先获取结构化时间 print(time.mktime(t)) #将机构化时间转换成时间戳 1569564152.0 9.2.3 字符串时间时间戳 需要先转换为中间人结构化时间再转换，不能直接转化 字符串时间结构化时间时间戳 10. datetime模块 # import datetime ⚠️此写法不正确 1.获取当前时间，是一个对象，不是字符串 from datetime import datetime print(datetime.now()) 2017-10-03 18:58:09.455678 print(type(datetime.now())) 2.自定义时间 print(datetime(2016,11,11,11,11,11)) 2016-11-11 11:11:11 3.时间戳转换成对象 import time print(datetime.fromtimestamp(time.time())) 2017-10-07 18:27:43.683452 4.将对象转换成时间戳 print(datetime.timestamp(datetime.now())) 1570444141.19223 5.将对象转换成字符串 print(datetime.strftime(datetime.now(),\"%Y-%m-%d %H:%M:%S\")) 2017-10-07 18:29:50 6.将字符串转换成对象 print(datetime.strptime(\"2016/11/11\",\"%Y/%m/%d\")) 2016-11-11 00:00:00 7.对象时间与自定义时间做运算 print(datetime.now() - datetime(9999,11,1,12,13,14)) -2914660 days, 6:20:23.854611 8.计算从当前对象时间到某一天 from datetime import datetime,timedelta print(datetime.now()) print(datetime.now() - timedelta(days=1)) print(datetime.now() + timedelta(days=1)) 2017-10-07 18:37:18.013572 2017-10-06 18:37:18.013611 2017-10-08 18:37:18.013628 11. random模块 随机数 1.获取0-1之间的小数 import random random.random() #0-1之间的小数 2.获取范围的随机整数 random.randint(1,5) #获取1-5之间的整数 3.获取范围内的随机偶数 random.randrange(0,10,2) 4.获取列表中单个元素 lst = [1,2,3,4,5,6] random.choice(lst) 5.获取列表中指定个数元素 lst = [1,2,3,4,5,6] random.choices(lst,k=5) #随机获取5个数，会出现重复元素 random.sample(lst,k=5) #随机获取5个数，不会出现重复元素 6.打乱顺序 lst = [1,2,3,4,5,6,7,8] random.shuffle(lst) 12. sys模块 与python解释器做交互 1.获取系统路径 import sys sys.path 2.获取系统平台 sys.platform windowns --> win32 mac --> darwin 3.获取当前py文件路径 sys.argv #返回列表 4.获取python解释器版本 sys.version 5.退出码 sys.exit(1) #0是正常退出，可以修改 6.获取所有模块 sys.modules() 13. os模块 13.1 文件 1.修改文件名 import os os.rename(\"旧名\",\"新名\") 2.删除文件 os.remove(\"要删除的文件名\") 13.2 文件夹 1.创建文件夹 os.makedirs('a/b/c') #递归创建 os.mkdir('a') #单独创建 2.删除文件夹 os.removedirs('a') #递归删除 os.rmdir('a') #删除文件夹 3.查看文件夹 os.listdir() #查看当前路径下所有的文件 13.3 路径 1.获取路径 os.getcwd() #获取当前工作路径 2.切换路径 os.chdir() #切换路径 3.获取当前路径 os.curdir() 4.获取上级目录 os.pardir() 5.获取绝对路径 ⚠️重要 注意是当前路径下的文件或者文件夹 os.path.abspath('当前文件或者文件夹名') 6.路径分割 ⚠️只分一刀 获得的是元组 os.path.split('路径') 7.父级目录 ⚠️⚠️⚠️ 🌟 os.path.dirname('路径') 8.获取路径最外层 os.path.basename('路径') 9.将多个路径组合后返回，第一个绝对路径之前的参数将被忽略 🌟🌟🌟 os.path.join('路径1','路径2'.'路径3') 10.获取文件大小 os.path.getsize() is系列 1.判断路径是否存在 返回布尔值 os.path.exists() 2.判断是否是绝对路径 返回布尔值 os.path.isabs() 3.判断是否是存在的文件 os.path.isfile('绝对路径') 4.判断是否是目录 os.path.isdir() 13.4 其他 1.执行shell命令 os.system() os.popen('dir').read() 2.获取环境变量 os.environ() 14.hashlib模块 14.1 含义 摘要算法，加密算法 14.2 功能 加密，校验一致性 14.3 加密说明 1.内容相同，密码一定相同 2.加密的密文是不可逆的 3.明文-->字节-->密文 4.加密方法 md5、sha1、sha256、sha512 14.4 加密示例 import hashlib #导入hashlib模块 s = \"123abc\" md5 = hashlib.md5() #选择加密的方式，初始化一个加密 md5.update(s.encode(\"utf-8\")) #将要加密的内容添加到变量md5中 print(md5.hexdigest()) #进行加密 14.5 加盐 14.5.1 固定加盐 user = input(\"user:\") pwd = input(\"pwd:\") import hashlib md5 = hashlib.md5(\"abc\".encode(\"utf-8\")) #这里的abc就是盐 md5.update(pwd.encode(\"utf-8\")) print(md5.hexdigest()) 14.5.1 动态加盐 user = input(\"user:\") pwd = input(\"pwd:\") import hashlib md5 = hashlib.md5(user.encode(\"utf-8\")) #这里的user就是动态盐 md5.update(pwd.encode(\"utf-8\")) print(md5.hexdigest()) 15.collections模块 15.1 统计 🌟🌟🌟 //示例 统计列表中每个元素出现的次数 #方法1 for循环 lst = [1,1,2,5,6,7,7,9,99,99,1,3,7] dic = {} for i in lst: dic[i] = lst.count(i) print(dic) {1: 3, 2: 1, 5: 1, 6: 1, 7: 3, 9: 1, 99: 2, 3: 1} #方法2 collections记数 lst = [1,1,2,5,6,7,7,9,99,99,1,3,7] from collections import Counter print(dict(Counter(lst))) {1: 3, 2: 1, 5: 1, 6: 1, 7: 3, 9: 1, 99: 2, 3: 1} 15.2 有序字典 🌟🌟🌟 python2中使用 from collections import OrderedDict a = OrderedDict({\"key1\":1,\"key2\":2}) print(a) print(a[\"key1\"]) OrderedDict([('key1', 1), ('key2', 2)]) 1 15.3 默认字典 from collections import defaultdict dic = defaultdict(list) #括号中写不加括号的方法 例如列表只写list，不写list()，这里字典默认值就是空列表 dic['k1'].append(10) #指明字典的值为10 dic['k2'] #不指定字典的值，默认是空列表 print(dic) defaultdict(, {'k1': [10], 'k2': []}) //示例题 将列表中元素大于66的追加到字典的key1中，小于66的追加到字典的key2中 #方法1 lst = [11,22,33,44,55,77,88,99] dic = {\"key1\":[],\"key2\":[]} for i in lst: if i > 66: dic['key2'].append(i) else: dic['key1'].append(i) print(dic) {'key1': [11, 22, 33, 44, 55], 'key2': [77, 88, 99]} #方法2 lst = [11,22,33,44,55,77,88,99] dic = {} for i in lst: if i > 66: dic.setdefault('key2',[]).append(i) else: dic.setdefault('key1', []).append(i) print(dic) {'key1': [11, 22, 33, 44, 55], 'key2': [77, 88, 99]} #方法3 from collections import defaultdict lst = [11,22,33,44,55,77,88,99] dic = defaultdict(list) for i in lst: if i > 66: dic['key2'].append(i) else: dic['key1'].append(i) print(dic) defaultdict(, {'key1': [11, 22, 33, 44, 55], 'key2': [77, 88, 99]}) 15.4 双端队列 1.队列 先进先出 deque 🌟🌟🌟 from collections import deque lst = deque([11,22,33,44,55]) lst.appendleft(00) #从左侧开始追加 print(lst) deque([0, 11, 22, 33, 44, 55]) lst.popleft() #从左侧开始删除 print(lst) deque([22, 33, 44, 55]) 2.栈 先进后出 lst = [] lst.append(1) lst.append(2) lst.append(3) print(lst) lst.pop() print(lst) lst.pop() print(lst) lst.pop() 15.5 命名元组 namedtuple 🌟🌟🌟 from collections import namedtuple dg = namedtuple('name',[\"aa\",\"bb\",\"cc\"]) print(dg('hehe','haha','xixi')) name(aa='hehe', bb='haha', cc='xixi') 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/15.python基础十五 闭包.html":{"url":"python/python基础/15.python基础十五 闭包.html","title":"python基础十五 闭包","keywords":"","body":"python基础十五 闭包 1.闭包 1.1作用 保护数据安全，保护数据干净性 1.2 定义 1.在嵌套函数内，使用非全局变量(且不使用本层变量) 2.将嵌套函数返回 ⚠️不能加函数的() 1.3 闭包注意点⚠️ 1.⚠️⚠️⚠️ 没有将嵌套的函数返回也是一个闭包，但是这个闭包不能使用！！！ 2.闭包不能传可变类型数据 1.4 示例 //闭包示例1 def func(): a = 10 #自由变量 def foo(): print(a) return foo f = func() print(f.__closure__) #验证是否是闭包 (,) ⚠️在嵌套函数内，使用非全局变量(且不使用本层变量) //示例2 未返回嵌套函数值，虽然是一个闭包，但是不能使用 def func(): a = 10 def foo(): print (a) print (foo.__closure__) #(,) func() //示例3 def func(): a = 10 def foo(): print (a) return foo func()() #⚠️此时func() == foo == foo() func()() f = func() f() //示例4 ⚠️⚠️⚠️函数在接受参数的时候会在下边定义参数的变量 因此，这是一个闭包 def wrapper(a,b): #a = 2 ⚠️函数接受参数就相当于在函数中再次定义这个变量 #b = 3 ⚠️函数接受参数就相当于在函数中再次定义这个变量 def inner(): print (a) print (b) return inner a = 2 b = 3 ret = wrapper(a,b) print(ret.__closure__) #(, ) > 说明，虽然变量a和b是在wrapper同级定义的，但是wrapper中是接受ab两个参数的，会在wrapper下级定义ab两个变量 1.5 应用场景 1.装饰器 2.防止数据被误改动 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/16.python基础十六 推导式.html":{"url":"python/python基础/16.python基础十六 推导式.html","title":"python基础十六 推导式","keywords":"","body":"python基础十六 推导式 1.推导式 1.1 作用 做一些有规律的数据结构 1.2 列表推导式 普通循环 [加工后的变量 for循环] 筛选模式 [加工后的变量 for循环 条件] 1.2.1 普通循环 [变量 for循环] //代码示例1 要循环输出1-10 原先的代码 lst = [] for i in range(1,11): lst.append(i) print(lst) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 使用列表推导式 lst = [ i for i in range(1,11)] print (lst) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] //代码示例2 将1-10内的数的平方追加到列表中 原先代码 l1 = [] for i in range(1,11): i *= i l1.append(i) print (l1) [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] 使用列表推导式 l1 = [i*i for i in range(1,11)] print(l1) [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] 1.2.2 筛选模式 [加工后的变量 for循环 条件] //代码示例1 找出30以内可以被3整除的数 原先的代码 lst = [] for i in range(1,31): if i % 3 == 0: lst.append(i) print (lst) [3, 6, 9, 12, 15, 18, 21, 24, 27, 30] 列表推导式 f = [i for i in range(1,31) if i % 3 == 0] print (f) ⚠️推导式外边加括号就是返回生成器的内存空间地址 f = (i for i in range(1,31) if i % 3 == 0) print (f) at 0x7fa7281a7d00> 1.3 字典推导式 普通循环 筛选模式 1.3.1 普通循环 print({i:i+1 for i in range(3)}) {0: 1, 1: 2, 2: 3} 1.3.2 筛选模式 print({i:i+1 for i in range(3) if i > 1}) {加工后的变量:加工的后的变量 for循环 加工条件} {2: 3} 1.4 集合推导式 普通循环 筛选模式 1.4.1 普通循环 print({i for i in range(3)}) {0, 1, 2} 1.4.2 筛选模式 print({i for i in range(3) if i > 1}) {2} 1.5 生成器推导式 普通循环 筛选模式 1.5.1 普通模式 g = (i for i in range(3)) print(next(g)) print(next(g)) 0 1 1.5.2 筛选模式 g = (i for i in range(3) if i+1 == 2) print (next(g)) 1 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/17.python基础十七 匿名函数.html":{"url":"python/python基础/17.python基础十七 匿名函数.html","title":"python基础十七 匿名函数","keywords":"","body":"python基础十七 匿名函数 1. 定义 示例：给函数传两个参数并计算和 f = lambda a,b:a+b 其中 a,b表示形参，可以传多个，冒号后边的表示函数体中要执行的代码 2. lambda函数简单示例说明 //代码示例 给函数传两个参数并计算和 普通函数写法 def func(a,b): c = a + b return c print(func(1,2)) 3 匿名函数写法1 f = lambda a,b:a+b print(f(1,2)) 3 匿名函数写法2 print((lambda a,b:a+b)(1,2)) 3 3. lambda函数与普通函数对比说明 普通函数写法 def func(a,b): c = a + b return c print(func(1,2)) 匿名函数写法 print((lambda a,b:a+b)(1,2)) 1.lambda和def是一样的 2.lambda中的 a,b 和def中的（a,b）是一样的 3.lambda中的 a+b 和def中的 return a + b 是一样的 4.lambda中a,b是形参，a+b是返回值，即冒号前边的是形参，冒号后边的返回值 形参：可以接受位置参数、动态位置参数、默认参数、动态关键字参数 返回值：只能返回一个数据，如果想返回多个数据，需要用()括起来 4. 匿名函数风骚走位 4.1 lambda+列表 示例1 //示例1 这种写法结果是3个函数地址 print([lambda i:i+1 for i in range(3)]) [. at 0x7f9bf0068620>, . at 0x7f9bf00681e0>, . at 0x7f9bf0068048>] 拆分写法 lst = [] for i in range(3): def func(i): return i+1 lst.append(func) print(lst) [, , ] 示例1进阶版 //错误写法示例 g = [lambda i:i+1 for i in range(3)] #lambda后边的i与for循环中的i没有关系 print([em() for em in g]) 结果报错，因为lambda后的i是形参，em()没有传参，因此报错 拆分写法 lst = [] for i in range(3): def func(i): return i+1 lst.append(func) new_lst = [] for em in lst: new_lst.append(em()) #这里的em()就是func() 结果报错，因为em()没有传参 //正确写法示例 g = [lambda i:i+1 for i in range(3)] #lambda后边的i与for循环中的i没有关系 print([em(3) for em in g]) [4, 4, 4] 拆分写法 lst = [] for i in range(3): def func(i): return i+1 lst.append(func) new_lst = [] for em in lst: #此时lst = [func,func,func] new_lst.append(em(3)) #这里的em()就是func() print(new_lst) [4, 4, 4] 示例2 🦙🦙🦙这个题一般人能想到？？？ g = [lambda x:x*i for i in range(3)] for j in [2,10]: g1 = (em(3) for em in g) print([e+j for e in g1]) [16, 16, 16] 代码拆分 #g = [lambda x:x*i for i in range(3)]拆分如下 lst = [] #循环完后这里是3个函数 [func,func,func] for i in range(3): def func(x): return x*i lst.append(func) for j in [2,10]: #这里执行完后j就是10 def g1(): #生成器存放于g1中,先循环2，然后循环10，会覆盖 for em in lst: yield em(3) new_lst = [] for e in g1(): #g1()产生了一个生成器，一执行就触发for em in lst，lst是3个func，这里就是yield em(3)，执行3次func(3),就是执行3次return 3*2，因为i的for循环已经执行完成，最后的值i是2 new_lst.append(e+j) #6+10，循环3次 print(new_lst) [16, 16, 16] 4.2 lambda+生成器 //示例1 g = (lambda i:i+1 for i in range(3)) #lambda后边的i与for循环中的i没有关系 print([em(3) for em in g]) [4, 4, 4] #代码解析 lambda i:i+1与for i in range(3)没有任何关系！！！ 只是借助for循环执行了3次 return i+1 em(3)就是给i传递了参数，因此执行3次 i+1 拆分写法 def foo(): for j in range(3): def func(i): return i+1 yield func g = foo() lst = [] for i in g: #这里的i就是func lst.append(i(3)) print(lst) [4, 4, 4] //示例2 g = [lambda :i+1 for i in range(3)] print([em() for em in g]) [3, 3, 3] #g = [lambda :i+1 for i in range(3)]拆分后如下 g = [] #循环3次后，列表中是3个func [func,func,func] for i in range(3): def func(): return i+1 g.append(func) #print([em() for em in g])拆分后如下 new_lst = [] for em in g: #这里的g是[func,func,func] new_lst.append(em()) #em()就是调用函数func()，因为上边的for循环已经执行完成了，因此return i+1就是2+1=3,所以这里追加3次func()，func()就是执行return 2+1，所以结果是3次3 print(new_lst) 4.3 lambda+列表与lambda+生成器对比 //不传参示例 g = [lambda :i+1 for i in range(3)] print([em() for em in g]) [3, 3, 3] g = (lambda :i+1 for i in range(3)) print([em() for em in g]) [1, 2, 3] //传参示例 g = [lambda x:x*i for i in range(3)] print([em(3) for em in g]) [6, 6, 6] g = (lambda x:x*i for i in range(3)) print([em(3) for em in g]) [0, 3, 6] 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/18.python基础十八 内置函数.html":{"url":"python/python基础/18.python基础十八 内置函数.html","title":"python基础十八 内置函数","keywords":"","body":"python基础十八 内置函数 内置函数 1. 含义 python帮助我们写了很多的功能供使用 2. 了解函数 all() any() bytes() callable() chr() complex() divmod() eval() exec() frozenset() globals() hash() help() id() input() int() iter() locals() next() oct() ord() pow() repr() round() 2.1 all 判断元素是否都为True，全部为True才返回True print(all(['a','b','c'])) True print(all(['a','b','c',0])) False 2.2 any 判断元素中是否含有True，有一个True即为True print(any(['a','b','c',0])) True 2.3 bytes 字节串 print(bytes('呵呵',encoding='utf-8')) b'\\xe5\\x91\\xb5\\xe5\\x91\\xb5' 2.4 callable 判断是否可调用，返回布尔值 print(callable([1,1])) False def func(): pass print(callable(func)) True 2.5 chr 根据当前编码（unicode，兼容所有）查对应的内容 print (chr(15678)) 摎 2.6 ord 查看内容对应的编码 print (ord('摎')) 15678 2.7 complex 复数 print(complex(10)) (10+0j) 2.8 divmod 获取的是元组，第一个是商，第二个是余数 print(divmod(10,3)) (3, 1) 2.9 hash 查看内容是否可哈希 print(hash(111)) #结果111 print(hash([1,1,3])) #结果报错TypeError: unhashable type: 'list' 2.10 help 查看帮助 print (help(str)) 2.11bin 十进制转换成二进制 print(bin(10)) 0b1010 2.12 oct 十进制转换成八进制 print(oct(10)) 0o11 2.13 hex 十进制转换成十六进制 print(hex(10)) 0xa 2.14 int 其他进制转换为十进制 int(\"xxx\",16) 十六进制转换为10进制 int(\"xxx\",8) 八进制转换为10进制 2.15 pow 幂 print(pow(3,1)) 9 2.16 repr 显示数据类型 原形必漏 s = \"113\" s1 = 113 print(repr(s)) #原形必漏 '113' print(s1) #113 2.17 round 保留小数位，默认取值 print(round(1.431341314,3)) 2.18 frozenset 冻结集合 //创建可变集合 s={'a','b'} print(s) {'a', 'b'} 修改集合 s.add('c') print(s) {'a', 'b', 'c'} //创建不可变集合 s=frozenset('abc') print(s) frozenset({'b', 'c', 'a'}) print(type(s)) 尝试修改不可变集合 s.add('d') print(s) 结果报错 AttributeError: 'frozenset' object has no attribute 'add' 2.19 eval ⚠️禁用 eval会将字符串转成表达式并执行，比较危险 这样就可以利用执行系统命令，执行删除文件等操作，因此禁用 //代码示例1 eval函数会将字符串转换成表达式执行 msg = \"1+2+3\" print(eval(msg)) 6 //代码示例2 危险用法，可以执行用户输入的任何内容 如果用在了用户评论中，则用户评论输入的内容就会执行，例如输入死循环、删除等操作，非常危险 msg = \"input('>>>')\" print(eval(msg)) 2.20 exec ⚠️禁用 比较危险，msg中的任何代码都会执行 //代码示例 msg = \"\"\" def func(): print(\"这么牛逼\") func() \"\"\" print(exec(msg)) 这么牛逼 None 3. 重点函数 enumerate() open() range() len() str() list() tuple() dict() set() print() sum() abs() dir() zip() format() reversed() filter() map() sorted() max() min() reduce() 3.1 abs 绝对值 不管是正数还是负数都是正数 print(abs(-6)) print(abs(6)) 6 6 3.2 format 格式转换 1.对齐方式 s = \"你好\" s1 = format(s,\">10\") s1 = format(s,\" 3.3 enumerate 枚举 enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。 s = ['a','b','c'] lst = list(enumerate(s)) print (lst) [(0, 'a'), (1, 'b'), (1, 'c')] lst = list(enumerate(s,start=1)) print (lst) [(1, 'a'), (3, 'b'), (4, 'c')] 3.4 sum 求和 print(sum([1,1,3,4])) 10 3.5 print 打印 1.文件流 f = open('a','a',encoding=\"utf-8\") print ('hehe',file=f) 会在当前py文件目录下创建文件a，文件a中的内容为hehe 2.修改print默认换行 //print默认有换行符 print ('a') print ('b') a b //修改print默认换行符 print ('a',end=\"|\") print ('b') a|b //修改print默认分隔符 print默认以空格分隔 print ('a','b') a b print ('a','b',sep='?') a?b 3.6 zip 拉链 lst1 = [1,2,3,4,5] lst2 = [5,4,3,2,1] 将lst1和lst2中下标相同的元素组成一个新的结构 //lambda+map写法 print (list(map(lambda x,y:(x,y),lst1,lst2))) [(1, 5), (2, 4), (3, 3), (4, 2), (5, 1)] //list+zip写法 lst1 = [1,2,3,4,5] lst2 = [5,4,3,2,1] print (list(zip(lst1,lst2))) [(1, 5), (2, 4), (3, 3), (4, 2), (5, 1)] //卧槽 lst1 = [1,2,3,4,5] lst2 = [5,4,3,2,1] print (dict(zip(lst1,lst2))) {1: 5, 2: 4, 3: 3, 4: 2, 5: 1} 4.高阶函数 filter() map() reduce() 以上3个函数必须有条件和参数！！！ max() min() sorted() 4.1 filter 🌟🌟🌟 过滤 筛选列表中数字大于5的 lst = [1,2,3,5,66,7,8,9] 原先代码 new_lst = [] for i in lst: if i > 5: new_lst.append(i) print (new_lst) [66, 7, 8, 9] filter高阶函数写法 //写法1 lst = [1,2,3,5,66,7,8,9] def func(x): return x > 5 print (list(filter(func,lst))) [66, 7, 8, 9] //写法2 lst = [1,2,3,5,66,7,8,9] print (list(filter(lambda x:x>5,lst))) [66, 7, 8, 9] 4.2 map 🌟🌟🌟 映射 映射，将可迭代对象中每个元素执行函数功能 //示例1 将列表中的元素转换成字符串 lst = [1,2,3,4,5] new_lst = [] for i in lst: new_lst.append(str(i)) print (new_lst) ['1', '2', '3', '4', '5'] 高阶函数写法 lst = [1,2,3,4,5] print (list(map(str,lst))) ['1', '2', '3', '4', '5'] //示例2 将两个列表中下标相同的元素相加 原先代码 lst1 = [1,2,3] lst2 = [3,2,1] for i in range(len(lst1)): print (lst1[i] + lst2[i]) 4 4 4 高阶函数写法 //写法1 lst1 = [1,2,3] lst2 = [3,2,1] def func(x,y): return x+y print (list(map(func,lst1,lst2))) [4, 4, 4] //写法2 lst1 = [1,2,3] lst2 = [3,2,1] print (list(map(lambda x,y:x+y,lst1,lst2))) [4, 4, 4] //写法3 当两个列表中的元素个数不同时 lst1 = [1,2,3,4] lst2 = [3,2,1] lst3 = [9,8,7,6,5] print (list(map(lambda x,y,z:x+y+z,lst1,lst2,lst3))) [13, 12, 11] ⚠️只相加最短的 4.3 reduce 🌟🌟🌟 累计算 lst = [1,2,3,4,5] from functools import reduce def func(x,y): return x+y print(reduce(func,lst)) 15 累计算过程 1.将1和2同时赋予x和y，此时x为3，将3赋予y,此时x为6，将4赋予y,此时x为10，将5赋予y，最后x和y相加 //lambda写法 lst = [1,2,3,4,5] from functools import reduce print (reduce(lambda x,y:x+y,lst)) 15 4.4 sorted 排序 用于排序 对以下列表排序 lst = [1,2,9,5,7,8,-6] //写法1 lst = [1,2,9,5,7,8,-6] lst.sort() #⚠️原地修改 print (lst) [-6, 1, 2, 5, 7, 8, 9] //写法2 lst = [1,2,9,5,7,8,-6] print (sorted(lst)) #⚠️新开内存空间 [-6, 1, 2, 5, 7, 8, 9] 对字符串进行排序 print (sorted('hehe,ggsimida')) #升序 [',', 'a', 'd', 'e', 'e', 'g', 'g', 'h', 'h', 'i', 'i', 'm', 's'] print (sorted('hehe,ggsimida',reverse=True)) #降序 ['s', 'm', 'i', 'i', 'h', 'h', 'g', 'g', 'e', 'e', 'd', 'a', ','] 高阶函数写法 按照长度进行排序 //写法1 lst = ['你好啊','呵呵','不好理解','啊'] print (sorted(lst,key=len)) ['啊', '呵呵', '你好啊', '不好理解'] ⚠️sorted这里要先写操作对象名，然后指定key，根据什么进行排序 //写法2 lst = ['你好啊','呵呵','不好理解','啊'] print (sorted(lst,key=lambda x:len(x))) ['啊', '呵呵', '你好啊', '不好理解'] 4.5 max() 最大 min()最小 print (max([1,2,3,5,6,-8])) 6 print (max([1,2,3,5,6,-8],key=abs)) #不管正负数，选择最大 dic = {'a':3,'b':2,'c':1} print (max(dic,key=lambda x:dic[x])) #按值排序拿到键 a print (min([1,2,3,5,6,-8])) 8 print (min([1,2,3,5,6,-8],key=abs)) #不管正负数，选择最小 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/19.python基础十九 序列化.html":{"url":"python/python基础/19.python基础十九 序列化.html","title":"python基础十九 序列化","keywords":"","body":"python基础十九 序列化 1. 含义 将一个数据类型转换成另一个数据类型 2. 分类 2.1 json 转换成字符串 dump load 用于文件写入存储 dumps(序列) loads(反序列) 用于网络传输 //dumps、loads用法 🌟列表 import json lst = [1,2,3] a = json.dumps(lst) #将列表转换为字符串 print(a) #[1, 2, 3] print(type(a)) # b = json.loads(a) #将字符串转换为列表 print(b) #[1, 2, 3] print(type(b)) # ⚠️列表中有中文 lst = ['呵呵','哈哈'] a = json.dumps(a) print(a) #[\"\\u5475\\u5475\", \"\\u54c8\\u54c8\"]，直接转中文有问题 加参数ensure_ascii=False解决 lst = ['呵呵','哈哈'] a = json.dumps(lst,ensure_ascii=False) print(a) #[\"呵呵\", \"哈哈\"] 🌟字典 import json dic = {\"key\":1,\"key2\":3} a = json.dumps(dic) #将字典转换成字符串 print(a) print(type(a)) {\"key\": 1, \"key2\": 3} b = json.loads(a) #将字符串转换为字典 print(b) print(type(b)) {'key': 1, 'key2': 3} print(json.loads(a)['key']) #字典取值 1 2.2 pickle 几乎支持python中所有的对象(不支持lambda) 转换成字节 pickle写入多行时自动带有换行 dump load 用于文件写入存储 dumps loads 用于网络传输 //将函数转换为字节 import pickle def func(): print(111) a = pickle.dumps(func) #将函数转换为字节 print(a) print(type(a)) b'\\x80\\x03c__main__\\nfunc\\nq\\x00.' b = pickle.loads(a) #将字节转换为函数 b() print(type(b)) 111 //将元组转换为字节 tu = (1,2,3,4,5) import pickle a = pickle.dumps(tu) #将元组转换为字节 print(a) b'\\x80\\x03(K\\x01K\\x02K\\x03K\\x04K\\x05tq\\x00.' b = pickle.loads(a) #将字节转换为元组 print(b) (1, 2, 3, 4, 5) 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/20.python基础二十 正则表达式.html":{"url":"python/python基础/20.python基础二十 正则表达式.html","title":"python基础二十 正则表达式","keywords":"","body":"python基础二十 正则表达式 1.正则表达式说明 正则就是用一些具有特殊含义的符号组合到一起去匹配相应的内容的方法，在python中，使用正则需要导入re模块正则表达式模式被编译成一系列的字节码，然后用c编写的匹配引擎执行 正则表达式元字符 元字符 匹配内容 \\w 匹配字母（包含中文）或数字或下划线 \\W 匹配非字母（包含中文）或数字或下划线 \\s 匹配任意的空白符 \\S 匹配任意非空白符 \\d 匹配数字 \\D 匹配非数字 \\A 从字符串开头匹配 \\z 匹配字符串的结束，如果是换行，只匹配到换行前的结果 \\n 匹配一个换行符 \\t 匹配一个制表符 ^ 匹配字符串的开始 $ 匹配字符串的结尾 . 匹配任意字符，除了换行符，当re.DOTALL标记被指定时，则可以匹配包括换行符的任意字符。 [...] 匹配字符组中的字符 ... 匹配除了字符组中的字符的所有字符 * 匹配0个或者多个左边的字符。 + 匹配一个或者多个左边的字符。 ？ 匹配0个或者1个左边的字符，非贪婪方式。 {n} 精准匹配n个前面的表达式。 {n,m} 匹配n到m次由前面的正则表达式定义的片段，贪婪方式 ab 匹配a或者b () 匹配括号内的表达式，也表示一个组 2.匹配模式 2.1字符串常用操作 s1 = 'python正则练习' print(s1.find('python')) 0 print(s1.find('正则')) 6 print(s1.find('abc')) -1 2.2正则匹配示例 \\w 匹配中文、字母、数字、下划线 import re s = 'python-正则表达式 练习_1.11' print(re.findall('\\w',s)) 结果： ['p', 'y', 't', 'h', 'o', 'n', '正', '则', '表', '达', '式', '练', '习', '_', '1', '1', '1'] \\W 和\\w相反，不匹配中文、字母、数字、下划线 import re s = 'python-正则表达式 练习_1.11' print(re.findall('\\W',s)) 结果： ['-', ' ', ' ', '.'] \\s 匹配任意空白符 import re s = 'python-正则表达式 练习_1.11' print(re.findall('\\s',s)) 结果，匹配到了练习前边的两个空格： [' ', ' '] \\d 匹配数字 import re s = 'python-正则表达式 练习_1.11' print(re.findall('\\d',s)) 结果： ['1', '1', '1'] \\D 与\\d相反，匹配非数字 import re s = 'python-正则表达式 练习_1.11' print(re.findall('\\D',s)) 结果： ['p', 'y', 't', 'h', 'o', 'n', '-', '正', '则', '表', '达', '式', ' ', ' ', '练', '习', '_', '.'] \\A与^ 以什么开头 import re s = 'python-正则表达式 练习_1.11' print(re.findall('\\Apython',s)) print(re.findall('^python',s)) 结果： ['python'] \\Z与$ 以什么结尾 import re s = 'python-正则表达式 练习_1.11' print(re.findall('1.11\\Z',s)) print(re.findall('1.11$',s)) 结果： ['1.11'] \\n 匹配换行符 import re s = 'python-正则表达式 \\n\\t练习_1.11' print(re.findall('\\n',s)) 结果： ['\\n'] \\t 匹配制表符 import re s = 'python-正则表达式 \\n\\t练习_1.11' print(re.findall('\\t',s)) 结果： ['\\t'] 3.匹配方式 . 匹配除换行符外的任意字符 import re s = 'python-正则表达式 \\n\\t练习_1.11' print(re.findall('.',s)) 结果： ['p', 'y', 't', 'h', 'o', 'n', '-', '正', '则', '表', '达', '式', ' ', ' ', '\\t', '练', '习', '_', '1', '.', '1', '1'] . 如果加了DOTALL标记就可以匹配任意字符 import re s = 'python-正则表达式 \\n\\t练习_1.11' print(re.findall('.',s,re.DOTALL)) 结果，可以看到加了DOTALL标志就匹配到了.原本无法匹配的换行符\\t ['p', 'y', 't', 'h', 'o', 'n', '-', '正', '则', '表', '达', '式', ' ', ' ', '\\n', '\\t', '练', '习', '_', '1', '.', '1', '1'] ? 匹配前边的元素出现0个或者1个 import re s = 'a-b-ab-abab-ababab-ababc' print(re.findall('ab?',s)) 结果，匹配到了全部的8个连续的ab，还可以匹配到一个a，因为b可以没有 ['a', 'ab', 'ab', 'ab', 'ab', 'ab', 'ab', 'ab', 'ab'] * 匹配前边的元素出现0个或者多个(贪婪匹配) import re s = 'a-b-ab-abab' print(re.findall('ab*',s)) 结果： ['a', 'ab', 'ab', 'ab'] + 匹配前边的元素出现1个或者多个(贪婪匹配) import re s = 'a-b-ab-abab' print(re.findall('ab+',s)) 结果： ['ab', 'ab', 'ab'] {n,m} 匹配前边的元素出现n到m个 import re s = 'aa-bb-aaabb-aaaaab' print(re.findall('aaa{1,3}',s)) 结果： ['aaa', 'aaaaa'] #其他匹配 {n} #前边的字符出现n次 {n,} #前边的字符最少出现n次 {,m} #前边的字符最多出现m次 .* 匹配任意内容0个或者多个 import re s = 'aa-bb-aaabb-aaaaab' print(re.findall('b.*',s)) 结果： ['bb-aaabb-aaaaab'] .? 匹配任意内容1个或者多个 import re s = 'ab-bb-aab-aaaaab' print(re.findall('a.?b',s)) 结果： ['ab', 'aab', 'aab'] [] 范围匹配 import re s = 'ab-bb-aab-123' print(re.findall('[a-z]',s)) 结果： ['a', 'b', 'b', 'b', 'a', 'a', 'b'] 与范围匹配相反，不匹配中括号中的内容 import re s = 'ab-bb-aab-123' print(re.findall('[^a-z]',s)) 结果： ['-', '-', '-', '1', '2', '3'] 4.常用方法 4.1findall 全部找到并返回一个列表 import re s = 'ab-bb-aab-abc-abbc' print(re.findall('abc',s)) ['abc'] 4.2search 从字符串任意位置进行匹配，查找到一个就停止 返回的是一个对象，获取匹配内容必须使用.group() import re s = 'ab-bb-abc-abc-abbc' print(re.search('abc',s)) 结果，如果不加.group()获取匹配内容，返回的是一个对象 #使用.group()方法获取匹配内容 print(re.search('abc',s).group()) abc 4.3match 从字符串开始位置进行匹配 import re s = 'ab-bb-abc-abc-abbc' print(re.match('ab ',s).group()) ab #以上示例中必须以a或者ab开始查看，否则会报错 print(re.match('bb ',s).group()) AttributeError: 'NoneType' object has no attribute 'group' 4.4split 分隔，可按照任意分隔符进行分隔 import re s = 'ab-bb-abc-abc-abbc' print(re.split('bb',s)) #以bb为分隔符 结果： ['ab-', '-abc-abc-a', 'c'] 4.5sub 替换 import re s = 'ab-bb-abc-abc-abbc' print(re.sub('bb','呵呵',s)) #将bb替换为呵呵 结果： ab-呵呵-abc-abc-a呵呵c 4.6compile 定义匹配规则 import re s = 'ab-123-abc-abc-a123bbc' obj = re.compile('\\d{2}') #定义匹配规则，数字出现2次 print(obj.findall(s)) 结果： ['12', '12'] 4.7finditer 返回一个迭代器 格式 re.finditer('匹配的内容',操作的对象) import re s = 'ab-123-abc-abc-a123bbc' g = re.finditer('ab',s) #'ab'为匹配的内容，s为操作的对象 print(next(g).group()) 结果： ab 4.8给分组()起名字 格式 (?P) import re s = 'ab-123-abc-abc-a123bbc' ret = re.search('(?P)abc',s) #给分组起名为test_abc print(ret.group()) 结果： abc 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/21.python基础二十一 logging日志.html":{"url":"python/python基础/21.python基础二十一 logging日志.html","title":"python基础二十一 logging日志","keywords":"","body":"python基础二十一 logging日志 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/22.python基础二十二 包.html":{"url":"python/python基础/22.python基础二十二 包.html","title":"python基础二十二 包","keywords":"","body":"python基础二十二 包 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/23.python基础二十三 异常处理.html":{"url":"python/python基础/23.python基础二十三 异常处理.html","title":"python基础二十三 异常处理","keywords":"","body":"python基础二十三 异常处理 1.异常和错误 1.1错误 1.1.1语法错误 #if后边没有加冒号，属于语法错误，无法通过python解释器，必须运行前修改 num = 10 if num == 11 print('ok') 结果报错： SyntaxError: invalid syntax 1.1.2逻辑错误 #除数为0 num = 10 print(num/0) 结果报错： ZeroDivisionError: division by zero 1.2异常 什么是异常？ 异常即是一个事件，该事件会在程序执行过程中发生，影响了程序的正常执行。 一般情况下，在Python无法正常处理程序时就会发生一个异常。 异常是Python对象，表示一个错误。 当Python脚本发生异常时我们需要捕获处理它，否则程序会终止执行。 1.3python中异常的类 错误示例 #触发IndexError: 索引超出范围 lst = [1,2,3] print(lst[5]) 结果报错： IndexError: list index out of range #触发KeyError: 字典中没有此键 dic = {'k1':1,'k2':2} print(dic['k3']) 结果报错： KeyError: 'k3' 常见异常 异常名称 描述 BaseException 所有异常的基类 SystemExit 解释器请求退出 KeyboardInterrupt 用户中断执行(通常是输入^C) Exception 常规错误的基类 StopIteration 迭代器没有更多的值 GeneratorExit 生成器(generator)发生异常来通知退出 StandardError 所有的内建标准异常的基类 ArithmeticError 所有数值计算错误的基类 FloatingPointError 浮点计算错误 OverflowError 数值运算超出最大限制 ZeroDivisionError 除(或取模)零 (所有数据类型) AssertionError 断言语句失败 AttributeError 对象没有这个属性 EOFError 没有内建输入,到达EOF 标记 EnvironmentError 操作系统错误的基类 IOError 输入/输出操作失败 OSError 操作系统错误 WindowsError 系统调用失败 ImportError 导入模块/对象失败 LookupError 无效数据查询的基类 IndexError 序列中没有此索引(index) KeyError 映射中没有这个键 MemoryError 内存溢出错误(对于Python 解释器不是致命的) NameError 未声明/初始化对象 (没有属性) UnboundLocalError 访问未初始化的本地变量 ReferenceError 弱引用(Weak reference)试图访问已经垃圾回收了的对象 RuntimeError 一般的运行时错误 NotImplementedError 尚未实现的方法 SyntaxError Python 语法错误 IndentationError 缩进错误 TabError Tab 和空格混用 SystemError 一般的解释器系统错误 TypeError 对类型无效的操作 ValueError 传入无效的参数 UnicodeError Unicode 相关的错误 UnicodeDecodeError Unicode 解码时的错误 UnicodeEncodeError Unicode 编码时错误 UnicodeTranslateError Unicode 转换时错误 Warning 警告的基类 DeprecationWarning 关于被弃用的特征的警告 FutureWarning 关于构造将来语义会有改变的警告 OverflowWarning 旧的关于自动提升为长整型(long)的警告 PendingDeprecationWarning 关于特性将会被废弃的警告 RuntimeWarning 可疑的运行时行为(runtime behavior)的警告 SyntaxWarning 可疑的语法的警告 UserWarning 用户代码生成的警告 2.异常处理 捕捉异常可以使用try/except语句。 try/except语句用来检测try语句块中的错误，从而让except语句捕获异常信息并处理。 如果你不想在异常发生时结束你的程序，只需在try里捕获它。 2.1try/except语句 语法 try: 被检测的代码块 except 异常类型： try中一旦检测到异常，就执行这里的代码 2.2try/except...else语句 语法 try: 被检测的代码块 except 异常类型： try中一旦检测到异常，就执行这里的代码 else: 没有发生异常执行的代码 try的工作原理是，当开始一个try语句后，python就在当前程序的上下文中作标记，这样当异常出现时就可以回到这里，try子句先执行，接下来会发生什么依赖于执行时是否出现异常。 如果当try后的语句执行时发生异常，python就跳回到try并执行第一个匹配该异常的except子句，异常处理完毕，控制流就通过整个try语句（除非在处理异常时又引发新的异常）。 如果在try后的语句里发生了异常，却没有匹配的except子句，异常将被递交到上层的try，或者到程序的最上层（这样将结束程序，并打印默认的出错信息）。 如果在try子句执行时没有发生异常，python将执行else语句后的语句（如果有else的话），然后控制流通过整个try语句。 正常运行示例，打开一个文件test.py，在该文件中写入以下内容，且并未发生异常： #!/usr/bin/python # -*- coding: UTF-8 -*- try: fh = open(\"testfile\", \"w\") fh.write(\"这是一个测试文件，用于测试异常!!\") except IOError: print(\"Error: 没有找到文件或读取文件失败\") else: print(\"内容写入文件成功\") fh.close() 运行结果： $ python3 test.py 内容写入文件成功 $ cat testfile # 查看写入的内容 这是一个测试文件，用于测试异常!! 异常运行示例，还是运行以上文件，但文件没有写入权限，发生了异常 先取消test.py文件的执行权限 $ python3 test.py Error: 没有找到文件或读取文件失败 2.3try-finally 语句 try-finally 语句无论是否发生异常都将执行最后的代码。 语法 try: finally: #退出try时总会执行 raise 示例 #!/usr/bin/python # -*- coding: UTF-8 -*- 代码写法一 try: fh = open(\"testfile\", \"w\") fh.write(\"这是一个测试文件，用于测试异常!!\") finally: print(\"Error: 没有找到文件或读取文件失败\") 代码写法二 属于异常嵌套 try: fh = open(\"testfile\", \"w\") try: fh.write(\"这是一个测试文件，用于测试异常!!\") finally: print(\"关闭文件\") fh.close() except IOError: print(\"Error: 没有找到文件或读取文件失败\") 如果文件没有可写权限，会报错 $ python3 test.py Error: 没有找到文件或读取文件失败 当在try块中抛出一个异常，立即执行finally块代码。 finally块中的所有语句执行后，异常被再次触发，并执行except块代码。 参数的内容不同于异常。 2.4万能异常 Exception exception可以捕获所有异常 示例，将字符串转换为整型，会报错 s1 = 'hello' try: int(s1) except Exception as e: print(e) 结果： invalid literal for int() with base 10: 'hello' 2.5异常捕获嵌套示例 a = int(input(\"请输入除数>>>\")) b = int(input(\"请输入被除数>>>\")) try: print(a/b) except Exception: try: b = int(input(\"被除数为0，请重新输入被除数>>>\")) print(a/b) except ZeroDivisionError: print(\"被除数能为0？？？，滚吧！！！\") 2.6raise抛出异常 语法 raise [异常类型[(异常原因)]] 其中，用 [] 括起来的为可选参数，其作用是指定抛出的异常名称，以及异常信息的相关描述。如果可选参数全部省略，则 raise 会把当前错误原样抛出；如果仅省略 (异常原因)，则在抛出异常时，将不附带任何的异常描述信息。 也就是说，raise 语句有如下三种常用的用法： raise：单独一个 raise。该语句引发当前上下文中捕获的异常（比如在 except 块中），或默认引发 RuntimeError 异常。 raise 异常类名称：raise 后带一个异常类名称。该语句引发指定异常类的默认实例。 raise 异常类名称(描述信息)：在引发指定异常的同时，附带异常的描述信息。 上面三种用法最终都是要引发一个异常实例（即使指定的是异常类，实际上也是引发该类的默认实例），raise 语句每次只能引发一个异常实例。 2.6.1 raise def main(): try: # 使用try...except来捕捉异常 # 此时即使程序出现异常，也不会传播给main函数 mtd(3) except Exception as e: print('程序出现异常:', e) # 不使用try...except捕捉异常，异常会传播出来导致程序中止 mtd(3) def mtd(a): if a > 0: raise main() 程序运行结果： 程序出现异常: No active exception to reraise raise RuntimeError: No active exception to reraise 2.6.2 raise 异常类名称 def main(): try: # 使用try...except来捕捉异常 # 此时即使程序出现异常，也不会传播给main函数 mtd(3) except Exception as e: print('程序出现异常:', e) # 不使用try...except捕捉异常，异常会传播出来导致程序中止 mtd(3) def mtd(a): if a > 0: raise ValueError main() 程序运行结果： 程序出现异常: raise ValueError ValueError 2.6.3 raise异常类名称(描述信息) def main(): try: # 使用try...except来捕捉异常 # 此时即使程序出现异常，也不会传播给main函数 mtd(3) except Exception as e: print('程序出现异常:', e) # 不使用try...except捕捉异常，异常会传播出来导致程序中止 mtd(3) def mtd(a): if a > 0: raise ValueError(\"a的值大于0，不符合要求\") main() 程序运行结果： 程序出现异常: a的值大于0，不符合要求 raise ValueError(\"a的值大于0，不符合要求\") ValueError: a的值大于0，不符合要求 2.7自定义异常 可以通过创建一个新的异常类来拥有自己的异常。异常类继承自 Exception 类，可以直接继承，或者间接继承，例如: class MyError(Exception): def __init__(self, value): self.value = value def __str__(self): return repr(self.value) try: raise MyError(3 * 2) except MyError as e: print(f'这是我自定义的异常，自定义运算结果是{e.value}') 程序运行结果： 这是我自定义的异常，自定义运算结果是6 2.8assert断言 Python assert（断言）用于判断一个表达式，在表达式条件为 false 的时候触发异常。 断言可以在条件不满足程序运行的情况下直接返回错误，而不必等待程序运行后出现崩溃的情况，例如我们的代码只能在 Linux 系统下运行，可以先判断当前系统是否符合条件。 语法 assert 异常类型 等价于 if not expression: raise AssertionError assert后边可以紧跟参数 assert expression [, arguments] 等价于 if not expression: raise AssertionError(arguments) 使用示例 #使用示例1，这段代码只能在linux系统中运行 import sys assert ('linux' in sys.platform), \"该代码只能在Linux下执行\" #使用示例2 assert 1 == 2 结果： AssertionError >>> assert True # 条件为true正常执行 >>> assert False # 条件为false触发异常 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/24.1python基础二十四 面向对象初识.html":{"url":"python/python基础/24.1python基础二十四 面向对象初识.html","title":"面向对象初识","keywords":"","body":"python基础二十四 面向对象初识 1.面向过程与面向对象 1.1什么是面向过程？ 1.1.1面向过程概念 在未学习面向对象之前写的代码都算是面向过程 例如，想要实现一个功能，分析出解决问题所需要的步骤，然后用代码或者函数逐一实现，并按照代码顺序调用，这就是面向过程 1.1.2面过程优缺点 优点 性能比面向对象高，因为类调用时需要实例化，开销比较大，比较消耗资源;比如单片机、嵌入式开发、Linux/Unix等一般采用面向过程开发，性能是最重要的因素 缺点 维护性、复用行、扩展性较差 1.2什么是面向对象？ 1.2.1面向对象概念 面向对象的程序设计的核心是对象（上帝式思维），要理解对象为何物，必须把自己当成上帝，上帝眼里世间存在的万物皆为对象，不存在的也可以创造出来 ⾯向对象思维, 要⾃⼰建立对象. ⾃⼰建立场景. 你是就是⾯向对象世界中的上帝. 你想让⻋⼲嘛就⼲嘛. 你想让⼈⼲嘛⼈就能⼲嘛 1.2.2面向对象优缺点 优点 是一类相似功能函数的集合,使你的代码更清晰化，更合理化 易维护、易复用、易扩展，由于面向对象有封装、继承、多态性的特性，可以设计出低耦合的系统，使系统更加灵活、更加易于维护 缺点 性能比面向过程低 1.2.3面向对象特点 特点 1.程序设计的重点在于数据而不是过程； 2.程序被划分为所谓的对象； 3.数据结构为表现对象的特性而设计； 4.函数作为对某个对象数据的操作，与数据结构紧密的结合在一起； 5.数据被隐藏起来，不能为外部函数访问； 6.对象之间可以通过函数沟通； 7.新的数据和函数可以在需要的时候轻而易举的添加进来； 8.在程序设计过程中遵循由下至上（bottom-up）的设计方法。 2.类与对象 2.1什么是类？ 2.1.1类的概念 对象的抽象，一类事物的总称 具有相同属性和功能的一类事物 2.1.2类的说明 类：就是具有相同属性和功能的一类事物，比如，狗类、猫类、人类 狗类中的金毛、猫类中的橘猫、人类中的男人、女人就是具体的对象 汽车，车有轮胎、发动机、方向盘等等，车就是类 人，人有思想、名字、年龄、爱好、性别，人就是类 2.2什么是对象？ 2.2.1对象的概念 类的具象，即对象为类的具体实现，通过类可以创建对象 2.2.2对象的说明 对象：就是类的具体表现形式，例如狗类中的金毛、猫类中的橘猫、人类中的男人、女人就是具体的对象 3.类操作 3.1创建类 语法 class 类名(): 属性 方法 代码示例 //创建一个人类，人类有属性姓名、年龄、爱好，人类有方法玩 class Person(): name = \"呵呵\" age = 20 hobby = \"玩\" def play(self): #这里的self是固定写法 print(\"人喜欢玩\") 3.1.1类属性 上述代码中的name、age、hobby就是类属性，属于类中的全局属性，后续还有传参方式的私有属性 3.1.2类方法 将函数写在类中加上默认参数self就是类中的方法，self不是固定叫self，只不过大家约定俗称叫self 上述代码中的函数play就是类方法，self代表类实例对象本身，⚠️不是类本身 3.2类名的操作 3.2.1类名操作静态属性 方式一 类名.__dict__() 查看类中所有内容 类名.__dict__()只能做查看操作，不能修改、删除 class Person(): name = \"呵呵\" age = 20 hobby = \"玩\" def play(self): print(\"人喜欢玩\") #查看类中所有的内容 print(Person.__dict__) 结果： {'__module__': '__main__', 'name': '呵呵', 'age': 20, 'hobby': '玩', 'play': , '__dict__': , '__weakref__': , '__doc__': None} 方式二 万能的点 . 操作单个属性(增删改查) 万能的点可以做增、删、改、查操作 class Person(): name = \"呵呵\" age = 20 hobby = \"玩\" def play(self): print(\"人喜欢玩\") #增操作 增加类属性 Person.weight = 100 print(Person.weight) 结果： 100 #删操作 删除类属性 del Person.name print(Person.name) 结果： AttributeError: type object 'Person' has no attribute 'name' #改操作 修改类属性 Person.name = \"哈哈\" print(Person.name) 结果： 哈哈 #查操作 查看类属性 print(Person.name) 结果： 呵呵 3.2.2类名操作动态方法 ⚠️除了类中的属性和类方法之外，一般都是通过对象名操作 class Person(): name = \"呵呵\" age = 20 hobby = \"玩\" def play(self): print(\"人喜欢玩\") Person.play(1) #1是随便传的一个参数，因为类中方法必须有一个参数 结果： 人喜欢玩 3.2.3增加类的静态属性 //类外增加 class Person: def __init__(self,name): self.name = name def func(self,sex): self.sex = sex def func1(self): Person.bbb = 'ccc' Person.aaa = '小明' print(Person.__dict__) 结果： {'__module__': '__main__', '__init__': , 'func': , 'func1': , '__dict__': , '__weakref__': , '__doc__': None, 'aaa': '小明'} 4.对象操作 4.1创建对象 对象是从类中出来的，只要是类名加上（），这就是一个实例化过程，这个就会实例化一个对象。 class Person(): name = \"呵呵\" age = 20 hobby = \"玩\" def play(self): print(\"人喜欢玩\") man = Person() #实例化对象 print(man) 实例化对象发生的事情 1.在内存中开辟了一个对象空间。 2.自动执行类中的__init__方法，并将这个对象空间（内存地址）传给了__init__方法的第一个位置参数self。 3.在__init__ 方法中通过self给对象空间添加属性。 以下为代码示例 class Person(): #self和man指向的是同一个内存地址同一个空间，下面就是通过self给这个对象空间封装四个属性 def __init__(self,name,age,sex): self.name = name self.age = age self.sex = sex def a(self): print(f\"我叫{self.name},我今年{self.age}了,我是{self.sex}的\") man = Person(\"小明\",20,'男') #实例化对象，man现在就是Person类的实例化对象 man.a() #调用类中的方法 结果： 我叫小明,我今年20了,我是男的 4.2对象的操作 4.2.1对象名操作对象空间属性 方式一 对象名查看对象中所有属性 对象名.__dict__ class Person(): def __init__(self,name,age,sex): self.name = name self.age = age self.sex = sex def a(self): print(f\"我叫{self.name},我今年{self.age}了,我是{self.sex}的\") man = Person(\"小明\",20,'男') print(man.__dict__) 结果： {'name': '小明', 'age': 20, 'sex': '男'} 方式二 万能的点 . 万能的点可以做增、删、改、查操作 class Person(): def __init__(self,name,age,sex): self.name = name self.age = age self.sex = sex def a(self): print(f\"我叫{self.name},我今年{self.age}了,我是{self.sex}的\") man = Person(\"小明\",20,'男') #增操作 增加类属性 man.job = \"python开发\" print(man.job) 结果： python开发 #删操作 删除类属性 del man.name print(man.name) 结果： AttributeError: 'Person' object has no attribute 'name' #改操作 修改类属性 man.name = \"小红\" print(man.name) 结果： 小红 #查操作 查看类属性 print(man.name) 结果： 小明 4.2.2对象名查看类中属性 class Person(): size = 36 weight = 100 def __init__(self,name,age,sex): self.name = name self.age = age self.sex = sex def a(self): print(f\"我叫{self.name},我今年{self.age}了,我是{self.sex}的\") man = Person(\"小明\",20,'男') #通过对象名查看类中属性 print(man.size,man.weight) 36 100 4.2.3对象名操作类中方法 类中的方法一般都是通过对象执行的（除去类方法，静态方法外），并且对象执行这些方法都会自动将对象空间传给方法中的第一个参数self class Person(): size = 36 weight = 100 def __init__(self,name,age,sex): self.name = name self.age = age self.sex = sex def a(self): print(f\"我叫{self.name},我今年{self.age}了,我是{self.sex}的\") def f1(self): print(\"我是类中的方法f1\") man = Person(\"小明\",20,'男') man.f1() 结果： 我是类中的方法f1 4.2.4增加对象属性 //类外添加 class Person: def __init__(self,name): self.name = name def func(self,sex): self.sex = sex #类外面可以： obj = Person('小明') obj.age = 20 print(obj.__dict__) 结果： {'name': 'meet', 'age': 18} //类内添加 class Person: def __init__(self,name): self.name = name def func(self,sex): self.sex = sex #类内部也可以： obj = Person('小明') # __init__方法可以。 obj.func(\"男\") #func方法可以 print(obj.__dict__) 结果： {'name': '小明', 'sex': '男'} 5.补充说明 5.1self是什么 self其实就是类中方法（函数）的第一个位置参数，只不过解释器会自动将调用这个函数的对象传给self。所以把类中方法的第一个参数约定俗成设置成self, 代表这个就是对象.这个self可以进行改变但是不建议大家进行修 传参分为隐式传参和显示传参,self这种方式就是隐式传参 class Person(): size = 36 weight = 100 def __init__(self,name,age,sex): self.name = name self.age = age self.sex = sex def a(self): #这里的self就是对象man print(f\"我叫{self.name},我今年{self.age}了,我是{self.sex}的\") man = Person(\"小明\",20,'男') man.a() 结果： 我叫小明,我今年20了,我是男的 5.2 类中__init__()方法 构造方法：类中的__init__()方法（主要用作初始化） 在obj = 类名() 执行后做了两件事 #1.创建对象，对象名叫obj #2.通过对象执行类中的一个特殊方法 __init__ class Bar: def __init__(self): #这里的self就是对象名obj print('123') obj = Bar() 类中__init__()方法示例 //第一版代码 class Man: def __init__(self, name, age): self.n = name self.a = age print(f\"我叫{self.n},我今年{self.a}岁\") b = Man(\"小明\", 20) #打印结果 我叫小明,我今年20岁 #内存中发生的事 内存中有一个空间存放类Man，__init__()方法在类Man中，对象b指向类Man 类中的__init__()方法会自动执行 #代码说明 类Man中的self就是对象b，self.n就是b.n __init__()就叫构造方法，构造方法会在类名()的时候自动执行，即在b = Man()的时候自动执行 //第二版代码 class Man: def __init__(self, name, age): \"\"\" 构造方法，会在类名()的时候自动执行，即在b = Man()的时候自动执行 :param name: :param age: \"\"\" self.n = name self.a = age def show(self): print(f\"我叫{self.n},我今年{self.a}岁\") b = Man(\"小明\", 20) b.show() #打印结果 我叫小明,我今年20岁 5.3对象、类查找属性的顺序 对象查找属性的顺序 对象空间 ------> 类空间 ------> 父类空间 类查找属性的顺序 本类空间 ------> 父类空间 ⚠️⚠️⚠️类名不可能找到对象的属性 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/25.1python基础二十五 并发编程-多进程.html":{"url":"python/python基础/25.1python基础二十五 并发编程-多进程.html","title":"并发编程-多进程","keywords":"","body":"python基础二十五 并发编程-多进程 1.多任务处理 多任务处理就是使计算机同时处理多个任务 1.1 实现方式 多进程 多线程 1.2 串行、并发、并行示意图 串行 并发 并行 2.多进程 2.1 多进程涉及的概念 程序：是一个指令的集合，例如编写完的代码，还没有运行 进程：正在执行的程序，例如当运行一个程序的时候，就启动了一个进程 2.2 python多进程 1.程序开始运行时，首先会创建一个主进程 2.在主进程(父进程)下，可以创建新的进程(子进程)，子进程依赖于主进程，如果主进程结束，程序会退出 3.python提供了非常好用的进程包multiprocessing，借助这个包，可以轻松完成从单进程到并发执行的转换 2.2.1 multiprocessing模块、类方法创建多进程 方法一：multiprocessing模块提供了一个Process类来创建一个进程对象 //代码示例1 from multiprocessing import Process def run(name): print(f\"子进程 '{name}' 运行中\") if __name__ == \"__main__\": #windowns中防止递归执行创建子进程导致内存不足，Linux、Mac中可以不写 print(\"父进程启动\") p = Process(target=run,args=('我是传入的参数',)) #创建子进程 p.start() #启动进程 print(p.name) #打印进程名字，可以自定义 p.join() #告知主进程等待子进程结束 print(\"子进程结束\") 结果： 父进程启动 Process-1 子进程 '我是传入的参数' 运行中 子进程结束 //代码示例2 创建多个子进程、自定义进程名字 from multiprocessing import Process def run1(name,sex): print(f\"子进程 '{name}' 运行中,我是{sex}的\") def run2(name,sex): print(f\"子进程 '{name}' 运行中,我是{sex}的\") if __name__ == \"__main__\": print(\"父进程启动\") p1 = Process(target=run1,args=('我是子进程1','男',),name='自定义子进程1') p2 = Process(target=run2,args=('我是子进程2','女',),name='自定义子进程2') p1.start() p2.start() print(p1.name) print(p2.name) p1.join() p2.join() print(\"子进程结束\") 结果： 父进程启动 自定义子进程1 自定义子进程2 子进程 '我是子进程1' 运行中,我是男的 子进程 '我是子进程2' 运行中,我是女的 子进程结束 方法二：类方法创建多进程 创建新的进程还可以使用类的方式，可以自定义一个类，继承Process类，每次实例化这个类的时候，就等同于实例化一个进程对象 //multiprocessing模块创建多进程方法 from multiprocessing import Process def run(name): print(f\"我是进程：'{name}'\") if __name__ == \"__main__\": p = Process(target=run,args=('呵呵',)) p.start() p.join() print(\"子进程结束\") 结果： 我是进程：'呵呵' 子进程结束 //基于以上代码，使用类的方式创建多进程 from multiprocessing import Process class Custum(Process): def __init__(self,name): super().__init__() self.name = name def run(self): #重写run方法，只能有一个且必须叫run print(f\"我是进程：'{self.name}'\") if __name__ == \"__main__\": p = Custum(\"类创建进程\") p.start() p.join() print(\"子进程结束\") 结果： 我是进程：'类创建进程' 子进程结束 使用类方法创建多进程 from multiprocessing import Process class A(Process): def __init__(self,name): super().__init__() self.name = name def hehe(self): #名称必须叫run，否则运行结果会有问题 print(f\"子进程 {self.name} 运行中\") if __name__ == \"__main__\": print(\"父进程启动\") p = A(\"类创建进程\") p.start() p.join() print(\"子进程结束\") 结果： 父进程启动 子进程结束 2.2.2 __name == \"__main__\"参数 1.一个python的文件有两种使用的方法，第一是直接作为程序执行，第二是import到其他的python程序 中被调用(模块重用)执行。 2.因此if __name__ == 'main': 的作用就是控制这两种情况执行代码的过程，__name__ 是内置变量，用于表示当前模块的名字 3.在if __name__ == 'main': 下的代码只有在文件作为程序直接执行才会被执行，而import到其他程序中是不会被执行的 4.在Windows 上，子进程会自动 import 启动它的这个文件，而在 import 的时候是会执行这些语句的。 如果不加if __name__ == \"__main__\":的话就会无限递归创建子进程 所以必须把创建子进程的部分用那个 if 判断保护起来 import 的时候 __name__ 不是__main__ ，就不会递归运行了 //错误示例 from multiprocessing import Process def run(name): print(f\"我是进程： '{name}'\") p = Process(target=run,args=('呵呵',)) p.start() p.join() print(\"子进程结束\") 结果： windows会报一堆错，Linux、Mac没有问题 //正确示例 from multiprocessing import Process def run(name): print(f\"我是进程： '{name}'\") if __name__ == \"__main__\": p = Process(target=run,args=('呵呵',)) p.start() p.join() print(\"子进程结束\") 我是进程： '呵呵' 子进程结束 2.2.3 多进程参数 target 表示调用对象，即子进程要执行的任务 p = Process(target=对象名(函数名)) args 表示调用对象的位置参数元组，args=(传入的参数,) ⚠️括号中传入的参数后面必须加逗号 p = Process(target=xxx,args=('传入的参数',)) name 表示进程的名称 p = Process(target=xxx,args=('传入的参数',),name='子进程名称') 2.2.4 Process类常用方法 p.start() 启动进程，并调用该子进程中的p.run() p.run() 进程启动时运行的方法，正是它去调用target指定的函数，我们自定义类中的一定要实现该方法 p.terminate() 强制终止进程p，不会进行任何清理操作 p.is_alive() 如果子进程p仍然运行，返回True，用来判断进程是否还在运行 p.join([超时时间]) 主进程等待p终止，timeout是可选的超时时间 2.2.5 Process类常用属性 name 当前进程实例别名，默认为Process-N,N为从1开始递增的整数，可以指定进程名称 pid 当前进程实例的PID 2.2.6 多进程中的全局变量 全局变量在多个进程中不共享，进程之间的数据是独立的，默认情况下互不影响 from multiprocessing import Process num = 10 def f1(): global num num += 1 print(f\"第一个子进程中的num值为:{num}\") def f2(): global num num += 2 print(f\"第二个子进程中的num值为:{num}\") if __name__ == \"__main__\": p1 = Process(target=f1) p2 = Process(target=f2) p1.start() p2.start() p1.join() p2.join() print(f\"全局变量中的num值为:{num}\") 结果： 第一个子进程中的num值为:11 第二个子进程中的num值为:12 全局变量中的num值为:10 2.3 进程池 进程池：用来创建多个进程 当需要创建多子进程数量不多时，可以直接利用multiprocessing中的Process动态生成多个进程，但如果是大量的进程目标，手动创建进程的工作量巨大，此时就可以利用multiprocessing模块提供的Pool 初始化Pool时，可以指定一个最大进程数，当有新的请求提交到Pool中时，如果池还没有满，那么就会创建一个新的进程用来执行该请求，但是如果池中的进程数已经达到指定的最大值，那么该请求就会等待，直到池中有进程结束，才会创建新的进程来执行 from multiprocessing import Pool import time def r1(): print(\"123\") time.sleep(5) def r2(): print(\"abc\") time.sleep(3) if __name__ == \"__main__\": po = Pool(5) #定义一个进程池，最大进程数为5，不写默认为CPU核心数 for i in range(5): po.apply_async(r1) #apply_async选择要调用的目标，每次循环会用空出来的子进程去调用目标 po.apply_async(r2) po.close() #进程关闭之后不再接受新的请求 po.join() #等待po中所有子进程结束，必须放在close后面 结果： 第一秒会出现以下结果，但是后续不确定 因为进程池中定义了最大进程数为5 123 abc 123 abc 123 2.3.1 进程池常用函数解析 multiprocessing.Pool常用函数解析 apply_async(func[,args[,kwds]]): 使用非阻塞方式调用func(并行执行，堵塞方式必须等待上一个进程退出才能进行下一个进程)，args为传递给func的参数列表，kwds为传递给func的关键字参数列表 apply(func[,args[,kwds]]) 使用阻塞方式调用func close() 关闭Pool，使其不再接受新的任务 join() 主进程阻塞，等待子进程的退出，必须在close或terminate之后使用 2.4 进程间通信 2.4.1 队列Q实现进程间数据传递 多进程之间，默认是不共享数据的 通过Queue(队列Q)可以实现进程间数据传递 Q本身是一个消息队列 Queue方法说明 Queue.put([num]) 存入消息，num不写或者为负数不限制 Queue.qsize() 返回当前队列包含的消息数量 Queue.empty() 如果队列为空，返回True，反之返回False Queue.full() 如果队列满了，返回True，反之返回False Queue.get([block[,timeout]]) 获取队列中的一条消息，然后将其从队列移除，block默认值为True 如果block使用默认值，且没有设置timeout(单位秒)，消息队列如果为空，此时程序将被阻塞(停在读取状态)，直到从消息队列读到消息为止 如果设置了timeout，则会等待timeout秒，若还没有读取到任何消息，则抛出\"Queue.Empty\"异常 如果block值为False，消息队列如果为空，则会立刻抛出\"Queue.Empty\"异常 2.4.1.1 存入消息 Queue.put([num]) #存入消息，num不写或者为负数不限制 //存入消息，最多存入3条，此时运行程序不回报错 from multiprocessing import Queue q = Queue(3) q.put(\"存入消息1\") q.put(\"存入消息2\") q.put(\"存入消息3\") //存入消息，最多存入3条，如果此时存入4条，程序会卡住，知道能够存入为止 from multiprocessing import Queue q = Queue(3) q.put(\"存入消息1\") q.put(\"存入消息2\") q.put(\"存入消息3\") q.put(\"存入消息4\") #这一条消息不会存入到队列中，知道队列有空闲可以存入为止 2.4.1.2 读取消息 Queue.get([block[,timeout]]) #获取队列中的一条消息，然后将其从队列移除，block默认值为True //存入消息 from multiprocessing import Queue q = Queue(3) #初始化一个Queue对象，最多可接受3条消息 q.put(\"存入消息1\") #添加消息，数据类型不限 q.put(\"存入消息2\") q.put(\"存入消息3\") //读取消息，默认方式读取 from multiprocessing import Queue q = Queue(3) #初始化一个Queue对象，最多可接受3条消息 q.put(\"存入消息1\") #添加消息，数据类型不限 q.put(\"存入消息2\") q.put(\"存入消息3\") print(q.get()) print(q.get()) print(q.get()) 结果： 存入消息1 存入消息2 //读取消息，指定block值为False 如果block值为False，消息队列如果为空，则会立刻抛出\"Queue.Empty\"异常 from multiprocessing import Queue q = Queue(3) print(q.get(block=False)) 结果： queue.Empty ⚠️此方法有时会报错队列为空，有时就没有问题，win和mac中一样,linux会始终报错队列为空 from multiprocessing import Queue q = Queue(3) q.put(\"存入消息1\") q.put(\"存入消息2\") q.put(\"存入消息3\") print(q.get(block=False)) //读取消息，指定读取空队列超时时间 from multiprocessing import Queue q = Queue(3) print(q.get(timeout=3)) 结果： 等待3秒后会报错 queue.Empty Queue.get_nowait() 相当于Queue.get(False) from multiprocessing import Queue q = Queue(3) print(q.get_nowait()) 结果： queue.Empty 2.4.1.3 获取队列信息 Queue.empty() #如果队列为空，返回True，反之返回False //队列不为空，返回False from multiprocessing import Queue import time q = Queue(3) q.put(\"1\") q.put(\"2\") q.put(\"3\") time.sleep(0.1) #如果不加sleep可能会返回队列为空 print(q.empty()) 结果： False //队列为空，返回True from multiprocessing import Queue import time q = Queue(3) print(q.empty()) Queue.full() #如果队列满了，返回True，反之返回False //队列满，返回True from multiprocessing import Queue q = Queue(3) q.put(1) q.put(2) q.put(3) print(q.full()) 结果： True //队列不满，返回False from multiprocessing import Queue q = Queue(3) q.put(1) q.put(2) print(q.full()) 结果： False 多接受方代码示例 同时有2个以上的接收方 from multiprocessing import Process,Queue import time def write(q): for i in range(6): print(\"子进程1写入了：\",i) q.put(i) time.sleep(1) def read1(q): while True: if not q.empty(): print(\"子进程2读取了：\",q.get()) time.sleep(1) else: break def read2(q): while True: if not q.empty(): print(\"子进程3读取了：\",q.get()) time.sleep(1) else: break if __name__ == \"__main__\": q = Queue() pw = Process(target=write,args=(q,)) pr1 = Process(target=read1,args=(q,)) pr2 = Process(target=read2,args=(q,)) pw.start() pw.join() pr1.start() pr2.start() pr1.join() pr2.join() print(\"接受完毕！\") 结果： 子进程1写入了： 0 子进程1写入了： 1 子进程1写入了： 2 子进程1写入了： 3 子进程1写入了： 4 子进程1写入了： 5 子进程2读取了： 0 子进程3读取了： 1 子进程2读取了： 2 子进程3读取了： 3 子进程3读取了： 4 子进程2读取了： 5 接受完毕！ ⚠️上述代码的问题之处，子进程2和子进程3不能同时读取队列中的消息，子进程2读取了0、2、4，子进程3读取了1、3、5，需要做一些代码逻辑修改，让子进程2和子进程3能够同时读取消息队列中的消息 //两个接收方读取消息队列 思路： from multiprocessing import Process,Queue import time def write(q1): for i in range(6): print(\"子进程1写入了：\",i) q1.put(i) time.sleep(1) def read1(q1,q2): while True: if not q1.empty(): a = q1.get() #如果q1队列不为空则取值并赋值给a print(\"子进程2读取了：\",a) q2.put(a) #q2从a中读取并写入消息 time.sleep(1) else: break def read2(q2): while True: if not q2.empty(): print(\"子进程3读取了：\",q2.get()) time.sleep(1) else: break if __name__ == \"__main__\": q1 = Queue() q2 = Queue() pw = Process(target=write,args=(q1,)) pr1 = Process(target=read1,args=(q1,q2)) pr2 = Process(target=read2,args=(q2,)) pw.start() pw.join() pr1.start() pr2.start() pr1.join() pr2.join() print(\"接受完毕！\") 结果： 子进程1写入了： 0 子进程1写入了： 1 子进程1写入了： 2 子进程1写入了： 3 子进程1写入了： 4 子进程1写入了： 5 子进程2读取了： 0 子进程3读取了： 0 子进程2读取了： 1 子进程3读取了： 1 子进程2读取了： 2 子进程3读取了： 2 子进程2读取了： 3 子进程3读取了： 3 子进程2读取了： 4 子进程3读取了： 4 子进程2读取了： 5 子进程3读取了： 5 接受完毕！ ⚠️⚠️⚠️mac本中执行结果不正确： 子进程1写入了： 0 子进程1写入了： 1 子进程1写入了： 2 子进程1写入了： 3 子进程1写入了： 4 子进程1写入了： 5 子进程2读取了： 0 子进程2读取了： 1 子进程2读取了： 2 子进程2读取了： 3 子进程2读取了： 4 子进程2读取了： 5 接受完毕！ 进程、线程、协程之间的区别 进程 最小的资源单位，内存级别，如果进程中没有线程只是划分了一个空间 线程 最小的运行单位，cpu级别，进程在执行，实际上是线程在执行 协程 微线程 用户级别 操作系统不知道什么是协程，是程序员yy出来的，欺骗操作系统，因为有IO操作，操作系统会回收权限，协程就是在用户级别将多个任务做成一个任务，但凡有一个线程有IO，手动切换，让线程能获得更大占用系统资源的机会，提高单线程效率 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/25.2python基础二十五 并发编程-多线程.html":{"url":"python/python基础/25.2python基础二十五 并发编程-多线程.html","title":"并发编程-多线程","keywords":"","body":"python基础二十五 并发编程-多线程 1.线程概念 线程：实现多任务的另一种方式，一个进程中同时运行的多个子任务就成为线程 轻量级进程：线程又被称为轻量级进程，是更小的执行单元 一个进程可拥有多个并行的线程，当中每一个线程，共享当前进程的资源 一个进程中的线程共享相同的内存单元/内存地址空间，这样就可以访问相同的变量和对象，而且他们从同一堆中分配对象，进行通信、数据交换、同步操作 线程间的通信是在同一个地址上进行的，所以不需要额外的通信机制，这就使得通信更简单而且信息传递速度也更快 线程的5种状态 多线程程序的执行顺序是不确定的(操作系统决定)。当执行到sleep语句时，线 程将被阻塞(Blocked) ， 到sleep结束后， 线程进入就绪(Runnable) 状态， 等待调度。 而线程调度将自行选择一个线程执行。 代码中只能保证每个线程都运行 完整个run函数， 但是线程的启动顺序、run函数中每次循环的执行顺序都不能确定 1、新状态:线程对象已经创建，还没有在其上调用start()方法。 2、可运行状态:当线程有资格运行，但调度程序还没有把它选定为运行线程时线程所处的状态。当start()方法调用时，线程首先进入可运行状态。在线程运行之后或者从阻塞、等待或睡眠状态回来后，也返回到可运行状态。 3、运行状态:线程调度程序从可运行池中选择一个线程作为当前线程时线程所处的状态。这也是线程进入运行状态的唯一一种方式。 4、等待/阻塞/睡眠状态:这是线程有资格运行时它所处的状态。实际上这个三状态组合为一种，其共同点是:线程仍旧是活的(可运行的)，但是当前没有条件运行。 但是如果某件事件出现，他可能返回到可运行状态。 5、死亡态:当线程的run()方法完成时就认为它死去。这个线程对象也许是活的，但是，它已经不是一个单独执行的线程，线程一旦死亡，就不能再次执行，如果在一个死去的线程上调用start()方法，会抛出异常 2.线程和进程的区别 区别 进程 线程 根本区别 作为资源分配的单位 调度和执行的单位 开销 每个进程都有独立的代码和数据空间(进程上下文)，进程间的切换会有较大的开销 线程可以看成是轻量级的进程，同一个类线程共享代码和数据空间，每个线程有独立的运行栈和程序计数器(PC)，线程切换的开销小 所处环境 在操作系统中能同时运行多个任务 在同一个应用程序中有多个顺序流同时执行 分配内存 系统在运行的时候会为每个进程分配不同的内存区域 除了CPU之外，不会为线程分配内存，线程使用的资源是它所属的进程的资源，线程只能共享资源 包含关系 没有线程的进程是可以被看作单线程的，如果一个进程内拥有多个线程，则执行过程不是一个线程，而是多个线程完成的 线程是进程的一部分，所以线程有的时候被称为是轻权进程或者轻量进程 3.多线程实现 3.1 通过threading.Thread直接在线程中运行函数 //创建单线程 import threading #导入threading模块 def thread(): print(\"线程启动\") t = threading.Thread(target=thread) #创建线程 t.start() #启动线程 //利用for循环创建多线程 import threading def thread(): print(\"子线程启动\") for i in range(5): t = threading.Thread(target=thread) t.start() 结果： 子线程启动 子线程启动 子线程启动 子线程启动 子线程启动 3.2 通过类继承threading.Thread类来创建线程 import threading class MyThread(threading.Thread): def run(self): for i in range(5): print(i) t1 = MyThread() t2 = MyThread() t1.start() t2.start() 结果： 0 1 2 3 4 0 1 2 3 4 3.3 查看当前线程数量 len(threading.enumerate() import threading import time import random def func(): time.sleep(random.randint(1, 3)) print(threading.current_thread().name,f\"当前活跃线程数量{len(threading.enumerate())}\") lst = [threading.Thread(target=func,name=f\"线程{i}\") for i in range(10)] for i in lst: i.start() 结果： 线程名称不固定 线程2 当前活跃线程数量11 线程8 当前活跃线程数量10 线程7 当前活跃线程数量9 线程4 当前活跃线程数量8 线程3 当前活跃线程数量7 线程1 当前活跃线程数量6 线程0 当前活跃线程数量5 线程9 当前活跃线程数量4 线程6 当前活跃线程数量3 线程5 当前活跃线程数量2 4.线程同步 4.1互斥锁 创建锁 lock = threading.Lock() 锁定 lock.acquire() 释放锁 lock.release() 未加锁之前循环100万次出现的结果不准确BUG from multiprocessing import Queue,Process,Lock import threading num = 0 def f1(): global num for i in range(1000000): num += 1 print(num) def f2(): global num for i in range(1000000): num += 1 print(num) t1 = threading.Thread(target=f1) t2 = threading.Thread(target=f2) t1.start() t2.start() print(\"主线程的num是\",num) 结果1: 主线程的num是 299428 1226857 1536106 结果2: 主线程的num是 263111 1173618 1499331 每一次执行的结果都不一样 加锁解决循环100万次出现结果不准确的BUG from multiprocessing import Queue,Process,Lock import threading num = 0 def f1(): global num lock.acquire() for i in range(1000000): num += 1 print(num) lock.release() def f2(): global num lock.acquire() for i in range(1000000): num += 1 print(num) lock.release() lock = threading.Lock() #创建锁 t1 = threading.Thread(target=f1) t2 = threading.Thread(target=f2) t1.start() t2.start() print(\"主线程的num是\",num) 结果1: 主线程的num是 235674 1000000 2000000 结果2: 主线程的num是 227114 1000000 2000000 主线程的num还是不一致，因为线程间数据是共享的，锁只能保证f1、f2两个函数中完整执行 4.2互斥锁实现线程同步 代码整体思路 1.创建3个线程，分别执行3个函数f1、f2、f3 2.创建3个锁，只有在锁1创建后不上锁，锁2、锁3都上锁 3.由于锁1没有上锁，因此可以先执行，锁1中执行后释放锁2，锁2执行，执行后释放锁3，锁3执行，执行完后释放锁1，锁1执行，这样就可以无限循环顺序执行锁1、锁2、锁3 import threading from multiprocessing import Lock def f1(): while True: lock1.acquire() #抢锁1 print(1) lock2.release() #释放锁2，这样就能执行函数f2 def f2(): while True: lock2.acquire() #抢锁2 print(2) lock3.release() #释放锁3，这样就能执行函数f3 def f3(): while True: lock3.acquire() #抢锁3 print(3) lock1.release() #释放锁1，这样就能执行函数f1 #创建3个线程，并分别执行函数f1、f2、f3 t1 = threading.Thread(target=f1) t2 = threading.Thread(target=f2) t3 = threading.Thread(target=f3) #创建3个锁，并且锁2、锁3创建后就上锁 lock1 = threading.Lock() lock2 = threading.Lock() lock2.acquire() lock3 = threading.Lock() lock3.acquire() #启动线程 t1.start() t2.start() t3.start() 结果： 1 2 3 1 2 3 。。。 4.3消息队列Queue实现线程同步 4.3.1线程中的Queue与进程中的Queue区别 进程中的Queue 进程中的Queue是从multriprocessing模块中导入的， from multiprocessing import Queue，作用是作为消息队列接收消息 线程中的Queue 线程中的Queue是从queue模块中导入的，from queue import Queue，作用是实现线程同步 4.3.2线程中的Queue Python中Queue模块，实现了3种类型的队列来实现线程同步，包括 FIFO(先入先出) 队列Queue，按照先进先出的顺序检索条目 LIFO(后入先出) 栈LifoQueue，最后添加的条目最先检索到 优先级队列 PriorityQueue，条目被保存为有序的(使用heapq模块)并且最小值的条目最先被剪锁 class queue.Queue(maxsize=0) FIFO队列的构造器，maxsize为一个整数，表示队列的最大条目数，可用来限制内存的使用 一旦队列满，插入将被阻塞直到队列中存在空闲时间，如果maxsize小于等于0，队列大小为无限制，maxsize默认为0 import queue import threading def write(): while True: if q1.qsize() = 100: for i in range(20): a = q1.get() print(a) q1 = queue.Queue() #通过Queue隔离开了存放数据的线程与读取数据的线程 for i in range(1,501): q1.put(f\"初始数据f{i}\") for i in range(500): print(q1.get()) t1 = threading.Thread(target=write) t2 = threading.Thread(target=read) t1.start() t2.start() 结果： 循环打印新数据1-50 4.3.3生产者消费者模式 生产者就是生产数据的线程，消费者就是消费数据的线程 生产者消费者模式是通过一个容器(缓冲区)来解决生产者和消费者的强耦合问题 生产者和消费者之间不直接通讯，通过阻塞队列来进行通讯 4.4死锁(错误情况) 死锁属于错误情况，在线程共享多个资源的时候，如果两个线程分别占有一部分资源并同时等待对方的资源，就会造成死锁 #以下代码，锁1再等待锁2，锁2再等待锁1，因此造成了死锁 import threading import time def f1(): if lock1.acquire(): #f1抢到了锁1 print(\"lock1抢到了锁\") time.sleep(1) if lock2.acquire(): #再等待锁2，但是锁2已经被f2抢到，还未释放，因此无法继续执行后续代码 print(\"lock2\") lock2.release() lock1.release() def f2(): if lock2.acquire(): #f2抢到了锁2 print(\"lock2抢到了锁\") time.sleep(1) if lock1.acquire(): #再等待锁1，但是锁1已经被f1抢到，还未释放，因此无法继续执行后续代码 print(\"lock1\") lock1.release() lock2.release() lock1 = threading.Lock() lock2 = threading.Lock() t1 = threading.Thread(target=f1) t2 = threading.Thread(target=f2) t1.start() t2.start() 结果： lock1抢到了锁 lock2抢到了锁 程序会卡住不动 4.5信号量 semaphone 4.5.1概念 1.信号量semaphone用于控制一个时间点内线程进入数量的锁，信号量是用来控制线程并发数的 2.信号量只控制同一时间能并发执行的线程，其余不管 4.5.2使用场景 读写文件 读写文件的时候，一般只有一个线程再写，而读可以有多个线程同时进行，如果需要限制同时读取文件的线程个数，这时候就需要用到信号量 如果使用互斥锁，就是限制同一时间只能有一个线程读取文件 提供访问的web服务 web服务都是跑在服务器中的，而服务器的资源是有限的，如果访问请求数量特别多，不加限制就会导致服务器宕机，此时使用信号量限制同一时间web服务能处理的请求就不会造成因访问量巨大而造成服务器宕机 4.5.3信号量代码示例 //无法控制同时执行的线程数 import time import threading def f1(): time.sleep(1) print(111) for i in range(100): t1 = threading.Thread(target=f1) t1.start() 结果： 100个111 //使用信号量控制同时执行的线程数 import time import threading s = threading.Semaphore(5) #开启信号量 def f1(): s.acquire() #信号量加锁 time.sleep(2) print(111) s.release() #信号量解锁 for i in range(100): t1 = threading.Thread(target=f1) t1.start() 结果： 一次打印5个111，直到循环完成 4.6GIL全局解释器锁 4.6.1概念 Cpython独有的锁，牺牲效率保证数据安全，同一时间只能有一个线程来修改共享的数据 4.6.2GIL锁说明 首先，执行python文件是什么过程？谁把进程运行起来的？ 操作系统将你的应用程序从硬盘加载到内存然后运行python文件，在内存中开辟一个进程空间，将你的python解释器以及p y文件加载进去，解释器运行py文件 python解释器分为两部分，先将你的代码通过编译器编译成c的字节码，然后你的虚拟机拿到你的c字节码，输出机器码，再配合操作系统把你的这个机器仍给CPU处理 py文件有一个主线程，主线程做的就是这个过程，如果开多线程，每个线程都要进行这个过程 Cpython为什么用不了多核？ cpython在所有的线程进入解释器之前加了一个全局解释器锁即GIL锁，这个锁是互斥锁，是加在解释器上的，导致同一时间只有一个线程在执行，所以用不了多核 为什么这么设计？ 因为写python的人只有一个CPU 所以加了一个锁，保证了数据的安全，而且再写python解释器时，更加好写 为什么不取消这个锁？ 解释器内部的管理全部是针对单线程写的，如果要取消锁，需要重构python解释器 能不能不用Cpython？ 官方推荐使用Cpython，处理速度快，相对其他解释器比较完善 多线程无法使用多核，怎么办？ 虽然多线程无法使用多核，但是多进程可以应用多核，但是开销大 GIL全局解释器锁和互斥锁的区别 锁的目的就是为了保护共享的数据，同一时间只能有一个线程来修改共享数据 保护不同的数据就应该加不同的锁 GIL和lock是两种锁，保护的数据不一样，GIL是解释器级别的，保护的是解释器级别的数据，比如垃圾回收的数据，lock互斥锁是保护用户自己开发的应用程序的数据，GIL是不管这样的数据的 示意图 1⃣️xx.py文件中有多个线程，由于GIL锁的存在导致同时只能执行一个线程，因为多个线程操作一个资源会出问题，所以在解释器级别加了GIL锁 2⃣️cpython解释器不支持同时解释多个python线程，原因是为了保证解释器的安全，因此不支持多线程同时并发 3⃣️GIL锁是解释器级别的锁，只能保证解释器的安全，但是无法保证数据安全，我们自己加互斥锁能解决这个问题 5.线程异步 线程异步有多种方式 1.无需等待线程执行(正常写的线程执行代码就是异步，因为操作系统自动调用线程执行，多个线程执行顺序不固定) 2.通过循环控制(方法low) 3.通过回调机制实现线程异步 通过回调机制实现线程异步 from multiprocessing import Pool import random import time def download(name): for i in range(1,6): print(f\"{name}下载文件{i}\") time.sleep(random.randint(1,3)) return \"下载完成\" def alterUser(msg): print(msg) if __name__ == \"__main__\": p = Pool(3) #当func执行完成后，return的东西会给到回调函数callback p.apply_async(func=download,args=(\"线程1\",),callback=alterUser) p.apply_async(func=download,args=(\"线程2\",),callback=alterUser) p.apply_async(func=download,args=(\"线程3\",),callback=alterUser) p.close() #关闭进程池 p.join() 结果： 结果顺序每一次执行都会不同，最终结果为显示3次下载完成 线程1下载文件1 线程2下载文件1 线程3下载文件1 线程1下载文件2 线程2下载文件2 线程3下载文件2 线程3下载文件3 线程1下载文件3 线程3下载文件4 线程2下载文件3 线程3下载文件5 线程1下载文件4 下载完成 线程2下载文件4 线程1下载文件5 线程2下载文件5 下载完成 下载完成 进程、线程、协程之间的区别 进程 最小的资源单位，内存级别，如果进程中没有线程只是划分了一个空间 线程 最小的运行单位，cpu级别，进程在执行，实际上是线程在执行 协程 微线程 用户级别 操作系统不知道什么是协程，是程序员yy出来的，欺骗操作系统，因为有IO操作，操作系统会回收权限，协程就是在用户级别将多个任务做成一个任务，但凡有一个线程有IO，手动切换，让线程能获得更大占用系统资源的机会，提高单线程效率 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/25.3python基础二十五 并发编程-多协程.html":{"url":"python/python基础/25.3python基础二十五 并发编程-多协程.html","title":"并发编程-多协程","keywords":"","body":"python基础二十五 并发编程-多协程 1.协程 1.1概念 协程是比线程更小的执行单元，也叫微线程 一个线程作为一个容器里面可以放置多个协程 1.2协程作用 只切换函数调用即可完成多线程，可以减少CPU的切换 协程自己主动让出CPU，不需要系统调用 1.3协程实现 1.3.1 greenlet(第三方模块，手动切换函数执行) #协程间来回切换，不需要CPU的调用 #需要先安装greenlet pip install greenlet from greenlet import greenlet import time def t1(): while True: print(\"AAA\") #第一步先打印AAA gr2.switch() #第二步让协程gr2进来执行，gr1保留此处的执行位置，协程gr2执行的是t2函数 time.sleep(1) def t2(): while True: print(\"bbb\") #第三步打印bbb gr1.switch() #第四步让协程gr1进来执行，gr2保留此处的执行位置，协程gr1执行的是t1函数 time.sleep(1) gr1 = greenlet(t1) #创建一个协程对象 gr2 = greenlet(t2) gr1.switch() #此时会执行t1函数 结果： 循环打印 AAA bbb 1.3.2 gevent(第三方模块，自动切换函数执行) 概念 gevent是一个能够自动切换函数执行的协程模块，比greenlet功能强大 原理 gevent通过greenlet实现协程，当一个greenlet遇到IO操作时，就自动切换到其他的greenlet，等待IO操作完成，再在适当的时候切换回来继续执行 特点 gevent只有遇到模块能够识别的IO操作的时候，程序才会进行任务切换，实现并发效果 #需要先安装gevent pip install gevent //代码示例1 无限循环切换协程 import gevent def A(): while True: print(\".........A.........\") gevent.sleep(1)#用来模拟一个耗时操作 #gevent中：当一个协程遇到耗时操作会自动交出控制权给其他协程 def B(): while True: print(\".........B.........\") gevent.sleep(1) #每当遇到耗时操作，会自用转到其他协程 g1 = gevent.spawn(A) #创建一个gevent对象（创建了一个协程），此时就已经开始执行函数A g2 = gevent.spawn(B) g1.join() #等待协程执行结束 g2.join() #会等待协程运行结束后再退出 结果： 无限循环打印 .........A......... .........B......... 。。。 //代码示例2 控制协程循环次数 import gevent def A(): for i in range(10): print(\"AAA\") gevent.sleep(1) def B(): for i in range(10): print(\"BBB\") gevent.sleep(1) g1 = gevent.spawn(A) g2 = gevent.spawn(B) g1.join() g2.join() 结果： 打印10次 AAA BBB 进程、线程、协程之间的区别 进程 最小的资源单位，内存级别，如果进程中没有线程只是划分了一个空间 线程 最小的运行单位，cpu级别，进程在执行，实际上是线程在执行 协程 微线程 用户级别 操作系统不知道什么是协程，是程序员yy出来的，欺骗操作系统，因为有IO操作，操作系统会回收权限，协程就是在用户级别将多个任务做成一个任务，但凡有一个线程有IO，手动切换，让线程能获得更大占用系统资源的机会，提高单线程效率 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/26.1python基础二十六 网络编程-网络基础知识.html":{"url":"python/python基础/26.1python基础二十六 网络编程-网络基础知识.html","title":"网络编程-计算机网络基础","keywords":"","body":"python基础二十六 网络编程-网络基础知识 1.网络基础中涉及到的几种概念 1.1IP地址 1.1.1概念 IP地址是用来在网络中标记一台电脑的一串数字，在网络上是唯一的 IP地址分类私网IP地址和公网IP地址 1.1.2格式说明 每一个IP地址包括两部分：网络地址和主机地址 A类IP地址由1字节的⽹络地址和3字节主机地址组成， ⽹络地址的最⾼位必须是“0”，地址范围1.0.0.1-126.255.255.254可⽤的A类⽹络有126个， 每个⽹络能容纳1677214个主机 B类IP地址由2个字节的⽹络地址和2个字节的主机地址组成， ⽹络地址的最⾼位必须是“10”，地址范围128.1.0.1-191.255.255.254 可⽤的B类⽹络有16384个， 每个⽹络能容纳65534主机 C类IP地址由3字节的⽹络地址和1字节的主机地址组成， ⽹络地址的最⾼位必须是“110”范围192.0.1.1-223.255.255.254 C类⽹络可达2097152个， 每个⽹络能容纳254个主机 D类IP地址第⼀个字节以“1110”开始， 它是⼀个专⻔保留的地址。它并不指向特定的⽹络， ⽬前这⼀类地址被⽤在多点⼴播（一对多） 中多点⼴播地址⽤来⼀次寻址⼀组计算机 地址范围224.0.0.1-239.255.255.254 E类IP地址以“1111”开始，为将来保留使用，仅做实验和开发用 1.1.3私有IP地址 1.1.3.1含义 私有IP：本地局域网的IP，专门为组织机构内部使用 在这么多网络IP中，国际规定有一部分的Ip地址是用于我们的局域网使用，属于私网IP 1.1.3.2范围 A类 10.0.0.0 ～ 10.255.255.255 B类 172.16.0.0 ～ 172.31.0.0 C类 192.168.0.0 ～ 192.168.255.255 1.1.4回环地址 127.0.0.1 作用 测试当前计算机的网络通信协议，127.0.0.1可以代表本机 用来检测本机网络问题，ping 127.0.0.1即可检测 1.1.5子网掩码 1.1.5.1概念 子网掩码是在IPv4地址资源紧缺的背景下为了解决lP地址分配而产生的虚拟lP技术，通过子网掩码将A、B、C三类地址划分为若干子网，从而显著提高了IP地址的分配效率，有效解决了IP地址资源紧张的局面。另一方面，在企业内网中为了更好地管理网络，网管人员也利用子网掩码的作用，人为地将一个较大的企业内部网络划分为更多个小规模的子网，再利用三层交换机的路由功能实现子网互联，从而有效解决了网络广播风暴和网络病毒等诸多网络管理方面的问题。 1.1.5.2默认子网掩码 类别 子网掩码的二进制数值 子网掩码的十进制数值 A 11111111 00000000 00000000 00000000 255.0.0.0 B 11111111 11111111 00000000 00000000 255.255.0.0 C 11111111 11111111 11111111 000000000 255.255.255.0 1.1.5.3子网掩码功能 子网掩码是一个32位地址，是与IP地址结合使用的一种技术。它的主要作用有两个 一是用于屏蔽IP地址的一部分以区别网络标识和主机标识，并说明该IP地址是在局域网上，还是在远程网上 二是用于将一个大的IP网络划分为若干小的子网络。 1.2网络端口号 1.2.1概念及作用 端口号是网络中通过IP地址+端口号区分不同的服务 1.2.2范围及分类 端口号是一个数字，只有整数，范围是从0到65535(分为知名和动态两种) 知名端口是众所周知的端口号，用来做固定的事情，范围是从0到1023 80端口分配给http服务 21端口分配给ftp服务 动态端口是一般不固定分配某种服务，而是动态分配，动态分配是指当一个系统进程或应用程序进程需要网络通信是，它向主机申请一个端口，主机从可用的端口号中分配一个供它使用 1.3网络协议 1.3.1概念 协议：约定好的规范 早期的计算机⽹络， 都是由各⼚商⾃⼰规定⼀套协议， IBM、Apple和 Microsoft都有各⾃的⽹络协议， 互不兼容（语言、方言、阿帕网） 为了把全世界的所有不同类型的计算机都连接起来， 就必须规定⼀套全球通⽤的协议， 为了实现互联⽹这个⽬标，互联⽹协议簇（Internet Protocol Suite）就是通⽤协议标准。 因为互联⽹协议包含了上百种协议标准，但是最重要的两个协议是TCP和IP协议，所以，⼤家把互联⽹的协议总称TCP/IP协议 1.3.2TCP/IP模型 TCP/IP定义了电子设备如何连入因特网，以及数据如何在它们之间传输的标准 4层的层级结构中，每一层都呼叫它的下一层所提供的网络来完成自己的需求 其中的应用层关注的是应用程序的细节，而不是数据在网络中的传输活动 其他三层主要处理所有的通信细节，对应用程序一无所知； 应用层：应用程序间沟通的层，不同的文件系统有不同的文件命名原则和不同的文本行表示方法等，不同的系统之间传输文件还有各种不兼容问题，这些都将由应用层来处理 传输层：在此层中，它提供了节点间的数据传送服务，如传输控制协议（TCP）、用户数据报协议（UDP）等，这一层负责传送数据，并且确定数据已被送达并接收 网络层：负责提供基本的数据包传送功能，让每一块数据包都能够到达目的主机。网络层接收由更低层发来的数据包，并把该数据包发送到更高层，相反，IP层也把从TCP或UDP层接收来的数据包传送到更低层 网络接口层：对实际的网络媒体的管理，定义如何使用实际网络来传送数据（处理机械的、电气的和过程的接口） 示意图 TCP/IP协议簇中各协议之间的关系 1.3.3OSI七层模型 OSI七层模型示意图 物理层： 网线连接在客户端计算机上，其实是连接在了计算机的一个叫做网卡的设备上，网卡是专门负责与外界通信的。网线一般是双绞线或者光缆，也可以使用无线电波，中间经过交换机，路由器，防火墙等等一堆设备统称为物理连接介质，可以理解为经过互联网，再连接到服务端设备。首先工作的是物理层，发送电信号 数据链路层： 电信号分为两种，高电平和低电平，高电平可以被人定义成数字 1，低电平可以被人定义成数字 0。假如我客户端发送一个 0010101100，服务端相应的就会收到这些数字。但是单纯的一段二进制数字这是没有意义的，一定要明确，从哪里开始到哪里结束这表示一段内容，从哪里开始到哪里结束这又表示另外一段内容。这也就是说，我们要给这些二进制数字进行分组 以太网协议规定： 一组电信号构成一个数据报，叫做‘帧’ 每一数据帧分成：报头head和数据data两部分 这一点和我们写信类似，有信封，有信的内容，信封上面会写明这封信的发送者接受者分别是谁， 信里面的信纸上写的就是信的内容。 head包含：(固定18个字节) 发送者／源地址，6个字节 接收者／目标地址，6个字节 数据类型，6个字节 data包含：(最短46字节，最长1500字节) 注意：头固定长度18个字节，也只有固定长度，接收者才知道按照什么标准来读取 数据报的具体内容 head长度＋data长度＝最短64字节，最长1518字节，超过最大限制就分片发送 以太网规定head里面要有发送者的源地址和接受者的目标地址，源地址可以理解为是发送者的家，目标地址就是接收者的家。那么，在计算机中如何标识家在哪里？ 使用mac地址，注意这个mac地址不是你用的苹果电脑那个mac，只是巧合同名了。MAC地址（Media Access Control Address），直译为媒体访问控制地址，也称为局域网地址（LAN Address），以太网地址（Ethernet Address）或物理地址（Physical Address），它是一个用来确认网上设备位置的地址。 mac地址是计算机上一个唯一的地址，是在计算机的网卡上的，每块网卡出厂时都被烧制上一个 世界唯一的mac地址，长度为48位2进制，通常由12位16进制数表示（前六位是厂商编号，后六位是流水线号） 这样做的目的就是要保证每一个mac地址是全世界独一无二的 网络层： 网络层有一个IP协议，我们常说的IPV4就是IP协议的第四个版本，IPV6就是IP协议的第六个版本 传输层： 传输层有一个TCP协议和UDP协议，这两个协议都是基于端口工作的协议 会话层：负责文件发送/接收 表示层：负责数据压缩、编码 应用层： 应用层就是应用软件，应用软件是你写的，这个标准可以由你来定，当然了你也可以遵循一些大家已经定制好了的应用层协议的标准，常见的有 http，mail，ftp 发送过程： 应用层软件（有协议或无协议）===>传输层（TCP/UDP协议）===>网络层（ip协议）===>数据链路层（以太网协议）===>物理层===>电信号发送（100011001010110） 接收过程则相反 TCP/IP与OSI七层模型对比 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/26.2python基础二十六 网络编程-udp编程.html":{"url":"python/python基础/26.2python基础二十六 网络编程-udp编程.html","title":"网络编程-UDP编程","keywords":"","body":"python基础二十六 网络编程-udp编程 1.Socket编程简介 1.1含义 socket：套接字，通过网路完成进程间通信的方式(区别于一台计算机之间进程通信) 1.2说明 socket本质是编程接口(API) :socket是对TCP/IP协议的封装，socket只是个编程接口不是协议，通过socket我们才能使用TCP/IP协议簇 TCP/IP也要提供可供程序员做网络开发所用的接口，这就是socket编程接口，socket提供了网络通信的能力 套接字之间的连接过程可分为3个步骤： 1.服务器监听 2.客户端请求 3.连接确认 2.创建socket 语法 #导入套接字模块 from socket import * #创建套接字对象 s = socket(socket.AF_NENT,SOCK_DGRAM) 参数说明 AF_NENT #指明IPV4 SOCKET_DGRAM #套接字类型，SOCKET_DGRAM是tcp协议 SOCKET_STREAM #套接字类型，SOCKET_STREAM是udp协议 3.socket编程-udp 3.1udp说明 3.1.1概念 UDP：User Data Protocol，用户数据报协议，是一个无连接的简单的面向数据报的传输层协议，udp不提供可靠性，它只是把应用层传给IP层的数据报发出去，但是并不能保证它们能到达目的地，由于udp在传输数据报前不用在客户端和服务器之间建立一个连接，且没有超时重发等机制，故而传输速度很快** 3.1.2udp用处 udp一般用于多点通信和实时的数据业务，比如 语音广播 视频 QQ TFTP(简单文件传输) 3.2使用udp发送数据 第一步 发送数据，为看到效果先安装网络调试助手NetAssist(windows安装) NetAssist初始配置，协议选择UDP，IP地址会自动识别本机地址，端口号任意选择一个可使用的，配置完成后点击连接按钮 from socket import * #AF_INET表示IPV4 SOCK_DGRAM表示udp协议 s = socket(AF_INET,SOCK_DGRAM) #NetAssist中的默认编码是gb2312，这里需要指定一下，否则显示的信息会是乱码 s.sendto(\"你好\".encode(\"gb2312\"),(\"192.168.34.90\",8080)) 第二步 运行以上代码，会在NetAssist中看到效果 这里可以看到发送的你好已经在NetAssist中收到 3.3使用udp接收数据 3.3.1udp接收数据 from socket import * s = socket(AF_INET, SOCK_DGRAM) #创建套接字 addr = ('127.0.0.1', 8888) #准备接收方地址 data = input(\"请输入：\") s.sendto(data.encode(),addr) #等待接收数据 redata = s.recvfrom(1024) #1024表示本次接收的最大字节数 print(redata) s.close() mac和linux中运行程序，输入内容后程序会卡住，原因未知⚠️⚠️⚠️ windows中运行程序，输入内容后会返回如下结果 (b'abc', ('127.0.0.1', 8888)) 3.2.2udp绑定信息 bind 如果信息(IP地址、端口号)没有绑定，每发送一次信息，系统会随机分配一个端口，还要避免同一台计算机上的不同进程端口号相同的问题 绑定信息：让一个进程可以使用固定的端口 一般情况下，发送方不绑定端口，接收方会绑定 from socket import * s = socket(AF_INET, SOCK_DGRAM) #创建套接字 s.bind(('', 8788)) #绑定本机一个端口，ip地址和端⼝号，ip⼀般不⽤写 addr = ('192.168.1.17', 8080) #准备接收方地址和端口 data = input(\"请输入：\") s.sendto(data.encode(),addr) redata = s.recvfrom(1024) #1024表示本次接收的最⼤字节数 print(redata) s.close() 3.3.3echo服务器 echo服务器就是发送什么，返回什么 udp接收使用recvfrom方法 from socket import * s = socket(AF_INET,SOCK_DGRAM) port = 8888 s.bind((\"\",port)) rdata = s.recvfrom(1024) print(rdata) 执行以上代码，程序会等待接受消息 NetAssist端发送消息，程序会接收到如下结果，是一个元组 (b'hehe', ('192.168.34.11', 8080)) 结果说明： b'hehe' #接收到的是一个字节码 192.168.34.11 #发送方IP地址 8080 #发送方端口 以下代码为udp无限接收消息 from socket import * s = socket(AF_INET,SOCK_DGRAM) port = 8888 s.bind((\"\",port)) #绑定8888端口，注意这里是一个元组⚠️ while True: rdata = s.recvfrom(1024) #s.recvfrom表示接收的消息，1024表示本次接收的最大字节数 s.sendto(rdata[0],rdata[1]) #发送数据，rdata[0]是接受的信息，rdata[1]是接收的IP地址和端口 4.使用socket进行网络通信的过程 1.导入socket模块 2.创建套接字对象 3.绑定IP地址和端口号(接收数据时要绑定端口，发送时可以不绑定) 4.发送消息，需要写明接收方的IP和端口号 5.接受消息(接受消息前如果没有进行过通信，需要先发送一次) 以下代码为模拟全双工，python程序发送信息给NetAssist,NetASssist发送信息给python程序，如果发送的信息中包含886、在见、再见等就退出程序 from socket import * import time #1创建套接字 udpSocket = socket(AF_INET, SOCK_DGRAM) bindAddr = (\"\",7088) udpSocket.bind(bindAddr)#绑定 while True: lst = ['886','在见','再见'] #接收对方发送的数据 recvData = udpSocket.recvfrom(1024) print(recvData) print(type(recvData[0].strip())) #类型是字节 print(str(recvData[0].strip(), encoding='gb2312')) #类型是字符串 if str(recvData[0].strip(),encoding='gb2312') in lst: break print('[%s] %s.%s' %(time.ctime(),recvData[1],recvData[0].decode(\"gb2312\"))) a = input(\"请输入：\") udpSocket.sendto(a.encode('gb2312'),('192.168.34.11',8080)) if a in lst: break udpSocket.close() 5.udp广播 5.1概念、分类、示意图 概念 udp广播：当前网络上所有电脑的某个进程都收到同一个数据(⚠️tcp没有广播) 分类 单播：点对点 多播：一对多 广播：一对所有 示意图 5.2配置udp广播 发送方 from socket import * #创建udp套接字 s = socket(AF_INET,SOCK_DGRAM) #对这个需要发送广播数据的套接字进行修改设置，固定格式，否则不能发送广播数据 s.setsockopt(SOL_SOCKET,SO_BROADCAST,1) #代表当前网段的广播地址，编码如果不写就是utf-8 s.sendto(\"udp广播信息测试\".encode(),(\"\",8080)) s.close() 接收方 from socket import * s = socket(AF_INET,SOCK_DGRAM) addr = s.bind((\"\",8080)) recv = s.recvfrom(1024) print(recv[0].decode()) s.close() 运行过程 1.先运行接收方程序等待接受，程序会卡住直到接收到信息 2.发送方运行程序，向当前网络中发送udp广播，接收程序就会收到发送方的信息 6.基于udp实现的TFTP 6.1TFTP介绍 概念 TFTP(Trivial File Transfer Protocol，简单文件传输协议)是TCP/IP协议簇中一个用来在客户端和服务器之间进行简单文件传输的协议 作用 使用TFTP协议，就可以实现简单文件的下载 特点 简单 占用资源小 适合传递小文件 适合在局域网进行传递 端口号为69 基于udp实现 6.2TFTP传输过程 第一步、客户端向服务端发送读写请求，服务端默认端口udp69 第二步、服务端响应数据包发送给客户端，TFTP数据包有固定的格式 第三步、客户端收到数据包后向服务端返回确认信息ACK 传输过程中涉及的一些问题 服务端向客户端传数据的时候发生丢包怎么办？ 如果服务端发送给客户端的数据包发生丢失情况，则服务端会重新发送数据给客户端 客户端向服务端返回的确认信息丢失怎么办？ 客户端会重发ACK给服务端，这样服务端才能继续传输数据 客户端如何确定服务端已经全部传输完毕？ TFTP协议中，服务端每次会固定向客户端返回516字节的数据(2字节操作码+2字节块编号+512字节真实数据)，当客户端接收到的数据小于516字节时，就意味着服务端已经发送完毕了 如果恰好最后一次数据长度为516字节，服务端会再发一个长度为0的数据包 TFTP能否保证数据不丢包？ TFTP是可以保证数据不丢包的，因为客户端如果没有收到数据服务端会重发数据，服务端没有收到客户端发送的ACK就不会继续发送数据 TFTP不能保证数据不丢失，例如，客户端收到的数据小于服务端发送的516字节，这种情况无法做校验 6.3TFTP格式要求 TFTP格式要求 6.4TFTP构造下载请求数据 TFTP构造下载请求数据需要根据TFTP读写请求格式来编写 以下代码为构造TFTP请求数据示例 #需要导入struct模块 import struct #构造下载请求 filename = \"abc.jpg\" //将文件名赋值给变量，方便修改 requestData = struct.pack(\"!H%dsb5sb\" %len(filename.encode(\"gb2312\")),1,filename.encode(\"gb2312\"),0,\"octet\".encode(\"gb2312\"),0) struct.pack(\"!H%dsb5sb\" %len(filename.encode(\"gb2312\")),1,filename.encode(\"gb2312\"),0,\"octet\".encode(\"gb2312\"),0) struct.pack是一种打包的方法，打包格式中分为6个部分，第1部分是对后5部分进行的统一说明，后5部分是TFTP读写请求固定格式 !H%dsb5sb\" %len(filename.encode(\"gb2312\")) 1 filename.encode(\"gb2312\"）#编码方式根据实际情况修改 0 \"octet\".encode(\"gb2312\") #编码方式根据实际情况修改 0 第一部分 \"!H%dsb5sb\" %len(filename.encode(\"gb2312\")) !表示按照网络传输数据要求的形式来组织数据 H表示将第二部分的1替换成占2个字节 %d是数字占位符，因为后面写了 %len(filename.encode(\"gb2312\"))，因此这里的%s就是存放文件名的变量filename中的文件的字节长度，%d后边的b表示字节 5sb是指后边的 octet,sb表示的是字节，octet是5个字节，因此是5sb，这里是固定的格式 第二部分 1 这里的1已经由前边的H替换成2个字节，表示的是上传还是下载，1是下载，2是上传 第三部分 filename.encode(\"gb2312\") 这里表示将文件名编码成二进制，⚠️注意，这里的编码方式要根据实际情况做相应的修改 第四部分 0 这里的0是固定格式 第五部分 \"octet\".encode(\"gb2312\") 这里的octet是固定格式 第六部分 0 这里的0是固定格式 6.5实现TFTP下载 6.5.1struct模块说明 作用 struct模块可以按照指定格式将python数据转换为字符串，该字符串为字节流 struct中的三个重要函数 pack 按照给定的格式(fmt)，把数据封装成字符串(实际上是类似于c结构的字节流) pack(fmt,v1,v2,...) struct.pack(\"!H8sb5sb\",1,\"test.jpg\",0,\"octet\",0) unpack 按照给的格式(fmt)解析字节流string，返回解析出来的元组 unpact(fat,string) struct.unpack(\"!HH\",4,p_num) cmdTuple = struct.unpack(\"!HH\",recvData[:4]) calcsize 计算给定的格式(fmt)占用多少字节 struct模块使用说明图 6.5.2TFTP下载程序 第一步、设置TFTP服务端 实现TFTP需要用到一个软件Tftpd32，选择共享的目录用来提供下载，选择本机网卡127.0.0.1 第二步、编写下载器(客户端) 实现TFTP下载器 下载：从服务器上将一个文件复制到本地 下载过程 在本地创建一个空文件，文件名一定要与下载的文件名相同 向空文件中写入接收到的数据，接收一点写入一点 接收完所有数据后关闭文件 编写一个TFTP下载程序 #导入struct模块、socket模块、time模块 import struct from socket import * import time #TFTP中共享的文件及TFTP服务端IP地址分别写入变量中 filename = \"xiaohua.jpg\" serverIP = \"192.168.34.112\" #利用struck模块的pack方法封装请求数据，代码具体含义在6.4TFTP构造下载请求数据 requestData = struct.pack(\"!H%dsb5sb\" %len(filename.encode(\"gb2312\")),1,filename.encode(\"gb2312\"),0,\"octet\".encode(\"gb2312\"),0) #创建套接字对象 s = socket(AF_INET,SOCK_DGRAM) #发送请求数据 s.sendto(requestData,(serverIP,69)) #设置文件句柄，将后续接收的数据写入到文件中，⚠️写入的文件必须与TFTP中共享的文件名相同 f = open(filename,\"ab\") #因为不知道要接受的数据有多大，因此写一个while循环循环接收，知道接收完成 while True: #接收数据，打印一下看看接收到的内容是什么 recvData = s.recvfrom(1024) print(recvData) 收到的数据内容如下，是一个元组，分为两个部分 第一部分是 操作码+块编号+真实数据 一共516字节 操作码：前2个字节 块编号：前2个字节 真实数据：512字节 第二部分是 TFTP服务端IP及TFTP向客户端响应数据时用到的随机端口 ⚠️TFTP向客户端返回数据时不会使用默认的69端口，会使用一个随机端口，因为69端口还需要向其他客户端响应请求，而后续客户端向服务端返回ACK确认信息时，也需要用到这个随机端口⚠️ (b'\\x00\\x03\\x00\\x01FLV\\x01\\此处省略一万字\\x00!modified by youku.com in 20111202\\x00\\x0chasKeyframes\\\\x00\\x00Aj\\xb0\\xa6@\\x00', ('192.168.34.112', 49373)) \\x00\\x03\\x00\\x01FLV 这一部分其实就能看到操作码和块编号，操作码是3(\\x03),块编号是1(\\x01)，文件名是(FLv) 上述代码中已经收到了TFTP响应的数据，接下来获取一下操作码和块编号 #因为不知道要接收的数据有多大，因此写一个while循环循环接收，知道接收完成 while True: #接收数据，打印一下看看接收到的内容是什么 recvData = s.recvfrom(1024) print(recvData) #获取操作码和块编号，这里用到了struct模块中的unpack(解包)方法 caozuoma,kuaibianhao = struct.unpack(\"!HH\",recvData[0][:4]) //获取操作码和块编号代码说明 收到的数据如下 (b'\\x00\\x03\\x00\\x01FLV\\x01\\此处省略一万字\\x00!modified by youku.com in 20111202\\x00\\x0chasKeyframes\\\\x00\\x00Aj\\xb0\\xa6@\\x00', ('192.168.34.112', 49373)) 要获取操作码和代码块，需要截取收到的数据的第一部分中的前4个字节 返回的数据的是一个元组 第一部分是 操作码+块编号+真实数据 一共516字节 操作码：前2个字节 块编号：前2个字节 真实数据：512字节 第二部分是 服务器IP地址和随机端口 获取到的结果如下，因为还没有向服务器发送ACK确认信息，因此块编号会一直收到1 3 1 3 1 。。。 现在已经获取到了操作码和块编号，接下来就可以写入本地文件以及向服务器发送ACK确认信息了 #先判断一下操作码是否是5，如果是5则就是错误信息 if caozuoma == 5: print(\"文件不存在！！！\") break #将收到的数据写入本地文件，收到的数据的第一部分第4个字节后的512字节就是真实数据 f.write(recvData[0][4:]) #TFTP协议中每次传输的数据是512字节，这里做一个判断，如果数据小于512字节则说明客户端接收完毕 ⚠️这里需要注意一下的是，如果最后一次传输的数据恰好等于512字节，则服务端会再次发送一个数据长度为0的包 if len(recvData[0]) 完整代码 import struct from socket import * import time filename = \"xiaohua.jpg\" serverIP = \"192.168.34.112\" requestData = struct.pack(\"!H%dsb5sb\" %len(filename.encode(\"gb2312\")),1,filename.encode(\"gb2312\"),0,\"octet\".encode(\"gb2312\"),0) s = socket(AF_INET,SOCK_DGRAM) s.sendto(requestData,(serverIP,69)) f = open(filename,\"ab\") while True: recvData = s.recvfrom(1024) print(recvData) caozuoma,kuaibianhao = struct.unpack(\"!HH\",recvData[0][:4]) serverPort = recvData[1][1] print(caozuoma,kuaibianhao) if caozuoma == 5: print(\"文件不存在！！！\") break f.write(recvData[0][4:]) if len(recvData[0]) 6.6实现TFTP上传 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/26.3python基础二十六 网络编程-tcp编程.html":{"url":"python/python基础/26.3python基础二十六 网络编程-tcp编程.html","title":"网络编程-TCP编程","keywords":"","body":"python基础二十六 网络编程-tcp编程 1.TCP介绍 TCP 与 UDP 的区别相当大。它充分地实现了数据传输时各种控制功能，可以进行丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。而这些在 UDP 中都没有。 此外，TCP 作为一种面向有连接的协议，只有在确认通信对端存在时才会发送数据，从而可以控制通信流量的浪费。 根据 TCP 的这些机制，在 IP 这种无连接的网络上也能够实现高可靠性的通信（ 主要通过检验和、序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现）。 2.TCP三次握手与四次挥手 2.1TCP三次握手 TCP 提供面向有连接的通信传输。面向有连接是指在数据通信开始之前先做好两端之间的准备工作。 所谓三次握手是指建立一个 TCP 连接时需要客户端和服务器端总共发送三个包以确认连接的建立。在socket编程中，这一过程由客户端执行connect来触发。 下面来看看三次握手的流程图： 三次握手过程 第一次握手：客户端将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给服务器端，客户端进入SYN_SENT状态，等待服务器端确认。 第二次握手：服务器端收到数据包后由标志位SYN=1知道客户端请求建立连接，服务器端将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给客户端以确认连接请求，服务器端进入SYN_RCVD状态。 第三次握手：客户端收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给服务器端，服务器端检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，客户端和服务器端进入ESTABLISHED状态，完成三次握手，随后客户端与服务器端之间可以开始传输数据了。 2.2TCP四次挥手 四次挥手即终止TCP连接，就是指断开一个TCP连接时，需要客户端和服务端总共发送4个包以确认连接的断开。在socket编程中，这一过程由客户端或服务端任一方执行close来触发。 由于TCP连接是全双工的，因此，每个方向都必须要单独进行关闭，这一原则是当一方完成数据发送任务后，发送一个FIN来终止这一方向的连接，收到一个FIN只是意味着这一方向上没有数据流动了，即不会再收到数据了，但是在这个TCP连接上仍然能够发送数据，直到这一方向也发送了FIN。首先进行关闭的一方将执行主动关闭，而另一方则执行被动关闭。 下面来看看四次挥手的流程图： 中断连接端可以是客户端，也可以是服务器端。 第一次挥手：客户端发送一个FIN=M，用来关闭客户端到服务器端的数据传送，客户端进入FIN_WAIT_1状态。意思是说\"我客户端没有数据要发给你了\"，但是如果你服务器端还有数据没有发送完成，则不必急着关闭连接，可以继续发送数据。 第二次挥手：服务器端收到FIN后，先发送ack=M+1，告诉客户端，你的请求我收到了，但是我还没准备好，请继续你等我的消息。这个时候客户端就进入FIN_WAIT_2 状态，继续等待服务器端的FIN报文。 第三次挥手：当服务器端确定数据已发送完成，则向客户端发送FIN=N报文，告诉客户端，好了，我这边数据发完了，准备好关闭连接了。服务器端进入LAST_ACK状态。 第四次挥手：客户端收到FIN=N报文后，就知道可以关闭连接了，但是他还是不相信网络，怕服务器端不知道要关闭，所以发送ack=N+1后进入TIME_WAIT状态，如果Server端没有收到ACK则可以重传。服务器端收到ACK后，就知道可以断开连接了。客户端等待了2MSL后依然没有收到回复，则证明服务器端已正常关闭，那好，我客户端也可以关闭连接了。最终完成了四次挥手。 上面是一方主动关闭，另一方被动关闭的情况，实际中还会出现同时发起主动关闭的情况， 具体流程如下图： 3.TCP其他特性 3.1通过序列号与确认应答提高可靠性 在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个已收到消息的通知。这个消息叫做确认应答（ACK）。当发送端将数据发出之后会等待对端的确认应答。如果有确认应答，说明数据已经成功到达对端。反之，则数据丢失的可能性很大。 在一定时间内没有等待到确认应答，发送端就可以认为数据已经丢失，并进行重发。由此，即使产生了丢包，仍然能够保证数据能够到达对端，实现可靠传输。 未收到确认应答并不意味着数据一定丢失。也有可能是数据对方已经收到，只是返回的确认应答在途中丢失。这种情况也会导致发送端误以为数据没有到达目的地而重发数据。 此外，也有可能因为一些其他原因导致确认应答延迟到达，在源主机重发数据以后才到达的情况也屡见不鲜。此时，源主机只要按照机制重发数据即可。 对于目标主机来说，反复收到相同的数据是不可取的。为了对上层应用提供可靠的传输，目标主机必须放弃重复的数据包。为此我们引入了序列号。 序列号是按照顺序给发送数据的每一个字节（8位字节）都标上号码的编号。接收端查询接收数据 TCP 首部中的序列号和数据的长度，将自己下一步应该接收的序列号作为确认应答返送回去。通过序列号和确认应答号，TCP 能够识别是否已经接收数据，又能够判断是否需要接收，从而实现可靠传输。 3.2重发超时的确定 重发超时是指在重发数据之前，等待确认应答到来的那个特定时间间隔。如果超过这个时间仍未收到确认应答，发送端将进行数据重发。最理想的是，找到一个最小时间，它能保证“确认应答一定能在这个时间内返回”。 TCP 要求不论处在何种网络环境下都要提供高性能通信，并且无论网络拥堵情况发生何种变化，都必须保持这一特性。为此，它在每次发包时都会计算往返时间及其偏差。将这个往返时间和偏差时间相加，重发超时的时间就是比这个总和要稍大一点的值。 在 BSD 的 Unix 以及 Windows 系统中，超时都以0.5秒为单位进行控制，因此重发超时都是0.5秒的整数倍。不过，最初其重发超时的默认值一般设置为6秒左右。 数据被重发之后若还是收不到确认应答，则进行再次发送。此时，等待确认应答的时间将会以2倍、4倍的指数函数延长。 此外，数据也不会被无限、反复地重发。达到一定重发次数之后，如果仍没有任何确认应答返回，就会判断为网络或对端主机发生了异常，强制关闭连接。并且通知应用通信异常强行终止。 3.3以段为单位发送数据 在建立 TCP 连接的同时，也可以确定发送数据包的单位，我们也可以称其为“最大消息长度”（MSS）。最理想的情况是，最大消息长度正好是 IP 中不会被分片处理的最大数据长度。 TCP 在传送大量数据时，是以 MSS 的大小将数据进行分割发送。进行重发时也是以 MSS 为单位。 MSS 在三次握手的时候，在两端主机之间被计算得出。两端的主机在发出建立连接的请求时，会在 TCP 首部中写入 MSS 选项，告诉对方自己的接口能够适应的 MSS 的大小。然后会在两者之间选择一个较小的值投入使用。 3.4利用窗口控制提高速度 TCP 以1个段为单位，每发送一个段进行一次确认应答的处理。这样的传输方式有一个缺点，就是包的往返时间越长通信性能就越低。 为解决这个问题，TCP 引入了窗口这个概念。确认应答不再是以每个分段，而是以更大的单位进行确认，转发时间将会被大幅地缩短。也就是说，发送端主机，在发送了一个段以后不必要一直等待确认应答，而是继续发送。如下图所示： 窗口大小就是指无需等待确认应答而可以继续发送数据的最大值。上图中窗口大小为4个段。这个机制实现了使用大量的缓冲区，通过对多个段同时进行确认应答的功能。 3.5滑动窗口控制 上图中的窗口内的数据即便没有收到确认应答也可以被发送出去。不过，在整个窗口的确认应答没有到达之前，如果其中部分数据出现丢包，那么发送端仍然要负责重传。为此，发送端主机需要设置缓存保留这些待被重传的数据，直到收到他们的确认应答。 在滑动窗口以外的部分包括未发送的数据以及已经确认对端已收到的数据。当数据发出后若如期收到确认应答就可以不用再进行重发，此时数据就可以从缓存区清除。 收到确认应答的情况下，将窗口滑动到确认应答中的序列号的位置。这样可以顺序地将多个段同时发送提高通信性能。这种机制也别称为滑动窗口控制。 3.6窗口控制中的重发控制 在使用窗口控制中， 出现丢包一般分为两种情况： ① 确认应答未能返回的情况。在这种情况下，数据已经到达对端，是不需要再进行重发的，如下图： ② 某个报文段丢失的情况。接收主机如果收到一个自己应该接收的序列号以外的数据时，会针对当前为止收到数据返回确认应答。如下图所示，当某一报文段丢失后，发送端会一直收到序号为1001的确认应答，因此，在窗口比较大，又出现报文段丢失的情况下，同一个序列号的确认应答将会被重复不断地返回。而发送端主机如果连续3次收到同一个确认应答，就会将其对应的数据进行重发。这种机制比之前提到的超时管理更加高效，因此也被称为高速重发控制。 4.TCP编程流程 4.1长连接与短连接 长连接 长连接指的是三次握手与四次挥手之间分多次传递完所有数据，会长时间占用某个套接字，例如在线看视频、打游戏就是长连接 短连接 短连接指的是三次握手与四次挥手之间传递少部分数据，多次握手挥手才传递完所有数据，会短时间占用某个套接字，例如浏览器静态页面就是短连接，因为浏览器静态页面可能会非常多，而浏览者不一定会全部阅读完，因此浏览器会先加载一部分页面，然后断开连接，将连接空闲出来提供其他请求，等到浏览者继续往下流览再把剩余的内容建立连接发送完成 4.2TCP编程流程说明 过程说明 服务端 1.服务端创建socket套接字对象，用于收发数据 socket() 2.服务端绑定自身的IP及端口 bind() 3.服务端设置最大连接数 listen() 这里的最大连接数指的是，服务端达到最大连接数后，后续可以排队等待的请求数，超过这个数字就会被服务端拒绝服务，例如listen(5)，这里设置为5，假如服务器达到了最大连接数1万，则可以排队等待的请求数为5 4.服务端创建accept()，等待接受socket连接，服务端的accept会与客户端创建的connect建立TCP三次握手 客户端 1.客户端创建socket套接字对象，用于收发数据 socket() 2.客户端创建connect，用于连接服务端，connect会与服务端创建的accept建立TCP三次握手 5.创建TCP服务器、客户端 5.1最low版TCP服务器、客户端 编写一个最简单的TCP服务器 #导入socket模块 from socket import * #创建socket套接字，用于tcp监听 tcpSocket = socket(AF_INET,SOCK_STREAM) #绑定服务端IP地址和端口 tcpSocket.bind((\"127.0.0.1\",8080)) #设置最大连接数,这里的最大连接数指的是服务端达到最大连接数后可以排队等待的请求数 tcpSocket.listen(5) #创建一个新的套接字，等待接受socket连接，于收发数据,接受到的数据解构为新套接字和客户端IP地址 newTcpSocket,addr = tcpSocket.accept() #发送数据，编码根据实际情况指定 newTcpSocket.send(\"我是tcp服务端，快来连我！\".encode()) print(newTcpSocket.recv(1024).decode()) #发送完数据后关闭用于收发数据的新套接字对象 newTcpSocket.close() #关闭用于监听的套接字对象，关闭后程序不再接受任何新的客户端连接 tcpSocket.close() 编写一个最简单的TCP客户端 #导入socket模块 from socket import * #创建socket套接字对象 tcpSocket = socket(AF_INET,SOCK_STREAM) #创建connect，用于连接TCP服务器 tcpSocket.connect((\"127.0.0.1\",8080)) #接受数据 recvData = tcpSocket.recv(1024) print(recvData.decode()) #向TCP服务端发送数据 tcpSocket.send(\"我是tcp客户端，我来了！\".encode()) #关闭套接字对象 tcpSocket.close() 5.2单进程TCP服务器 单进程的TCP服务器每次只能服务一个客户端 #导入socket模块 from socket import * #创建只用来监听的套接字对象 serverSocket = socket(AF_INET,SOCK_STREAM) #绑定TCP服务端IP和端口 addr = (\"192.168.34.90\",9999) serverSocket.bind(addr) #设置最大排队等待数 serverSocket.listen(3) #这里要能多次处理客户端连接请求，因此写一个while循环 while True: print(\"主进程等待新客户端连接\") #创建accept，用来等待客户端socket连接 newSocket,clientAddr = serverSocket.accept() print(newSocket) #打印结果 print(clientAddr) #打印结果 ('192.168.34.90', 55255) #clientAddr[0]就是客户端的IP地址，clientAddr[1]就是客户端的端口 print(f\"主进程接下来负责处理{clientAddr[0]},端口{clientAddr[1]}的请求\") #传输过程可能会出错，因此写一个异常处理避免程序崩溃 try: while True: #接受数据并解码，编码类型根据实际情况填写 recvData = newSocket.recv(1024).decode() #做一个判断，如果收到的数据内容长度大于0，则说明是在接受数据，并打印接受的数据，都则就提示客户端已关闭 if len(recvData) > 0: print(f\"接收到来自{clientAddr[0]}，端口{clientAddr[1]}的数据:\",recvData) else: print(f\"{clientAddr[0]}客户端已关闭\") break except Exception: print(\"接收数据出错！\") #无论接受是否报错最后都执行关闭新建的用于收发数据的套接字 finally: newSocket.close() break #关闭用于监听的套接字 serverSocket.close() TCP客户端编写 #导入socket模块 from socket import * #创建socket套接字对象 tcpSocket = socket(AF_INET,SOCK_STREAM) #创建connect，用于连接TCP服务器 tcpSocket.connect((\"192.168.34.90\",9999)) #向TCP服务端发送数据 while True: s = input(\"请输入要发送的内容>>>\") tcpSocket.send(s.encode()) #如果客户端输入的是Q或者q，则关闭套接字对象并退出程序 if s.lower() == \"q\": tcpSocket.close() break 服务端接受本机客户端发送的信息 服务端接收其他机器客户端发送的信息 5.3并发TCP服务器 5.3.1 setsockopt(SOL_SOCKET,SO_REUSEADDR,1）方法 serSocket.setsockopt(SOL_SOCKET,SO_REUSEADDR,1） serSokcet是套接字对象变量名，此选项意思为重新设置套接字选项，重复使用绑定的信息 这么做的原因？ 当有一个有相同本地地址和端口的socket1处于TIME_WAIT状态时，而你启动的程序的socket2要占用该地址和端口，你的程序就要用到SO_REUSEADDR选项。 在多进程中的作用？ 使用多进程编写并发TCP服务，因为有多个子进程可以提供服务，因此每个子进程需要占用主进程的端口，但是端口只能被一个进程占用，这个时候就出现了端口被占用的情况，所以用到了setsockopt(SOL_SOCKET,SO_REUSEADDR,1）方法 在多线程中的作用？ 使用多线程编写并发TCP服务，线程之间是共享数据的，不存在端口被占用情况，但是多线程中每个子线程使用主进程的端口后，系统会保留几分钟端口被占用的状态，不让别的线程使用，使用setsockopt(SOL_SOCKET,SO_REUSEADDR,1）方法让端口不被系统保留 5.3.2多进程TCP服务器 5.3.3多线程TCP服务器 6.sockeserver 6.1sockeserver介绍 概念 socketserver可以实现和多个客户端通信（实现并发处理多个客户端请求的Socket服务端） 作用 可以使用socketserver来创建socket用来简化并发服务器 原理 它是在socket的基础上进行了一层封装，也就是说底层还是调用的socket 处理请求过程 服务器接受客户端连接请求 ➡️ 实例化一个请求处理程序 ➡️ 根据服务器类和请求处理程序类，调用处理方法。 例如：基本请求程序类（BaseRequestHandler）调用方法 handle 。此方法通过属性 self.request来访问客户端套接字 7.远程执行命令subprocess 7.1subprocess介绍 作用 python可以使用subprocess模块下Popen类中封装的方法来执行系统终端命令 语法 obj = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) //参数说明 shell=True #命令解释器，相当于调用windows中的cmd或者mac中的终端执行指定的命令 stdout=subprocess.PIPE #stdout表示正确结果丢到管道中 stderr=subprocess.PIPE #stderr表示错误结果丢到管道中 PIPE #PIPE表示将结果转移到当前进程 subprocess方法 Popen() 构造方法，用于创建Popen类的实例化对象 stdout.read() stderr.read() 可以获取命令执行的结果(正确的与错误的) 7.2subprocess使用示例 import subprocess while True: cmd = input(\"请输入命令>>>\") obj = subprocess.Popen(cmd, shell = True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, ) error = obj.stderr.read().decode(\"utf-8\") out = obj.stdout.read().decode(\"utf-8\") print(error + out) if cmd.lower() == \"q\": break 执行以上代码，输入命令，就会有返回结果 ⚠️windows中的系统编码是GBK，mac中的是utf-8 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python基础/27.python基础二十七 python操作mysql.html":{"url":"python/python基础/27.python基础二十七 python操作mysql.html","title":"python基础二十七 python操作mysql","keywords":"","body":"python基础二十七 python操作mysql 1.安装pymysql pip3 install pymysql 2.python连接mysql 2.1python连接mysql语法 //导入pymysql模块 import pymysql //打开数据库连接 ⚠️⚠️⚠️指定字符集的时候utf-8在这里的写法为utf8 conn = pymysql.connect(\"数据库ip\",\"用户\",\"密码\",\"数据库\",\"端口(不写默认为3306)\",\"字符集\") //使用cursor()方法获取操作游标 cursor = conn.cursor() //使用execute()方法执行SQL操作 cursor.execute(\"SQL语句\") //使用fetchone()方法获取单条数据 data = cursor.fetchone() print (\"Database version : %s \" %data) //关闭游标 cursor.close() //关闭数据库连接 conn.close() 2.2python连接mysql简单查询示例 //数据库db1中有一张t1表，表内容如下 mysql> select * from t1; +------+--------+ | id | name | +------+--------+ | 1 | 小明 | | 2 | 小颖 | | 3 | 小丽 | +------+--------+ 3 rows in set (0.00 sec) //接下来连接数据库进行操作 #导入pymysql模块 import pymysql #打开数据库连接 conn = pymysql.connect( host='xxx', user='xxx', password=\"xxx\", database='db1', port=3306, charset='utf8', ) #创建游标 cursor = conn.cursor() #定义一个变量，存放sql语句 sql = 'select * from t1' #使用execute()方法执行sql操作 cursor.execute(sql) #使用fetchall()方法获取所有数据 data = cursor.fetchall() #打印查询的内容 print(data) ((1, '小明'), (2, '小颖'), (3, '小丽')) #关闭游标 cursor.close() #关闭连接 conn.close() 3.python操作mysql 3.1创建表操作 #导入pymysql模块 import pymysql #打开数据库连接 db = pymysql.connect(\"localhost\",\"testuser\",\"test123\",\"TESTDB\" ) #使用cursor()方法创建一个游标对象cursor cursor = db.cursor() #使用execute()方法执行 SQL，如果表存在则删除 cursor.execute(\"drop table if exists t2\") #使用预处理语句创建表 sql = \"\"\"create table t2( id int not null, age int not null, name char(10) not null, hobby set('唱','跳','rap','篮球'))\"\"\" #执行sql语句 cursor.execute(sql) #查看结果 mysql> show tables; +---------------+ | Tables_in_db1 | +---------------+ | t1 | | t2 | +---------------+ 2 rows in set (0.00 sec) mysql> desc t2; +-------+---------------------------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+---------------------------------+------+-----+---------+-------+ | id | int(11) | NO | | NULL | | | age | int(11) | NO | | NULL | | | name | char(10) | NO | | NULL | | | hobby | set('唱','跳','rap','篮球') | YES | | NULL | | +-------+---------------------------------+------+-----+---------+-------+ 4 rows in set (0.00 sec) #关闭游标 cursor.clos() #关闭数据库连接 conn.close() 3.2数据操作 3.2.1查询操作 python操作mysql时获取数据的方法有3种 cursor.fetchone() #查询返回一条结果 cursor.fetchmany(n) #查询返回指定的条数，n为数字 cursor.fetchall() #查询返回所有的结果 //数据库db1中有一张t1表，表内容如下 mysql> select * from t1; +------+--------+ | id | name | +------+--------+ | 1 | 小明 | | 2 | 小颖 | | 3 | 小丽 | +------+--------+ 3 rows in set (0.00 sec) //使用cursor.fetchone()方法获取一条结果 data = cursor.fetchone() print(data) (1, '小明') //使用cursor.fetchmany(n)方法指定获取的内容个数，n为数字 #fetchmany不指定获取个数时返回的内容 data = cursor.fetchmany() print(data) ((1, '小明'),) #fetchmany指定获取个数时返回的内容 data = cursor.fetchmany(2) print(data) ((1, '小明'), (2, '小颖')) //使用cursor.fetchall()方法获取全部内容 data = cursor.fetchall() print(data) ((1, '小明'), (2, '小颖'), (3, '小丽')) fetch方法返回的结果都是元组，没法看出哪个数据是对应的哪个字段，可以采用字典的方式显示，这样看起来比较明确 可以在创建游标的时候，加上一个参数让返回的结果是字典格式展示 //创建游标的时候加上一个参数cursor=pymysql.cursors.DictCursor让返回的结果是字典格式 cursor = conn.cursor(cursor=pymysql.cursors.DictCursor) data = cursor.fetchall() print(data) [{'id': 1, 'name': '小明'}, {'id': 2, 'name': '小颖'}, {'id': 3, 'name': '小丽'}] 3.2.2增加数据操作 //数据库中t2表内容为空 mysql> desc t2; +-------+---------------------------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+---------------------------------+------+-----+---------+-------+ | id | int(11) | NO | | NULL | | | age | int(11) | NO | | NULL | | | name | char(10) | NO | | NULL | | | hobby | set('唱','跳','rap','篮球') | YES | | NULL | | +-------+---------------------------------+------+-----+---------+-------+ 4 rows in set (0.00 sec) mysql> select * from t2; Empty set (0.00 sec) //现在向t2表中插入数据 import pymysql conn = pymysql.connect( host='xxx', user='pptfz', password=\"xxx\", database='db1', port=3306, charset='utf8', ) cursor = conn.cursor(cursor=pymysql.cursors.DictCursor) sql = \"\"\" insert into t2 values(1,18,'小明','唱,篮球'), (2,20,'小颖','唱,跳'), (3,28,'小坤','唱,跳,rap,篮球') \"\"\" cursor.execute(sql) conn.commit() conn.close() //查看结果 sql = 'select * from t2' cursor.execute(sql) data = cursor.fetchall() print(data) [{'id': 1, 'age': 18, 'name': '小明', 'hobby': '唱,篮球'}, {'id': 2, 'age': 20, 'name': '小颖', 'hobby': '唱,跳'}, {'id': 3, 'age': 28, 'name': '小坤', 'hobby': '唱,跳,rap,篮球'}] 3.2.3删除数据操作 #创建游标 cursor = conn.cursor(cursor=pymysql.cursors.DictCursor) #sql语句 sql = 'delete from t2 where id=3' #执行sql操作，发生错误回滚 try: cursor.execute(sql) conn.commit() except: conn.rollback() #关闭连接 conn.close() 3.2.4修改数据操作 #创建游标 cursor = conn.cursor(cursor=pymysql.cursors.DictCursor) #sql语句 sql = 'update t2 set age=30 where id=2' #执行sql操作，发生错误回滚 try: cursor.execute(sql) conn.commit() except: conn.rollback() #关闭连接 conn.close() 4.execute()之sql注入 4.1先做一个简单的登陆认证 ⚠️这里的示例有sql注入的问题，会在后边的示例中解决 //userinfo表内容如下 mysql> select * from userinfo; +-------+-------+ | uname | pwd | +-------+-------+ | admin | admin | +-------+-------+ 1 row in set (0.00 sec) //接下来做一个单一的判断 #导入pymysql import pymysql #连接mysql conn = pymysql.connect( host='xxx', user='pptfz', password=\"xxx\", database='db1', port=3306, charset='utf8', ) #创建游标 cursor = conn.cursor(cursor=pymysql.cursors.DictCursor) #输入用户民共和密码 uname = input('请输入用户名>>>') password = input('请输入密码>>>') #执行sql语句，返回结果大于1说明用户名和密码存在，否则就是不存在 sql = \"select * from userinfo where uname='%s' and pwd='%s'\"%(uname,password) #执行sql语句 cursor.execute(sql) #查询的结果 data = cursor.fetchone() #做判断 if data: print('登陆成功') else: print('用户名或密码错误') conn.close() 执行结果如下： 当输入的用户名和密码存在于userinfo表中时，这里为固定的用户名amin密码admin返回登陆成功，否则返回用户名或密码错误，这样就做了一个简单的用户登陆认证 登陆成功 登陆失败 4.2sql注入简单示例 4.2.1示例1 接下来做一个操作，在输入用户名的时候，在用户名后边加一个单引号，然后空格，然后写上--，最后--的后面写上任意字符，这样就能在知道用户名的情况下不需要输入密码就可以登陆成功 import pymysql conn = pymysql.connect( host='xxx', user='pptfz', password=\"xxx\", database='db1', port=3306, charset='utf8', ) cursor = conn.cursor(cursor=pymysql.cursors.DictCursor) uname = input('请输入用户名>>>') password = input('请输入密码>>>') # sql = f'select * from userinfo where uname=\"{uname}\" and pwd=\"{password}\"' sql = \"select * from userinfo where uname='%s' and pwd='%s';\"%(uname,password) cursor.execute(sql) # data = cursor.fetchall() data = cursor.fetchone() if data: print('登陆成功') else: print('登陆失败') conn.close() 分析一下结果 此时uname这个变量等于admin' -- xxx，sql语句被字符串替换之后会变成如下 select * from userinfo where uname='admin' -- xxx' and pwd=''; 其中admin后边的'，在进行字符串替换的时候，我们输入的是admin'，这个引号和前边的引号组成了一对，也就是select * from userinfo where uname='admin'' -- xxx and pwd='' --在sql语句中是注释的意思，也就是说后面的语句被注释了，此时的sql语句变成了select * from usrinfo where uname='admin'，后边的' -- xxx and pwd=''变成了注释 这样的话就是知道用户名即可登陆成功，这就是最简单的sql注释 4.2.2示例2 用户名和密码都不需要输入就能登陆成功 or后边跟了一个永真的条件，因此不管输入什么都能登陆成功 有些网站直接在输入内容的时候，就限定了不能输入一些特殊的符号，因为有些特殊符号可以改变sql的执行逻辑，其实不光是--，还有一些其他的符号也能改变sql语句的执行逻辑，这个方案是在客户端给用户输入的地方进行限制，但是别人可不可以模拟你的客户端来发送请求，是可以的，他模拟一个客户端，不按照你的客户端的要求来，就发一些特殊字符，你的客户端是限制不了的。 》所以单纯的在客户端进行这个特殊字符的过滤是不能解决根本问题的，那怎么办？我们服务端也需要进行验证，可以通过正则来将客户端发送过来的内容进行特殊字符的匹配，如果有这些特殊字符，我们就让它登陆失败。 在服务端来解决sql注入的问题：不要自己来进行sql字符串的拼接了，pymysql能帮我们拼接，他能够防止sql注入，所以以后我们再写sql语句的时候按下面的方式写： //之前我们的sql语句是这样写的： sql = \"select * from userinfo where uname='%s' and pwd='%s';\"%(uname,passwdor) //以后再写的时候，sql语句里面的%s左右的引号去掉，并且语句后面的%(uname,pword)这些内容也不要自己写了，按照下面的方式写 sql = \"select * from userinfo where username=%s and password=%s;\" //难道我们不传值了吗，不是的，我们通过下面的形式，在excute里面写参数： 其实它本质也是帮你进行了字符串的替换，只不过它会将uname和password里面的特殊字符给过滤掉 cursor.execute(sql,[uname,password]) 使用cursor.execute方法执行sql语句正确写法 import pymysql conn = pymysql.connect( host='xxx', user='pptfz', password=\"xxx\", database='db1', port=3306, charset='utf8', ) cursor = conn.cursor(cursor=pymysql.cursors.DictCursor) uname = input('请输入用户名>>>') password = input('请输入密码>>>') # sql = f'select * from userinfo where uname=\"{uname}\" and pwd=\"{password}\"' sql = \"select * from userinfo where uname=%s and pwd=%s\" cursor.execute(sql,[uname,password]) # data = cursor.fetchall() data = cursor.fetchone() if data: print('登陆成功') else: print('登陆失败') conn.close() 使用4.2.1示例1中的写法登陆，会提示登陆失败 使用4.2.2示例2中的写法登陆，会提示登陆失败 这样使用cursor.execute方法就解决了简单sql注入的问题，因此以后的任意语句都必须使用此写法来代替我们自己写的字符串替换 cursor.execute(sql,[uname,password]) 4.3sql注入简单总结 4.3.1sql注入的两种方法 两种sql注入方法 1、sql注入之：用户存在，绕过密码 用户名' -- 任意字符 2、sql注入之：用户不存在，绕过用户与密码 用户名' or 1=1 -- 任意字符 4.3.2通过pymysql提供的excute()方法解决了简单sql注入问题 //原来是我们对sql进行字符串拼接 sql=\"select * from userinfo where uname='%s' and pwd='%s'\" %(uname,password) print(sql) data = cursor.execute(sql) //改写为execute帮我们做字符串拼接，我们无需且一定不能再为%s加引号了 sql=\"select * from userinfo where uname=%s and pwd=%s\" //⚠️%s需要去掉引号，因为pymysql会自动为我们加上 data = cursor.execute(sql,[uname,password]) #pymysql模块自动帮我们解决sql注入的问题，只要我们按照pymysql的规矩来。 ⚠️⚠️⚠️sql语句不要自己拼接，交给pymysql提供的execute方法解决 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python进阶/django/1.django创建项目.html":{"url":"python/python进阶/django/1.django创建项目.html","title":"django基础一 创建项目","keywords":"","body":"1.django创建项目 1.1方式一 命令创建项目 第一步、安装django pip3 install django==1.11.9 第二步、创建项目 创建一个目录并切换到这个目录下，然后执行以下命令创建项目 django-admin startproject 项目名称 创建项目时遇到的项目名称问题，不能加-，可以加_ 第三步、创建应用 进入到创建的项目目录中然后执行以下命令 python3 manage.py startapp 应用名称 第四步、修改配置文件 #创建的项目路径 project01就是项目 /jetBrains/pycharm/django/project01 #创建的应用的路径 app03就是应用 /jetBrains/pycharm/django/project01/app03 #修改的配置文件的路径 创建的项目下同名的目录中的settings.py /jetBrains/pycharm/django/project01/project01 修改以下配置，添加创建的应用名称 大概在40行 INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'app03', #最后一行添加创建的应用名称,将项目和应用关联到一起 ] 第五步、启动项目 如果端口不写，默认是8000 如果IP地址和端口号都不写，默认是127.0.0.1:8000 python3 manage.py runserver 127.0.0.1:8001 第六步、浏览器访问 127.0.0.1:8001 到此，最基本的django创建项目、应用、启动完成 用pycharm打开创建的django项目 1.2方式二 利用pycharm创建项目 File-->New Project 打开pycharm创建的django项目 1.3项目目录文件介绍 manage.py -----> Django项目里面的工具，通过它可以调用django shell和数据库，启动关闭项目与项目交互等，不管你将框架分了几个文件，必然有一个启动文件，其实他们本身就是一个文件 settings.py -----> 包含了项目的默认设置，包括数据库信息，调试标志以及其他一些工作的变量 urls.py -----> 负责把URL模式映射到应用程序 wsgi.py -----> runserver命令就使用wsgiref模块做简单的web server，后面会看到renserver命令，所有与socket相关的内容都在这个文件里面了 1.4MVC和MTV模式 MVC模式 Web服务器开发领域里著名的MVC模式，所谓MVC就是把Web应用分为模型(M)，控制器(C)和视图(V)三层，他们之间以一种插件式的、松耦合的方式连接在一起，模型负责业务对象与数据库的映射(ORM)，视图负责与用户的交互(页面)，控制器接受用户的输入调用模型和视图完成用户的请求，其示意图如下所示： MTV模式(django中的模式) Django的MTV模式本质上和MVC是一样的，也是为了各组件间保持松耦合关系，只是定义上有些许不同，Django的MTV分别是值： M 代表模型（Model）： 负责业务对象和数据库的关系映射(ORM) T 代表模板 (Template)：负责如何把页面展示给用户(html) V 代表视图（View）： 负责业务逻辑，并在适当时候调用Model和Template 　　除了以上三层之外，还需要一个URL分发器，它的作用是将一个个URL的页面请求分发给不同的View处理，View再调用相应的Model和Template，MTV的响应模式如下所示： 过程 1.用户输入url访问，请求发送至视图 2.视图的业务逻辑是我们自己写的，视图判断请求的类型 如果是静态页面，从模版中获取静态html文件返回给视图，再由视图返回给用户 如果是动态页面，视图将请求发送至模型，模型从数据库中获取数据返回用户 3.用户的请求最终由视图返回给用户 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python进阶/django/2.django urls路由.html":{"url":"python/python进阶/django/2.django urls路由.html","title":"django基础二 urls路由","keywords":"","body":"2.urls路由 2.1urls路由使用示例 在项目目录中的urls文件中编写路由规则 from django.conf.urls import url from django.contrib import admin from app01 import views #这一行为导入应用中的views文件(用于写业务逻辑) urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^index/$', views.index), #这一行自定义一个访问路径 ] 需要在urls文件中引入应用程序中的views 在应用程序中的views文件中编写业务逻辑 from django.shortcuts import render # Create your views here. def index(request): return render(request,'index.html') #编写函数，返回index.html页面，函数中的request参数为默认写法，名称随意，render方法用于返回给view视图index.html文件，再由view视图返回给用户 自定义的函数中需要传入一个request参数，这个参数封装了所有的请求相关信息，这个request是一个对象 视图中需要用到render()方法，render中需要用到request参数，并且返回templates目录下的html文件 为什么这里render方法中写一个html文件就能返回给用户呢，在项目下同名的目录中的settings配置文件中TEMPLATES一项(关于模版html文件的配置) 'DIRS': [os.path.join(BASE_DIR, 'templates')] os.path.join(BASE_DIR,'templates') BASE_DIR在开头import os处定义如下 BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__))) __file__是当前文件 os.path.abspath当前文件绝对路径 os.path.dirname找到当前文件上层目录 两个os.path.dirname就找到了项目目录，因此BASE_DIR就是项目目录 再回头看'DIRS': [os.path.join(BASE_DIR, 'templates')] BASE_DIR就是项目目录，和templates目录做了一个拼接，因此在render方法中直接写html文件就能找到 项目/templates/html文件 在templates目录下创建index.html文件 Title 第一次django使用 如果要想给用户返回一个html页面，需要在项目下的templates中编辑html文件 浏览器访问 这样就是一个简单的django使用示例 关于url路径最后边的斜杠说明，例如 index/ url(r'^home/', views.home) 前置导航斜杠不需要写,后面的斜杠是根据django的配置来的,如果在settings配置文件中我们设置了APPEND_SLASH = False,那么浏览器发送来的请求如果没有带着后面的斜杠,也是可以正常请求的,但是如果没有这个配置的话,django要求浏览器必须带着路径后面的斜杠来进行访问,如果你输入路径的时候没有加/,那么django让你的浏览器发一个重定向请求带上/ 比如，访问的时候只写了index，django会让浏览器再次发送一个重定向请求index/ 2.2url别名和命名空间 url别名的作用是当修改了url的访问路径，视图逻辑中返回的url路径也需要改动，其他相关联的地方也可能需要改动，这个时候我们在url中定义一个别名，如果后续更改了url的访问路径，其他地方只需要用到url别名的反向解析就能自动找到别名对应的url路径，这样的话只需要修改url路径而不更改其余地方 写法: url(r'^login/v2/', views.login,name='login'), 视图中反向解析: from django.urls import reverse def login(request): print(reverse('login')) #/login/v2/ if request.method == 'GET': return render(request,'login.html') else: uname = request.POST.get('uname') pwd = request.POST.get('pwd') if uname == 'admin' and pwd == 'admin': return HttpResponse('ok') else: return redirect(reverse('login')) #使用反向解析 html模板渲染时反向解析的语法{% url 别名 %} {% csrf_token %} 用户名: 密码: 2.3url别名反向解析参数 在urls文件中定义的url路径中如果有正则匹配，那么在视图函数中进行url别名反向解析的时候就需要带上参数了，而带参数又分为无名分组和有名分组 2.3.1url无名分组传参方式 args=(参数1,) urls文件中定义url路径如下所示 url(r'book1/1/', views.book,name='book1'), url(r'book2/(\\d+)/', views.book,name='book2'), 现在想做的效果是访问book1/1/然后重定向到book2，视图文件内容如下 def book1(request): return redirect('book2') def book2(request): return HttpResponse('book2') 这个时候访问127.0.0.1/book/1会报错，因为book2的url是有正则匹配的，这个时候没有传参数，所以会报错如下 此时就需要在url反向解析时传参了，urls文件中的正则匹配是无名分组，无名分组的传参方式是args=() from django.urls import reverse def book1(request): #url无名分组传参是args return redirect(reverse('book2',args=(1,))) #urls中book2有无名分组，因此需要传一个参数，参数名任意 def book2(request,n): return HttpResponse('book2') 传参后再访问就可以正确重定向了 2.3.2url有名分组传参方式 kwargs={'分组名称':'参数'} urls文件中定义url路径如下所示 url(r'book1/1/', views.book1,name='book1'), #定义一个有名分组，名称为book2 url(r'book2/(?P\\d+)/', views.book2,name='book2'), 现在想做的效果是访问book1/1/然后重定向到book2，视图文件内容如下 def book1(request): return redirect('book2') def book2(request): return HttpResponse('book2') 这个时候访问127.0.0.1/book/1会报错，因为book2的url是有正则匹配的，这个时候没有传参数，所以会报错如下 此时就需要在url反向解析时传参了，urls文件中的正则匹配是有名分组，有名分组传参方式是kwargs={'分组名称':'参数'} from django.urls import reverse def book1(request): #这里是url有名分组位置传参，page就是urls文件中定义的url有名分组名称 return redirect(reverse('book2',kwargs={'page':1})) #在要重定向的路径函数中也需要传递urls文件中定义的url有名分组名称 def book2(request,page): return HttpResponse('book2') 传参后再访问就可以正确重定向了 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python进阶/django/3.django 视图函数.html":{"url":"python/python进阶/django/3.django 视图函数.html","title":"django基础三 视图函数","keywords":"","body":"3.视图函数 3.1request对象 request.path #request.path当前请求路径 request.method #当前请求方法(get,post...) request.GET #获取所有get请求携带过来的数据 request.POST #获取所有post请求携带过来的数据 request.body #获取所有post请求携带过来的数据的原始格式 3.2视图函数使用小示例 urls文件 urlpatterns = [ url(r'^admin/', admin.site.urls), #编写一个login登陆视图文件 url(r'^login/', views.login), ] views文件 from django.shortcuts import render,HttpResponse def login(request): if request.method == 'GET': return render(request,'login.html') else: uname = request.POST.get('username') pwd = request.POST.get('password') if uname == 'admin' and pwd == 'admin': return HttpResponse('登陆成功！') else: return HttpResponse('登陆失败!!!') html文件 Title {##} 用户名： 密码： 为了验证post请求，注释settings文件中的一行 Django项目下同名目录中的settings文件，48行 MIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', # 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware', ] 浏览器访问 错误的示例 urls文件 def login(request): if request.method == 'POST': return render(request,'login.html') else: uname = request.GET.get('username') pwd = request.GET.get('password') if uname == 'admin' and pwd == 'admin': return HttpResponse('登陆成功！') else: return HttpResponse('登陆失败!!!') html文件 Title {##} 用户名： 密码： 为了验证post请求，注释settings文件中的一行 Django项目下同名目录中的settings文件，48行 MIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', # 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware', ] 按照之前的理解应该是会返回登陆界面，因为我login.html文件中form表单写的请求方法是post，而views视图文件中的逻辑判断是如果请求是post则返回登陆界面，但是实际情况并不是这样 为什么会直接返回登陆失败呢？ 原因：当浏览器打开页面的时候，默认的方法就是GET，当点击登陆那一刻才会根据form表单中的method指定的请求类型而进行转变，但是现在直接就是GET方法，因此在login函数的判断中就直接跳到了第一个else后面，但是此时根本就没有用户登陆界面出现，所以就无法获取用户名和密码，所以会直接提示登陆失败！！！ 3.3响应方法 render返回html页面 HttpResponse返回字符串 redirect 3.3.1render 返回html页面 views文件中的写法 #需要导入HttpResponse from django.shortcuts import render,HttpResponse # Create your views here. def index(request): return render(request,'index.html') 3.3.2HttpResponse 返回字符串 views文件中的写法 #需要导入HttpResponse from django.shortcuts import render,HttpResponse # Create your views here. #HttpResponse方法中直接写字符串 def index(request): # return render(request,'index.html') return HttpResponse('HttpResponse方法返回的是字符串') 3.3.3redirect 重定向 FBV写法 urls文件 urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^home/', views.home), url(r'^login/', views.login), ] views文件 #redirect方法需要导入redirect from django.shortcuts import render,HttpResponse,redirect # Create your views here. def home(request): return HttpResponse('登陆成功') def login(request): if request.method == 'GET': return render(request,'login.html') else: uname = request.POST.get('uname') pwd = request.POST.get('pwd') if uname == 'admin' and pwd == 'admin': # return HttpResponse('登陆成功') return redirect('/home/') else: # return HttpResponse('登陆失败') return redirect('/login/') redict是重定向，之前我们访问的时候如果登陆失败就直接提示登陆失败 现在使用了redict重定向 如果登陆成功就重定向到另一个路径下，这里是/home，也就是登陆成功页面 如果登陆失败就还是重定向到访问路径下，这里是/login，也就是登陆界面 CBV写法 urls文件 urlpatterns = [ url(r'^admin/', admin.site.urls), # url(r'^login/', views.login), url(r'^login/', views.LoginView.as_view()), ] views文件 #redirect方法需要导入redirect from django.shortcuts import render,HttpResponse,redirect from django.views import View #CBV写法中需要导入View # Create your views here. def home(request): return HttpResponse('登陆成功') class LoginView(View): def get(self,request): return render(request, 'login.html') def post(self,request): uname = request.POST.get('username') pwd = request.POST.get('password') if uname == 'admin' and pwd == 'admin': # return HttpResponse('登陆成功') return redirect('/home/') else: # return HttpResponse('登陆失败') return redirect('/login/') redict是重定向，之前我们访问的时候如果登陆失败就直接提示登陆失败 现在使用了redict重定向 如果登陆成功就重定向到另一个路径下，这里是/home，也就是登陆成功页面 如果登陆失败就还是重定向到访问路径下，这里是/login，也就是登陆界面 3.4CBV和FBV 3.4.1含义 FBV:function based view :基于函数的视图逻辑 CBV:class based view :基于类的视图逻辑 3.4.1CBV CBV中url写法 # url(r'^login/', views.login), url(r'^login/', views.LoginView.as_view()), CBV中views写法 from django.shortcuts import render,HttpResponse,redirect from django.views import View #CBV写法中需要导入View # Create your views here. class LoginView(View): def get(self,request): return render(request, 'login.html') def post(self,request): uname = request.POST.get('username') pwd = request.POST.get('password') if uname == 'admin' and pwd == 'admin': # return HttpResponse('登陆成功') return redirect('/home/') else: # return HttpResponse('登陆失败') return redirect('/login/') CBV中源码重点 def dispatch(self, request, *args, **kwargs): #根据请求方法去分发对应的类发放来执行 # Try to dispatch to the right method; if a method doesn't exist, # defer to the error handler. Also defer to the error handler if the # request method isn't on the approved list. if request.method.lower() in self.http_method_names: handler = getattr(self, request.method.lower(), self.http_method_not_allowed) #反射!!!! else: handler = self.http_method_not_allowed return handler(request, *args, **kwargs) CBV中重写dispatch方法 class LoginView(View): def dispatch(self, request, *args, **kwargs): print(111) # print(request.META) #http所有相关请求头信息 ret = super().dispatch(request, *args, **kwargs) #render(request, 'login.html') print(222) return ret def get(self,request): print('this is get method!!!') return render(request, 'login.html') def post(self,request): uname = request.POST.get('username') pwd = request.POST.get('password') if uname == 'admin' and pwd == 'admin': return redirect('/home/') else: return redirect('/login/') 3.4.2FBV FBV中url写法 url(r'^login/', views.login), #url(r'^login/', views.LoginView.as_view()), FBV中views写法 from django.shortcuts import render,HttpResponse,redirect # Create your views here. def login(request): if request.method == 'GET': return render(request,'login.html') else: uname = request.POST.get('uname') pwd = request.POST.get('pwd') if uname == 'admin' and pwd == 'admin': # return HttpResponse('登陆成功') return redirect('/home/') else: # return HttpResponse('登陆失败') return redirect('/login/') 3.4.3CBV和FBV的装饰器 def func(f): def foo(request): print(111) ret = f(request) print(222) return ret return foo #FBV 模式下,和普通函数加装饰器是一样的写法 @func def home(request): print('home') return HttpResponse('你懂什么是装饰器吗？') CBV加装饰的三个姿势: # @method_decorator(func,name='get') 位置3 class LoginView(View): # @method_decorator(func) #位置2 def dispatch(self, request, *args, **kwargs): print('aaaa') ret = super().dispatch(request, *args, **kwargs) #render(request, 'login.html') print('bbbb') return ret @method_decorator(func) #位置1 def get(self,request): print('this is get method!!!') return render(request, 'login.html') def post(self,request): uname = request.POST.get('username') pwd = request.POST.get('password') if uname == 'admin' and pwd == 'admin': return redirect('/home/') else: return redirect('/login/') 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python进阶/django/4.django 模版渲染.html":{"url":"python/python进阶/django/4.django 模版渲染.html","title":"django基础四 模版渲染","keywords":"","body":"4.模版渲染 4.1settings文件配置 settings配置文件中的TEMPLATES项是对静态页面的设置，DIRS处需要写上对应的静态文件存放的位置，默认为templates TEMPLATES = [ { 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [os.path.join(BASE_DIR, 'templates')] #别忘了配置这个路径 , 'APP_DIRS': True, 'OPTIONS': { 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], }, }, ] 4.2模版语法 在html文件标签中写 {{ 变量 }} {% 逻辑 %} 4.3万能的点 . html文件 以下代码中dic.name就是.的运用 Title {{ num }} {{ str }} {{ lst }} {{ dic.name }} {# #注意,调用方法时,不能加括号,所有如果方法带参数,就没法用了#} {{ woman.play }} {{ woman.xx }} views文件 from django.shortcuts import render,HttpResponse,redirect from django.views import View #CBV进程的类 # Create your views here. def home(request): # return HttpResponse('登陆成功') # return render(request,'index.html') num = 10 str = 'I am a running 的草泥马' lst = [1,2,3,4,5,6] dic = {'name':'小明','age':20} class A: money = 100 def __init__(self): self.xx = 'oo' def play(self): return '什么价位？' woman = A() return render(request,'模版渲染.html',{'num':num,'str':str,'lst':lst,'dic':dic,'woman':woman}) 运行后的初次效果 4.4过滤器 4.4.1过滤器用法 有参数的过滤器用法 {{ 变量|过滤器名称:'参数' }} 没参数的过滤器用法 {{ 变量|过滤器名称 }} 4.4.2内置过滤器 views文件 from django.shortcuts import render,HttpResponse,redirect from django.views import View #CBV进程的类 # Create your views here. def home(request): # return HttpResponse('登陆成功') # return render(request,'index.html') num = 10 str = 'I am a running 的草泥马' lst = [1,2,3,4,5,6] dic = {'name':'小明','age':20} class A: money = 100 def __init__(self): self.xx = 'oo' def play(self): return '什么价位？' woman = A() return render(request,'模版渲染.html',{'num':num,'str':str,'lst':lst,'dic':dic,'woman':woman}) 4.4.2.1 truncatechars 截断字符串 truncatechars:数字 数字表示要截断的字符数 未截断前 截断后 truncatechars:5表示截取5个字符，其中包括3个. {{ str | truncatechars:5 }} 4.4.2.2 default 如果一个变量是false或者为空，使用给定的默认值。 否则，使用变量的值 在views文件中只有num变量，没有num1变量，因此使用default指定的值 {{ num1 | default:'没有num1这个变量' }} 4.4.2.3 length 获取变量数据长度 {{ lst | length }} 4.4.2.4 filesizeformat 大小按照人类可读方式显示 views文件中定义file_size = 1024，注意还需要在render方法中以字典的形式定义返回 {{ file_size | filesizeformat }} 4.4.2.5 slice 切片(顾头不顾腚) {{ str | slice:'2:9' }} 使用切片截取 4.4.2.6 date 日期格式化显示 views文件 import datetime now = datetime.datetime.now() 注意在render方法中返回 html文件 {{ now | date:'Y-m-d H:i:s' }} 4.4.2.7 safe 关闭HTML的自动转义 safe是防止xss攻击让一些js、html等等代码变成普通字符而不执行，但有的时候我们想要执行这些代码，就需要用到safe Django的模板中在进行模板渲染的时候会对HTML标签和JS等语法标签进行自动转义，原因显而易见，这样是为了安全，django担心这是用户添加的数据，比如如果有人给你评论的时候写了一段js代码，这个评论一提交，js代码就执行啦，这样就可以搞一些坏事儿了，写个弹窗的死循环，浏览器会一直弹窗，这叫做xss攻击，所以浏览器不让你这么搞，给你转义了。但是有的时候我们可能不希望这些HTML元素被转义，比如我们做一个内容管理系统，后台添加的文章中是经过修饰的，这些修饰可能是通过一个类似于FCKeditor编辑加注了HTML修饰符的文本，如果自动转义的话显示的就是保护HTML标签的源文件。为了在Django中关闭HTML的自动转义有两种方式，如果是一个单独的变量我们可以通过 过滤器\"|safe\" 的方式告诉Django这段代码是安全的不必转义。 views文件中定义了一个a_tag，我门现在就想让这个标签成为一个超链接 a_tag = \"百度\" html文件 {{ a_tag | safe }} 没有加safe 加上safe后 4.4.2.8 join 字符串拼接列表 views文件 lst = [1,2,3,4,5,6] html文件 {{ lst | join:\"+\"}} 4.4.2.9 cut 移除变量中所有的与给出的变量相同的字符串 views文件 str = 'I am a running 的草泥马' html文件 {{ str | cut:' ' }} 4.5标签 4.5.1 for标签 for标签语法 {% for foo in 循环的对象 %} {% endfor %} for标签循环列表简单示例 views文件 def home(request): lst = [1,2,3,4,5] return render(request,'home.html',{'lst':lst}) html文件 {% for foo in lst %} {{ foo }} {% endfor %} 结果如下 for标签中加reversed可以反转列表 {% for foo in lst reversed %} {{ foo }} {% endfor %} for标签循环字典简单示例 views文件 def home(request): lst = [1,2,3,4,5] dic = {'name':'小明','age':20,'hobby':'唱、跳、rap、篮球'} return render(request,'home.html',{'lst':lst,'dic':dic}) html文件 {% for foo in dic.items %} //这里可以循环字典的键、值、键和值 {{ foo }} {% endfor %} {% for key,value in dic.items %} {{ key }}--->{{ value }} {% endfor %} for标签中的empty {% for i in lst1 %} #当没有数据时,会生成empty的内容 {{ i }} {% empty %} 啥数据也没有! {% endfor %} for标签中的forloop方法，必须在循环内使用 forloop.counter #当前循环的索引值(从1开始)，forloop是循环器，通过点来使用功能 forloop.counter0 #当前循环的索引值（从0开始） forloop.revcounter #当前循环的倒序索引值（从1开始） forloop.revcounter0 #当前循环的倒序索引值（从0开始） forloop.first #当前循环是不是第一次循环（布尔值） forloop.last #当前循环是不是最后一次循环（布尔值） forloop.parentloop #本层循环的外层循环的对象，再通过上面的几个属性来显示外层循环的计数等 forloop.counter #当前循环的索引值(从1开始)，forloop是循环器，通过点来使用功能 {% for key,value in dic.items %} {{ forloop.counter }}{{ key }}--->{{ value }} {% endfor %} forloop.counter0 #当前循环的索引值（从0开始） {% for key,value in dic.items %} {{ forloop.counter0 }}{{ key }}--->{{ value }} {% endfor %} forloop.first #当前循环是不是第一次循环（布尔值） {% for key,value in dic.items %} {{ forloop.first }} {{ key }}--->{{ value }} {% endfor %} forloop.parentloop #本层循环的外层循环的对象，再通过上面的几个属性来显示外层循环的计数等 views文件 def home(request): lst = [1,2,3,4,5] dic = {'name':'小明','age':20,'hobby':['唱','跳','rap','篮球']} return render(request,'home.html',{'lst':lst,'dic':dic}) html文件 {% for key,value in dic.items %} {{ forloop.last }} {{ key }}--->{{ value }} {% for foo in dic.hobby %} {{ forloop.parentloop.counter }}---{{ forloop.counter }}{{ foo }} {% endfor %} {% endfor %} 4.5.2 if标签 if语句支持 and 、or、==、>、=、in、not in、is、is not判断，注意条件两边都有空格 views文件 def home(request): num = 100 str = 'helow' lst = [1,2,3,4,5] dic = {'name':'小明','age':20,'hobby':'唱、跳、rap、篮球'} return render(request,'home.html',{'lst':lst,'dic':dic,'num':num,'str':str}) html文件 普通判断 {% if num == 100 %} 数字等于100 {% else %} 数字不等于100 {% endif %} #语法 {% if %} {% elif %} {% else %} {% endif %} //以endif结尾 结合过滤器使用 {% if str|length == 5 %} 字符串长度为5 {% endif %} 4.5.3 with标签 用于给比较长的数据调用起别名，只能在with标签中只用 views文件 def home(request): lst = [1,2,{'name':'小明','age':20},4,5] return render(request,'home.html',{'lst':lst} html文件 html文件中想渲染views文件中返回的列表中的元素中的字典的值，如果每一次都写的话会比较长，例如lst.2.name，这个时候我们就可以取一个别名，用于给这个数据的调用，这样的话下次别的地方有引用的时候写起啦会比较简单 //例如，h1标签和a标签中都想引用这个数据的调用，没有起别名之前的写法，这样每次引用都需要在写一遍，比较麻烦 {{ lst.2.name }} {{ lst.2.name }} //这个时候就可以用到with别名的方法 {% with lst.2.name as l %} {{ l }} {% endwith %} 4.5.4 csrf_token 通过csrf认证机制 #写法 {% csrf_token %} csrf_token 　　　　我们以post方式提交表单的时候，会报错，我们在settings里面的中间件配置里面把一个csrf的防御机制给注销了，本身不应该注销的，而是应该学会怎么使用它，并且不让自己的操作被forbiden，通过这个东西就能搞定。 　　　　这个标签用于跨站请求伪造保护， 　　　　在页面的form表单里面（注意是在form表单里面）任何位置写上{% csrf_token %}，这个东西模板渲染的时候替换成了，隐藏的，这个标签的值是个随机字符串，提交的时候，这个东西也被提交了，首先这个东西是我们后端渲染的时候给页面加上的，那么当你通过我给你的form表单提交数据的时候，你带着这个内容我就认识你，不带着，我就禁止你，因为后台我们django也存着这个东西，和你这个值相同的一个值，可以做对应验证是不是我给你的token，就像一个我们后台给这个用户的一个通行证，如果你用户没有按照我给你的这个正常的页面来post提交表单数据，或者说你没有先去请求我这个登陆页面，而是直接模拟请求来提交数据，那么我就能知道，你这个请求是非法的，反爬虫或者恶意攻击我的网站 4.6自定义标签和自定义过滤器 4.6.1自定义标签 1.在应用程序目录中创建一个templatetags目录(名称只能叫templatetags) 2.在templatetabs目录中创建xx.py 3.在xx.py中导入template from django import template #变量名称必须叫register register = template.Library() #自定义标签 @register.simple_tag def tag(v1): return v1 + 'tag' 使用自定义标签 urls文件 url(r'^tags/', views.tags), views文件 def tags(request): name = 'hehe' return render(request,'tags.html',{'name':name}) tags.html文件 //这里表示引入应用程序目录下templatetags目录中自定义的xx.py，这个xx.py中是我们自定义的标签 {% load xx %} {% tag name %} args.html文件中不给自定义标签传参数 views文件中指定给自定义的标签传2个参数，v1是views中tag函数定义的变量name，v2就是args.html中自定义标签传的一个参数 from django import template #变量名称必须叫register register = template.Library() #自定义标签 @register.simple_tag def tag(v1,v2): return v1 + 'tag' + v2 args.html文件中给自定义标签传参 {% tag name '参数1' %} 4.6.2自定义过滤器 1.在应用程序目录中创建一个templatetags目录(名称只能叫templatetags) 2.在templatetabs目录中创建xx.py 3.在xx.py中导入template from django import template #变量名称必须叫register register = template.Library() #自定义过滤器，最多2个参数 这里自定义一个过滤器，接受任意一个参数，给这个参数后边加一个字符串 @register.filter def oo(v1): return v1 + 'oo' 使用自定义过滤器 urls文件 url(r'^tags/', views.tags), views文件 def tags(request): name = 'hehe' return render(request,'tags.html',{'name':name}) tags.html //这里表示引入应用程序目录下templatetags目录中自定义的xx.py，这个xx.py中是我们自定义的过滤器 {% load xx %} {{ name | oo }} 结果如下，可以看到，我们自定义的过滤器，接受任意一个参数，给这个参数后边加一个字符串oo 上述结果是xx.py就是我们自定义的过滤器文件中的函数只传了一个参数，现在我们给这个函数传2个参数(最多传两个参数) xx.py写法 from django import template #变量名称必须叫register register = template.Library() #自定义过滤器，最多2个参数 这里自定义一个过滤器，接受任意一个参数，给这个参数后边加一个字符串 @register.filter def oo(v1,v2): return v2 + 'oo' + v1 上述代码中v1是views中定义的name变量的值，也就是hehe，v2就是tags.html中函数oo后面传的参数，因此打印的结果就是 哈哈oohehe urls文件 url(r'^tags/', views.tags), views文件 def tags(request): name = 'hehe' return render(request,'tags.html',{'name':name}) tags.html //这里表示引入应用程序目录下templatetags目录中自定义的xx.py，这个xx.py中是我们自定义的过滤器 {% load xx %} {{ name | oo:'哈哈' }} 4.6.3 inclusion_tag 修改引入组件的样式（ 非常难理解） inclusion_tag作用如下 接下来开始整个过程 第一步、先在django项目同路径下的templates目录下创建一个菜单静态页面作为一个组件 zujian.html Title .menus{ width: 200px; } .menus .item{ background-color: green; color: white; height: 50px; } 菜单1 菜单2 菜单3 效果如下 第二步、分别在urls和views文件中写上对应的访问路径和函数 这里在后边定义一个xx.html，这个xx.html引入组件文件zujian.html，并且访问路径是xx，视图中的函数也叫xx(返回xx.html) urls文件 url(r'^xx/', views.xx), views文件 def xx(request): return render(request,'xx.html') 第三步、还是在templates目录下创建一个xx.html文件，这个html文件引入刚才创建的组件文件 xx.html文件初始内容如下 Title .nav{ height: 200px; width: 150px; background-color: burlywood; } 我是xx.html，一会我要引入组件中的样式，就是组件中的那个菜单栏，并且我不修改引入的样式，只是修改菜单栏为其他内容 初始xx.html 接下来在xx.html文件中引入组件文件的样式 在div标签下引入zujian.html 我是xx.html，一会我要引入组件中的样式，就是组件中的那个菜单栏，并且我不修改引入的样式，只是修改菜单栏为其他内容 {% include 'zujian.html' %} 引入组件后的样式，绿色为zujian.html文件中的内容 接下来想要将引入的样式中的菜单栏变为其他内容，需要做以下操作，在组件文件zujian.html文件中将想要更改的内容利用for循环便利 zujian.html文件 //利用for循环遍历data变量，foo就是data变量中的所有内容，这样的话就做成了动态的效果，原先的菜单栏div标签现在只需要写一个，因为foo是变量data中所有的值 {% for foo in data %} {{ foo }} {% endfor %} //注释之前的菜单栏，因为我们需要用到动态传入内容 {# 菜单1#} {# 菜单2#} {# 菜单3#} 这里有个问题，现在想把zujian.html文件中的菜单栏做一下动态修改，这里写了从data中取值，但是循环遍历的data是从哪来的？？？这时就引出了inclusion_tag inclusion_tag需要写在templatetags目录下自定义的py文件中，而data就是我们自定义的返回给xx.html文件的动态内容，因为xx.html引入zujian.html的样式是固定的，只有zujian.html文件中定义的内容 第四步、在templatetags目录下创建一个mytags.py templatetags目录是在django项目的应用程序目录下创建的目录，在自定义标签和自定义过滤器的时候必须创建这个目录，且名字只能是这个，在这个templatetags目录下创建的py文件中自定义标签和过滤器 mytags.py @register.inclusion_tag('zujian.html')是固定写法，括号中的参数就是组件文件，这里的data是我们自定义的字典 @register.inclusion_tag('zujian.html') def hehe(v1): return {'data':['唱','跳','rap','篮球']} 第五步、在xx.html文件中引入动态内容 我是xx.html，一会我要引入组件中的样式，就是组件中的那个菜单栏，并且我不修改引入的样式，只是修改菜单栏为其他内容 {#{% include 'zujian.html' %}#} {% load mytags %} //引入自定义函数的那个文件名 {% hehe %} //引入自定义函数，用于返回data 最终运行效果如下，引入的组件的背景颜色绿色没有改变，但是改变了之前的菜单栏 整个过程总结 1.定义urls url(r'^xx/', views.xx), 2.定义视图 def xx(request): return render(request,'xx.html') 3.xx.html文件引入组件文件zujian.html，组件中只定义了一个背景色，但是xx.html文件想要动态的添加一些内容，例如菜单栏，此时需要在组件文件中做如下改动 组件文件中定义的背景色 Title .menus{ width: 200px; } 利用for循环去循环一个变量，例如data，这个变量是在django项目下的应用程序目录下的templatetags下的任意名称py文件中利用@register.inclusion_tag('zujian.html')和自定义函数中的return返回值定义的变量 应用程序下templates目录中定义一个mytags.py(名称任意)，文件内容如下 inclusion_tag中必须跟一个参数，这个参数必须是组件文件，自定义一个函数hehe(名称任意)，return的返回值会返回给组件文件 mytags.py文件内容如下 from django import template register = template.Library() @register.inclusion_tag('zujian.html') def hehe(): return {'data':['唱','跳','rap','篮球']} 4.第3步中的data变量已经返回给了组件文件，因此xx.html文件中需要引入应用程序下的templatetags中定义的那个py文件(这里是mytag.py) 还需要引入这个py文件中自定义的函数的名称(这里是hehe) mytags.py(自定义标签需要在应用程序下的templatetags目录中定义一个任意的py文件，然后在这个文件中写自定义标签内容) xx.html文件内容如下 我是xx.html，一会我要引入组件中的样式，就是组件中的那个菜单栏，并且我不修改引入的样式，只是修改菜单栏为其他内容 {#{% include 'zujian.html' %}#} {% load mytags %} {% hehe %} #参数说明 {% load mytags %} //引入应用程序下的templatetags中定义的那个py文件(这里是mytags.py) {% hehe %} //引入这个py文件(mytags.py)中自定义的函数的名称(这里是hehe) 最终的渲染效果就由应用程序下的templatetags中定义的那个py文件(这里是mytags.py)中定义的函数中自定义的返回值决定 这里定义的data是一个字典，data会返回给组件文件用于动态渲染 from django import template register = template.Library() @register.inclusion_tag('zujian.html') def hehe(): return {'data':['唱','跳','rap','篮球']} 关于动态返回内容的一个问题 写在mytags中是写死的，我们应该写成动态的，所以应该写在views中从数据库中获取数据达到动态返回的效果，因此修改mytags文件如下 mytags文件 from django import template register = template.Library() @register.inclusion_tag('zujian.html') #这里的v1就是给xx.html文件中引入hehe函数能够传一个参数 def hehe(v1): return {'data':v1} views文件 def xx(request): #这里的lst就相当于从数据库中动态获取的数据 lst = ['唱1','跳1','rap1','篮球1'] return render(request,'xx.html',{'lst':lst}) xx.html文件 我是xx.html，一会我要引入组件中的样式，就是组件中的那个菜单栏，并且我不修改引入的样式，只是修改菜单栏为其他内容 {#{% include 'zujian.html' %}#} {% load mytags %} {% hehe lst %} //在这里引入views中定义的lst 最终真正的动态获取内容效果如下 4.7组件 组件类似于python中的模块，组件是把其他html页面引入过来，但是不能修改引入的文件的内容 组件文件 Title 1 2 3 自定义文件 在自定义文件中，我们想引入组件文件中的列表样式，需要如下代码，这个就是在自定义文件中表示引入组件.html文件 #写法 {% include '组件.html' %} Title .c1{ background-color: green; } {% include '组件.html' %} 我是一个引入了组件文件的自定义文件 4.8模版继承 我们在写多个静态页面的时候可能会有一些相同的样式，这样的话每写一个页面就需要复制相同的代码，这样就造成了代码大量重复，此时就用到了模版继承，我们可以把相同样式的页面的代码单独放在一个模版文件中，其余页面继承这个模版文件，然后在设置自定义内容即可，这样就不用重复写相同样式的代码了 模版文件 base.html文件 Title .nav{ background-color: pink; height: 40px; } .left-menu{ display: inline-block; width: 200px; background-color: mediumpurple; } .content{ display: inline-block; height: 200px; width: 600px; background-color: burlywood; color:white; } ul{ padding: 0; margin: 0; } #这里表示预留css样式，子模版继承后可以修改模版的样式 {% block css %} {% endblock %} 个人中心 登录|注册 菜单1 菜单2 菜单3 {% block content %} base页面 xxx {% endblock %} {% block js %} {% endblock %} 模版继承的写法 在模版html文件中需要用到block方法，例如上述示例中，我们想要菜单1和菜单2有自己的自定义界面而不继承模版文件，写法如下 {% block content %} base页面 xxx {% endblock %} 这个标签就是菜单1和菜单2中需要单独设置样式的标签，为了不继承模版文件，需要在这个标签写如下内容 block中包含的a标签就是菜单1和菜单2的html文件中需要重写的 {% block content %} base页面 xxx {% endblock %} 这段代码的意思是，模版文件中的base页面不希望被继承，这里就单独把这个页面预留出来，接下来在菜单1和菜单2的html文件中在单独写这块的样式，写法如下 //这里表示继承模版文件base.html {% extends 'base.html' %} 因为不需要继承模版文件中的 base页面 处的内容，而模版文件中也把这一块内容已经预留出来了，并且定义了预留名称为 content，在菜单1和菜单2的html文件中之需要引入这个模版预留名称，这样就可以自定义自己的样式了，写法如下 {% block content %} 菜单1的内容 {% endblock %} base.html文件如上，现在我们设置菜单1、菜单2的自定义内容，需要做以下操作 urls文件 from app01 import views urlpatterns = [ url(r'^admin/', admin.site.urls), #这个就是模版页面 url(r'^base/', views.base), #下边两个是菜单1和菜单2返回的页面 url(r'^menu01/', views.menu01), url(r'^menu02/', views.menu02), ] views文件 def base(request): return render(request,'base.html') def menu01(request): return render(request,'menu01.html') def menu02(request): return render(request,'menu02.html') menu01.html {% extends 'base.html' %} .content{ display: inline-block; height: 200px; width: 600px; background-color: green; color:white; } {% endblock %} {% block content %} 菜单1的内容 {% endblock %} menu02.html {% extends 'base.html' %} {% block content %} 菜单2的内容 {% endblock %} 访问base页面，点击菜单1，返回页面如下，因为在menu01.html文件中，我门自己指定了样式，因此背景颜色就和模版的不同了 访问base页面，点击菜单2，返回页面如下 block.super() 这个方法就是继承模板预留块的内容的同时在自定义内容 {% block content %} {{ block.super }} #将模版中的content这个名称的块中的内容拿过来 菜单1的内容 {% endblock %} 4.9url别名和反向解析 url别名的作用是当修改了url的访问路径，视图逻辑中返回的url路径也需要改动，其他相关联的地方也可能需要改动，这个时候我们在url中定义一个别名，如果后续更改了url的访问路径，其他地方只需要用到url别名的反向解析就能自动找到别名对应的url路径，这样的话只需要修改url路径而不更改其余地方 写法: url(r'^login/v2/', views.login,name='login'), 视图中反向解析: from django.urls import reverse def login(request): print(reverse('login')) #/login/v2/ if request.method == 'GET': return render(request,'login.html') else: uname = request.POST.get('uname') pwd = request.POST.get('pwd') if uname == 'admin' and pwd == 'admin': return HttpResponse('ok') else: return redirect(reverse('login')) #使用反向解析 html模板渲染时反向解析的语法{% url 别名 %} {% csrf_token %} 用户名: 密码: ⚠️⚠️⚠️进行html模板渲染时反向解析时，如果定义了命名空间，则在html中需要如下写法 html模板渲染时反向解析的语法{% url 命名空间:别名 %} 4.10include路由分发和url命名空间 4.10.1include路由分发 include路由分发就是将不同的url放在不同的应用程序下的urls文件中，先匹配一个应用程序的路径，然后在分别去这两个应用程序对应的urls文件中找下一级目录 例如，现在有app01和app02两个应用程序，现在设置的访问路径如下 /app01/index /app02/index 访问到app01就去app01路径下找index 接下来做一下演示 第一步、在项目目录下同名的目录下的urls.py中写入以下内容 代码的意思是访问app01就去找app01.urls文件，访问app02就去找app02.urls文件，namespace是命名空间，为了防止路由分发中出现同名的url别名引发的错误 #需要导入include from django.conf.urls import url,include from django.contrib import admin urlpatterns = [ #注意，初始的admin需要注释 #url(r'^admin/', admin.site.urls), url(r'^index/', views.index), url(r'^app01/', include('app01.urls',namespace='app01')), url(r'^app02/', include('app02.urls',namespace='app02')), ] #匹配说明 /app01/index 先匹配app01这个路径，然后到app01url中写的include包含的urls文件中在去找index路径 第二步、在各个app应用目录下面创建urls.py文件，在urls.py文件中写自己应用的各个路径 app01 from django.conf.urls import url, include from django.contrib import admin from app01 import views urlpatterns = [ url(r'^index/', views.index, name='index'), ] app02 from django.conf.urls import url, include from django.contrib import admin from app02 import views urlpatterns = [ url(r'^index/', views.index,name='index'), ] 第三步、编写views文件 app01 views文件 from django.shortcuts import render,HttpResponse # Create your views here. def index(request): return HttpResponse('app01-index') app02 views文件 from django.shortcuts import render,HttpResponse # Create your views here. def index(request): return HttpResponse('app02-index') 浏览器访问结果 访问127.0.0.1/app01/index 访问127.0.0.1/app02/index 4.10.2url命名空间 注意：url命名空间是在进行路由分发的时候写的，而url别名是在urls文件中指定路径的时候写的别名 url命名空间是为了防止url有相同别名而导致的问题 写法: url(r'^app01/', include('app01.urls',namespace='app01')), 将每个应用自己的url路径划分一个空间,将来通过别名反向解析时,通过空间名称可以找到对应应用下面的路径 使用: views.py文件中写法 from django.urls import reverse def index(request): print('app01反向解析:', reverse('app01:index')) #app02反向解析: /app02/index/ return HttpResponse('app01-index') #reverse('app01:index') app01就是命名空间 index就是app01下的index路径 html中写法: {% url 'app01:login' %} 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python进阶/django/5.django ORM.html":{"url":"python/python进阶/django/5.django ORM.html","title":"django基础五 ORM","keywords":"","body":"5.ORM 5.1ORM简介 MVC或者MVC框架中包括一个重要的部分，就是ORM，它实现了数据模型与数据库的解耦，即数据模型的设计不需要依赖于特定的数据库，通过简单的配置就可以轻松更换数据库，这极大的减轻了开发人员的工作量，不需要面对因数据库变更而导致的无效劳动 ORM是“对象-关系-映射”的简称。（Object Relational Mapping，简称ORM） ORM执行的过程 类对象--->sql--->pymysql--->mysql服务端--->磁盘，orm其实就是将类对象的语法翻译成sql语句的一个引擎 ORM与原生SQL对比 5.2ORM操作 5.2.1ORM连接mysql 这里先来一个orm连接mysql并创建一张表的示例 第一步、修改settings配置文件，配置mysql相关信息 #先注释默认项 # DATABASES = { # 'default': { # 'ENGINE': 'django.db.backends.sqlite3', # 'NAME': os.path.join(BASE_DIR, 'db.sqlite3'), # } # } DATABASES = { 'default': { 'ENGINE': 'django.db.backends.mysql', 'NAME': '数据库名', 'HOST': '数据库IP', 'PORT': '数据库端口', 'USER': '用户', 'PASSWORD': '密码' } } 第二步、在项目目录下的同名目录下的__init__.py文件中写上以下内容,来指定pymysql作为连接客户端 import pymysql pymysql.install_as_MySQLdb() 第三步、在应用程序目录下面的models.py文件中写对应的类，这里为创建一张表 from django.db import models #这里表示创建一个userinfo表，需要注意的是，django在创建表的时候会把表名小写并重命名为 应用程序_userinfo class UserInfo(models.Model): id = models.AutoField(primary_key=True) username = models.CharField(max_length=10) password = models.CharField(max_length=32) 第四步: 执行数据库同步指令，在终端中执行，执行的路径是django项目下 #在migrations文件夹下面生成记录文件 python3 manage.py makemigrations #执行记录文件 python3 manage.py migrate 可以看到，我们自定义的表已经创建完成了，但是发现多了好多其他的表，那这些表是从哪来的呢，这些是django从settings文件中循环读取INSTALLED_APPS下的所有子项而默认创建的表 表结构 5.2.2单表操作 5.2.2.1增 应用程序的models.py文件中已经定义了创建一张表的语句 urls文件 from app01 import views urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^index/', views.index), ] views文件 from django.shortcuts import render,HttpResponse from app01 import models #方式1 def index(request): obj = models.UserInfo( username='小明', password='123' ) obj.save() return HttpResponse('ok') #方式2 def index(request): models.UserInfo.objects.create( username='小颖', password='666' ) return HttpResponse('ok') 接下来启动django项目，浏览器访问我们指定的127.0.0.1:8000/index 执行以上任意一种方式都可以插入数据 5.2.2.2删 views文件 def index(request): #删除UserInfo表中id值为1的值 models.UserInfo.objects.filter(id=1).delete() return HttpResponse('ok') 浏览器访问127.0.0.1/index即可成功执行语句 可以看到，id为1的字段已经被删除 5.2.2.3改 views文件 from django.shortcuts import render,HttpResponse from app01 import models # Create your views here. def index(request): # 方式1 models.UserInfo.objects.filter(id=2).update( username='abc', password='abc', ) # 方式2 # obj = models.UserInfo.objects.filter(id=2)[0] # obj.username = 'ggg' # obj.password = 'ggg' # obj.save() return HttpResponse('ok') 浏览器访问127.0.0.1/index 可以看到修改已经生效 批量创建 views文件 from django.shortcuts import render,HttpResponse from app01 import models # Create your views here. def index(request): list_obj = [] for i in range(6): obj = models.UserInfo( username='name%s' %i, password='pwd%s' %i, ) list_obj.append(obj) print(list_obj) models.UserInfo.objects.bulk_create(list_obj) return HttpResponse('ok') print(list_obj)返回的结果如下 [, , , , , ] 浏览器访问127.0.0.1/index 可以看到已经批量插入了数据 update_or_create 有就更新,没有就创建 from django.shortcuts import render,HttpResponse from app01 import models # Create your views here. def index(request): a,b = models.UserInfo.objects.update_or_create( username='name0', defaults={ 'id': 20, 'password': 'abcdef', } ) print(a) #当前更新后的model对象,或者是你新增的记录的model对象 print(b) #新增就是True,查询就False return HttpResponse('ok') #a返回的结果 UserInfo object #b返回的结果 True 5.2.2.4查 最简单的查询 from django.shortcuts import render,HttpResponse from app01 import models # Create your views here. def index(request): ret = models.UserInfo.objects.filter(id=1) print(ret) # ]> -- [] obj = ret[0] print(obj.id, obj.username) return HttpResponse('ok') 表app01_userinfo内容如下 print(ret)结果如下 ]> print(obj.id, obj.username)执行后结果如下 1 aaa 查询非常重要的13种方法 1 all() 查询所有结果，结果是queryset类型 views文件 from django.shortcuts import render,HttpResponse from app01 import models # Create your views here. def index(request): ret = models.UserInfo.objects.all() print(ret) return HttpResponse('ok') #print(ret)结果如下 , ]> 现在我们想看到的是数据库中的数据，需要在models文件中我们创建的UserInfo中写一个类的属性 class UserInfo(models.Model): id = models.AutoField(primary_key=True) username = models.CharField(max_length=10) password = models.CharField(max_length=32) #在models文件中写上这个属性后就能在all()方法中返回数据而不是对戏那个 def __str__(self): return self.username #结果如下 , ]> 2 get() 只能返回一个数据，没有或者数据多就报错，不是queryset类型，是行记录对象 例如，查询一个表中密码为aaa的数据，如果这个表中只有一个用户的密码是aaa，则可以查询成功，如果这个表中有多个用户的密码是aaa这个时候就会报错并且这个表中如果没有用户的密码是aaa同样会报错 from django.shortcuts import render,HttpResponse from app01 import models # Create your views here. def index(request): ret = models.UserInfo.objects.get(password='aaa') print(ret) return HttpResponse('ok') 表app01_userinfo内容如下 浏览器访问127.0.0.1/index 此时返回的结果是可以成功查询的 现在修改表内容如下 再次执行以上代码，查询表中密码为aaa的数据，此时会报错 修改代码为查询表中密码为bbb的数据，同样会报错 get两个报错,但是get请求返回的结果是model对象 #1.UserInfo matching query does not exist. 没有查到的报错 #2 get() returned more than one UserInfo -- it returned 11! 结果多了,不行! 3 filter() 查询数据，返回值是queryset类型 views文件 from django.shortcuts import render,HttpResponse from app01 import models # Create your views here. def index(request): ret = models.UserInfo.objects.filter(password='bbb') print(ret) return HttpResponse('ok') filter查询表中密码为bbb的数据，虽然表中结果没有，但是不会像get报错 print(ret)结果如下 filter查询表中密码为aaa的数据，表中密码为aaa的数据有2条，filter不会像get一样报错 , ]> 4 exclude() 排除，返回值是queryset类型 现有app01_book表如下 查询所有数据，排除bid为4的数据 urls文件 from django.conf.urls import url,include from django.contrib import admin from app01 import views urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^index/', views.index), ] views文件 from django.shortcuts import render,reverse,redirect,HttpResponse from app01 import models def index(request): #查询bid不为4的数据，这里还可以写多个排除条件，以逗号分隔 ret = models.Book.objects.exclude(bid=4) print(ret) return HttpResponse('ok') models文件 class Book(models.Model): bid = models.AutoField(primary_key=True) bname = models.CharField(max_length=20) price = models.DecimalField(max_digits=6,decimal_places=2) publish_date = models.DateField(auto_now_add=False) publish = models.CharField(max_length=20) def __str__(self): return self.bname 浏览器访问127.0.0.1/index，返回结果如下，bid为4的隔壁老王的故事没有返回 , , , , ]> 5 order_by() queryset类型的数据来调用，对查询结果排序,默认是按照id来升序排列的，返回值是queryset类型 按照bid倒序排序，在bid前加个-号即可 viwes文件 def index(request): ret = models.Book.objects.all().order_by('-bid') print(ret) return HttpResponse('ok') 浏览器反问127.0.0.1/index，返回结果如下，结果是倒序 , , , , , ]> order_by()中加多个条件说明 #这段代码的意思是按照id倒叙排序，然后再按照id相同的数据进行价格升序排序 models.Test.objects.all().order_by('-id','money') 现有表app01_test如下 先按照id进行倒叙排序 ret = models.Test.objects.all().order_by('-id') print(ret.values()) 返回结果如下 再加一个条件进行排序，先根据id相同的进行倒序排序，然后再根据money升序排序 ret = models.Test.objects.order_by('-id','money') print(ret.values()) 返回结果如下 6 reverse() queryset类型的数据来调用，对查询结果反向排序，返回值还是queryset类型 以例5中app01_test表为例 ⚠️直接进行reverse进行反向排序是不生效的，必须先进行分组 ret = models.Test.objects.all().reverse() 返回结果如下，不分组进行反向排序是不生效的 先进行分组，然后再进行反向排序才能生效 ret = models.Test.objects.all().order_by('id').reverse() 返回结果如下 7 count() queryset类型的数据来调用，返回数据库中匹配查询(QuerySet)的对象数量 以例5中app01_test表为例 ret = models.Test.objects.all().count() print(ret) 返回结果为5，因为app01_test表中有5条记录 8 first() queryset类型的数据来调用，返回第一条记录，得到的都是model对象，不是queryset 以例5中app01_test表为例 ret = models.Test.objects.all().first() print(ret) #models文件表的类中需要写如下代码 class Test(models.Model): id = models.IntegerField(primary_key=True) name = models.CharField(max_length=10) money = models.IntegerField() def __str__(self): return self.name 返回结果为1-小明 9 last() queryset类型的数据来调用，返回最后一条记录，得到的是model对象 以例5中app01_test表为例 ret = models.Test.objects.all().last() print(ret) #models文件表的类中需要写如下代码 class Test(models.Model): id = models.IntegerField(primary_key=True) name = models.CharField(max_length=10) money = models.IntegerField() def __str__(self): return self.name 查询时遇到的一个问题，使用last方法查询一个没有设置主键的表时，只能返回id相同的记录中的第一个id的记录 例如，一张表中id字段如下：1、2、3、3、3，查询的返回的结果是id=3的第一条记录，即2后边的第一个3 此表中没有设置主键，只能返回3-大强，而理论上是3-哈哈 10 exists() queryset类型的数据来调用，如果QuerySet包含数据，就返回True，否则返回False 空的queryset类型数据也有布尔值True和False，但是一般不用它来判断数据库里面是不是有数据，如果有大量的数据，你用它来判断，那么就需要查询出所有的数据，效率太差了，用count或者exits 例：all_books = models.Book.objects.all().exists() #翻译成的sql是SELECT (1) AS a FROM app01_book LIMIT 1，就是通过limit 1，取一条来看看是不是有数据 以例5中app01_test表为例 test表中没有id=5的数据，因此会返回False ret = models.Test.objects.filter(id=5).exists() 11 values() 用的比较多，queryset类型的数据来调用，返回一ValueQuerySet——一个特殊的QuerySet，运行后得到的并不是一系列model的实例化对象，而是一个可迭代的字典序列,只要是返回的queryset类型，就可以继续连续调用queryset类型的其他的查找方法，其他方法也是一样的。 以例5中app01_test表为例 ret = models.UserInfo.objects.all().values('id','name') queryset调用 ret = models.UserInfo.objects.values('id','name') objects调用--对所有数据进行取值 返回结果如下 12 values_list 它与values()非常相似，它返回的是一个元组序列，values返回的是一个字典序列 以例5中app01_test表为例 ret = models.Test.objects.all().values_list('id','name') 返回结果如下 13 distinct() values和values_list得到的queryset类型的数据来调用，从返回结果中剔除重复纪录 以例5中app01_test表为例 ret = models.UserInfo.objects.all().values('id','name').distinct() ret = models.UserInfo.objects.values('id','name').distinct() 基于双下划线的模糊查询 表app01_book内容如下 #price值等于这三个里面的任意一个的对象 Book.objects.filter(price__in=[10,33,9999]) #大于，大于等于是price__gte=100，别写price>100，这种参数不支持 Book.objects.filter(price__gt=100) #小于，小于等于是price__lte=100，别写price 查询示例 1 查询某某出版社出版过的价格大于100的书籍 ret = models.Book.objects.filter(price__gt=100,publish='老王出版社').values('bname') 2 查询2018年11月出版的所有以Li开头的书籍名称 ret = models.Book.objects.filter(bname__startswith='Linux',publish_date__year=2018,publish_date__month=11).values('bname') 3 查询价格为88,100或者9999的所有书籍名称及其出版社名称 ret = models.Book.objects.filter(price__in=[88,100,9999]).values('bname','publish') 4 查询价格在80到100之间的所有书籍名称及其价格 ret = models.Book.objects.filter(price__range=[80,100]).values('bname','price') 5 查询所有老王出版社出版的书籍的价格（从高到低排序，去重） ret = models.Book.objects.filter(publish='老王出版社').values('price').order_by('-price').distinct() 5.2.3多表操作 表关系及字段设计 urls文件 from django.conf.urls import url from django.contrib import admin from app01 import views urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^query/', views.query), ] settings文件配置数据库连接 DATABASES = { 'default': { 'ENGINE': 'django.db.backends.mysql', 'NAME': 'orm01', 'HOST': '127.0.0.1', 'PORT': '3306', 'USER': 'root', 'PASSWORD': 'xxx' } } models文件 from django.db import models # Create your models here. class Author(models.Model): name=models.CharField(max_length=32) age=models.IntegerField() ad=models.OneToOneField(to=\"AuthorDetail\",to_field=\"id\",on_delete=models.CASCADE) # to_field=\"id\" 可以不写,默认找主键 # to=\"AuthorDetail\", to=可以不用写 # models.SET_NULL 置空 # on_delete=models.CASCADE 默认是级联删除,想做级联更新,直接去数据库修改表结构 class AuthorDetail(models.Model): birthday=models.DateField() telephone=models.CharField(max_length=16) addr=models.CharField(max_length=64) class Publish(models.Model): name=models.CharField(max_length=32) city=models.CharField(max_length=32) class Book(models.Model): title = models.CharField(max_length=32) publishDate=models.DateField() price=models.DecimalField(max_digits=5,decimal_places=2) publishs=models.ForeignKey(to=\"Publish\",to_field=\"id\",on_delete=models.CASCADE) #这行代码的意思是生成第3张表关联book表和author表 authors=models.ManyToManyField(to='Author',) ⚠️如果AuthorDetail写在Author的上边，则ad=models.OneToOneField(to=\"AuthorDetail\"中的AuthorDetail可以不加引号 ⚠️django1.x版本on_delete=models.CASCADE可以不写，默认是级连删除，如果想做级连更新，直接到数据库中操作，但是django2.x必须写级连删除 ⚠️OneToOneField是一对一 ForeignKey是一对多 ManyToManyField是多对多 django项目下同名目录__init__.py文件 import pymysql pymysql.install_as_MySQLdb() 相关配置文件配置完成后开始同步数据库 ⚠️makemigrations执行后必须执行migrate，否则会出问题 //在django项目下 #在migrations目录下面生成记录文件 python3 manage.py makemigrations #执行记录文件 python3 manage.py migrate 关于只执行makemigrations不执行migrate可能出现的问题 1.当执行makemigrations后，会在django项目下的makemigrations目录中创建一个0001_initial.py，这个文件记录的是models文件中的操作(创建表、删除表)，当执行migrate后会执行数据库同步操作，同时在数据库中django会自动创建一张django_migrations表，这个表记录的是models文件中的操作 2.如果只执行了makemigrations而不执行migrate，当修改了models文件再次重复执行makemigrations，django会从数据库中的django_migrations查看0001_initial是否执行过，而此时0001_initial已经执行过了，因此会出现修改了models文件执行migrate提示没有改动的问题 同步后的数据库，可以看到app01_book_authors这张表是orm自动帮我们创建的 5.2.3.1增 views文件 一对一，作者表和作者详细信息表 //给作者详细信息表添加一条记录 models.AuthorDetail.objects.create( birthday='2018-11-11', telephone='18033336789', addr='北京' ) //给作者表添加一条记录 models.Author.objects.create( name='小明', age=1, #方式1 #关联作者详细信息表中id为1的 ad=models.AuthorDetail.objects.get(id=1) #方式2(常用) ad_id = 1 ) 一对多，出版社和书籍表 models.Book.objects.create( title='隔壁老王的故事', publishDate='2011-01-01', price='99', #方式1 publishs=models.Publish.objects.get(id=1) #方式2 publishs_id=2 ) 多对多，书籍表和作者表 //方式一 book_obj = models.Book.objects.get(id=1) author1 =models.Author.objects.get(id=1) author2 =models.Author.objects.get(id=2) #向关联书籍表和作者表的第3张表中插入作者1和作者2，书籍id为1的书的作者有2个，分别为作者id为1的和作者id为2的 #方式1 book_obj.authors.add(author1,author2) #方式2 book_obj.authors.add(*[author1,author2]) //方式二 book_obj = models.Book.objects.get(id=1) #方式1 book_obj.authors.add(1,2) #方式2 book.obj.authors.add(*[1,2]) 查看关联作者表和书籍表的第3张表app01_book_authors，书籍id为1的书作者有2个 5.2.3.2删 一对一、一对多删除方式一样 models.Author.objects.get(id=1).delete() 删除了作者表中id为1的记录，但是不会影响作者详细信息表中作者id为1的记录 作者表的id作为外键关联作者详细信息表中的作者id，可以理解为我抱别人的大腿，删除我自己不影响别人，但是别人如果删除大腿会影响我 作者表是关联者，作者详细信息表是被关联者 多对多 //方式一 remove 移除 #找到书籍id为1的书 book_obj = models.Book.objects.get(id=1) #删除书籍id为1的书的作者id为2和3 book_obj.authors.remove(2,3) //方式二 clear 全部清空 #把书籍id为1的对应的作者全部删除 book_obj = models.Book.objects.get(id=1) book_obj.authors.clear() 5.2.3.3改 一对多和一对一和单表是一样的 #将书籍表中id为1的数据数名修改为python从入门到放弃并且出版社修改为出版社id为3的 book_obj = models.Book.objects.filter(id=1).update( title='python从入门到放弃', #方式1 publishs=models.Publish.objects.get(id=3) #方式2 publishs_id=3 ） 多对多 //set 先清空再追加，set中必须写字符串，删除多个在列表中填写多个数值 #把书籍id为1的作者全部改为2 book_obj = models.Book.objects.get(id=1) book_obj.authors.set(['2',]) 5.2.3.4查 基于对象的跨表查询 一对一 作者表和作者详细信息表 //正向查询 #查询作者小明的住址 author_obj = models.Author.objects.get(name='小明') # author_obj.ad直接拿到authordetail表中的那个记录对 print(author_obj.ad.addr) //反向查询 #查询作者详细信息表中电话号以170开头的作者名字 authordetail_ojb = models.AuthorDetail.objects.filter( telephone__startswith='170').first() print(book_obj) #不加first打印结果 ]> print(book_obj) #加first打印结果 Book object #authordetail_ojb.author中的author是类名小写，直接定位到app01_author这张表 print(authordetail_ojb.author.name) 关于正向查询和反向查询的说明 一对多 出版社表和书籍表 //正向查询 #查询python从入门到放弃这本书的出版社 book_obj = models.Book.objects.filter(title='python从入门到放弃').first() print(book_obj.publishs.name) //反向查询 pub_obj = models.Publish.objects.get(name='南京出版社') #pub_obj.book_set.all()中book_set是结果可能为多个，最后的all是拿到的书籍对象所有信息 books = pub_obj.book_set.all().values('title') print(books) #查询南京出版社中数名包含linux的书 books = pub_obj.book_set.filter(title__contains='linux').values('title') 多对多 书籍表和作者表 //正向查询 #查询书籍表中书名为linux从入门到放弃的作者 book_obj = models.Book.objects.filter(title='linux从入门到放弃').first() authors = book_obj.authors.all().values('name') print(authors) //反向查询 反向查询中用字段存在的表的小写类名，这里为book #查询作者小明写的书 xiaoming_obj = models.Author.objects.get(name='小明') ret = xiaoming_obj.book_set.all().values('title') print(ret) 查询书籍表中书名为linux从入门到放弃的作者 基于双下划线的跨表查询 就是join连表查询 一对一 作者表与作者详细信息表 //查询作者小明的住址 #基于对象的跨表查询写法 正向查询 author_obj = models.Author.objects.get(name='小明') #author_obj.ad直接拿到authordetail表中的那个记录对 print(author_obj.ad.addr) #基于双下划线的跨表查询写法 #正向查询 ret = models.Author.objects.filter(name='小明').values('ad__addr') print(ret) #反向查询 ret = models.AuthorDetail.objects.filter(author__name='小明').values('addr') print(ret) 正向查询中 关联字段__字段 就获得了关联表的数据 反向查询中 表名__字段 一对多 书籍表和出版社表 //查询东京出版社出版的书 #原生sql语句 select app01_book.title from app01_publish inner join app01_book on app01_publish.id = app01_book.publishs_id where app01_publish.name='东京出版社'; #正向查询 ret = models.Book.objects.filter(publishs__name='东京出版社').values('title') #反向查询 ret = models.Publish.objects.filter(name='东京出版社').values('book__title') 多对多 书籍表和作者表 关联字段在书籍表中，从书籍表查询是正向查询 #查询一下小明写了哪些书 #正向查询 关联字段在book表中，现在要查询小明写了哪些书，当前是book表，表中没有作者名字的字段，因此需要先连表然后在取值 ret = models.Book.objects.filter(authors__name='小明').values('title') print(ret) #反向查询 现在要查询小明写了哪些书，当前是author表，表中有作者名字的字段，因此不需要先连表，已知字段在本表的就可以先写条件最后在连表 ret = models.Author.objects.filter(name='小明').values('book__title') print(ret) 关联的方式，正向查询和反向查询都可以使用，关键在于查询的条件 关联字段__字段 就获得了关联表的数据 小写类名__字段 聚合查询 aggregate聚合查询,结果是普通字典,queryset的结束符 #导入相关模块 from django.db.models import Avg,Max,Min,Count,Sum //查询书籍表中价格最高的 obj = models.Book.objects.all().aggregate(a=Max('price')) print(obj) 结果： {'a': Decimal('125.00')} 分组查询 //查询每个出版社出版的书的最高价格 #方式一 ret = models.Book.objects.values('publishs_id').annotate(m=Max('price')) print(ret) 结果： 方式一写法说明 values写在annotate前面,意思是以values括号内的字段作为分组的依据,annotate里面是你要做的统计结果,这样,返回结果为queryset类型数据,里面是字典{'publishs_id':1,'m':100} #方式二 #从出版社表中查询，需要连接book表，因为book表中才有书名和价格，这么写表示直接以publish这张表的id进行分组 ret = models.Publish.objects.annotate(m=Max('book__price')).values('m','name') print(ret) 结果： 方式二写法说明 annotate直接写在了objects后面,意思是按照前面表的所有的数据(默认是id值)作为分组依据,结果返回的是前面这个表的所有models对象(model对象中包含了每个对象自己的统计结果),在通过values来取值,取值时可以直接写字段和统计结果的别名,也是queryset类型,里面是字典{'m':100,'name':'东京出版社'} F和Q查询 在book表中添加连个字段：点赞(dianzan)和评论(pinglun) class Book(models.Model): title = models.CharField(max_length=32) publishDate=models.DateField() dianzan = models.IntegerField(default=100) pinglun = models.IntegerField(default=100) price=models.DecimalField(max_digits=5,decimal_places=2) publishs=models.ForeignKey(to=\"Publish\",to_field=\"id\",on_delete=models.CASCADE) app01_book表中内容 F查询 F查询用于一张表中的两个字段比较之后的符合条件的结果集 //查询book表中点赞数大于评论数的所有书籍 #low版写法 list1 = [] books = models.Book.objects.all() for i in books: if i.dianzan > i.comment: list1.append(i) #F查询写法 ret = models.Book.objects.filter(dianzan__gt=F('pinglun')).values('title') print(ret) 结果： //F还支持四则运算，例如将book表中的价格都上调50元models.Book.objects.all().update( price=F('price')+50 ) Q查询 Q查询用于多个条件有与、或、非时的综合查询 与：& 或：| 非：～ orm执行原生sql语句 //方式一 ret = models.Book.objects.raw('select * from app01_book') for i in ret: print(i.title) 结果： 会把表中所有书名打印出来 //方式二 django自带的连接通道(在项目下同名目录__init__.py中配置的pymysql) from django.db import connection import pymysql def query(request): conn = pymysql.connect() cursor = connection.cursor() cursor.execute('select * from app01_book;') print(cursor.fetchall()) //方式三 def query(request): conn = pymysql.connect( host='127.0.0.1', port=3306, user='root', password='PAPAlichencan!1', database='orm02', charset='utf8' ) cursor = conn.cursor(pymysql.cursors.DictCursor) cursor.execute('select * from app01_book;') print(cursor.fetchall()) 结果： [{'id': 1, 'title': 'python从入门到放弃', 'publishDate': datetime.date(2011, 1, 1), 'price': Decimal('99.00'), 'publishs_id': 3, 'dianzan': 600, 'pinglun': 150}, {'id': 2, 'title': 'linux从入门到放弃', 'publishDate': datetime.date(2019, 12, 12), 'price': Decimal('99.90'), 'publishs_id': 2, 'dianzan': 500, 'pinglun': 300}, {'id': 3, 'title': '隔壁老王的故事', 'publishDate': datetime.date(2019, 11, 7), 'price': Decimal('125.00'), 'publishs_id': 2, 'dianzan': 100, 'pinglun': 100}, {'id': 4, 'title': 'linux安全指南', 'publishDate': datetime.date(2020, 11, 30), 'price': Decimal('66.00'), 'publishs_id': 2, 'dianzan': 300, 'pinglun': 2000}, {'id': 5, 'title': '奔跑的linux内核', 'publishDate': datetime.date(2019, 11, 1), 'price': Decimal('77.00'), 'publishs_id': 2, 'dianzan': 50, 'pinglun': 100}] django外部脚本调用models数据库操作 使用场景：有的时候我们不想运行django项目只想执行一些视图中的逻辑，这个时候就用到了django外部脚本调用models数据库操作 操作方法：在django项目下新建一个xx.py文件，在xx.py文件中写入以下内容，然后直接运行这个xx.py文件就可以在不启动django项目的情况下而单独执行我们想执行的测试逻辑 #导入os模块 import os if __name__ == '__main__': #最后一个参数要写项目名.settings os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"orm02.settings\") #导入django import django django.setup() #导入应用程序的models from app01 import models ret = models.Book.objects.all().values('title') print(ret) ORM事务和锁 锁 models.Book.objects.select_for_update().filter(id=1) 事务 //方式1 全局配置 DATABASES = { 'default': { 'ENGINE': 'django.db.backends.mysql', 'NAME': 'mxshop', 'HOST': '127.0.0.1', 'PORT': '3306', 'USER': 'root', 'PASSWORD': '123', \"ATOMIC_REQUESTS\": True, #全局开启事务，绑定的是http请求响应整个过程当中的sql } } 方式1中，django项目中所有的视图逻辑全部加上了事物 //方式2: 视图函数加装饰器 from django.db import transaction @transaction.atomic def viewfunc(request): # This code executes inside a transaction. 逻辑语句 方式2中，我们只想给某一个视图函数加事物，这个时候就用到了上述的方法 方式3: 上下文加装饰器 from django.db import transaction def viewfunc(request): # This code executes in autocommit mode (Django's default). 逻辑语句1 with transaction.atomic(): #保存点 # This code executes inside a transaction. 逻辑语句2 逻辑语句3 方式3中，我们只想给逻辑语句2添加事物，而其他语句不需要，这个时候就在逻辑语句2的上边写如上语句即可 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python进阶/django/6.cookie和session.html":{"url":"python/python进阶/django/6.cookie和session.html","title":"django基础六 cookie和session","keywords":"","body":"cookie和session 一、cookie 1.1cookie的由来 http协议是无状态的，无状态的意思就是每次请求都是独立的，它的执行情况和结果与前面的请求和之后的请求都无直接关系，对于服务器来讲，每次都请求都是全新的 状态可以理解为客户端和服务端在某次会话中产生的数据，那无状态的情况下，产生的数据就不会被保存，而会话产生的数据又是需要我们保存的，经典的需求就是客户端登陆服务端后，服务端需要记住客户端是谁，而不用每次都重新登陆，这样就产生了cookie 1.2cookie是什么 cookie是浏览器的技术，cookie具体指的是一段小信息，它是服务器发送出来存储在浏览器上的一组组简直对，可以理解为服务端给客户端的一个小甜点，下次客户端的浏览器访问服务器时就会自动携带这些键值对，一便服务器提取有用信息 1.3cookie的原理 cookie的工作原理是：浏览器访问服务端，带着一个空的cookie，然后由服务器产生内容，浏览器收到内容后保存在本地，当浏览器再次访问服务器时，浏览器会自动带上cookie，这样服务器就能通过cookie的内容来判断请求者是谁了 查看cookie cookie原理示意图 1.4cookie规范 Cookie大小上限为4KB，是总数大小为4KB不是单个 一个服务器最多在客户端浏览器上保存20个Cookie 一个浏览器最多保存300个Cookie，因为一个浏览器可以访问多个服务器 不同浏览器之间是不共享Cookie的 1.5cookie和http头 Cookie是通过HTTP请求和响应头在客户端和服务器端传递的： Cookie：请求头，客户端发送给服务器端； 格式： Cookie: a=A; b=B; c=C。即多个Cookie用分号离开；  Set-Cookie：响应头，服务器端发送给客户端； 一个Cookie对象一个Set-Cookie： Set-Cookie: a=A Set-Cookie: b=B Set-Cookie: c=C 1.6cookie的覆盖 如果服务器端发送重复的Cookie那么会覆盖原有的Cookie，例如客户端的第一个请求服务器端发送的Cookie是：Set-Cookie: a=A；第二请求服务器端发送的是：Set-Cookie: a=AA，那么客户端只留下一个Cookie，即：a=AA。 1.7django中操作cookie 1.7.1django设置cookie 设置cookie #方式一 获取cookie: request.COOKIES.get('xx') 设置cookie: HttpResponse('xx').set_cookie('键','值') #方式二 获取签名cookie: request.get_signed_cookie('is_login',salt='xxx') 设置签名cookie: ret.set_signed_cookie('is_login',True,'xxx') 设置cookie中的参数 key #cookie的键 value='' #cookie的值 max_age=None #超时时间，单位秒，经过多少秒后cookie失效，默认两周 expires=None #超时时间(IE requires expires, so set it if hasn't been already.)，例如，当前时间为1月1日10时10分，设置为7就是1月8日的10时10分失效 path='/' #Cookie生效的路径，/ 表示根路径，特殊的：根路径的cookie可以被任何url的页面访问 domain=None #Cookie生效的域名 secure=False #https传输 httponly=False #只能http协议传输，无法被JavaScript获取（不是绝对，底层抓包可以获取到也可以被覆盖） cookie设置时不要设置中文！！！因为不专业 如果非要设置中文的解决方法 #方式1 def login(request): ret = HttpResponse('ok') ret.set_cookie('k1','你好'.encode('utf-8').decode('iso-8859-1')) #取值：request.COOKIES['k1'].encode('utf-8').decode('iso-8859-1').encode('iso-8859-1').decode('utf-8') return ret #方式2 json def login(request): ret = HttpResponse('ok') import json ret.set_cookie('k1',json.dumps('你好')) #取值 json.loads(request.COOKIES['k1']) return ret 1.7.2django删除cookie 删除cookie: ret = redirect(\"/login/\") ret.delete_cookie('cookie键名称') 1.7.3cookie版登陆校验示例 用户访问login，登陆成功重定向到页面home展示内容 urls文件 from django.conf.urls import url from django.contrib import admin from app01 import views urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^login/', views.login,name='login'), url(r'^home/', views.home,name='home'), ] views文件 from django.shortcuts import render,HttpResponse,redirect # Create your views here. def login(request): if request.method == 'GET': return render(request,'login.html') else: username = request.POST.get('username') password = request.POST.get('password') if username == 'admin' and password == 'admin': ret = redirect('home') #这里是我们自己设置cookie ret.set_cookie('is_login',True) # return redirect('home') return ret else: return redirect('login') def home(request): #这里获取上边我们自己设置的cookie is_login = request.COOKIES.get('is_login') if is_login == 'True': return render(request,'home.html') else: return redirect('login') html文件 #login.html Title 登录页面 {% csrf_token %} 用户名: 密码: #home.html Title 欢迎来到乔杉大保健会所 整体的逻辑是用户登陆成功后返回home页面，直接访问home页面不可以，清除cookie后用户需要重新登陆 查看浏览器中的cookie 二、session 2.1session是什么 Session是服务器端技术，利用这个技术，服务器在运行时可以为每一个用户的浏览器创建一个其独享的session对象，由于session为用户浏览器独享，所以用户在访问服务器的web资源时 ，可以把各自的数据放在各自的session中，当用户再去访问该服务器中的其它web资源时，其它web资源再从用户各自的session中取出数据为用户服务。 session图解 2.2session详细流程 1.当用户登陆之后，服务端生成一个字典{'key':'value'}，并且将字典存入session，key是服务端自动生成的一段字符串标示，返回cookie，value是一个自定义格式的字典，这个字典的内容由我们自己决定 2.在1中生成的字典value中自定义格式来存储用户信息，如用户名、密码等等 3.当我们在django中用到session时，cookie由服务端随机生成，写到浏览器的cookie中，每个浏览器都有自己的cookie值，是session寻找用户信息的唯一标识，每个浏览器请求到后台的接收的request_session等价于1中session字典的key(cookie)对应的value 2.3session规范 借助于cookie进行传输 非明文显示 长度不限 2.4django中操作session 2.4.1django设置session //session可以设置多个 request.session['is_login'] = True request.session['username'] = username //获取session request.session.get('is_login') request.session.get('username') django设置session过程 1.生成随机字符串 2.放到cookie中进行传输 3.将随机字符串和对应数据保存到自己服务端的数据库中 django获取session过程 1.取出cookie中的session随机字符串{'sessionid':'asdfasfpoaijsdgihsdj'} xx = request.COOKIES.get('sessionid') 2.到数据库中查询这个sessionid对应的那条记录 data = select session_data from django_session where session_key = xx; 3.拿出记录中的session_data数据部分进行解密,并取出数据 dic.get('is_login') --> True dic = ss(data) --> {'is_login':True} django删除session过程 1.删除cookie中的sessionid那个键值对 2.删除了数据库中的这条记录 2.4.2django删除session request.session.flush() 2.4.3session版登陆校验示例 用户访问login，登陆成功重定向到页面home展示内容 urls文件 from django.conf.urls import url from django.contrib import admin from app01 import views urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^login/', views.login,name='login'), url(r'^home/', views.home,name='home'), ] views文件 from django.shortcuts import render,HttpResponse,redirect # Create your views here. def login(request): if request.method == 'GET': return render(request,'login.html') else: username = request.POST.get('username') password = request.POST.get('password') if username == 'admin' and password == 'admin': request.session['is_login'] = True request.session['username'] = username \"\"\" 设置session后做的3件事 1.生成随机字符串 2.放到cookie中进行传输 3.将随机字符串和对应数据保存到自己服务端的数据库中 \"\"\" return redirect('home') else: return redirect('login') def home(request): #这里获取上边我们自己设置的session is_login = request.session.get('is_login') \"\"\" request.session.get做的事 1.取出cookie中的session随机字符串{'sessionid':'asdfasfpoaijsdgihsdj'} xx = request.COOKIES.get('sessionid') 2.到数据库中查询这个sessionid对应的那条记录 data = select session_data from django_session where session_key = xx; 3.拿出记录中的session_data数据部分进行解密,并取出数据 dic = sss(data) --> {'is_login':True} dic.get('is_login') --> True \"\"\" if is_login == True: return render(request,'home.html') else: return redirect('login') def logout(request): #删除session request.session.flush() \"\"\" 删除session 1.删除cookie中的sessionid那个键值对 2.删除了数据库中的这条记录 \"\"\" return redirect('login') html文件 #login.html Title 登录页面 {% csrf_token %} 用户名: 密码: #home.html Title 欢迎来到乔杉大保健会所 注销 cookie与session总结 cookie的作用: 保持会话,使用户不需要重复的去登录 1.有大小限制,Cookie总大小上限为4KB； 2.有个数限制 一个服务器最多在客户端浏览器上保存20个Cookie； 一个浏览器最多保存300个Cookie，因为一个浏览器可以访问多个服务器。 session 1.比cookie面上安全一些 2.session没有大小限制 3.可以配置多个存储方案,可以配置到缓存中 django session表中session key标记的是浏览器，不是用户，一个浏览器对应一个服务端 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python进阶/django/7.Ajax.html":{"url":"python/python进阶/django/7.Ajax.html","title":"django基础七 Ajax","keywords":"","body":"6.Ajax 异步提交 局部刷新 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python进阶/django/8.django中间件.html":{"url":"python/python进阶/django/8.django中间件.html","title":"django基础八 django中间件","keywords":"","body":"django中间件 1.中间件介绍 1.1django中间件简介及定义 django中间件是介于request与response处理之间的一道处理过程，相对比较轻量级，并且在全局上改变django的输入与输出。因为改变的是全局，所以需要谨慎实用，用不好会影响到性能。 Django的中间件的定义： #中间件是一个钩子框架，用于Django的请求/响应处理。这是一个轻量级的、底层的“插件”系统，用于全局地改变Django的输入或输出。 Middleware is a framework of hooks into Django’s request/response processing. It’s a light, low-level “plugin” system for globally altering Django’s input or output. 1.2django中间件的作用 如果你想修改请求，例如被传送到view中的HttpRequest对象。 或者你想修改view返回的HttpResponse对象，这些都可以通过中间件来实现。 可能你还想在view执行之前做一些操作，这种情况就可以用 middleware来实现。 说的直白一点中间件是帮助我们在视图函数执行之前和执行之后都可以做一些额外的操作，它本质上就是一个自定义类，类中定义了几个方法，Django框架会在请求的特定的时间去执行这些方法。 1.3django中间件的配置项 打开django项目的settings.py文件，看到下面的MIDDLEWARE配置项，django默认自带的一些中间件： MIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware', ] 2.django生命周期 django生命周期 3.自定义中间件 第一步、在django项目下的应用程序目录下创建一个mymiddleware目录，名称任意，在这个目录中再创建一个middleware文件，名称任意，在这个文件中写入以下内容 #导入MiddlewareMixin from django.utils.deprecation import MiddlewareMixin from django.shortcuts import redirect,render,HttpResponse class Auth(MiddlewareMixin): # 定义一个白名单 white_list = ['/login/', ] def process_request(self,request): if request.path in self.white_list: pass else: is_login = request.session.get('is_login') \"\"\" request.session.get做的事 1.取出cookie中的session随机字符串{'sessionid':'asdfasfpoaijsdgihsdj'} xx = request.COOKIES.get('sessionid') 2.到数据库中查询这个sessionid对应的那条记录 data = select session_data from django_session where session_key = xx; 3.拿出记录中的session_data数据部分进行解密,并取出数据 dic = sss(data) --> {'is_login':True} dic.get('is_login') --> True \"\"\" # 这里写一个pass，就是返回一个None，如果返回是None，则说明通过了请求 if is_login == True: pass else: # return redirect('login') return HttpResponse('中间件不让你登陆') 第二步、在settings文件中MIDDLEWARE项的最后边配置中间件 #应用程序名.自定义中间件的目录.自定义中间件py文件.自定义类 'app01.mymiddleware.middleware.Auth' 第三步、视图文件 from django.shortcuts import render,HttpResponse,redirect from django.urls import reverse # Create your views here. def login(request): if request.method == 'GET': return render(request,'login.html') else: username = request.POST.get('username') password = request.POST.get('password') if username == 'admin' and password == 'admin': request.session['is_login'] = True request.session['username'] = username \"\"\" 设置session后做的3件事 1 生成随机字符串 2 放到cookie中进行传输 3 将随机字符串和对应数据保存到自己服务端的数据库中 \"\"\" return redirect('home') else: return redirect('login') def home(request): #这里获取上边我们自己设置的cookie # is_login = request.COOKIES.get('is_login') is_login = request.session.get('is_login') \"\"\" request.session.get做的事 1.取出cookie中的session随机字符串{'sessionid':'asdfasfpoaijsdgihsdj'} xx = request.COOKIES.get('sessionid') 2.到数据库中查询这个sessionid对应的那条记录 data = select session_data from django_session where session_key = xx; 3.拿出记录中的session_data数据部分进行解密,并取出数据 dic = sss(data) --> {'is_login':True} dic.get('is_login') --> True \"\"\" if is_login == True: return render(request,'home.html') else: return redirect('login') 4.中间件5大方法 4.1process_request(self,request) 3中的自定义中间件用到的就是process_request(self,request)，这是一个对请求进行处理的方法 process_request有一个参数，就是request，这个request和视图函数中的request是一样的。 它的返回值可以是None也可以是HttpResponse对象。返回值是None的话，按正常流程继续走，交给下一个中间件处理，如果是HttpResponse对象，Django将不执行视图函数，而将响应对象返回给浏览器。 4.2process_response(self, request, response) process_response是对视图函数所有的响应进行处理 它有两个参数，一个是request，一个是response，request和视图函数中的request是一样的，response是视图函数返回的HttpResponse对象。该方法的返回值也必须是HttpResponse对象。 例如，在每一个视图函数的响应头中添加一些东西，就可以在process_response方法中添加响应头 def process_response(self,request,response): ''' :param request: :param response: 就是视图函数的返回值(HttpResonse对象) :return: ''' ''' print(response) response返回的是一个HttpResponse对象 ''' #必须返回response这个值，不返回下一个中间件的respnse方法拿不到这个值 return response 4.3process_view(self, request, view_func, view_args, view_kwargs) process_view是在视图函数执行前执行 该方法有四个参数 request是HttpRequest对象。 view_func是Django即将使用的视图函数。（它是实际的函数对象，而不是函数的名称作为字符串。） view_args是将传递给视图的位置参数的列表. view_kwargs是将传递给视图的关键字参数的字典。 view_args和view_kwargs都不包含第一个视图参数（request）。 Django会在调用视图函数之前调用process_view方法。 它应该返回None或一个HttpResponse对象。 如果返回None，Django将继续处理这个请求，执行任何其他中间件的process_view方法，然后再执行相应的视图。 如果它返回一个HttpResponse对象，Django不会调用对应的视图函数。 它将执行中间件的process_response方法并将应用到该HttpResponse并返回结果。 process_view执行顺序示意图 中间件文件 from django.utils.deprecation import MiddlewareMixin from django.shortcuts import redirect,render,HttpResponse class MD1(MiddlewareMixin): def process_request(self,request): print('MD1的process_request方法') def process_response(self,request,response): print('MD1的process_response方法') return response def process_view(self,request,view_func,view_args,view_kwargs): print('MD1的process_view方法',view_func.__name__) class MD2(MiddlewareMixin): def process_request(self, request): print('MD2的process_request方法') def process_response(self, request, response): print('MD2的process_response方法') return response def process_view(self, request, view_func, view_args, view_kwargs): print('MD2的process_view方法', view_func.__name__) 配置settings文件，MIDDLEWARE项 'app01.mymiddleware.xx.MD1', 'app01.mymiddleware.xx.MD2', 视图文件 def login(request): #这里打印一个login视图函数是为了看到执行的顺序，process_request,process_response,process_view print('login视图函数') if request.method == 'GET': return render(request,'login.html') 打印结果 可以看到，先执行process_request方法，然后执行process_view方法，process_view方法是在视图函数执行前执行，之后执行视图函数，最后执行process_response方法，并且process_response是倒序执行 ⚠️⚠️⚠️如果在process_request方法中返回了HttpResponse对象，则只执行自己中间件的process_request方法和process_response方法，如果自己的中间件没有定义process_response方法，则会交给自己类的上一个中间件，如果上一个类也没有，会一直往上推 class MD1(MiddlewareMixin): def process_request(self,request): print('MD1的process_request方法') #这里返回了一个HttpResponse对象，则只执行自己中间件的process_request方法和process_response方法 return HttpResponse('xxx') def process_response(self,request,response): print('MD1的process_response方法') return response def process_view(self,request,view_func,view_args,view_kwargs): print('MD1的process_view方法',view_func.__name__) 打印结果 MD1的process_request方法 MD1的process_response方法 示意图 4.4process_exception(self, request, exception) 该方法两个参数: 一个HttpRequest对象 一个exception是视图函数异常产生的Exception对象。 这个方法只有在视图函数中出现异常了才执行，它返回的值可以是一个None也可以是一个HttpResponse对象。如果是HttpResponse对象，Django将调用模板和中间件中的process_response方法，并返回给浏览器，否则将默认处理异常。如果返回一个None，则交给下一个中间件的process_exception方法来处理异常。它的执行顺序也是按照中间件注册顺序的倒序执行。 process_exception执行示意图 中间件文件 from django.utils.deprecation import MiddlewareMixin from django.shortcuts import redirect,render,HttpResponse class MD1(MiddlewareMixin): def process_request(self,request): print('MD1的process_request方法') # return HttpResponse('xxx') def process_response(self,request,response): print('MD1的process_response方法') return response def process_view(self,request,view_func,view_args,view_kwargs): print('MD1的process_view方法',view_func.__name__) def process_exception(self, request, exception): print(exception) print(\"MD1的process_exception方法\") return HttpResponse(str(exception)) class MD2(MiddlewareMixin): def process_request(self, request): print('MD2的process_request方法') def process_response(self, request, response): print('MD2的process_response方法') return response def process_view(self, request, view_func, view_args, view_kwargs): print('MD2的process_view方法', view_func.__name__) def process_exception(self, request, exception): print(exception) print(\"MD2的process_exception方法\") return HttpResponse(str(exception)) 视图函数文件，在视图函数中抛出一个异常 def login(request): # print('login视图函数') print(\"app01中的login视图函数\") raise ValueError(\"视图函数中出错了才执行process_exception方法\") return HttpResponse(\"OK\") if request.method == 'GET': return render(request,'login.html') else: username = request.POST.get('username') password = request.POST.get('password') if username == 'admin' and password == 'admin': request.session['is_login'] = True request.session['username'] = username \"\"\" 设置session后做的3件事 1 生成随机字符串 2 放到cookie中进行传输 3 将随机字符串和对应数据保存到自己服务端的数据库中 \"\"\" return redirect('home') else: return redirect('login') 打印结果，当md1和md2中的process_exception方法都返回了Httpresponse对象，只执行md2的process_exception方法 当只有md1返回Httpresponse对象时，md1和md2的process_exception方法都执行 4.5process_template_response(self, request, response) 它的参数，一个HttpRequest对象，response是TemplateResponse对象（由视图函数或者中间件产生） process_template_response是在视图函数执行完成后立即执行，但是它有一个前提条件，那就是视图函数返回的对象有一个render()方法（或者表明该对象是一个TemplateResponse对象或等价方法） 中间件文件 from django.utils.deprecation import MiddlewareMixin from django.shortcuts import redirect,render,HttpResponse class MD1(MiddlewareMixin): def process_request(self,request): print('MD1的process_request方法') # return HttpResponse('xxx') def process_response(self,request,response): print('MD1的process_response方法') return response def process_view(self,request,view_func,view_args,view_kwargs): print('MD1的process_view方法',view_func.__name__) def process_exception(self, request, exception): print(exception) print(\"MD1的process_exception方法\") return HttpResponse(str(exception)) def process_template_response(self, request, response): print(\"MD1的process_template_response方法\") return response class MD2(MiddlewareMixin): def process_request(self, request): print('MD2的process_request方法') def process_response(self, request, response): print('MD2的process_response方法') return response def process_view(self, request, view_func, view_args, view_kwargs): print('MD2的process_view方法', view_func.__name__) def process_exception(self, request, exception): print(exception) print(\"MD2的process_exception方法\") # return HttpResponse(str(exception)) def process_template_response(self, request, response): print(\"MD2的process_template_response方法\") return response 视图文件，必须这么写才行 def login(request): def render(): print(\"in index/render\") return HttpResponse(\"OK\") # 返回的将是这个新的对象 rep = HttpResponse(\"OK\") rep.render = render return rep 打印结果 5.中间件执行流程 请求到达中间件之后，先按照正序执行每个注册中间件的process_reques方法，process_request方法返回的值是None，就依次执行，如果返回的值是HttpResponse对象，不再执行后面的process_request方法，而是执行当前对应中间件的process_response方法，将HttpResponse对象返回给浏览器。也就是说：如果MIDDLEWARE中注册了6个中间件，执行过程中，第3个中间件返回了一个HttpResponse对象，那么第4,5,6中间件的process_request和process_response方法都不执行，顺序执行3,2,1中间件的process_response方法 process_request方法都执行完后，匹配路由，找到要执行的视图函数，先不执行视图函数，先执行中间件中的process_view方法，process_view方法返回None，继续按顺序执行，所有process_view方法执行完后执行视图函数。加入中间件3 的process_view方法返回了HttpResponse对象，则4,5,6的process_view以及视图函数都不执行，直接从最后一个中间件，也就是中间件6的process_response方法开始倒序执行 process_template_response和process_exception两个方法的触发是有条件的，执行顺序也是倒序。总结所有的执行流程如下 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python-other/nginx+django+uwsgi部署项目.html":{"url":"python/python-other/nginx+django+uwsgi部署项目.html","title":"nginx+django+uWSGI部署项目","keywords":"","body":"nginx+django+uwsgi部署项目 一、WSGI、uWSGI、uwsgi概念简述 WSGI WSGI，全称 Web Server Gateway Interface，或者 Python Web Server Gateway Interface ，是为 Python 语言定义的 Web 服务器和 Web 应用程序或框架之间的一种简单而通用的接口 wsgi server (比如uWSGI） 要和 wsgi application（比如django ）交互，uwsgi需要将过来的请求转给django 处理，那么uWSGI 和 django的交互和调用就需要一个统一的规范，这个规范就是WSGI WSGI 的官方定义是，the Python Web Server Gateway Interface。从名字就可以看出来，这东西是一个Gateway，也就是网关。网关的作用就是在协议之间进行转换。 WSGI 是作为 Web 服务器与 Web 应用程序或应用框架之间的一种低级别的接口，以提升可移植 Web 应用开发的共同点。WSGI 是基于现存的 CGI 标准而设计的。 uWSGI uWSGI是一个Web服务器，它实现了WSGI协议、uwsgi、http等协议。Nginx中HttpUwsgiModule的作用是与uWSGI服务器进行交换。 uwsgi uwsgi是服务器和服务端应用程序的通信协议，规定了怎么把请求转发给应用程序和返回 二、处理过程 nginx+django+uWSGI处理过程 1.客户端(浏览器)准备发送请求 2.如果请求的是静态内容则直接返回给客户端，nginx在这里统一收集后端django项目的静态文件 3.如果请求的是动态内容, 就把请求转发给uWSGI ,uWSGI连接Django进入我们的Python程序进行处理，这期间uWSGI会连接数据库获取数据 三、部署过程 3.1环境及角色说明 系统环境 角色 版本 系统 centos7.6 nginx 1.16 django 2.1 mysql 5.7.22 uWSGI 2.0.18 supervisor 4.1.0 角色说明 nginx 提供反向解析功能，将80端口请求转发至django端口，同时还负责处理静态资源 uWSGI+django 启动后端项目，处理动态请求 mysql 数据库，存储数据，django从数据库中获取数据 supervisor 进程管理工具，防止uWSGI突然崩溃，supervisor能自动启动uWSGI 3.2部署过程 3.2.1安装nginx1.16 1.下载nginx [root@django ~]# wget http://nginx.org/download/nginx-1.16.1.tar.gz 2.安装依赖 [root@django ~]# yum -y install gcc gcc-c++ zlib zlib-devel openssl openssl-devel pcre-devel 3.添加ngxin用户和组 [root@django ~]# groupadd nginx && useradd nginx -g nginx -s /sbin/nologin -M 4.解压缩并编译安装 [root@django ~]# tar xf nginx-1.16.1.tar.gz [root@django ~]# cd nginx-1.16.1/ [root@django nginx-1.16.1]# ./configure --user=nginx --group=nginx --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module --with-http_realip_module --with-http_gzip_static_module [root@django nginx-1.16.1]# make -j 2 && make install 5.设置nginx命令环境变量 [root@django ~]# echo \"PATH=/usr/local/nginx/sbin:$PATH\" >/etc/profile.d/nginx.sh [root@django ~]# source /etc/profile 6.启动nginx [root@django ~]# nginx [root@django ~]# ps aux|grep nginx root 6833 0.0 0.2 45968 1132 ? Ss 15:20 0:00 nginx: master process nginx nginx 6834 0.0 0.3 48508 1972 ? S 15:20 0:00 nginx: worker process root 6920 0.0 0.1 112708 988 pts/0 S+ 15:21 0:00 grep --color=auto nginx 3.2.2安装mysql5.7.22 ⚠️⚠️⚠️ 二进制安装mysql的启动脚本和 安装目录/mysql/bin/mysqld_safe 这两个文件中都是默认/usr/local/mysql，如果安装目录不在/usr/local/下，需要修改这两个文件中的路径，即把/usr/local替换为mysql安装目录 sed -i 's#/usr/local#/application#g' /etc/init.d/mysql /application/mysql/bin/mysqld_safe 1.下载MySQL-5.7.22二进制包 [root@django ~]# wget https://cdn.mysql.com/archives/mysql-5.7/mysql-5.7.22-linux-glibc2.12-x86_64.tar.gz MD5值 9ef7a05695f8b4ea29f8d077c3b415e2 2.解压缩mysql二进制包到/usr/local [root@django ~]# tar xf mysql-5.7.22-linux-glibc2.12-x86_64.tar.gz -C /usr/local 3.修改名称、做软连接 [root@django local]# mv /usr/local/mysql-5.7.22-linux-glibc2.12-x86_64 /usr/local/mysql-5.7.22 && \\ ln -s /usr/local/mysql-5.7.22 /usr/local/mysql 4.创建mysql用户和组 [root@django local]# groupadd mysql && useradd -g mysql -s /bin/false mysql 5.编辑主配置文件，myql-5.7.22二进制包默认没有mysql配置文件 #备份/etc/my.cnf [root@django local]# mv /etc/my.cnf /etc/my.cnf.old #以下配置为最精简版，可根据实际情况进行相应设置 [root@django~]# cat >> /etc/my.cnf /etc/profile.d/mysql.sh #使配置生效 [root@django ~]# source /etc/profile 9.配置systemd管理mysql [root@django ~]# cat >> /etc/systemd/system/mysqld.service set password='123'; Query OK, 0 rows affected (0.00 sec) mysql> flush privileges; Query OK, 0 rows affected (0.01 sec) 3.2.3安装python3.6 1.下载python [root@django ~]# wget https://www.python.org/ftp/python/3.6.9/Python-3.6.9.tar.xz 2.安装依赖包 [root@django ~]# yum -y install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel libffi-devel gcc gcc-c++ make 3.解压缩python并编译安装 [root@django ~]# tar xf Python-3.6.9.tar.gz [root@django ~]# cd Python-3.6.9/ [root@django Python-3.6.9]# ./configure --prefix=/usr/local/python36 [root@django Python-3.6.9]# make -j 2 && make install 4.导出python命令环境变量 [root@django ~]# echo \"PATH=/usr/local/python36/bin:$PATH\" >/etc/profile.d/python36.sh [root@django ~]# source /etc/profile [root@django ~]# python3 -V Python 3.6.9 5.配置pip国内源 [root@django ~]# mkdir ~/.pip [root@django ~]# cat >~/.pip/pip.conf 3.2.4部署python虚拟环境virtualenv、virtualenvwrappe、uwsgi及django项目 鉴于virtualenv不便于对虚拟环境集中管理,所以推荐直接使用virtualenvwrapper,virtualenvwrapper提供了一系列命令使得和虚拟环境工作变得便利,它把你所有的虚拟环境都放在一个地方 virtualenvwrapper整体工作过程 1.安装virtualenvwrapper 2.在~/.bashrc文件中指定virtualenvwrapper存放虚拟环境总目录,指定virtualenvwrapper.sh存放位置(find查找) 3.mkvirtualenv命令创建python虚拟环境,-p选项指定不同python版本命令路径 4. workon命令切换不同python虚拟环境 第一步、安装virtualenv、virtualenvwrapper [root@django ~]# pip3 install virtualenv virtualenvwrapper 第二步、编辑virtualenvwrapper环境变量 //向~/.bashrc中写入以下内容 [root@django ~]# cat >> ~/.bashrc requirements.txt导出开发环境中所有安装的模块 第六步、修改项目requirements.txt文件中的django版本为2.1 克隆的django博客项目中的requirements.txt文件django版本是2.2.8，结果出了一堆问题，但是作者在github上介绍却是基于django2.1，修改完后安装requirements.txt中的模块 (django) [root@django DjangoBlog]# pip3 install -Ur requirements.txt (django) [root@django DjangoBlog]# pip3 install pymysql 第七步、配置mysql字符集 //修改my.cnf，写入以下内容 [mysqld] character-set-server=utf8mb4 collation-server=utf8mb4_unicode_ci [client] default-character-set = utf8mb4 [mysql] default-character-set = utf8mb4 //重启mysql (django) [root@django DjangoBlog]# systemctl restart mysqld 第八步、建库授权 CREATE USER 'djangoblog'@'localhost' IDENTIFIED BY 'DjAnGoBlOg123!@#'; CREATE DATABASE `djangoblog` /*!40100 DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci */; GRANT all ON djangoblog.* TO 'djangoblog'@'localhost'; FLUSH PRIVILEGES; 第九步、修改django项目mysql配置 //修改DjangoBlog/settings.py中的DATABASES配置，如下所示 DATABASES = { 'default': { 'ENGINE': 'django.db.backends.mysql', 'NAME': 'djangoblog', 'USER': 'djangoblog', 'PASSWORD': 'DjAnGoBlOg123!@#', 'HOST': 'localhost', 'PORT': 3306, 'OPTIONS': {'charset': 'utf8mb4'}, } } 第十步、编辑DjangoBlog/__init__.py，指定pymysql为客户端 cat >DjangoBlog/__init__.py /usr/local/nginx/conf/conf.d/django.blog.conf 配置本机hosts解析后访问django.blog，项目界面如下 3.2.5安装supervisor管理uWSGI 1.安装supervisor (django) [root@django DjangoBlog]# pip3 install supervisor (django) [root@django DjangoBlog]# supervisord -v 4.1.0 2.生成supervisor配置文件，也可以使用命令echo_supervisord_conf > /etc/supervisord.conf cat >> /etc/supervisord.conf /etc/logrotate.d/supervisor > /usr/lib/tmpfiles.d/tmp.conf> /usr/lib/systemd/system/supervisord.service /etc/supervisor/config.d/django.ini update django django: added process group supervisor> status django RUNNING pid 19728, uptime 0:00:17 关于django收集静态文件配置 uwsig默认不解析静态文件，需要统一收集一下，交给nginx去返回给客户端 //settings.py文件中如下参数是配置统一收集所有静态文件 STATIC_ROOT='xxx' //这里克隆的项目作者把目录设置为了如下路径 DjangoBlog/collectedstatic //配置完后需要执行以下命令 ./manage.py collectstatic --no-input #收集静态文件 ./manage.py compress --force #压缩静态文件 nginx对于静态资源的配置 nginx+django+uWSGI中还可以配置nginx专门匹配静态资源路径 location /static { alias /django/DjangoBlog/collectedstatic; } django中配置静态资源别名，这里static是别名，statics是真正的路径 STATIC_URL = '/static/' STATICFILES_DIRS = [ os.path.join(BASE_DIR,'statics'), ] python manage.py runserver 其实是调用wsgiref这个python内置的wsgi 服务器，性能很低，单线程 uWSGI是C写的一个基于uwsgi协议运行的高性能Web服务器，支持多进程、多线程 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python-other/python虚拟环境.html":{"url":"python/python-other/python虚拟环境.html","title":"python虚拟环境","keywords":"","body":"python虚拟环境 为什么要创建python虚拟环境 python版本众多,部分版本功能差异较大,centOS7.5 默认python版本2.7.5,centOS6.9 默认python版本2.6.6,在使用过程中经常遇到第三方库依赖的python版本和系统python版本不一致的情况,同时又因系统底层需要调用当前版本python,所以不能随意变更当前系统python版本,如此情境下就会有python多版本共存的情况,因此python多环境管理工具应用而生 一、pyenv pyenv github地址 1.1pyenv简介 pyenv是一个简单的python版本管理工具,以前叫做pythonbrew,这个工具可以方便切换全局python版本,安装多个不同的python版本,设置独立的某个文件夹或者工程目录特异的python版本,同时创建python虚拟环境 1.2pyenv原理 pyenv作为python的版本管理工具,通过改变shell的环境变量来切换不同的python版本,以达到多版本共存的目的 1) pyenv安装后会在系统PATH中插入shims路径,每次执行python相关的可执行文件,会优先在shims里寻找python路径~/.pyenv/shims:/usr/local/bin:/usr/bin:/bin 2) 系统选择python版本,按照如下顺序选择python脚本 ​ ①shell变量设置(执行pyenv查看) ​ ②当前可执行文件目录下的.python_version文件里的版本号(执行pyenv shell查看) ​ ③上层目录查询找到的第一个.pyenv-version文件 ​ ④全局的版本号在~/.pyenv/version文件内(执行pyenv global) 3) 确定版本文件的位置和python版本后,pyenv会根据版本号在~/.pyenv/versions/目录中查找对应的python版本,执行命令pyenv versions可查看系统目前安装的python版本 1.3部署pyenv //克隆pyenv至root家目录 [root@test1 ~]# git clone git://github.com/yyuu/pyenv.git ~/.pyenv //修改环境变量 [root@test1 ~]# echo 'export PYENV_ROOT=\"$HOME/.pyenv\"' >> ~/.bashrc [root@test1 ~]# echo 'export PATH=\"$PYENV_ROOT/bin:$PATH\"' >> ~/.bashrc [root@test1 ~]# echo 'eval \"$(pyenv init -)\"' >> ~/.bashrc [root@test1 ~]# tail -3 ~/.bashrc export PYENV_ROOT=\"$HOME/.pyenv\" export PATH=\"$PYENV_ROOT/bin:$PATH\" eval \"$(pyenv init -)\" //使配置生效 [root@test1 ~]# source ~/.bashrc //测试安装是否正确,返回如下即表明正确 [root@test1 ~]# pyenv versions * system (set by /root/.pyenv/version) //设置pip国内源 mkdir ~/.pip cat >~/.pip/pip.conf 1.4通过oyenv管理多版本python pyenv命令语法 Usage: pyenv [] //查看可安装的版本列表 [root@test1 ~]# pyenv install --list 会列出好多不同版本 //安装依赖包 [root@test1 ~]# yum -y install python-pip python-devel gcc gcc-c++ zlib-devel libffi-devel bzip2-devel bzip2-libs readline readline-devel readline-static openssl openssl-devel openssl-static sqlite-devel //安装指定的python版本 [root@test1 ~]# pyenv install 3.7.1 Downloading Python-3.7.1.tar.xz... -> https://www.python.org/ftp/python/3.7.1/Python-3.7.1.tar.xz Installing Python-3.7.1... Installed Python-3.7.1 to /root/.pyenv/versions/3.7.1 //切换当前目录python目录为3.7.1 #未切换前 [root@test1 ~]# python Python 2.7.5 (default, Aug 7 2019, 00:51:29) [GCC 4.8.5 20150623 (Red Hat 4.8.5-39)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> #切换 [root@test1 ~]# pyenv local 3.7.1 [root@test1 ~]# python Python 3.7.1 (default, Feb 18 2020, 13:20:03) [GCC 4.8.5 20150623 (Red Hat 4.8.5-39)] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. //切换后刷新shims [root@test1 ~]# pyenv rehash //切换回系统版本 [root@test1 ~]# pyenv global system pyenv遇到的问题 1.pyenv global system切换失败，正常应该是回切换到系统默认的python2.7.5，但是切换失败，原因未知 2.pyenv切换到安装的python版本后，会导致原先编译安装的python环境变量失效，例如，原先编译安装了python3.6，然后通过pyenv安装了python3.7，切换后会导致python3.6的环境变量失效，原因未知！！！ 二、virtualenv 2.1virtualenv简介 python的第三方包很多,在一个python环境下开发时间越久,安装依赖越多,就越容易出现依赖包冲突问题,为了解决这个问题,virtualenv被开发出来,它可以搭建虚拟且独立的python环境,这样就可以使每个项目环境与其他项目独立开来,保持环境的干净,避免包冲突问题,另外,在开发python应用程序的时候,所有第三方的包都会被pip安装到系统python版本的site-packages目录下,如果要开发多个应用程序,那么这些程序会共用一个python,这意味着所有的包都安装在系统的python目录下,这不仅影响正常开发工作,还有可能因为随意变更系统python版本信息而造成系统不稳定,这种情况下,每个应用可能需要各自拥有一套独立的python运行环境,virtualenv就是用来为一个应用创建一套隔离的python运行环境的,virtualenv是底层基于python开发的python环境隔离工具,其通过虚拟目录的方式来实现多环境的并存 2.2virtualenv原理 在系统中创建工作目录,该目录类似安装系统的python目录,保留完整的python环境,解释器,标准库和第三方库等,当需要时,切换环境变量激活即可使用 2.3安装virtualenv //安装python-pip和python-devel程序包 [root@test1 ~]# yum -y install python-pip python-devel //安装virtualenv [root@test1 ~]# pip install virtualenv 2.4通过virtualenv管理多python版本 virtualenv不是通过多版本管理的方式来实现系统同时兼容多python环境的,而是通过其在工作目录中虚拟完整的python环境来实现python多环境并存 2.4.1virtualenv命令用法说明 virtualenv命令语法 virtualenv [options] dest_dir options --version #显示当前版本号 -h,--help #显示帮助信息 -v,--verbose #显示详细信息 -q,--quiet #不现实详细信息 -p PYTHON_EXE,--python=PYTHON_EXE #指定所用的python解析器的版本,比如 --python=python2.5就是使用python2.5版本的解析器创建新的隔离环境,默认使用的时当前系统安装的python解析器(/usr/bin/python) --clear #清空非root用户的安装,并从头开始创建隔离环境 --no-site-packages #令隔离环境不能访问系统全局的site-packages目录 --system-site-packages #令隔离环境可以访问系统全局的site-packages目录 --unzip-setuptools #安装时解压setuptools或distribute --relocatable #重定位某个已存在的隔离环境,使用该选项将修正脚本,并令所有 .pth文件使用相应路径 --distribute #使用distribute代替setuptools,也可以设置环境变量 VIRTUALENV_DISTRIBUTE达到同样效果 --extra-search-dir=SEARCH_DIRS #用于查找setuptools/distribute/pip发布包的目录,可以添加任意数量的 -extra-search-dir路径 --never-dowload #禁止从网上下载任何数据,此时,如果在本地搜索发布包失败,virtualenv就会报错 --prompt==PROMPT #定义隔离环境的命令行前缀 2.4.2virtualenv创建python虚拟环境示例 ⚠️这里提前已经安装好python3.6 1.创建python虚拟工作目录，这里指定使用python3 [root@test1 ~]# virtualenv -p /usr/local/python36/bin/python3 /opt/venv1 2.加载虚拟环境 [root@test2 ~]# source /opt/venv1/bin/activate (venv1) [root@test1 ~]# python Python 3.6.9 (default, Feb 18 2020, 19:47:30) [GCC 4.8.5 20150623 (Red Hat 4.8.5-39)] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> 3.查看当前python环境安装的包 (venv1) [root@test1 ~]# pip3 list Package Version ---------- ------- pip 20.0.2 setuptools 45.2.0 wheel 0.34.2 4.退出虚拟环境 (venv1) [root@test ~]# deactivate [root@test2 ~]# 三、virtualenvwrapper 3.1virtualenvwrapper简介 鉴于virtualenv不便于对虚拟环境集中管理,所以推荐直接使用virtualenvwrapper,virtualenvwrapper提供了一系列命令使得和虚拟环境工作变得便利,它把你所有的虚拟环境都放在一个地方 virtualenvwrapper整体工作过程 1.安装virtualenvwrapper 2.在~/.bashrc文件中指定virtualenvwrapper存放虚拟环境总目录,指定virtualenvwrapper.sh存放位置(find查找) 3.mkvirtualenv命令创建python虚拟环境,-p选项指定不同python版本命令路径 4. workon命令切换不同python虚拟环境 3.2virtualenvwrapper配置过程 3.2.1安装virtualenvwrapper(确保virtualenv已安装) [root@test1 ~]# pip install virtualenvwrapper 3.2.2编辑环境变量 //向~/.bashrc中写入以下内容 [root@test1 ~]# echo \"export WORKON_HOME=/opt/virtualenvwrapper\" >> ~/.bashrc ;echo \"source /usr/bin/virtualenvwrapper.sh\" >> ~/.bashrc 1 export WORKON_HOME=/opt/virtualenvwrapper 2 source /usr/bin/virtualenvwrapper.sh 1：virtualenvwrapper存放虚拟环境目录,这里自定义在/opt/virtualenvwrapper 2：virtrualenvwrapper会安装到python的bin目录下，所以该路径是python安装目录下bin/virtualenvwrapper.sh,本文python安装在了/usr/local/ //使配置生效 [root@test1 ~]# source ~/.bashrc 3.2.3创建虚拟环境 mkvirtualenv //因为在3.2.2中指定了WORKON_HOME=/opt/virtualenvwrapper，所以创建的python虚拟环境都会在这个目录下 root@test1 ~]# mkvirtualenv -p /usr/local/python36/bin/python3 venv1 created virtual environment in 200ms CPython3Posix(dest=/opt/virtualenvwrapper/venv1, clear=False, global=False) with seeder FromAppData pip=latest setuptools=latest wheel=latest app_data_dir=/root/.local/share/virtualenv/seed-v1 via=copy virtualenvwrapper.user_scripts creating /opt/virtualenvwrapper/venv1/bin/predeactivate virtualenvwrapper.user_scripts creating /opt/virtualenvwrapper/venv1/bin/postdeactivate virtualenvwrapper.user_scripts creating /opt/virtualenvwrapper/venv1/bin/preactivate virtualenvwrapper.user_scripts creating /opt/virtualenvwrapper/venv1/bin/postactivate virtualenvwrapper.user_scripts creating /opt/virtualenvwrapper/venv1/bin/get_env_details (venv1) [root@test1 ~]# //查看创建的虚拟环境，venv1就是刚刚创建的虚拟环境 [root@test2 ~]# ls /opt/virtualenvwrapper/ get_env_details postmkproject predeactivate venv1 initialize postmkvirtualenv premkproject postactivate postrmvirtualenv premkvirtualenv postdeactivate preactivate prermvirtualenv 3.2.4切换虚拟环境 //先创建两个虚拟环境，并指定python版本 [root@test1 ~]# mkvirtualenv -p /usr/bin/python py2 [root@test1 ~]# mkvirtualenv -p /usr/local/python36/bin/python3 py3 //切换虚拟环境 [root@test1 ~]# workon py2 (py2) [root@test1 ~]# python -V Python 2.7.5 [root@test1 ~]# workon py3 (py3) [root@test1 ~]# python -V Python 3.6.9 3.2.5其他操作 //查看当前的虚拟环境目录，即通过mkvirtualenv命令创建的venv虚拟环境 [root@test1 ~]# workon py2 py3 //退出虚拟环境 (py3) [root@test1 ~]# deactivate [root@test1 ~]# //删除虚拟环境 [root@test1 ~]# rmvirtualenv py2 Removing py2... 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"python/python安装/centos7.6编译安装python3.6.9.html":{"url":"python/python安装/centos7.6编译安装python3.6.9.html","title":"centos7.6编译安装python3.6","keywords":"","body":"centos7.6编译安装python3.6.9 python各版本下载地址 1.安装依赖包 yum -y install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel libffi-devel gcc gcc-c++ make 2.下载python包 wget https://www.python.org/ftp/python/3.6.9/Python-3.6.9.tar.xz 3.解压缩包并编译安装 tar xf Python-3.6.9.tar.xz && cd Python-3.6.9 ./configure --prefix=/usr/local/python36 --with-ssl make && make install 4.导出python命令环境变量 echo 'PATH=/usr/local/python36/bin:$PATH' >/etc/profile.d/python36.sh && source /etc/profile ⚠️如果把python环境变量写在/etc/profile.d/*.sh，在使用pip3安装的时候可能会报错Caused by SSLError(\"Can't connect to HTTPS URL because the SSL module is not available.\",），但是导入到/etc/profile中就没有问题，不知道怎么解决，并且绝对不是网上说的openssl问题 5.配置pip国内源 mkdir ~/.pip cat >~/.pip/pip.conf pip更新 pip install --upgrade pip 或者 python -m pip install --upgrade pip 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"web/html/1.html5基础知识.html":{"url":"web/html/1.html5基础知识.html","title":"html5基础知识","keywords":"","body":"前端基础 1.基础结构 泡泡吐肥皂o 一级标题 普通文字 1.1 标签写法分类 全封闭标签 xxx 标签属性 xxx xx:属性名 ss:属性值 自封闭标签 1.2 标签分类 块标签(行外标签):独占一行显示 - **h1-h6(标题标签)** - **p(段落标签)** - **br(换行标签)** - **hr(横线标签)** - **div(普通文本标签)** - **ul(无序列表)** - **ol(有序列表)** - **li(列表中用到的标签，列表中的行)** 内联标签(行内标签):不独占一行显示，内联标签只能包含内联标签，不能包含块级标签 img(图片标签) a(超链接标签) span(普通文本标签) 2.head标签 2.1 meta标签 2.2.1 meta 文档字符编码 我的网页 一级标题 2.2.2 meta 页面刷新 世上最牛逼的页面标题 meta页面刷新测试 运行以上代码，浏览器中就会每隔2秒刷新一次 2.2.3 meta 关键字 meta标签可以设置关键字，用于搜索引擎收录和关键字搜索。 世上最牛逼的页面标题 给搜索引擎交钱就会优先显示上述关键字 例如，在百度搜索的html页面中有上述代码中content中的关键字，搜索框中输入关键字就会有返回结果，给搜索引擎交的钱越多，优先级越大，排在前面的概率也就越大 2.2.4 meta 网站描述 meta标签可以设置网站描述信息，用于在搜索引擎搜索时，显示网站基本描述信息。 大保健会所 搜索引擎搜索到 2.2.5 meta 触屏缩放 meta标签可以设置页面是否支持触屏缩放功能，其中各元素的含义如下： width=device-width ，表示宽度按照设备屏幕的宽度。 initial-scale=1.0，初始显示缩放比例。 minimum-scale=0.5，最小缩放比例。 maximum-scale=1.0，最大缩放比例。 user-scalable=yes，是否支持可缩放比例（触屏缩放） 标题 --> 哈哈哈 2.2 link标签 隔壁老王 隔壁王老汉的幸福生活 隔壁老王 隔壁王老汉的幸福生活 3.body标签 3.1 h1-h6 标题标签 一级标题 二级标题 三级标题 四级标题 五级标题 六级标题 隔壁老王 一级标题 二级标题 三级标题 四级标题 五级标题 六级标题 3.2 br 换行标签 隔壁老王 一级标题 3.3 hr 一行横线标签 隔壁老王 一级标题 一级标题 3.3 a 超链接标签 3.3.1 不加href属性，就是普通文本显示 python从入门到放弃 隔壁老王 一级标题 python从入门到放弃 3.3.2 集上href属性，不加值，文字有颜色效果，还有下划线，并且点击后会刷新当前的html页面 python从入门到放弃 隔壁老王 一级标题 python从入门到放弃 3.3.3 加上href属性，并且加上值，点击后会跳转至对应的网址 python短片 隔壁老王 一级标题 python从入门到放弃 3.3.4 锚点 在页面内容进行跳转 描述:标签设置id属性=值(xx) a标签href属性的值写法:href='#xx',点击这个a标签就能跳转到id属性为xx的那个标签所在位置. Title 这是顶部 第一章 开局(链接) 第二章 捡了一只狗(链接) 第三章 给狗洗澡(链接) 第四章 二手洗澡液有毒(链接) 第五章 大结局(链接) 第一章 开局 没干啥好事儿!! 没干啥好事儿!! 没干啥好事儿!! 第二章 捡了一只狗 草丛有动静!! 走过去看看!! 卧槽，是一条狗!! 把狗捡走!! 第三章 给狗洗澡 狗有点脏!!! 需要给狗洗澡!!! 买了一瓶二手洗澡液!!! 开始给狗洗澡!!! 洗完了!!! 第四章 二手洗澡液有毒 给狗洗完澡了!!! 但是身体有点不适!!! 逐渐开始麻木!!! 糟糕，洗澡液有毒!!! 情况不乐观!!! 卧槽，后悔买二手的了!!! 下次再也不买二手的了!!! 第五章 大结局 中毒身亡!!! 中毒身亡!!! 中毒身亡!!! 中毒身亡!!! 返回顶部 3.4 img 图片标签 参数说明 src属性:图片路径 必须写 alt属性:图片加载失败或者正在加载时提示的内容 title属性:鼠标悬浮时显示的内容 不常用,通过css来控制 width:设置宽度 height:设置高度 设置图片大小 Title 一级标题 img中width(设置宽度，单位:像素)，height(设置高度，单位:像素)设置图片大小 设置鼠标悬浮时图片显示的内容 Title 一级标题 3.5 div和span 普通文本标签 div和span默认是没有任何修饰的文本标签，也可以指定样式，但是一般在css中指定 div默认是普通文本 Title div默认是普通文本 div也可以指定文本颜色，一般写在css中 Title div也可以指定文本颜色，一般写在css中 span默认是普通文本 Title span默认是普通文本 span也可以指定文本颜色，一般写在css中 Title span也可以指定文本颜色，一般写在css中 3.6 列表标签 3.6.1 ul 无序标签 Title 篮球 足球 排球 3.6.2 ol 有序标签 Title 篮球 足球 排球 3.6.3 dl 描述列表标签 Title 河北省 邯郸 石家庄 山西省 太原 运城 3.7 table 表格标签 参数说明 id name hobby 1 小明 看电影 2 小洲 打篮球 没有边框的表格 Title id name hobby 1 小明 看电影 2 小洲 打篮球 3 小颖 逛街 加上边框的表格 Title id name hobby 1 小明 看电影 2 小洲 打篮球 3 小颖 逛街 表格合并(rowspan=\"2\") 枞行合并 Title id name hobby 1 小明 看电影 2 小洲 3 小颖 逛街 表格合并(colspan=\"2\") 横列合并 Title id name hobby 1 小明 看电影 2 小洲 打篮球 3 小颖 3.8 input 输入框标签 3.8.1 用户名、密码、登陆、重置、注册 Title 用户名： 密码： 3.8.2 时间日期输入框 Title 3.8.3 文件选择框 Title 3.8.4 纯数字输入框 Title 3.9 select 下拉框标签 3.9.1 单选 Title 北京 上海 广州 深圳 3.9.2 多选 Title 北京 上海 广州 深圳 杭州 青岛 哈尔滨 成都 3.10 textarea 多行文本输入框标签 Title 3.11 form 表单标签 在网站开发的过程中，用户可以使用用户交互相关的标签让用户输入内容，但如果想要再浏览器上把输入的内容提交到后台，则需要 表单 和 提交按钮 。 form标签内置属性 action=\"/xx/\" ，表示表单要提交的地址 method=\"get\"，表示表单的提交方式（get或post） enctype=\"multipart/form-data\"，如果form内部有文件上传，必须加上此设置 #action属性: 指定提交路径,提交到哪里去 #form表单标签会将嵌套在form标签里面的输入框的数据全部提交到指定路径 form内部【用户交互】相关标签必须设置name，不然提交数据后后端无法获取，例如下方的模拟登陆界面中用户名后的input标签中指定name属性 // 提交表单之后，实际上会将表单中的数据构造成一种特殊的结构，发送给后台，类似于： { user:用户输入的姓名, pwd:用户输入的密码, ... } 简单编辑一个模拟登陆的界面 Title 用户名： 密码： 运行上述代码效果如下 接下来编写一个简单的tcp服务端，服务端绑定本机8080端口 from socket import * tcp_server = socket() tcp_server.bind(('127.0.0.1',8080)) tcp_server.listen() while True: conn, client_addr = tcp_server.accept() from_client_msg = conn.recv(1024) print(from_client_msg.decode('utf-8')) conn.send(b'HTTP/1.1 200 ok\\r\\n\\r\\n') # conn.send(b'lai le laodi!') with open('send.html', 'rb') as f: data = f.read() conn.send(data) conn.close() tcp_server.close() tcp服务端用到的给客户端返回的内容send.html文件内容如下 Title 恭喜登陆成功！！！ 运行模拟登陆界面的html文件，随便输入一个用户名和密码，然后点击登陆 因为模拟登陆界面的html代码中指定了访问本地8080端口，因此tcp服务端会返回指定的send.html文件中的内容 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"web/css/2.css基础知识.html":{"url":"web/css/2.css基础知识.html","title":"css3基础知识","keywords":"","body":"css基本知识 1.css样式引入方式 第一种方式 head标签中引入 在body中写的标签在head标签下的style标签中引入样式 Title div{ width: 200px; height: 200px; background-color: greenyellow; } 我是一个div标签 第二种方式 外部css文件引入(常用) /*css代码*/ /*创建一个css文件，在html文件中使用link标签引入*/ div{ /*css注释写法*/ width: 200px; height: 200px; background-color: greenyellow; } Title 我是一个div标签 第三种方式 内联样式，标签中写样式 Title 我是一个div标签 2.css选择器 2.1基本选择器 2.1.1元素选择器 元素选择器写法 标签名称{ css属性:值 } div{ width:100px; } html代码示例 Title div{ width: 200px; height: 200px; background-color: greenyellow; } 我是一个div标签 2.1.2id选择器 Title #d1{ width: 200px; height: 200px; background-color: greenyellow; } 我是一个div标签 2.1.3类选择器 Title .c1{ width: 200px; height: 200px; background-color: greenyellow; } 我是一个div标签 2.2属性选择器 根据自定义属性查找 Title [xx]{ width: 200px; height: 200px; background-color: greenyellow; } 我是第一个div标签 我是第二个div标签 根据自定义属性值查找 Title [xx='x1']{ width: 200px; height: 200px; background-color: greenyellow; } 我是第一个div标签 我是第二个div标签 2.3后代选择器 以下代码中，只有在div标签下的a标签才能生效(有颜色) Title /*只有在div标签下的a标签(多级标签都可以)才能生效*/ div a{ color:orange; /* 字体颜色 */ } 我是div标签的孙子 我是div标签的儿子 我是一个div标签 百度 2.4组合选择器(逗号连接) 必须找到a标签才可以生效 Title #d1 a,#d2 a{ color:orange; } 我是div1 我是div2 我是div3 百度 3.css样式相关 3.1高度、宽度 div1 span1 div{ height: 200px; width: 100px; background-color: pink; } span{ height: 200px; width: 100px; background-color: green; } Title div{ height: 200px; width: 100px; background-color: pink; } span{ height: 200px; width: 100px; background-color: green; } div1 span1 3.2字体相关 Title div{ font-size: 20px; /* 默认字体大小是16px */ color: olivedrab; font-family: '微软雅黑'; /* 字体格式 */ font-weight: 500; /* 字体粗细，100-900，默认是400 */ } 写作日当午， 谁知学生苦。 几本小破书， 一坐一上午。 3.3字体对齐 Title div{ color: #2a8282; /*!*右对齐*!*/ /*text-align: right;*/ /* 水平居中*/ /*text-align: center; */ height: 100px; width: 200px; text-align: left; /*和height高度相同，标签文本垂直居中*/ line-height: 50px; } 只身赴宴鸡毛装！ 都是同学装鸡毛！ 3.4颜色设置 三种方式: 英文单词:red; 十六进制: #ff746d; rgb: rgb(155, 255, 236); ​ 带透明度的: rgba(255, 0, 0,0.3); 单纯的就是颜色透明度 ​ 标签透明度:opacity: 0.3; 0到1的数字,这是整个标签的透明度 rgba是带透明度的，第4个数越小，透明度越高 Title div{ color: rgba(255,0,0,0.3); } 只身赴宴鸡毛装！ 都是同学装鸡毛！ 透明度为0.3 opacity，整个标签的透明度 Title div{ /*单纯的颜色透明度*/ /*color: rgba(255,0,0,0.3);*/ /*整个标签的透明度 */ opacity: 0.3; } 只身赴宴鸡毛装！ 都是同学装鸡毛！ 3.5背景 3.5.1背景图片 Title .c1{ height: 1000px; width: 800px; background-image: url(\"cjk.jpeg\"); } 背景图片，默认会平铺，即设置了样式的高度和宽度，如果图片比设置的小，会继续显示图片的一部分 加参数background-repeat: no-repeat;设置背景图片不平铺 3.5.2背景图片的位置 先截取一个200x200像素的图片，然后背景颜色为600x600像素，效果如下，图片默认的位置是left top center center示例 Title .c1{ height: 600px; width: 600px; background-color: pink; background-image: url(\"200.png\"); background-repeat: no-repeat; /*背景图片居中显示*/ background-position: center center; /* 简写方式 */ background: #ff0000 url(\"200.png\") no-repeat center center; } 3.5.3背景颜色 Title .c1{ height: 200px; width: 200px; background-color: pink; } 200x200像素的背景颜色 3.6边框 border-width 边框宽度 border-style 边框样式(dashed是虚线，solid是实线) border-color 边框颜色 3.6.1对4个边框设置 Title div{ width: 200px; height: 100px; /*边框简写方式,边框粗为1px，solid是实线*/ border: 1px solid red; } 都是同学装鸡毛！ 3.6.2单独对一个边框设置 border-left 左边框 border-right 右边框 border-top 上边框 border-bottom 下边框 Title div{ width: 200px; height: 100px; /*边框简写方式,边框粗为1px，solid是实线*/ border-right: 1px solid red; } 都是同学装鸡毛！ solid 实线边框 **dashed 虚线边框** 3.7盒子模型 盒子模型的各个值 margin: 外边距 距离其他标签或者自己父级标签的距离 padding: 内边距 内容和边框之间的距离 border: 边框 content: 内容部分 设置的width和height 3.7.1内边距 padding Title #d1{ width: 200px; height: 100px; /*边框4像素，实线，红色*/ border: 4px solid red; /*上下6px 左右8px*/ /*padding: 6px 8px;*/ /*上4右2下6左8*/ /*padding: 4px 2px 6px 8px*/ /*左上右下*/ /*padding-left: 200px;*/ /*padding-top: 20px;*/ /*padding-right: 20px;*/ /*padding-bottom: 20px;*/ } 我是一个div标签 原先效果 padding: 4px 2px 6px 80px效果 3.7.2外边距 margin Title .c1{ background-color: red; height: 100px; width: 100px; /*margin-left: -1000px;*/ /*margin: 10px 15px;*/ } .c2{ background-color: green; height: 20px; width: 20px; /*margin: 10px 15px;*/ margin-left: 20px; } 都是同学装鸡毛! 3.8display属性 display的几个值: inline: 将块级标签变成了内联标签 block:将内联标签变成块级标签 inline-block: 同时具备内联标签和块级标签的属性,也就是不独占一行,但是可以设置高度宽度 none: 设置标签隐藏 Title span{ /*display: block;*/ /*display: none;*/ } .c1{ background-color: red; height: 100px; width: 100px; /*display: inline;*/ display: inline-block; /*display: none;*/ } .c2{ background-color: green; height: 100px; width: 100px; } 我是span标签 鹅鹅鹅,曲项向天歌! 拔毛烧开水,铁锅炖大鹅! display:none隐藏标签 3.9浮动 浮动的元素,不独占一行,并且可以设置高度宽度 Title body{ margin: 0; } .c1{ background-color: red; height: 100px; width: 200px; float: left; } .c2{ background-color: brown; height: 100px; width: 200px; float: right; } .c3{ background-color: pink; height: 100px; width: 100%; } 吟诗作对--> 左右浮动效果 粉色标签设置了宽度100%，但是设置左右浮动后会覆盖这个粉色标签，这种现象就是父级标签塌陷(cc是父级标签，左右浮动的c1和c2是儿子标签)，因为左右两边的标签设置了浮动，已经脱离了文档流，所以粉色的标签(和cc同级的c3)会向上顶，正确情况应该为粉色单独占一行 解决父级标签塌陷问题: 方法一 给父级标签加高度，本示例中是给cc加高度 方法二 清除浮动:clear属性，本示例中给c3添加清除浮动，clear:both的意思是本标签的上边不允许有浮动元素 .c3{ background-color: pink; height: 100px; width: 100%; clear: both; } 方式三(常用)伪元素选择器解决 css样式: .clearfix:after{ content: ''; #这里设置个空值，因为是伪元素，所以无法选中，并且占一行，这样就解决了父级标签塌陷的问题 display: block; #将内联标签变成块级标签，占一行 clear: both; } html代码: 吟诗作对--> 解决后的效果 3.10伪元素选择器 Title div{ background-color: pink; height: 100px; width: 200px; } div:after{ content: '我是无法选中的0.0'; color:white; } 这是c2 都是同学装鸡毛! div:after表示找到div标签后的内容且内容无法选中 3.11伪类选择器 3.11.1hover、pointer hover表示当鼠标悬浮时的效果 pointer表示鼠标悬浮时显示小手 Title .c1{ background-color: red; height: 200px; width: 200px; } .c1:hover{ /*background-color: green;*/ background-image: url(\"200.png\"); cursor: pointer; } 3.11.2其他伪类选择器 /* a标签未访问的时候设置效果 */ a:link{ color:yellow; } /* 鼠标悬浮上去时设置效果 */ a:hover{ color:black; } /* 鼠标左键点击下去的还没有抬起来的时候,设置效果 */ a:active{ color:green; } /* 鼠标抬起后,访问过之后设置效果 */ a:visited{ color:purple; } 完整代码 我不适合学前端 a:link { color: #000000; } /* 未访问链接*/ a:visited { color: #00FF00; } /* 已访问链接 */ a:hover { color: #FF00FF; } /* 鼠标移动到链接上 */ a:active { color: #0000FF; } /* 鼠标点击时 */ 这是一个链接 注意： a:hover 必须在 a:link 和 a:visited 之后，需要严格按顺序才能看到效果。 注意： a:active 必须在 a:hover 之后。 3.12文字装饰 Title a{ text-decoration: none; } 来点我！！！ 没有去除超链接下划线前的效果 去除超链接下划线后的效果 3.13定位postion static: 静态定位,也就是标签默认 relative: 相对定位,按照自己原来的位置进行移动 absolute: 绝对定位,按照父级标签或者祖先辈儿标签设置了相对定位的标签位置进行移动,如果没有找到相对定位标签,会找到整个文档的位置进行移动 fixed: 固定定位, 按照浏览器窗口的位置进行移动 固定定位示例 Title body{ margin: 0; } .c1{ background-color: red; height: 1000px; width: 800px; } .c2{ background-color: green; height: 1000px; width: 800px; } .c3{ background-color: blue; height: 1000px; width: 800px; } .s1{ position: fixed; left: 1000px; bottom: 20px; height: 40px; width: 60px; background-color: aqua; line-height: 40px; text-align: center; } .s1 a{ color:white; text-decoration: none; font-size: 12px; } 这是顶部 返回顶部 定位示例 3.14选择器优先级 /* css属性有继承的概念 权重0*/ /* 标签(元素)选择器 权重1*/ /* 类选择器 权重10*/ /* id选择器 权重100*/ /* 内联样式 权重1000*/ /* color:green!important; 无敌! */ /* 如果优先级相同,按照后面的为准 */ 别忘了,class属性的值可以写多个 简单示例 Title .c1{ height: 100px; width: 100px; background-color: red; } #d1{ height: 100px; width: 100px; background-color: greenyellow; } 我是一个div标签 id选择器优先级大于类选择器优先级，所以显示的颜色是d1中的绿黄色 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"web/js/3.js基础.html":{"url":"web/js/3.js基础.html","title":"javaScript基础知识","keywords":"","body":"js基础 1.js简介 -- javascript ECMAscript5 ECMAscript6 -- vue.js react .. 由三个部分组成 1 ECMAscript5的核心 js语言 2 BOM 浏览器对象模型 js操作浏览器,做出对应的一些效果 3 DOM 文档对象模型 -- HTML文件 2.js代码引入方式 三种方式 1.head标签的script标签里面(alert('xx'), confirm('xx')) 2.body标签的script标签里面 3.外部文件引入的方式来使用 3.1创建一个.js结尾的文件,写上咱们的js代码 比如:alert('are you ok?'); 3.2在想使用这个js代码的html文件中,head标签或者body标签下面或者上面写下面的内容 第一种方式 head标签中script标签中写js代码 Title alert('are you ok?') 效果图 第二种方式 body标签中的script标签中写js代码 Title alert('are you ok?') 第三种方式 外部文件引入方式 第一步、先创建一个.js结尾的文件，内容如下 alert('are you ok'); 第二步、html文件中引入这个js文件 Title alert('are you ok?') 3.js变量 定义方式一(在函数中是局部变量，在函数外是全局变量) var 变量名 = 值; 定义方式二(都是全局变量) 变量名 = 值; 4.js注释 单行注释 //单行注释内容 // 改变标题： document.getElementById(\"myH\").innerHTML = \"我的第一张页面\"; // 改变段落： document.getElementById(\"myP\").innerHTML = \"我的第一个段落。\"; 多行注释 / 多行注释内容/ /* 下面的代码会改变 网页中 id = \"myH\" 的标题 以及 id = \"myP\" 的段落： */ document.getElementById(\"myH\").innerHTML = \"我的第一张页面\"; document.getElementById(\"myP\").innerHTML = \"我的第一个段落。\"; 5.js数据类型 5.1number类型(整数,浮点数) var n = 11; var n2 = 11.11; 查看数据类型 typeof 变量名; typeof n; -- number类型 变量声明,但没有赋值的时候,变量的值为undefined 5.2string类型(字符串) 示例: var a = 'abcdef'; typeof a; --> \"string\" var a = new String('s'); typeof a; --> \"object\" 字符串的操作方式 定义一个字符串 var s = '好好学习，天天向上'; 索引取值 s[1] --> '好' 移除空格,不能移除字符串中的空格 s.trim(); #去除两端的空格 s.trimLeft(); #去除左边的空格 s.trimRight(); #去除右边的空格 根据索引获取字符 //语法 var value = name.charAt(index) //示例 var s = 'hello'; s.charAt(4); --> 'o' 根据索引获取子序列(切片) //语法 var values = name.substring(开始位置，结束位置) //示例 var s = 'hello'; s.substring(1,3); --> \"el\" 5.3布尔类型(boolean类型) var a = true; var b = false; typeof a; \"boolean\" js的基础数据类型都有布尔值属性, []--false 0,{},'',undefined,null,NaN 字符串转数字: var a = '11'; parseInt(a); var a = '23abc'; parseInt(a); 23 var a = 'asdfabc'; parseInt(a); -- NAN -- not a number typeof NaN; -- \"number\" NaN === NaN; -- false NaN == NaN; -- false 5.4undefined和null类型 undefined 变量声明了,但是没有赋值,此时这个变量是undefined类型 //示例 var b; b undefined typeof b; \"undefined\" null : 变量不用了,就可以给变量赋值为null,--- object类型 //示例 var b = null; undefined b null typeof b; \"object\" 5.5数组(array) var name = [1,2,3]; //括号中的3表示数组有3个元素 names; (3) [1, 2, 3] //⚠️，数组类型也是字符串 typeof names; \"string\" 5.5.1索引取值，从0开始 //数组a中的元素 names = [1,2,3]; (3) [1, 2, 3] //索引取值，从0开始 names[0]; 1 5.5.2尾部追加元素 //数组a中的元素 names = [1,2,3]; (3) [1, 2, 3] //追加数字 names.push(5); 4 names; (4) [1, 2, 3, 5] //追加字符串 names.push('啊'); 5 names; (5) [1, 2, 3, 5, \"啊\"] 5.5.3尾部移除元素 //数组names中的元素 names; (5) [1, 2, 3, 5, \"啊\"] //移除尾部元素 names.pop(); \"啊\" names; (4) [1, 2, 3, 5] 5.5.4头部插入元素 //数组names中的元素 names; (4) [1, 2, 3, 5] //头部插入元素 names.unshift(9); 5 names; (5) [9, 1, 2, 3, 5] 5.5.5头部移除元素 //数组names中的元素 names; (5) [9, 1, 2, 3, 5] //头部移除元素 names.shift(); 9 names; (4) [1, 2, 3, 5] 5.5.6在指定索引位置插入元素 //语法 names.splice(从哪删(索引),删几个(个数),删除位置替换的新元素(可不写,可写多个)) //数组names中的元素 names = [1,2,3,5,6]; (5) [1, 2, 3, 5, 6] names; (5) [1, 2, 3, 5, 6] //在指定索引位置插入元素，这里其实与删除差不多，只不过是第二个参数删除个数为0，不删除元素，插入元素 names.splice(1,0,'呵呵'); [] names; (6) [1, \"呵呵\", 2, 3, 5, 6] 5.5.7在指定索引位置替换元素 //语法 语法和在指定位置插入元素相同，只不过在指定位置插入元素删除的元素个数为0，而在指定索引位置替换元素是删除元素并替换 names.splice(从哪删(索引),删几个(个数),删除位置替换的新元素(可不写,可写多个)) //数组names中的元素 names; (5) [1, 2, 3, 5, 6] //在指定索引位置替换元素,从索引1开始，删除1个元素，并替换为呵呵 names.splice(1,1,'呵呵'); [2] names; (5) [1, \"呵呵\", 3, 5, 6] 5.5.8在指定索引位置删除元素 //语法 names.splice(从哪删(索引),删几个(个数),删除位置替换的新元素(可不写,可写多个)) //数组names中的元素 names; (5) [1, 2, 3, 5, 6] //示例1，只删除指定索引处的元素，不替换 names.splice(1,3); (3) [2, 3, 5] names; (2) [1, 6] //示例2，删除指定索引处的元素，并替换 names.splice(1,3,'呵呵'); (3) [2, 3, 5] names; (3) [1, \"呵呵\", 6] //示例3，删除指定索引处的元素，并替换多个，看效果 names.splice(1,3,'呵呵','哈哈',666); (3) [2, 3, 5] names; (5) [1, \"呵呵\", \"哈哈\", 666, 6] 5.5.9切片 //语法 names.slice(开始位置,结束位置) //数组names中的元素 names; (5) [1, 2, 3, 5, 6] //从索引1开始到索引3结束，顾头不顾尾 names.slice(1,3); (2) [2, 3] 5.5.10数组反转(会直接修改原数组) //数组names中的元素 names; (5) [1, 2, 3, 5, 6] //原数组反转 names.reverse(); (5) [6, 5, 3, 2, 1] 5.5.11数组元素拼接 //数组names中的元素 names; (5) [1, 2, 3, 5, 6] //将数组元素连接起来以构建一个字符串 names.join('滚'); \"1滚2滚3滚5滚6\" 5.5.12连接数组 //数组a中的元素 a = [1,2,3]; (3) [1, 2, 3] //数组b中的元素 b = ['a','b','c']; (3) [\"a\", \"b\", \"c\"] //连接数组a和b a.concat(b); (6) [1, 2, 3, \"a\", \"b\", \"c\"] 5.5.13对原数组进行排序 //数组a中的元素 a = [11,32,2,66,7]; (5) [11, 32, 2, 66, 7] //对原数组进行排序，发现结果并不是正确的，排序并没有按照数字大小进行排序，而是按照数字的第一个数字进行大小排序的 a.sort(); (5) [11, 2, 32, 66, 7] 因此，为了解决上述排序问题，需要自己定义规则 //定义一个函数，使用冒泡排序法进行排序才能得到正确结果 function compare(a,b){ return a - b; /* 当a-b大于0时，两个数互换位置*/ } a.sort(compare); /* a-b是升序排序 */ (5) [2, 7, 11, 32, 66] //倒叙排序 function compare(a,b){ return b - a; } a.sort(compare); (5) [66, 32, 11, 7, 2] 5.6自定义对象(相当于python的中的dict) // 声明一个对象 info = { name:'小明', 'age:18 } info {name: '小明', age: 18} //查看数据类型 typeof info; \"object\" //常用方法 //获取值，通过键获取值必须加引号 info['name']; \"小明\" info.name; \"小明\" //修改值 info.age = 22; 22 info; {name: \"小明\", age: 22} //新增值 info['gender'] = 'man'; \"man\" info; {name: \"小明\", age: 22, gender: \"man\"} //删除值 delete info['age']; true info; {name: \"小明\"} 6.运算符 6.1判断运算符 > = 6.2算术运算符 + - * / % ++ -- ++ 自增 1 -- 自减 1 var a = 2; a++ 先执行逻辑 在+1 ++a 先+1 在执行逻辑 简单示例: if (++a === 4){ console.log('xxx'); } else{ console.log('ooo'); }; 结果： 000 7.流程控制语句 7.1判断语句 7.1.1 if语句 单条件 if (a == 1){ //判断条件写在小括号里面,大括号里面写条件判断成功后的代码内容 console.log('1111'); } else{ console.log('222'); }; 多条件 var a = 0; if(a > 1){ console.log('0'); //浏览器显示结果 //var h = document.getElementById('d1'); //h.innerText = '小明'; }else if(a 7.1.2switch语句 //num只能是数字,case判断的只能是数字 var num = 50; switch(num++){ case 10: console.log('未成年'); break; case 18: console.log('成年'); break; case 35: console.log('大叔'); break; case 40: console.log('中年了'); break; default: console.log('没有前途。。。'); }; 7.2循环语句 7.2.1for循环 //普通循环 for (var i=0;i 7.2.2while循环 var a = 0; while(a 8.函数 8.1普通函数 //定义一个普通函数 function f1(a,b){ return a+b; } 执行: f1(1,2) --> 3 //此写法不能返回多个值 function f1(a,b){ return a,b; }; f1(1,2); 不能返回多个值: --> 2 //返回多个值 function f1(a,b){ return [a,b]; }; f1(1,2); (2) [1, 2] 8.2匿名函数 ⚠️⚠️⚠️匿名函数必须赋值给一个变量，否则会报错 //定义一个匿名函数 var a = function(a,b,c){ return a+b+c; } a(1,2,3) 6 //匿名函数还可以当作自定义对象的值 var d = { 'a':'b','f':function(a,b){ return a+b; } }; d.f(1,2); 3 8.3自执行函数 (function () { alert('自执行函数!') })() 9.序列化 //序列化 JSON.stringify，相当于python中的json.dumps，序列化后会变成json格式，全部替换为双引号 var d = {'a':'aa','b':'bb'}; undefined var d_json = JSON.stringify(d); undefined d_json \"{\"a\":\"aa\",\"b\":\"bb\"}\" //反序列化 JSON.parse d_json \"{\"a\":\"aa\",\"b\":\"bb\"}\" var reverse_json = JSON.parse(d_json); reverse_json {a: \"aa\", b: \"bb\"} 10.BOM对象 浏览器对象模型 10.1弹框 alert('are you ok?'); confirm('are you sure?') alert弹框(只有确定) confirm弹框(有确定和取消) 10.2location对象 //获取当前页面的地址 location.href; \"https://www.baidu.com/\" //跳转到这个网址上 location.href = 'http://www.baidu.com'; //刷新当前页面 location.reload(); 10.3计时器 10.3.1 一段时间后执行某个任务 //写法一 1000是毫秒，1秒后打印呵呵 var t = setTimeout(\"console.log('呵呵')\",1000); //t就是浏览器用来记录你的计时器的标识数字 t 2810 //清除计时器 clearTimeout(t) //写法二 常配合匿名函数使用，5秒后弹框 var t = setTimeout(function(){confirm('你满18岁了吗?')},5000); 10.3.2 每隔一段时间执行某个任务 var t = setInterval(function(){confirm('弹个框!!')},3000); //清除计时器 clearInterval(t); 11.DOM对象 html文档 11.1直接查找选择器 html代码: css代码: .c1{ background-color: green; height: 100px; width: 100px; } .c2{ background-color: red; /*height: 100px;*/ /*width: 100px;*/ color:red; } //按标签名查找: var divEle = document.getElementsByTagName('div'); divEle HTMLCollection(2) [div#d1.c1, div#d2.c1.c2, d1: div#d1.c1, d2: div#d2.c1.c2] //按id值查找: var d1 = document.getElementById('d1'); 示例: d1.style.height = '600px'; 上述操作会将id为d1的标签高度变为600px //按类值查找:var a = document.getElementsByClassName('c1'); a HTMLCollection(2) [div#d1.c1, div#d2.c1.c2, d1: div#d1.c1, d2: div#d2.c1.c2] 11.2间接查找选择器 html文件内容 Title .c1{ border: 1px solid red; height: 100px; width: 100px; } 京东a 百度span div3 修改边框颜色 div1.style.borderColor=\"green\"; div1.nextElementSibling.style.color = 'blue'; 找下一个兄弟标签,并改成蓝色 var div1 = document.getElementsByClassName('c1')[0]; div1.nextElementSibling.style.color = 'blue'; 找下一个兄弟标签,并改了色 div1.previousElementSibling; 找上一个兄弟 div1.firstElementChild; 找第一个儿子 div1.lastElementChild; 找最后一个儿子 div1.children; 找所有儿子,是一个数组 div1.parentElement; 找到自己的父级标签 11.3文本操作 html文件内容 Title .c1{ border: 1px solid red; height: 100px; width: 100px; } 京东a 百度span div3 innerText获取文本: var a = document.getElementById('jd'); a.innerText; 只获取文本内容 innerText设置文本: a.innerText = '呵呵';不能识别标签,单纯的文本内容显示 innerHTML获取文本 var d = document.getElementsByClassName('c1')[0]; d.innerHTML; 获取的内容包含标签 innerHTML设置文本 var d = document.getElementsByClassName('c1')[0]; d.innerHTML = '呵呵'能够识别标签,生成标签效果 //innerText 获取文本: var a = document.getElementById('jd'); a.innerText; 只获取文本内容 设置文本: a.innerText = '呵呵';不能识别标签,单纯的文本内容显示 //innerHTML 获取文本 var d = document.getElementsByClassName('c1')[0]; d.innerHTML; 获取的内容包含标签 设置文本: d.innerHTML = '呵呵'; 能够识别标签,生成标签效果 11.4value值操作 html文件 Title .c1{ border: 1px solid red; height: 100px; width: 100px; } 京东a 百度span div3 找到标签 var inp = document.getElementById('username'); 获取值 inp.value 修改值 inp.value = '哈哈!'; 示例: var inp = document.getElementById('username'); 找到标签 inp.value; 获取值 inp.value = '200块!'; 修改值 使用示例 闪烁效果 html文件 Title .c1{ height: 100px; width: 100px; background-color: red; } .c2{ height: 100px; width: 100px; background-color: green; } js代码 var div1 = document.getElementById('d1'); 找到c2就删除，没有则动态添加，因此动态显示 var t = setInterval(\"div1.classList.toggle('c2')\",100); 用户登陆输入为空触发事件 Title 用户名: 密码: --> 注册 var btnEle = document.getElementById('btn'); btnEle.onclick = function () { var unameEle = document.getElementById('username'); var uname = unameEle.value; var pwdEle = document.getElementById('password'); var pwd = pwdEle.value; if (uname.trim().length === 0){ unameEle.nextElementSibling.innerHTML = '用户名不能为空!'; }else if(pwd.trim().length === 0){ unameEle.nextElementSibling.innerHTML = ''; pwdEle.nextElementSibling.innerHTML = '密码不能为空!'; }else { document.getElementById('ss').innerText = '登录成功!'; unameEle.nextElementSibling.innerHTML=''; pwdEle.nextElementSibling.innerHTML = ''; } } 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"mac使用记录/MAC本添加多个github账号.html":{"url":"mac使用记录/MAC本添加多个github账号.html","title":"mac添加多个github账号","keywords":"","body":"MAC本添加多个github账号 使用需求 通常情况下，我们会有两个 github 账号：一个是公司的，另一个是私人的。由于 github 是使用 SSH key 的 fingerprint (对应的公钥id_rsa_pub)来判定你是哪个账户，而不是通过用户名，如果是在多台电脑上使用一个账号，可以为该账号添加多个 SSH key，如果是一台电脑使用多个账号，则分别生成多个 SSH key 添加到对应的账户即可。所以本文要实现的是公号和私号在 git 上同时使用，两者互不干扰。 第一步、生成多个sshkey cd ~/.ssh切换到用户家目录，然后生成sshkey，执行以下命令，一路回车即可 ssh-keygen -t rsa -f ~/.ssh/id_rsa_one -C \"one@xxx.com\" ssh-keygen -t rsa -f ~/.ssh/id_rsa_two -C \"two@xxx.com\" 这样会在~/.ssh目录下生成四个文件： id_rsa.one //账号one的私钥 id_rsa.one.pub //账号one的公钥 id_rsa.two //账号two的私钥 id_rsa.two.pub //账号two的公钥 第二步、创建配置文件config 在 ~/.ssh目录下新建 config 文件，令不同 Host 实际映射到同一 HostName，但密钥文件不同，这里举例为one和two，可自行修改为自己使用的用户 # one (first account) Host one.github.com HostName github.com PreferredAuthentications publickey User one IdentityFile ~/.ssh/id_rsa_one # two(second account) Host two.github.com HostName github.com PreferredAuthentications publickey User two IdentityFile ~/.ssh/id_rsa_two 第三步、github添加sshkey及测试 分别登陆两个 github 账号，在 Settings —> SSH and GPG keys 中，点击 “new SSH key”，把 “id_rsa.one.pub” 和 \"id_rsa.two.pub\"这两个公钥的内容分别添加到相应的账号中。 为了确认我们可以通过 SSH 连接 github，可通过输入下面命令来验证 //执行以下命令测试 ssh -T git@one.github.com //返回结果如下说明添加成功 Hi one! You've successfully authenticated, but GitHub does not provide shell access. 第四步、配置git信息 因为一台电脑上配置了多个 github 账号，所以就不能再配置全局的用户名和邮箱了，而是在不同的仓库下，如果需要连接不同的 git 账号，配置相应的局部用户名和邮箱即可，如果之前配置过全局的用户名和邮箱，需要取消配置 //取消之前的全局配置 git config --global --unset user.name git config --global --unset user.email //设置局部用户名和邮箱 git config --local user.name \"xx\" git config --local user.email \"xx@xx.com\" 第五步、使用git git的使用一般是从其他仓库直接clone或本地新建仓库 方式一：clone仓库到本地 原先写法 git clone git@github.com:用户名/仓库.git 现在的写法 //这里距离了one用户的写法，two用户的操作一样 git clone git@one.github.com:one的用户名/仓库.git 如果需要重建origin //清空原有的 git remote rm origin //使用ssh方式添加远程仓库 git remote add origin git@one.github.com:one/仓库名.git ⚠️⚠️⚠️这里有个坑，添加远程仓库时，从github仓库的Clone or download下的Use SSH复制的路径需要修改 ⚠️⚠️⚠️这里需要注意的是，使用ssh方式添加远程仓库原先写法是这样的 git@github.com:one/仓库名.git 现在需要修改为如下写法 it remote add origin git@one.github.com:one/仓库名.git 方式二、推送本地仓库 //初始化本地仓库 git init //创建一个文件并提交到本地仓库 touch test git add . git commit -m \"first commit\" //push到github上去 git remote add origin git@one.github.com:one/仓库名.git git push origin master 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"mac使用记录/mac使用gitbook记录.html":{"url":"mac使用记录/mac使用gitbook记录.html","title":"mac使用gitbook记录","keywords":"","body":"mac使用gitbook记录 1.gitbook搭建 1.1安装node.js 官网下载mac版本的node.js 1.2检测node.js是否安装成功 npm -v 6.12.1 1.3安装gitboot和命令行工具(-g 代表全局安装) //安装 sudo npm install -g gitbook sudo npm install -g gitbook-cli //查看版本 gitbook -V CLI version: 2.3.2 GitBook version: 3.2.3 //更新gitbook命令行工具 sudo npm update gitbook-cli -g //卸载gitbook命令 sudo npm uninstall gitbook-cli -g 2.gitbook的使用 2.1创建gitbook目录 //创建gitbook目录 sudo mkdir /gitbook //初始化gitbook cd /gitbook && sudo gitbook init //初始化完成后会生成两个文件 README.md #项目介绍文件 SUMMARY.md #gitbook目录结构 2.2配置gitbook生成书籍 1.编辑SUMMARY.md，写入以下内容(这里仅做示例) # Summary * [Linux](README.md) * [Linux基础](README.md) * [Linux命令](README.md) * [vim命令](README.md) * [vim命令](linux/linux命令/vim命令.md) ⚠️vim命令.md的路径是/gitbook/linux/linux命令 2.构建书籍(⚠️构建命令必须在SUMMARY.md同路径下) sudo gitbook build 3.启动gitbook sudo gitbook serve & gitbook默认监听4000端口 启动gitbook报错 //gitbook serve启动gitbook报错如下 Error: ENOENT: no such file or directory, stat '/gitbook/_book/gitbook/gitbook-plugin-livereload/plugin.js',Error: ENOENT: no such file or directory, stat '/gitbook/_book/gitbook/gitbook-plugin-livereload' //解决方法 找到copyPluginAssets.js文件，全部替换 将 confirm: true 改为 confirm: false /Users/baixuebing/.gitbook/versions/3.2.3/lib/output/website/copyPluginAssets.js 3.修改gitbook代码框字体大小 prismnode_modules/themes/themes/prism-base16-ateliersulphurpool.light.css 13、14行 font-size: 18px; line-height: 1.6; 4.设置gitbook开机自启 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"mac使用记录/brew替换国内源.html":{"url":"mac使用记录/brew替换国内源.html","title":"brew替换国内源","keywords":"","body":"brew替换国内源 //替换brew.git: cd \"$(brew --repo)\" #中国科大: git remote set-url origin https://mirrors.ustc.edu.cn/brew.git #清华大学: git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.git //替换homebrew-core.git: cd \"$(brew --repo)/Library/Taps/homebrew/homebrew-core\" #中国科大: git remote set-url origin https://mirrors.ustc.edu.cn/homebrew-core.git #清华大学: git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git //替换homebrew-bottles: #中国科大: echo 'export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.ustc.edu.cn/homebrew-bottles' >> ~/.bash_profile source ~/.bash_profile #清华大学: echo 'export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.tuna.tsinghua.edu.cn/homebrew-bottles' >> ~/.bash_profile source ~/.bash_profile #应用生效: brew update 重置brew #重置brew.git: cd \"$(brew --repo)\" git remote set-url origin https://github.com/Homebrew/brew.git #重置homebrew-core.git: cd \"$(brew --repo)/Library/Taps/homebrew/homebrew-core\" git remote set-url origin https://github.com/Homebrew/homebrew-core.git 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"git总结/git初次使用简单记录.html":{"url":"git总结/git初次使用简单记录.html","title":"git初次使用记录","keywords":"","body":"1.git初次使用 第一步、初次使用需要进行全局配置 操作命令 git config --global user.name \"你的用户名\" git config --global user.email \"邮箱\" 第二步、git本地仓库初始化 安装完git后，需要进入到存放代码的目录下，进行初始化(如果再次创建了一个目录，则需要重新初始化) 初始化命令 git init 初始化完成后，会在当前路径下生成一个.git目录 ls -a . .. .git .idea test.py 第三步、提交代码至本地仓库 初始化git仓库完成后，需要将代码目录下的内容提交至本地仓库 git add . #.表示匹配当前代码路径下所有内容 第四步、告知本地仓库提交的内容信息 将代码路径下的内容提交至本地仓库后，需要告知提交至本地仓库的内容信息 git commit -m \"提交的信息内容\" 第五步、与远程仓库建立连接 将代码目录下的文件提交至本地仓库后，需要与远程仓库建立连接从而将本地仓库中的内容提交至远程仓库 git remote add origin 远程仓库地址 第六步、将本地代码仓库文件推送至远程仓库 与远程仓库建立连接后，需要将本地仓库中的文件推送至远程仓库 git push -u origin master #输入远程仓库的用户名和密码即可 2.git非初次使用 第一步、提交代码至本地仓库 初始化git仓库完成后，需要将代码目录下的内容提交至本地仓库 git add . #.表示匹配当前代码路径下所有内容 第二步、告知本地仓库提交的内容信息 将代码路径下的内容提交至本地仓库后，需要告知提交至本地仓库的内容信息 git commit -m \"提交的信息内容\" 第三步、将本地代码仓库文件推送至远程仓库 与远程仓库建立连接后，需要将本地仓库中的文件推送至远程仓库 git push -u origin master #输入远程仓库的用户名和密码即可 3.关于git拉取代码冲突问题 3.1 遵守原则 不删除远程仓库的代码 如需删除代码，则只删除本地的 3.2手贱删除远程仓库文件导致代码冲突恢复演示 3.2.1 远程代码仓库中有以下内容，此时远程仓库和本地仓库中的内容相同 3.2.2 手动删除远程仓库中的test文件，删除后内容为下 3.2.3 手动删除远程仓库文件后，远程仓库和本地仓库中的内容就不同了，此时再次新建文件提交就会有冲突 本地仓库中新建文件test111，尝试提交，报错 解决方法 3.2.4 先拉取代码 git pull origin master 输入拉取代码的命令后会提示如下，意思为请输入一条提交消息来解释为什么需要合并，这里可以选择不输入 3.2.5 加选项 --allow-unrelated-histories (允许合并不相关的历史记录)再次拉取 git pull origin master --allow-unrelated-histories 3.2.6 再次提交代码即可,不会报错 ⚠️因为已经删除了远程仓库中的目录，因此本地的目录在提交之后也会被删除 因此,不要删除远程仓库中的文件！！！ git push origin master 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"git总结/git新建仓库后运行指令说明.html":{"url":"git总结/git新建仓库后运行指令说明.html","title":"git新建仓库后运行指令说明","keywords":"","body":"Command line instructions（命令行指令） You can also upload existing files from your computer using the instructions below.（您还可以使用下面的说明从您的计算机上载现有文件） Git global setup（git全局配置） git config --global user.name \"Administrator\" git config --global user.email \"admin@example.com\" git本地配置 git config --local user.name \"你的名字\" git config --local user.email \"邮箱\" Create a new repository（创建一个新的仓库） git clone http://gitlab.example.com/root/python-exercise.git cd python-exercise touch README.md git add README.md git commit -m \"add README\" git push -u origin master Push an existing folder（推送现有文件夹） cd existing_folder git init git remote add origin http://gitlab.example.com/root/python-exercise.git git add . git commit -m \"Initial commit\" git push -u origin master Push an existing Git repository（推送现有git仓库） cd existing_repo git remote rename origin old-origin git remote add origin http://gitlab.example.com/root/python-exercise.git git push -u origin --all git push -u origin --tags 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"git总结/git命令总结.html":{"url":"git总结/git命令总结.html","title":"git命令总结","keywords":"","body":"一、git简介 1.1git工作流程 1.2git四种状态 二、git命令总结 2.1git工作区域及文件颜色 git status 文件三种颜色的变化 红色 新增文件或者修改的旧文件-->执行命令git add .或者git add 文件名 绿色 git已经管理起来的文件-->执行命令git commit -m '描述信息' 白色 已经生成版本的文件 2.2git提交数据 1.创建文件 [root@test1 test]# touch aaa bbb 2.查看git文件状态（此时文件是红色的，属于新增文件） [root@test1 test]# git status On branch master Untracked files: (use \"git add ...\" to include in what will be committed) aaa bbb nothing added to commit but untracked files present (use \"git add\" to track) 3.提交文件至暂存区 [root@test1 test]# git add . //此时再查看文件，文件是绿色的，已被git管理起来 [root@test1 test]# git status On branch master Changes to be committed: (use \"git restore --staged ...\" to unstage) new file: aaa new file: bbb 2.3git删除数据 2.3.1git删除暂存区中的文件git rm --cached //git删除暂存区中的文件 [root@test1 test]# git rm --cached aaa bbb rm 'aaa' rm 'bbb' //此时文件变回红色 [root@test1 test]# git status On branch master Untracked files: (use \"git add ...\" to include in what will be committed) aaa bbb nothing added to commit but untracked files present (use \"git add\" to track) 2.3.2git删除工作区和暂存区中的文件git rm -f 文件名 //查看暂存区中的文件，此时是绿色的 [root@test1 test]# git status On branch master Changes to be committed: (use \"git restore --staged ...\" to unstage) new file: aaa new file: bbb //删除工作区的文件同时暂存区中的文件也会同时被删除 [root@test1 test]# git rm -f aaa bbb rm 'aaa' rm 'bbb' [root@test1 test]# ls [root@test1 test]# git status On branch master nothing to commit, working tree clean 2.4git移动数据 2.4.1git提交数据至版本库git commit -m '描述信息' //创建文件 [root@test1 test]# touch aaa bbb //提交文件至暂存区 [root@test1 test]# git add . //此时文件是绿色的 [root@test1 test]# git status On branch master Changes to be committed: (use \"git restore --staged ...\" to unstage) new file: aaa new file: bbb //提交文件至版本库 [root@test1 test]# git commit -m 'touch aaa bbb' [master 7215e51] touch aaa bbb 2 files changed, 0 insertions(+), 0 deletions(-) create mode 100644 aaa create mode 100644 bbb //此时再查看文件暂存区中已经没有了，已经被git管理起来了 [root@test1 test]# git status On branch master nothing to commit, working tree clean 2.4.2git移动数据，有时会将已经添加至暂存区的文件重命名git mv 原文件 新文件 //此时文件是绿色的 [root@test1 test]# git status On branch master Changes to be committed: (use \"git restore --staged ...\" to unstage) new file: aaa new file: bbb //现在想把暂存区中的文件aaa修改为AAA root@test1 test]# git mv aaa AAA [root@test1 test]# git status On branch master Changes to be committed: (use \"git restore --staged ...\" to unstage) new file: AAA new file: bbb //提交文件至git版本库 [root@test1 test]# git commit -m 'change file aaa->AAA' [master 7de2d02] change file aaa->AAA 2 files changed, 0 insertions(+), 0 deletions(-) create mode 100644 AAA create mode 100644 bbb 2.5git历史数据 2.5.1git查看历史数据git log //查看全部日志 [root@test1 test]# git log commit 7de2d02e662b1c47cb23085240860bf6a8d0d800 (HEAD -> master) Author: 什么都不会 Date: Sun Feb 23 21:10:03 2020 +0800 change file aaa->AAA commit b32661c0627eb5cdac793c3e80bcc89f3d40a13d (origin/master) Author: 什么都不会 Date: Sun Feb 23 20:00:47 2020 +0800 清空文件 commit 61acb78adac52288805ab59992e9c260866186f0 Author: 什么都不会 Date: Sat Feb 22 22:16:24 2020 +0800 忽略文件测试 。。。。。。。。。 //指定显示日志个数 [root@test1 test]# git log -n 1 commit 7de2d02e662b1c47cb23085240860bf6a8d0d800 (HEAD -> master) Author: 什么都不会 Date: Sun Feb 23 21:10:03 2020 +0800 change file aaa->AAA 2.5.2git以一行的形式查看日志git log --oneline //但是没有时间显示 [root@test1 test]# git log --oneline 7de2d02 (HEAD -> master) change file aaa->AAA b32661c (origin/master) 清空文件 61acb78 忽略文件测试 4901535 忽略文件测试 1b7cabd 提交忽略文件 a32513a (bug) master清空测试文件 42f05ec 文件内容就是文件名 d66565f caonima 4ae41d2 提交haha hehe test c266f9e touch hehe 7e353d7 增加test文件内容 9f30440 touch test //更长显示commit号 [root@test1 test]# git log --pretty=oneline 7de2d02e662b1c47cb23085240860bf6a8d0d800 (HEAD -> master) change file aaa->AAA b32661c0627eb5cdac793c3e80bcc89f3d40a13d (origin/master) 清空文件 61acb78adac52288805ab59992e9c260866186f0 忽略文件测试 49015353f48daf06f8e14c8d11f692eae795caa1 忽略文件测试 1b7cabd3ee779d68da6cf07241bd8a8dc1542ad4 提交忽略文件 a32513a471688ba24dff4851ce7b2100314c5497 (bug) master清空测试文件 42f05ec321aa987ecf5da2fc303ead235bd59822 文件内容就是文件名 d66565f107148d0827bbed931616a5f21b9bc581 caonima 4ae41d2706308d05fae5ef2183e7f6933bd955e0 提交haha hehe test c266f9ebd1d9bdac4fe8ce265484cf1c58ca6c68 touch hehe 7e353d71a408ec7414e42cbd51b39f208a16d618 增加test文件内容 9f30440387a13fec21d0de2e0e55ce12e32cd5ae touch test 2.5.3显示具体内容变化git log -p [root@test1 test]# git log -p commit 7de2d02e662b1c47cb23085240860bf6a8d0d800 (HEAD -> master) Author: 什么都不会 Date: Sun Feb 23 21:10:03 2020 +0800 change file aaa->AAA diff --git a/AAA b/AAA new file mode 100644 index 0000000..e69de29 diff --git a/bbb b/bbb new file mode 100644 index 0000000..e69de29 。。。。。。 2.5.4简要显示文件修改行数git log --stat [root@test1 test]# git log --stat commit 7de2d02e662b1c47cb23085240860bf6a8d0d800 (HEAD -> master) Author: 什么都不会 Date: Sun Feb 23 21:10:03 2020 +0800 change file aaa->AAA AAA | 0 bbb | 0 2 files changed, 0 insertions(+), 0 deletions(-) 。。。。。。 2.5.5根据不同格式展示历史提交信息git hlog 可以使用format参数来指定具体的输出格式，这样非常便于后期编程的提取分析，常用的格式有： %s 提交说明 %cd 提交日期 %an 作者的名字 %cn 提交者的姓名 %ce 提交者的电子邮件 %H 提交对象的完整SHA-1哈希字串 %h 提交对象的简短SHA-1哈希字串 %T 树对象的完整SHA-1哈希字串 %t 树对象的简短SHA-1哈希字串 %P 父对象的完整SHA-1哈希字串 %p 父对象的简短SHA-1哈希字串 %ad 作者的修订时间 [root@test1 test]# git log --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr)%Creset %cn\"' --abbrev-commit --date=relative * 7de2d02 - (HEAD -> master) change file aaa->AAA (73 minutes ago) 什么都不会\" * b32661c - (origin/master) 清空文件 (2 hours ago) 什么都不会\" * 61acb78 - 忽略文件测试 (24 hours ago) 什么都不会\" * 4901535 - 忽略文件测试 (24 hours ago) 什么都不会\" * 1b7cabd - 提交忽略文件 (24 hours ago) 什么都不会\" * a32513a - (bug) master清空测试文件 (24 hours ago) 什么都不会\" * 42f05ec - 文件内容就是文件名 (25 hours ago) 什么都不会\" * d66565f - caonima (25 hours ago) 什么都不会\" * 4ae41d2 - 提交haha hehe test (25 hours ago) 什么都不会\" * c266f9e - touch hehe (25 hours ago) 什么都不会\" * 7e353d7 - 增加test文件内容 (27 hours ago) 什么都不会\" * 9f30440 - touch test (28 hours ago) 什么都不会\" //设置命令别名，用git hlog代替以上复杂命令 cat >>.git/config 2.6git恢复数据 2.6.1恢复历史数据 情况一：修改了本地目录的文件并且提交到了暂存区 1.示例文件aaa原先内容 [root@test1 test]# [root@test1 test]# cat aaa aaa 2.提交文件aaa至暂存区 [root@test1 test]# git add aaa //此时文件是绿色，已提交至暂存区 [root@test1 test]# git status On branch master Changes to be committed: (use \"git restore --staged ...\" to unstage) new file: aaa 3.修改文件内容 [root@test1 test]# echo test >>aaa [root@test1 test]# cat aaa aaa test 4.查看文件状态 [root@test1 test]# git status On branch master Changes to be committed: (use \"git restore --staged ...\" to unstage) new file: aaa Changes not staged for commit: (use \"git add ...\" to update what will be committed) (use \"git restore ...\" to discard changes in working directory) modified: aaa 5.从暂存区覆盖本地目录文件 [root@test1 test]# git checkout -- aaa [root@test1 test]# git status On branch master Changes to be committed: (use \"git restore --staged ...\" to unstage) new file: aaa 6.查看文件，此时文件已经恢复至原先内容 [root@test1 test]# cat aaa aaa 情况二：修改了工作目录文件后提交到了暂存区和本地仓库 1.创建文件bbb [root@test1 test]# touch bbb 2.查看文件状态，此时文件是红色的，还没有提交到暂存区 [root@test1 test]# git status On branch master Untracked files: (use \"git add ...\" to include in what will be committed) bbb nothing added to commit but untracked files present (use \"git add\" to track) 3.往文件bbb中写入内容 [root@test1 test]# echo bbb>bbb [root@test1 test]# cat bbb bbb 4.提交文件bbb至暂存区 [root@test1 test]# git add bbb 5.查看文件状态，此时文件是绿色的 [root@test1 test]# git status On branch master Changes to be committed: (use \"git restore --staged ...\" to unstage) new file: bbb 6.提交文件bbb至本地仓库 [root@test1 test]# git commit -m 'bbb' [master 1dbe8c2] bbb 1 file changed, 1 insertion(+) create mode 100644 bbb 7.查看文件状态，此时暂存区中的文件已经提交到本地仓库了 [root@test1 test]# git status On branch master nothing to commit, working tree clean 8.再次往文件bbb中追加内容，多次追加并提交 第一次，追加内容1到文件中，并提交至暂存区和本地仓库 [root@test1 test]# echo 1 >> bbb [root@test1 test]# cat bbb bbb 1 [root@test1 test]# git add . [root@test1 test]# git commit -m 'echo 1 >> bbb' [master 65d12a7] echo 1 >> bbb 1 file changed, 1 insertion(+) 第二次，追加内容2到文件中，并提交至暂存区和本地仓库 [root@test1 test]# echo 2 >> bbb [root@test1 test]# cat bbb bbb 1 2 [root@test1 test]# git add . [root@test1 test]# git commit -m 'echo 2 >> bbb' [master da5695e] echo 2 >> bbb 1 file changed, 1 insertion(+) 9.此时文件bbb内容如下 [root@test1 test]# cat bbb bbb 1 2 //暂存区中没有内容 [root@test1 test]# git status On branch master nothing to commit, working tree clean 10.查看日志 [root@test1 test]# git log --oneline da5695e (HEAD -> master) echo 2 >> bbb 65d12a7 echo 1 >> bbb 1dbe8c2 bbb 。。。。。。 11.恢复文件内容只有bbb [root@test1 test]# git reset --hard 1dbe8c2 HEAD is now at 1dbe8c2 bbb [root@test1 test]# cat bbb bbb 12.恢复文件内容只有bbb和1 [root@test1 test]# git reset --hard 65d12a7 HEAD is now at 65d12a7 echo 1 >> bbb [root@test1 test]# cat bbb bbb 1 #恢复至一个版本后，通过git log命令查看到的日志就只截止到当前版本，下一个版本的不会记录，因此，如果需要查看全部日志记录，需要用到命令git reflog，此时就可以根据git reflog恢复至任意版本了 [root@test1 test]# git reflog 65d12a7 (HEAD -> master) HEAD@{0}: reset: moving to 65d12a7 1dbe8c2 HEAD@{1}: reset: moving to 1dbe8c2 da5695e HEAD@{2}: commit: echo 2 >> bbb 65d12a7 (HEAD -> master) HEAD@{3}: commit: echo 1 >> bbb 1dbe8c2 HEAD@{4}: commit: bbb git reflog查看全部日志记录 git恢复版本说明 git服务程序中有一个叫做HEAD的版本指针，当用户申请还原数据时，其实就是将HEAD指针指向到某个特定的提交版本，但是因为git是分布式版本控制系统，为了避免历史记录冲突，故使用了SHA-1计算出十六进制的哈希字串来区分每个提交版本，另外默认的HEAD版本指针会指向到最近的一次提交版本记录 git恢复版本重点 1.查看日志，获取对应的操作HEAD指针 2.根据获取到的HEAD指针然后进行 git reset --hard 指针编号 2.7git分支 2.7.1git分支命令总结 创建分支 git branch 分支名 切换分支 git checkout 分支名 列出分支 git branch 删除分支 git branch -d 分支名 合并分支 git merge 分支名 创建并切换分支 git checkout -b 分支名(创建分支的同时切换到这个分支) 2.7.2git分支合并 //master分支创建文件并写入内容 [root@test1 test]# echo 'master分支创建的内容' > txt [root@test1 test]# git add . [root@test1 test]# git commit -m 'master分支创建的内容' //创建切换到dev分支并写入内容 [root@test1 test]# git checkout -b dev Switched to a new branch 'dev' [root@test1 test]# git branch * dev master [root@test1 test]# cat txt master分支创建的内容 [root@test1 test]# echo 'dev分支创建的内容' >> txt [root@test1 test]# cat txt master分支创建的内容 dev分支创建的内容 [root@test1 test]# git add . [root@test1 test]# git commit -m 'dev分支创建的内容' //切换到master分支，可以看到此时文件的内容还没有dev分支写入的内容，需要合并才可以显示 [root@test1 test]# git checkout master Switched to branch 'master' [root@test1 test]# git branch dev * master [root@test1 test]# cat txt master分支创建的内容 //合并分支，可以看到，合并分支后dev分支写入的内容此时已经有了 [root@test1 test]# git merge dev Updating 1f0edf7..a87487f Fast-forward txt | 1 + 1 file changed, 1 insertion(+) [root@test1 test]# cat txt master分支创建的内容 dev分支创建的内容 2.7.3git合并冲突 合并并不仅仅是简单的文件添加、移除的操作，git 也会合并修改。 //在master分支创建一个空文件test.txt，注意⚠️这里为了演示冲突，不能将文件提交至master分支 [root@test1 test]# git branch * master [root@test1 test]# touch test.txt [root@test1 test]# cat test.txt [root@test1 test]# //创建一个dev分支并切换过去，然后修改test.txt文件的内容，并讲test.txt文件的修改提交到dev分支 [root@test1 test]# git checkout -b dev Switched to a new branch 'dev' [root@test1 test]# cat test.txt [root@test1 test]# echo 'dev分支修改test.txt文件' > test.txt [root@test1 test]# cat test.txt dev分支修改test.txt文件 [root@test1 test]# git add . [root@test1 test]# git commit -m 'dev分支修改test.txt文件' [dev 3d85604] dev分支修改test.txt文件 1 file changed, 1 insertion(+) create mode 100644 test.txt //切换回master分支，此时看不到test.txt文件，因为文件已经被提交到dev分支了，但是这里为了演示冲突手动再次向test.txt文件写入内容 [root@test1 test]# git branch dev * master [root@test1 test]# ls [root@test1 test]# [root@test1 test]# echo 'master分支修改test.txt文件' > test.txt [root@test1 test]# git add . [root@test1 test]# git commit -m 'master分支修改文件' [master 3eefd57] master分支修改文件 1 file changed, 1 insertion(+) create mode 100644 test.txt //合并dev分支，此时会有冲突报错 [root@test1 test]# git merge dev CONFLICT (add/add): Merge conflict in test.txt Auto-merging test.txt Automatic merge failed; fix conflicts and then commit the result. //查看文件，有箭头的地方就是有冲突的地方，删除这部分再合并就可以了 [root@test1 test]# cat test.txt >>>>>> dev //修改后的文件如下 [root@test1 test]# cat test.txt master分支修改test.txt文件 dev分支修改test.txt文件 //git add告诉git文件冲突已解决 [root@test1 test]# git add . [root@test1 test]# git commit -m '解决合并冲突' [master 6fd4fd2] 解决合并冲突 [root@test1 test]# git merge dev Already up to date. 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "},"markdown语法总结/markdown常用语法简记.html":{"url":"markdown语法总结/markdown常用语法简记.html","title":"markdown常用语法简记","keywords":"","body":"Markdown常规语法 一、标题 # 1个#代表一级标题，mac快捷键 command+1 ## 2个#代表二级标题，mac快捷键 command+2 ### 3个#代表三级标题，mac快捷键 command+3 #### 4个#代表四级标题，mac快捷键 command+4 ##### 5个#代表五级标题，mac快捷键 command+5 ###### 6个#代表六级标题，mac快捷键 command+6 最小到六级标题，#号后边必须有一个空格 一级标题 二级标题 三级标题 四级标题 五级标题 六级标题 二、列表 有序列表 数字1. 空格 无序列表 -号空格 +号空格 *号空格 实心黑圆，有序列表相同位级，按-号然后空格 空心圆，有序列表下一级，按-号然后空格 实心黑方块，空心圆的下一季，按-号然后空格 三、代码块 多行代码块 三个```，一对 多行代码块 多行代码块 。。。 单行代码块 两个``，一对 单行代码块 四、表格 mac快捷键 command+option+T --- --- 五、图片 六、超链接 示例 百度 语法 #中括号中写链接名称，()中写网址，网址形式为http://xxx或者https://xxx mac快捷键 command+K 七、加粗 示例 加粗 语法 **加粗内容** mac快捷键 command+B 八、倾斜 示例 倾斜 语法 *倾斜* mac快捷键 command+I 九、分割线 示例 语法 ---或者+++或者*** mac快捷键 command+option+- 十、颜色（需要借助前端标签实现） 示例 颜色 语法 内容 泡泡吐肥皂o © gitbook.pptfz.top 2020 all right reserved，powered by Gitbook文件修订时间： 秃笔南波湾！！！ "}}